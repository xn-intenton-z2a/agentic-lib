Thanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideBenefits of using Amazon SQSBasic architectureDifferences between Amazon SQS, Amazon MQ,
				and Amazon SNSWhat is Amazon Simple Queue Service?Amazon Simple Queue Service (Amazon SQS) offers a secure, durable, and available hosted queue that lets you
		integrate and decouple distributed software systems and components. Amazon SQS offers common
		constructs such as dead-letter queues and
			cost allocation tags. It provides a generic web
		services API that you can access using any programming language that the AWS SDK
		supports.
		Benefits of using Amazon SQS
		
			 
			 
			 
			 
			 
			 
		
				Security – You control who can
					send messages to and receive messages from an Amazon SQS queue. You can choose to
					transmit sensitive data by protecting the contents of messages in queues by
					using default Amazon SQS managed server-side encryption (SSE), or by using custom
						SSE keys managed in
					AWS Key Management Service (AWS KMS).
			
				Durability – For the safety of your
					messages, Amazon SQS stores them on multiple servers. Standard queues support at-least-once message
						delivery, and FIFO queues support exactly-once message
						processing and high-throughput mode.
			
				Availability – Amazon SQS uses redundant infrastructure to provide
					highly-concurrent access to messages and high availability for producing and
					consuming messages. 
			
				Scalability – Amazon SQS can process each
						buffered
						request independently, scaling transparently to handle any load
					increases or spikes without any provisioning instructions.
			
				Reliability – Amazon SQS locks your messages
					during processing, so that multiple producers can send and multiple consumers
					can receive messages at the same time. 
			
				Customization – Your queues don't
					have to be exactly alike—for example, you can set a default delay on a queue. You can
					store the contents of messages larger than 256 KB using Amazon Simple Storage Service (Amazon S3) or Amazon DynamoDB, with
					Amazon SQS holding a pointer to the Amazon S3 object, or you can split a large message
					into smaller messages.
			
	 
    Basic Amazon SQS architecture
    
         
    
    This section describes the components of a distributed messaging system and explains the
        lifecycle of an Amazon SQS message.
     
        Distributed queues
        There are three main parts in a distributed messaging system: the components of
        your distributed system, your queue (distributed on Amazon SQS servers), and the messages
        in the queue.
    In the following scenario, your system has several producers (components that send messages
        to the queue) and consumers (components that receive messages from the queue). The queue (which
        holds messages A through E) redundantly stores the messages across multiple Amazon SQS servers.
    
         
            
         
             
    
     
     
        Message lifecycle
        The following scenario describes the lifecycle of an Amazon SQS message in a queue, from
            creation to deletion.
        
             
                
             
             
        
        
                 
                    
                 
                 
             A producer (Component 1) sends message A to a queue, and the
            message is distributed across the Amazon SQS servers redundantly.
        
                 
                    
                 
                 
             When a consumer (Component 2) is ready to process messages, it
            consumes messages from the queue, and message A is returned. While message A is being
            processed, it remains in the queue and isn't returned to subsequent receive requests for
            the duration of the visibility
            timeout.
        
                 
                    
                 
                 
             The consumer (Component 2) deletes message A from the queue to
            prevent the message from being received and processed again when the visibility timeout
            expires.
        NoteAmazon SQS automatically deletes messages that have been in a queue for more than the
                maximum message retention period. The default message retention period is 4 days.
                However, you can set the message retention period to a value from 60 seconds to
                1,209,600 seconds (14 days) using the SetQueueAttributes action.
     
 
		Differences between Amazon SQS, Amazon MQ,
				and Amazon SNS
		 Amazon SQS, Amazon SNS, and Amazon MQ offer highly scalable and easy-to-use
			managed messaging services, each designed for specific roles within distributed systems.
			Here's an enhanced overview of the differences between these services:
		
			Amazon SQS decouples and scales distributed software systems
			and components as a queue service. It processes messages through a single subscriber
			typically, ideal for workflows where order and loss prevention are critical. For wider
			distribution, integrating Amazon SQS with Amazon SNS enables a fanout messaging pattern, effectively pushing messages to multiple
			subscribers at once.
		
			Amazon SNS allows publishers to send messages to multiple
			subscribers through topics, which serve as communication channels. Subscribers receive
			published messages using a supported endpoint type, such as Amazon Data Firehose, Amazon SQS,
				Lambda, HTTP,
			email, mobile push notifications, and mobile text messages (SMS). This service is ideal
			for scenarios requiring immediate notifications, such as real-time user engagement or
			alarm systems. To prevent message loss when subscribers are offline, integrating Amazon SNS
			with Amazon SQS queue messages ensures consistent delivery.
		
			Amazon MQ fits best with enterprises looking to migrate
			from traditional message brokers, supporting standard messaging protocols like AMQP and
			MQTT, along with Apache ActiveMQ and
				RabbitMQ. It offers compatibility
			with legacy systems needing stable, reliable messaging without significant
			reconfiguration.
		 The following chart provides an overview of each services' resource type: 
		
					
						Resource type
						Amazon SNS
						Amazon SQS
						Amazon MQ
					
				
					
						Synchronous
						No
						No
						Yes
					
					
						Asynchronous
						Yes
						Yes
						Yes
					
					
						Queues
						No
						Yes
						Yes
					
					
						Publisher-subscriber messaging
						Yes
						No
						Yes
					
					
						Message brokers
						No
						No
						Yes
					
				
		Both Amazon SQS and Amazon SNS are recommended for new applications that can benefit from nearly
			unlimited scalability and simple APIs. They generally offer more cost-effective
			solutions for high-volume applications with their pay-as-you-go pricing. We recommend
			Amazon MQ for migrating applications from existing message brokers that rely on
			compatibility with APIs such as JMS or protocols such as Advanced Message Queuing
			Protocol (AMQP), MQTT, OpenWire, and Simple Text Oriented Message Protocol
			(STOMP).
	Document ConventionsGetting startedDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideBenefits of using Amazon SQSBasic architectureDifferences between Amazon SQS, Amazon MQ,
				and Amazon SNSWhat is Amazon Simple Queue Service?Amazon Simple Queue Service (Amazon SQS) offers a secure, durable, and available hosted queue that lets you
		integrate and decouple distributed software systems and components. Amazon SQS offers common
		constructs such as dead-letter queues and
			cost allocation tags. It provides a generic web
		services API that you can access using any programming language that the AWS SDK
		supports.
		Benefits of using Amazon SQS
		
			 
			 
			 
			 
			 
			 
		
				Security – You control who can
					send messages to and receive messages from an Amazon SQS queue. You can choose to
					transmit sensitive data by protecting the contents of messages in queues by
					using default Amazon SQS managed server-side encryption (SSE), or by using custom
						SSE keys managed in
					AWS Key Management Service (AWS KMS).
			
				Durability – For the safety of your
					messages, Amazon SQS stores them on multiple servers. Standard queues support at-least-once message
						delivery, and FIFO queues support exactly-once message
						processing and high-throughput mode.
			
				Availability – Amazon SQS uses redundant infrastructure to provide
					highly-concurrent access to messages and high availability for producing and
					consuming messages. 
			
				Scalability – Amazon SQS can process each
						buffered
						request independently, scaling transparently to handle any load
					increases or spikes without any provisioning instructions.
			
				Reliability – Amazon SQS locks your messages
					during processing, so that multiple producers can send and multiple consumers
					can receive messages at the same time. 
			
				Customization – Your queues don't
					have to be exactly alike—for example, you can set a default delay on a queue. You can
					store the contents of messages larger than 256 KB using Amazon Simple Storage Service (Amazon S3) or Amazon DynamoDB, with
					Amazon SQS holding a pointer to the Amazon S3 object, or you can split a large message
					into smaller messages.
			
	 
    Basic Amazon SQS architecture
    
         
    
    This section describes the components of a distributed messaging system and explains the
        lifecycle of an Amazon SQS message.
     
        Distributed queues
        There are three main parts in a distributed messaging system: the components of
        your distributed system, your queue (distributed on Amazon SQS servers), and the messages
        in the queue.
    In the following scenario, your system has several producers (components that send messages
        to the queue) and consumers (components that receive messages from the queue). The queue (which
        holds messages A through E) redundantly stores the messages across multiple Amazon SQS servers.
    
         
            
         
             
    
     
     
        Message lifecycle
        The following scenario describes the lifecycle of an Amazon SQS message in a queue, from
            creation to deletion.
        
             
                
             
             
        
        
                 
                    
                 
                 
             A producer (Component 1) sends message A to a queue, and the
            message is distributed across the Amazon SQS servers redundantly.
        
                 
                    
                 
                 
             When a consumer (Component 2) is ready to process messages, it
            consumes messages from the queue, and message A is returned. While message A is being
            processed, it remains in the queue and isn't returned to subsequent receive requests for
            the duration of the visibility
            timeout.
        
                 
                    
                 
                 
             The consumer (Component 2) deletes message A from the queue to
            prevent the message from being received and processed again when the visibility timeout
            expires.
        NoteAmazon SQS automatically deletes messages that have been in a queue for more than the
                maximum message retention period. The default message retention period is 4 days.
                However, you can set the message retention period to a value from 60 seconds to
                1,209,600 seconds (14 days) using the SetQueueAttributes action.
     
 
		Differences between Amazon SQS, Amazon MQ,
				and Amazon SNS
		 Amazon SQS, Amazon SNS, and Amazon MQ offer highly scalable and easy-to-use
			managed messaging services, each designed for specific roles within distributed systems.
			Here's an enhanced overview of the differences between these services:
		
			Amazon SQS decouples and scales distributed software systems
			and components as a queue service. It processes messages through a single subscriber
			typically, ideal for workflows where order and loss prevention are critical. For wider
			distribution, integrating Amazon SQS with Amazon SNS enables a fanout messaging pattern, effectively pushing messages to multiple
			subscribers at once.
		
			Amazon SNS allows publishers to send messages to multiple
			subscribers through topics, which serve as communication channels. Subscribers receive
			published messages using a supported endpoint type, such as Amazon Data Firehose, Amazon SQS,
				Lambda, HTTP,
			email, mobile push notifications, and mobile text messages (SMS). This service is ideal
			for scenarios requiring immediate notifications, such as real-time user engagement or
			alarm systems. To prevent message loss when subscribers are offline, integrating Amazon SNS
			with Amazon SQS queue messages ensures consistent delivery.
		
			Amazon MQ fits best with enterprises looking to migrate
			from traditional message brokers, supporting standard messaging protocols like AMQP and
			MQTT, along with Apache ActiveMQ and
				RabbitMQ. It offers compatibility
			with legacy systems needing stable, reliable messaging without significant
			reconfiguration.
		 The following chart provides an overview of each services' resource type: 
		
					
						Resource type
						Amazon SNS
						Amazon SQS
						Amazon MQ
					
				
					
						Synchronous
						No
						No
						Yes
					
					
						Asynchronous
						Yes
						Yes
						Yes
					
					
						Queues
						No
						Yes
						Yes
					
					
						Publisher-subscriber messaging
						Yes
						No
						Yes
					
					
						Message brokers
						No
						No
						Yes
					
				
		Both Amazon SQS and Amazon SNS are recommended for new applications that can benefit from nearly
			unlimited scalability and simple APIs. They generally offer more cost-effective
			solutions for high-volume applications with their pay-as-you-go pricing. We recommend
			Amazon MQ for migrating applications from existing message brokers that rely on
			compatibility with APIs such as JMS or protocols such as Advanced Message Queuing
			Protocol (AMQP), MQTT, OpenWire, and Simple Text Oriented Message Protocol
			(STOMP).
	Document ConventionsGetting startedDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideBenefits of using Amazon SQSBasic architectureDifferences between Amazon SQS, Amazon MQ,
				and Amazon SNSWhat is Amazon Simple Queue Service?Amazon Simple Queue Service (Amazon SQS) offers a secure, durable, and available hosted queue that lets you
		integrate and decouple distributed software systems and components. Amazon SQS offers common
		constructs such as dead-letter queues and
			cost allocation tags. It provides a generic web
		services API that you can access using any programming language that the AWS SDK
		supports.
		Benefits of using Amazon SQS
		
			 
			 
			 
			 
			 
			 
		
				Security – You control who can
					send messages to and receive messages from an Amazon SQS queue. You can choose to
					transmit sensitive data by protecting the contents of messages in queues by
					using default Amazon SQS managed server-side encryption (SSE), or by using custom
						SSE keys managed in
					AWS Key Management Service (AWS KMS).
			
				Durability – For the safety of your
					messages, Amazon SQS stores them on multiple servers. Standard queues support at-least-once message
						delivery, and FIFO queues support exactly-once message
						processing and high-throughput mode.
			
				Availability – Amazon SQS uses redundant infrastructure to provide
					highly-concurrent access to messages and high availability for producing and
					consuming messages. 
			
				Scalability – Amazon SQS can process each
						buffered
						request independently, scaling transparently to handle any load
					increases or spikes without any provisioning instructions.
			
				Reliability – Amazon SQS locks your messages
					during processing, so that multiple producers can send and multiple consumers
					can receive messages at the same time. 
			
				Customization – Your queues don't
					have to be exactly alike—for example, you can set a default delay on a queue. You can
					store the contents of messages larger than 256 KB using Amazon Simple Storage Service (Amazon S3) or Amazon DynamoDB, with
					Amazon SQS holding a pointer to the Amazon S3 object, or you can split a large message
					into smaller messages.
			
	 
    Basic Amazon SQS architecture
    
         
    
    This section describes the components of a distributed messaging system and explains the
        lifecycle of an Amazon SQS message.
     
        Distributed queues
        There are three main parts in a distributed messaging system: the components of
        your distributed system, your queue (distributed on Amazon SQS servers), and the messages
        in the queue.
    In the following scenario, your system has several producers (components that send messages
        to the queue) and consumers (components that receive messages from the queue). The queue (which
        holds messages A through E) redundantly stores the messages across multiple Amazon SQS servers.
    
         
            
         
             
    
     
     
        Message lifecycle
        The following scenario describes the lifecycle of an Amazon SQS message in a queue, from
            creation to deletion.
        
             
                
             
             
        
        
                 
                    
                 
                 
             A producer (Component 1) sends message A to a queue, and the
            message is distributed across the Amazon SQS servers redundantly.
        
                 
                    
                 
                 
             When a consumer (Component 2) is ready to process messages, it
            consumes messages from the queue, and message A is returned. While message A is being
            processed, it remains in the queue and isn't returned to subsequent receive requests for
            the duration of the visibility
            timeout.
        
                 
                    
                 
                 
             The consumer (Component 2) deletes message A from the queue to
            prevent the message from being received and processed again when the visibility timeout
            expires.
        NoteAmazon SQS automatically deletes messages that have been in a queue for more than the
                maximum message retention period. The default message retention period is 4 days.
                However, you can set the message retention period to a value from 60 seconds to
                1,209,600 seconds (14 days) using the SetQueueAttributes action.
     
 
		Differences between Amazon SQS, Amazon MQ,
				and Amazon SNS
		 Amazon SQS, Amazon SNS, and Amazon MQ offer highly scalable and easy-to-use
			managed messaging services, each designed for specific roles within distributed systems.
			Here's an enhanced overview of the differences between these services:
		
			Amazon SQS decouples and scales distributed software systems
			and components as a queue service. It processes messages through a single subscriber
			typically, ideal for workflows where order and loss prevention are critical. For wider
			distribution, integrating Amazon SQS with Amazon SNS enables a fanout messaging pattern, effectively pushing messages to multiple
			subscribers at once.
		
			Amazon SNS allows publishers to send messages to multiple
			subscribers through topics, which serve as communication channels. Subscribers receive
			published messages using a supported endpoint type, such as Amazon Data Firehose, Amazon SQS,
				Lambda, HTTP,
			email, mobile push notifications, and mobile text messages (SMS). This service is ideal
			for scenarios requiring immediate notifications, such as real-time user engagement or
			alarm systems. To prevent message loss when subscribers are offline, integrating Amazon SNS
			with Amazon SQS queue messages ensures consistent delivery.
		
			Amazon MQ fits best with enterprises looking to migrate
			from traditional message brokers, supporting standard messaging protocols like AMQP and
			MQTT, along with Apache ActiveMQ and
				RabbitMQ. It offers compatibility
			with legacy systems needing stable, reliable messaging without significant
			reconfiguration.
		 The following chart provides an overview of each services' resource type: 
		
					
						Resource type
						Amazon SNS
						Amazon SQS
						Amazon MQ
					
				
					
						Synchronous
						No
						No
						Yes
					
					
						Asynchronous
						Yes
						Yes
						Yes
					
					
						Queues
						No
						Yes
						Yes
					
					
						Publisher-subscriber messaging
						Yes
						No
						Yes
					
					
						Message brokers
						No
						No
						Yes
					
				
		Both Amazon SQS and Amazon SNS are recommended for new applications that can benefit from nearly
			unlimited scalability and simple APIs. They generally offer more cost-effective
			solutions for high-volume applications with their pay-as-you-go pricing. We recommend
			Amazon MQ for migrating applications from existing message brokers that rely on
			compatibility with APIs such as JMS or protocols such as Advanced Message Queuing
			Protocol (AMQP), MQTT, OpenWire, and Simple Text Oriented Message Protocol
			(STOMP).
	Document ConventionsGetting startedDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideBenefits of using Amazon SQSBasic architectureDifferences between Amazon SQS, Amazon MQ,
				and Amazon SNSWhat is Amazon Simple Queue Service?Amazon Simple Queue Service (Amazon SQS) offers a secure, durable, and available hosted queue that lets you
		integrate and decouple distributed software systems and components. Amazon SQS offers common
		constructs such as dead-letter queues and
			cost allocation tags. It provides a generic web
		services API that you can access using any programming language that the AWS SDK
		supports.
		Benefits of using Amazon SQS
		
			 
			 
			 
			 
			 
			 
		
				Security – You control who can
					send messages to and receive messages from an Amazon SQS queue. You can choose to
					transmit sensitive data by protecting the contents of messages in queues by
					using default Amazon SQS managed server-side encryption (SSE), or by using custom
						SSE keys managed in
					AWS Key Management Service (AWS KMS).
			
				Durability – For the safety of your
					messages, Amazon SQS stores them on multiple servers. Standard queues support at-least-once message
						delivery, and FIFO queues support exactly-once message
						processing and high-throughput mode.
			
				Availability – Amazon SQS uses redundant infrastructure to provide
					highly-concurrent access to messages and high availability for producing and
					consuming messages. 
			
				Scalability – Amazon SQS can process each
						buffered
						request independently, scaling transparently to handle any load
					increases or spikes without any provisioning instructions.
			
				Reliability – Amazon SQS locks your messages
					during processing, so that multiple producers can send and multiple consumers
					can receive messages at the same time. 
			
				Customization – Your queues don't
					have to be exactly alike—for example, you can set a default delay on a queue. You can
					store the contents of messages larger than 256 KB using Amazon Simple Storage Service (Amazon S3) or Amazon DynamoDB, with
					Amazon SQS holding a pointer to the Amazon S3 object, or you can split a large message
					into smaller messages.
			
	 
    Basic Amazon SQS architecture
    
         
    
    This section describes the components of a distributed messaging system and explains the
        lifecycle of an Amazon SQS message.
     
        Distributed queues
        There are three main parts in a distributed messaging system: the components of
        your distributed system, your queue (distributed on Amazon SQS servers), and the messages
        in the queue.
    In the following scenario, your system has several producers (components that send messages
        to the queue) and consumers (components that receive messages from the queue). The queue (which
        holds messages A through E) redundantly stores the messages across multiple Amazon SQS servers.
    
         
            
         
             
    
     
     
        Message lifecycle
        The following scenario describes the lifecycle of an Amazon SQS message in a queue, from
            creation to deletion.
        
             
                
             
             
        
        
                 
                    
                 
                 
             A producer (Component 1) sends message A to a queue, and the
            message is distributed across the Amazon SQS servers redundantly.
        
                 
                    
                 
                 
             When a consumer (Component 2) is ready to process messages, it
            consumes messages from the queue, and message A is returned. While message A is being
            processed, it remains in the queue and isn't returned to subsequent receive requests for
            the duration of the visibility
            timeout.
        
                 
                    
                 
                 
             The consumer (Component 2) deletes message A from the queue to
            prevent the message from being received and processed again when the visibility timeout
            expires.
        NoteAmazon SQS automatically deletes messages that have been in a queue for more than the
                maximum message retention period. The default message retention period is 4 days.
                However, you can set the message retention period to a value from 60 seconds to
                1,209,600 seconds (14 days) using the SetQueueAttributes action.
     
 
		Differences between Amazon SQS, Amazon MQ,
				and Amazon SNS
		 Amazon SQS, Amazon SNS, and Amazon MQ offer highly scalable and easy-to-use
			managed messaging services, each designed for specific roles within distributed systems.
			Here's an enhanced overview of the differences between these services:
		
			Amazon SQS decouples and scales distributed software systems
			and components as a queue service. It processes messages through a single subscriber
			typically, ideal for workflows where order and loss prevention are critical. For wider
			distribution, integrating Amazon SQS with Amazon SNS enables a fanout messaging pattern, effectively pushing messages to multiple
			subscribers at once.
		
			Amazon SNS allows publishers to send messages to multiple
			subscribers through topics, which serve as communication channels. Subscribers receive
			published messages using a supported endpoint type, such as Amazon Data Firehose, Amazon SQS,
				Lambda, HTTP,
			email, mobile push notifications, and mobile text messages (SMS). This service is ideal
			for scenarios requiring immediate notifications, such as real-time user engagement or
			alarm systems. To prevent message loss when subscribers are offline, integrating Amazon SNS
			with Amazon SQS queue messages ensures consistent delivery.
		
			Amazon MQ fits best with enterprises looking to migrate
			from traditional message brokers, supporting standard messaging protocols like AMQP and
			MQTT, along with Apache ActiveMQ and
				RabbitMQ. It offers compatibility
			with legacy systems needing stable, reliable messaging without significant
			reconfiguration.
		 The following chart provides an overview of each services' resource type: 
		
					
						Resource type
						Amazon SNS
						Amazon SQS
						Amazon MQ
					
				
					
						Synchronous
						No
						No
						Yes
					
					
						Asynchronous
						Yes
						Yes
						Yes
					
					
						Queues
						No
						Yes
						Yes
					
					
						Publisher-subscriber messaging
						Yes
						No
						Yes
					
					
						Message brokers
						No
						No
						Yes
					
				
		Both Amazon SQS and Amazon SNS are recommended for new applications that can benefit from nearly
			unlimited scalability and simple APIs. They generally offer more cost-effective
			solutions for high-volume applications with their pay-as-you-go pricing. We recommend
			Amazon MQ for migrating applications from existing message brokers that rely on
			compatibility with APIs such as JMS or protocols such as Advanced Message Queuing
			Protocol (AMQP), MQTT, OpenWire, and Simple Text Oriented Message Protocol
			(STOMP).
	Document ConventionsGetting startedDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUsing policies for dead-letter
                queuesUnderstanding message
                retention periods for dead-letter queuesUsing dead-letter queues in Amazon SQS Amazon SQS supports dead-letter queues (DLQs), which source queues can target for messages that
        are not processed successfully. DLQs are useful for debugging your application because you
        can isolate unconsumed messages to determine why processing did not succeed. For optimal
        performance, it is a best practice to keep the source queue and DLQ within the same
        AWS account and Region. Once messages are in a dead-letter queue, you can:
         
         
         
         
    
            Examine logs for exceptions that might have caused messages to be moved to a
                dead-letter queue.
        
            Analyze the contents of messages moved to the dead-letter queue to diagnose
                application issues.
        
            Determine whether you have given your consumer sufficient time to process
                messages.
        
            Move messages out of the dead-letter queue using dead-letter queue
                redrive.
        You must first create a new queue before configuring it as a dead-letter queue. For
        information about configuring a dead-letter queue using the Amazon SQS console, see Configure a dead-letter queue using the
			Amazon SQS console. For help with dead-letter queues,
        such as how to configure an alarm for any messages moved to a dead-letter queue, see Creating alarms for dead-letter
            queues using Amazon CloudWatch.NoteDon't use a dead-letter queue with a FIFO queue if you don't want to break the exact
            order of messages or operations. For example, don't use a dead-letter queue with
            instructions in an Edit Decision List (EDL) for a video editing suite, where changing
            the order of edits changes the context of subsequent edits.
        Using policies for dead-letter
                queues
        Use a redrive policy to specify the
                maxReceiveCount. The maxReceiveCount is the number of
            times a consumer can receive a message from a source queue before it is moved to a
            dead-letter queue. For example, if the maxReceiveCount is set to a low
            value such as 1, one failure to receive a message would cause the message to move to the
            dead-letter queue. To ensure that your system is resilient against errors, set the
                maxReceiveCount high enough to allow for sufficient retries. 
        The redrive allow policy specifies which source
            queues can access the dead-letter queue. You can choose whether to allow all source
            queues, allow specific source queues, or deny all source queues use of the dead-letter
            queue. The default allows all source queues to use the dead-letter queue. If you choose
            to allow specific queues using the byQueue option, you can specify up to 10
            source queues using the source queue Amazon Resource Name (ARN). If you specify
                denyAll, the queue cannot be used as a dead-letter queue. 
     
        Understanding message
                retention periods for dead-letter queues
        For standard queues, the expiration of a message is always based on its original
            enqueue timestamp. When a message is moved to a dead-letter queue, the enqueue timestamp
            is unchanged. The ApproximateAgeOfOldestMessage metric indicates when the
            message moved to the dead-letter queue, not when the message was originally sent. For
            example, assume that a message spends 1 day in the original queue before it's moved to a
            dead-letter queue. If the dead-letter queue's retention period is 4 days, the message is
            deleted from the dead-letter queue after 3 days and the
                ApproximateAgeOfOldestMessage is 3 days. Thus, it is a best practice to
            always set the retention period of a dead-letter queue to be longer than the retention
            period of the original queue.
        For FIFO queues, the enqueue timestamp resets when the message is moved to a
            dead-letter queue. The ApproximateAgeOfOldestMessage metric indicates when
            the message moved to the dead-letter queue. In the same example above, the message is
            deleted from the dead-letter queue after four days and the
                ApproximateAgeOfOldestMessage is four days. 
    Document ConventionsFeatures and capabilitiesConfiguring a dead-letter queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS cost allocation tagsTo organize and identify your Amazon SQS queues for cost allocation, you can add metadata
            tags that identify a queue's purpose, owner, or environment. This
        is especially useful when you have many queues. To configure tags using the Amazon SQS console,
        see Configuring cost allocation tags for a queue using
			the Amazon SQS console
         
            
         
         
    You can use cost allocation tags to organize your AWS bill to reflect your own cost
        structure. To do this, sign up to get your AWS account bill to include tag keys and
        values. For more information, see Setting Up a Monthly
            Cost Allocation Report in the AWS Billing User Guide.Each tag consists of a key-value pair that you define. For example, you can easily
        identify your production and testing queues if you
        tag your queues as follows:
                
                    Queue
                    Key
                    Value
                
            
                
                    MyQueueA
                    QueueType
                    Production
                
                
                    MyQueueB
                    QueueType
                    Testing
                
            NoteWhen you use queue tags, keep the following guidelines in mind:
             
             
             
             
             
         We don't recommend adding more than 50 tags to a queue. Tagging supports Unicode characters in UTF-8. 
                Tags don't have any semantic meaning. Amazon SQS interprets tags as character
                    strings.
            
                Tags are case-sensitive.
            
                A new tag with a key identical to that of an existing tag overwrites the
                    existing tag.
            
                Tagging actions are limited to 30 TPS per AWS account. If your application requires a higher throughput, submit a request.
            For a full list of tag restrictions, see Amazon SQS standard queue quotas.Document ConventionsList queue paginationShort and long pollingDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAudienceAuthenticating with identitiesManaging access using policiesIdentity and access management in
			Amazon SQSAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely control access
      to AWS resources. IAM administrators control who can be authenticated (signed in) and authorized
      (have permissions) to use Amazon SQS resources. IAM is an AWS service that you can
      use with no additional charge.
      Audience 
      
   
      How you use AWS Identity and Access Management (IAM) differs, depending on the work that you do in Amazon SQS.
      Service user – If you use the Amazon SQS service to do your job, then your administrator provides you
         with the credentials and permissions that you need. As you use more Amazon SQS features to do your work, you might need additional permissions.
         Understanding how access is managed can help you request the right permissions from your administrator. If you cannot access a feature in
         Amazon SQS, see Troubleshooting Amazon Simple Queue Service identity and
				access.
      Service administrator – If you're in charge of Amazon SQS resources at your company, you probably have
         full access to Amazon SQS. It's your job to determine which Amazon SQS features and resources your service users should access. You must then
         submit requests to your IAM administrator to change the permissions of your service users. Review the information on this page to understand the
         basic concepts of IAM. To learn more about how your company can use IAM with Amazon SQS, see How Amazon Simple Queue Service works with
				IAM.
      IAM administrator – If you're an IAM administrator, you might want to learn details about how you can
         write policies to manage access to Amazon SQS. To view example Amazon SQS identity-based policies that you can use in IAM, see Policy best
						practices.
   
    
      Authenticating with identities 
      
   
Authentication is how you sign in to AWS using your identity credentials. You must be
authenticated (signed in to AWS) as the AWS account root user, as an
IAM user, or by assuming an IAM role.

You can sign in to AWS as a federated identity by using credentials provided through an identity source.
AWS IAM Identity Center (IAM Identity Center) users, your company's single sign-on authentication, and your Google or Facebook
credentials are examples of federated identities. When you sign in as a federated identity, your administrator previously set up identity federation using IAM roles. When you access AWS by using federation, you are indirectly assuming a role.

Depending on the type of user you are, you can sign in to the AWS Management Console or the AWS access
portal. For more information about signing in to AWS, see How to sign in to your AWS account
in the AWS Sign-In User Guide.

If you access AWS programmatically, AWS provides a software development kit (SDK) and a command line 
interface (CLI) to cryptographically sign your requests by using your credentials. If you don't use AWS tools, 
you must sign requests yourself. For more information about using the recommended method to sign requests yourself, see 
AWS Signature Version 4 for API requests 
in the IAM User Guide.

Regardless of the authentication method that you use, you might be required to provide
additional security information. For example, AWS recommends that you use multi-factor
authentication (MFA) to increase the security of your account. To learn more, see Multi-factor authentication in the
AWS IAM Identity Center User Guide and AWS Multi-factor authentication in IAM in the IAM User Guide.


   
       
         AWS account root user
         

 When you create an AWS account, you begin with one sign-in identity that has complete access to all AWS services
 and resources in the account. This identity is called the AWS account root user and is accessed by
 signing in with the email address and password that you used to create the account. We 
 strongly recommend that you don't use the root user for your everyday tasks. Safeguard your root user credentials and use them to
 perform the tasks that only the root user can perform. For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials in the IAM User Guide.
 
       
       
         Federated identity 
         

As a best practice, require human users, including users that require administrator access, to use federation with an identity provider to access AWS services by using temporary credentials.

A federated identity is a user from your enterprise user directory, a web identity provider, the AWS Directory Service, the Identity Center directory, or any user that
accesses AWS services by using credentials provided through an identity source. When federated identities access AWS accounts, they assume roles, and the roles provide temporary credentials.

For centralized access management, we recommend that you use AWS IAM Identity Center. You can create users and groups in IAM Identity Center, or you can connect and synchronize 
to a set of users and groups in your own identity source for use across all your AWS accounts and applications. For information 
about IAM Identity Center, see What is IAM Identity Center? in the AWS IAM Identity Center User Guide.
 
       
      
         IAM users and groups 
         
   
         An IAM user is an identity within your AWS account that has specific permissions for a single person or application. Where possible, we recommend relying on temporary credentials instead of creating IAM users who have long-term credentials such as passwords and access keys. However, if you have specific use cases that require long-term credentials with IAM users, we recommend that you rotate access keys. For more information, see Rotate access keys regularly for use cases that require long-term credentials in the IAM User Guide.
         
         An IAM group is an identity that specifies a collection of IAM users.
            You can't sign in as a group. You can use groups to specify permissions for multiple users at a time. Groups make permissions easier to manage for
            large sets of users. For example, you could have a group named IAMAdmins and give that group permissions to administer IAM
            resources.
         Users are different from roles. A user is uniquely associated with one person or application, but a role is intended to be assumable by anyone
            who needs it. Users have permanent long-term credentials, but roles provide temporary credentials. To learn more, see Use cases for IAM users in the
               IAM User Guide.
   
       
      
       
         IAM roles 
         
   
         An IAM role is an identity within your AWS account that
            has specific permissions. It is similar to an IAM user, but is not associated with a specific person. To temporarily assume an IAM role in
            the AWS Management Console, you can switch from a user to an IAM role (console). You can assume a role by calling an AWS CLI
            or AWS API operation or by using a custom URL. For more information about methods for using roles, see Methods to assume a role in the IAM User Guide.
         IAM roles with temporary credentials are useful in the following situations:
         
            
             
             
             
             
             
         
               Federated user access – 

To assign permissions to a federated identity, you create a role and define permissions for the role. When a federated identity authenticates, the identity is associated with the role and is granted the permissions that are defined by the role. For information about roles for federation, see 
Create a role for a third-party identity provider (federation) in the IAM User Guide.

If you use IAM Identity Center, you configure a permission set. To control what your identities can access after they authenticate, IAM Identity Center correlates the permission set to a role in IAM. 
For information about permissions sets, see 
Permission sets in the AWS IAM Identity Center User Guide.

            
               Temporary IAM user permissions – An IAM user or role can assume an IAM role to temporarily take on
            different permissions for a specific task.
            
               Cross-account access – You can use an
                  IAM role to allow someone (a trusted principal) in a different account to access
                  resources in your account. Roles are the primary way to grant cross-account
                  access. However, with some AWS services, you can attach a policy directly to a
                  resource (instead of using a role as a proxy). To learn the difference between
                  roles and resource-based policies for cross-account access, see Cross account resource access in IAM in the
                     IAM User Guide.
            
               Cross-service access –

      Some AWS services use features in other AWS services. For example, when you make a call in a service, 
      it's common for that service to run applications in Amazon EC2 or store objects in Amazon S3. A service might do this 
      using the calling principal's permissions, using a service role, or using a service-linked role.
  
                  
                      
                      
                      
                  
                        Forward access sessions (FAS) –

      When you use an IAM user or role to perform actions in AWS, you are considered a principal. When you use some services, you might perform an action that then initiates
      another action in a different service. FAS uses the permissions of the principal calling an AWS service, combined with the requesting AWS service to make requests to downstream services.
      FAS requests are only made when a service receives a request that requires interactions with other AWS services or resources to complete. In this case, you must have permissions to
      perform both actions. For policy details
      when making FAS requests, see Forward access sessions.
 
                     
                        Service role –

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
                     
                        Service-linked role –

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
                     
            
               Applications running on Amazon EC2 –

      You can use an IAM role to manage temporary credentials for applications that are running on an EC2 instance and making AWS CLI or AWS API requests. 
      This is preferable to storing access keys within the EC2 instance. To assign an AWS role to an EC2 instance and make it 
      available to all of its applications, you create an instance profile that is attached to the 
      instance. An instance profile contains the role and enables programs that are running on the EC2 instance to
      get temporary credentials. For more information, see Use an IAM role to grant permissions to applications running on Amazon EC2 instances in the 
      IAM User Guide.
 
            
   
       
    
      Managing access using policies 
      
   
 You control access in AWS by creating policies and attaching them to AWS identities or resources. A policy is an object in AWS that,
 when associated with an identity or resource, defines their permissions. AWS evaluates these policies when a principal (user, root user, or role session) makes a request. 
 Permissions in the policies determine whether the request is allowed or denied. 
 Most policies are stored in AWS as JSON documents. For more information about the structure and contents 
 of JSON policy documents, see Overview of JSON policies in the 
 IAM User Guide.

 
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  

By default, users and roles have no permissions. To grant users permission to perform actions on the resources that they need, an 
IAM administrator can create IAM policies. The administrator can then add the IAM policies to roles, and users can assume the roles.
 IAM policies define permissions for an action regardless of the method that you use to perform the operation. For example, suppose that you have a
 policy that allows the iam:GetRole action. A user with that policy can get role information from the AWS Management Console, the AWS CLI, or the AWS
 API.
   
       
         Identity-based
               policies 
         
   
         
   
         Identity-based policies are JSON permissions policy documents that you can attach to an identity, such as an IAM user, group of users, or role. These
            policies control what actions users and roles can perform, on which resources, and under what conditions. To learn how to create an identity-based
            policy, see Define custom IAM permissions with customer managed policies in the
            IAM User Guide.
  
         Identity-based policies can be further categorized as inline policies or managed
               policies. Inline policies are embedded directly into a single user, group, or role. Managed policies are standalone policies that you
            can attach to multiple users, groups, and roles in your AWS account. Managed policies include AWS managed policies and customer managed
            policies. To learn how to choose between a managed policy or an inline policy, see Choose between managed policies and inline policies in the IAM User Guide.
   
       
       
         Resource-based
               policies 
         
   
   
   
         Resource-based policies are JSON policy documents that you attach to a resource. Examples of resource-based policies are 
         IAM role trust policies and Amazon S3 bucket policies. In services that support resource-based policies, service 
         administrators can use them to control access to a specific resource. For the resource where the policy is attached, the policy defines what actions
            a specified principal can perform on that resource and under what conditions. You must specify a principal in a resource-based policy. Principals 
            can include accounts, users, roles, federated users, or AWS services.
  
   Resource-based policies are inline policies that are located in that service. You can't use AWS managed policies from IAM in a 
   resource-based policy.
   
       
       
         Access control lists (ACLs) 
         
   
      
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
      Amazon S3, AWS WAF, and Amazon VPC
            are examples of services that support ACLs. To learn more about ACLs, see Access control list (ACL)
               overview in the Amazon Simple Storage Service Developer Guide.
   
       
       
         Other policy types 
         
   
         AWS supports additional, less-common policy types. These policy types can set the maximum permissions granted to you by the more common policy
            types. 
         
             
             
             
             
         
               Permissions boundaries – A permissions
                  boundary is an advanced feature in which you set the maximum permissions that an
                  identity-based policy can grant to an IAM entity (IAM user or role). You can
                  set a permissions boundary for an entity. The resulting permissions are the
                  intersection of an entity's identity-based policies and its permissions boundaries.
                  Resource-based policies that specify the user or role in the
                     Principal field are not limited by the permissions boundary. An
                  explicit deny in any of these policies overrides the allow. For more information
                  about permissions boundaries, see Permissions boundaries for
                     IAM entities in the IAM User Guide.
            
               Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions for
                  an organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a service for grouping and centrally managing multiple AWS accounts that your business owns. If you enable all features in an organization, then you can apply service control policies (SCPs) to any or all of
                  your accounts. The SCP limits permissions for entities in member accounts, including each AWS account root user. For more information about Organizations and
                  SCPs, see Service control policies in the AWS Organizations User Guide.
            
            Resource control policies (RCPs) – RCPs
                are JSON policies that you can use to set the maximum available permissions for
                resources in your accounts without updating the IAM policies attached to each
                resource that you own. The RCP limits permissions for resources in member accounts
                and can impact the effective permissions for identities, including the AWS account root user,
                regardless of whether they belong to your organization. For more information about
                Organizations and RCPs, including a list of AWS services that support RCPs, see Resource
                    control policies (RCPs) in the AWS Organizations User Guide.
            
               Session policies – Session policies are
                  advanced policies that you pass as a parameter when you programmatically create a
                  temporary session for a role or federated user. The resulting session's
                  permissions are the intersection of the user or role's identity-based policies and
                  the session policies. Permissions can also come from a resource-based policy. An
                  explicit deny in any of these policies overrides the allow. For more information,
                  see Session
                     policies in the IAM User Guide. 
            
   
       
       
         Multiple policy
               types 
         
   
         When multiple types of policies apply to a request, the resulting permissions are more complicated to understand. To learn how AWS determines
            whether to allow a request when multiple policy types are involved, see Policy
               evaluation logic in the IAM User Guide.
   
       
   Document ConventionsInternetwork traffic privacyOverviewDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideEncryption scopeKey termsEncryption at rest in Amazon SQSServer-side encryption (SSE) lets you transmit sensitive data in encrypted
				queues. SSE protects the contents of messages in queues using SQS-managed
				encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS). For
				information about managing SSE using the AWS Management Console, see the following:
				 
				 
			
					Configuring SSE-SQS for a
							queue (console)
				
					Configuring SSE-KMS for a
							queue (console)
				 For information about managing SSE using the AWS SDK for Java (and the CreateQueue,
						SetQueueAttributes, and GetQueueAttributes actions), see the following examples:
				 
				 
			
					Using server-side encryption with Amazon SQS queues
				
					Configuring KMS
							permissions for AWS services
				
				 
					
				 
			SSE encrypts messages as soon as Amazon SQS receives them. The messages are stored in
				encrypted form and Amazon SQS decrypts messages only when they are sent to an authorized
				consumer.ImportantAll requests to queues with SSE enabled must use HTTPS and Signature Version
					4.An encrypted queue
    that uses the default key (AWS managed KMS key for Amazon SQS) cannot invoke a Lambda function in a different AWS account.Some features of AWS services that can send notifications to Amazon SQS using the
					AWS Security Token Service AssumeRole action are compatible with SSE but work
						only with standard queues:
					 
					 
				
						Auto Scaling Lifecycle
								Hooks
					
						AWS Lambda Dead-Letter
								Queues
					For information about compatibility of other services with encrypted queues,
					see Configure KMS permissions
							for AWS services and your service
					documentation.AWS KMS combines secure, highly available hardware and software to provide a key
				management system scaled for the cloud. When you use Amazon SQS with AWS KMS, the data keys that encrypt your message data are
				also encrypted and stored with the data they protect.The following are benefits of using AWS KMS:
				 
				 
				 
			
					You can create and manage AWS KMS keys yourself.
				
					You can also use the AWS managed KMS key for Amazon SQS, which is unique
						for each account and region.
				
					The AWS KMS security standards can help you meet encryption-related
						compliance requirements.
				For more information, see What is
					AWS Key Management Service? in the AWS Key Management Service Developer Guide.
				Encryption scope
				SSE encrypts the body of a message in an Amazon SQS queue.
				SSE doesn't encrypt the following:
				
					 
					 
					 
				
						Queue metadata (queue name and attributes)
					
						Message metadata (message ID, timestamp, and attributes)
					
						Per-queue metrics
					
				Encrypting a message makes its contents unavailable to unauthorized or
					anonymous users. With SSE enabled, anonymous SendMessage and
						ReceiveMessage requests to the encrypted queue will be
					rejected. Amazon SQS security best practices recommends against using anonymous
					requests. If you wish to send anonymous requests to an Amazon SQS queue, make sure
					you disable SSE. This doesn't affect the normal functioning of Amazon SQS:
				
					 
					 
				
						A message is encrypted only if it is sent after the encryption of a
							queue is enabled. Amazon SQS doesn't encrypt backlogged messages.
					
						Any encrypted message remains encrypted even if the encryption of its
							queue is disabled.
					
				Moving a message to a dead-letter
						queue doesn't affect its encryption:
				
					 
					 
				
						When Amazon SQS moves a message from an encrypted source queue to an
							unencrypted dead-letter queue, the message remains encrypted.
					
						When Amazon SQS moves a message from an unencrypted source queue to an
							encrypted dead-letter queue, the message remains unencrypted.
					
			 
				Key terms
				The following key terms can help you better understand the functionality of
					SSE. For detailed descriptions, see the Amazon Simple Queue Service API Reference.
				
					 
					 
					 
					 
				
						Data key
						
							The key (DEK) responsible for encrypting the contents of Amazon SQS
								messages.
							For more information, see Data Keys in
								the AWS Key Management Service Developer Guide in the
									AWS Encryption SDK Developer Guide.
						
					 
						Data key reuse period
						
							The length of time, in seconds, for which Amazon SQS can reuse a data
								key to encrypt or decrypt messages before calling AWS KMS again. An
								integer representing seconds, between 60 seconds (1 minute) and
								86,400 seconds (24 hours). The default is 300 (5 minutes). For more
								information, see Understanding the
						data key reuse period.
							NoteIn the unlikely event of being unable to reach AWS KMS, Amazon SQS
									continues to use the cached data key until a connection is
									reestablished.
						
					 
						KMS key ID
						
							The alias, alias ARN, key ID, or key ARN of an AWS managed
								KMS key or a custom KMS key—in your account or in another
								account. While the alias of the AWS managed KMS key for Amazon SQS is
								always alias/aws/sqs, the alias of a custom KMS key
								can, for example, be
									alias/MyAlias. You can
								use these KMS keys to protect the messages in Amazon SQS queues. 
							NoteKeep the following in mind:
									 
									 
									 
								
										If you don't specify a custom KMS key, Amazon SQS uses
											the AWS managed KMS key for Amazon SQS.
									
										The first time you use the AWS Management Console to specify the
											AWS managed KMS key for Amazon SQS for a queue, AWS KMS
											creates the AWS managed KMS key for Amazon SQS.
									
										Alternatively, the first time you use the
												SendMessage or
												SendMessageBatch action on a queue with
											SSE enabled, AWS KMS creates the AWS managed KMS key
											for Amazon SQS.
									
							You can create KMS keys, define the policies that control how
								KMS keys can be used, and audit KMS key usage using the
									Customer managed keys section of the AWS KMS
								console or the CreateKey AWS KMS action. For more
								information, see KMS keys and Creating Keys in the
									AWS Key Management Service Developer Guide. For more examples of
								KMS key identifiers, see KeyId in the AWS Key Management Service API Reference. For
								information about finding KMS key identifiers, see Find the
									Key ID and ARN in the
									AWS Key Management Service Developer Guide.
							ImportantThere are additional charges for using AWS KMS. For more
									information, see Estimating AWS KMS costs and AWS Key Management Service
									Pricing.
						
					 
						Envelope Encryption
						
							The security of your encrypted data depends in part on protecting
								the data key that can decrypt it. Amazon SQS uses the KMS key to
								encrypt the data key and then the encrypted data key is stored with
								the encrypted message. This practice of using a KMS key to encrypt
								data keys is known as envelope encryption. 
							For more information, see Envelope Encryption in the
									AWS Encryption SDK Developer Guide.
						
					
			Document ConventionsData encryptionKey managementDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS at-least-once
				deliveryAmazon SQS stores copies of your messages on multiple servers for redundancy and high
			availability. On rare occasions, one of the servers that stores a copy of a message
			might be unavailable when you receive or delete a message.If this occurs, the copy of the message isn't deleted on the server that is
			unavailable, and you might get that message copy again when you receive messages. Design
			your applications to be idempotent (they should not
			be affected adversely when processing the same message more than once). Document ConventionsStandard queuesQueue and message identifiersDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideExactly-once processing in
                Amazon SQSUnlike standard queues, FIFO queues don't introduce duplicate messages. FIFO queues
            help you avoid sending duplicates to a queue. If you retry the SendMessage
            action within the 5-minute deduplication interval, Amazon SQS doesn't introduce any
            duplicates into the queue.To configure deduplication, you must do one of the following:
             
             
        
                Enable content-based deduplication. This instructs Amazon SQS to use a SHA-256 hash
                    to generate the message deduplication ID using the body of the
                    message—but not the attributes of the message. For more information, see
                    the documentation on the CreateQueue, GetQueueAttributes, and SetQueueAttributes actions in the
                        Amazon Simple Queue Service API Reference.
            
                Explicitly provide the message deduplication ID (or view the sequence number)
                    for the message. For more information, see the documentation on the SendMessage,
                            SendMessageBatch, and ReceiveMessage
                    actions in the Amazon Simple Queue Service API Reference.
            Document ConventionsFIFO delivery
                logicMoving from a standard queue to a FIFO
                queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUse casesPartitions and data distributionHigh throughput for FIFO queues in Amazon SQSHigh throughput FIFO queues in Amazon SQS efficiently manage high message throughput while
    maintaining strict message order, ensuring reliability and scalability for applications
    processing numerous messages. This solution is ideal for scenarios demanding both high
    throughput and ordered message delivery.Amazon SQS high throughput FIFO queues are not necessary in scenarios where strict message
    ordering is not crucial and where the volume of incoming messages is relatively low or sporadic.
    For instance, if you have a small-scale application that processes infrequent or non-sequential
    messages, the added complexity and cost associated with high throughput FIFO queues may not be
    justified. Additionally, if your application does not require the enhanced throughput
    capabilities provided by high throughput FIFO queues, opting for a standard Amazon SQS queue might be
    more cost-effective and simpler to manage.To enhance request capacity in high throughput FIFO queues, increasing the number of message
    groups is recommended. For more information on high throughput message quotas, see Amazon SQS service
      quotas in the Amazon Web Services General Reference.For information per-queue quotas and data distribution strategies, see Amazon SQS message quotas and Partitions and data distribution for high
      throughput for SQS FIFO queues.
  Use cases for high throughput for Amazon SQS FIFO
      queues
  The following use cases highlight the diverse applications of high throughput FIFO queues,
    showcasing their effectiveness across industries and scenarios:
  
     
     
     
     
  
      Real-time data processing: Applications dealing with
        real-time data streams, such as event processing or telemetry data ingestion, can benefit
        from high throughput FIFO queues to handle the continuous influx of messages while
        preserving their order for accurate analysis.
    
      E-commerce order processing: In e-commerce platforms
        where maintaining the order of customer transactions is critical, high throughput FIFO
        queues ensure that orders are processed sequentially and without delays, even during peak
        shopping seasons.
    
      Financial services: Financial institutions handling
        high-frequency trading or transactional data rely on high throughput FIFO Queues to process
        market data and transactions with minimal latency while adhering to strict regulatory
        requirements for message ordering.
    
      Media streaming: Streaming platforms and media
        distribution services utilize high throughput FIFO queues to manage the delivery of media
        files and streaming content, ensuring smooth playback experiences for users while
        maintaining the correct order of content delivery.
    
 
  Partitions and data distribution for high
      throughput for SQS FIFO queues
  Amazon SQS stores FIFO queue data in partitions. A partition is an
    allocation of storage for a queue that is automatically replicated across multiple Availability
    Zones within an AWS Region. You don't manage partitions. Instead, Amazon SQS handles partition
    management.
  For FIFO queues, Amazon SQS modifies the number of partitions in a queue in the following
    situations:
  
     
     
  
      If the current request rate approaches or exceeds what the existing partitions can
        support, additional partitions are allocated until the queue reaches the regional quota. For
        information on quotas, see Amazon SQS message quotas.
    
      If the current partitions have low utilization, the number of partitions may be
        reduced.
    
  Partition management occurs automatically in the background and is transparent to your
    applications. Your queue and messages are available at all times.
   
    Distributing data by message group IDs
    To add a message to a FIFO queue, Amazon SQS uses the value of each message’s message group ID
      as input to an internal hash function. The output value from the hash function determines
      which partition stores the message.
    The following diagram shows a queue that spans multiple partitions. The queue’s message
      group ID is based on item number. Amazon SQS uses its hash function to determine where to store a
      new item; in this case, it's based on the hash value of the string item0. Note
      that the items are stored in the same order in which they are added to the queue. Each item's
      location is determined by the hash value of its message group ID.
    
       
        
       
       
    
    NoteAmazon SQS is optimized for uniform distribution of items across a FIFO queue's partitions,
        regardless of the number of partitions. AWS recommends that you use message group IDs that
        can have a large number of distinct values. 
   
   
    Optimizing partition
        utilization
    Each partition supports up to 3,000 messages per second with batching, or up to 300
      messages per second for send, receive, and delete operations in supported regions. For more
      information on high throughput message quotas, 
      see Amazon SQS service quotas
      in the Amazon Web Services General Reference.
    When using batch APIs, each message is routed based on the process described in
      Distributing data by message group IDs.
      Messages that are routed to the same partition are grouped and processed in a single transaction.
    To optimize partition utilization for the SendMessageBatch API, AWS recommends batching
      messages with the same message group IDs when possible.
    To optimize partition utilization for the DeleteMessageBatch and
        ChangeMessageVisibilityBatch APIs, AWS recommends using
        ReceiveMessage requests with the MaxNumberOfMessages parameter set
      to 10, and batching the receipt-handles returned by a single ReceiveMessage
      request.
    In the following example, a batch of messages with various message group IDs is sent. The
      batch is split into three groups, each of which counts against the quota for the
      partition.
    
       
        
       
       
    
    NoteAmazon SQS only guarantees that messages with the same message group ID's internal hash
        function are grouped within a batch request. Depending on the output of the internal hash
        function and the number of partitions, messages with different message group IDs might be
        grouped. Since the hash function or number of partitions can change at any time, messages
        that are grouped at one point may not be grouped later.
   
Document ConventionsFIFO queue and Lambda concurrency behaviorEnabling high throughput for FIFO
        queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUsing
					AmazonSQSBufferedAsyncClientEnabling client-side
				buffering and request batching with Amazon SQSThe AWS SDK for Java includes
				AmazonSQSBufferedAsyncClient which accesses Amazon SQS. This client allows
			for simple request batching using client-side buffering. Calls made from the client are
			first buffered and then sent as a batch request to Amazon SQS.Client-side buffering allows up to 10 requests to be buffered and sent as a batch
			request, decreasing your cost of using Amazon SQS and reducing the number of sent requests.
				AmazonSQSBufferedAsyncClient buffers both synchronous and asynchronous
			calls. Batched requests and support for long
				polling can also help increase throughput. For more information, see Increasing throughput
				using horizontal scaling and action batching with Amazon SQS.Because AmazonSQSBufferedAsyncClient implements the same interface as
				AmazonSQSAsyncClient, migrating from AmazonSQSAsyncClient
			to AmazonSQSBufferedAsyncClient typically requires only minimal changes to
			your existing code.NoteThe Amazon SQS Buffered Asynchronous Client doesn't currently support FIFO queues.
			Using
					AmazonSQSBufferedAsyncClient
			Before you begin, complete the steps in Setting up Amazon SQS. 
			 
				AWS SDK for Java
						1.x
				For AWS SDK for Java 1.x, you can create a new
						AmazonSQSBufferedAsyncClient based on the following
					example:
				// Create the basic Amazon SQS async client
final AmazonSQSAsync sqsAsync = new AmazonSQSAsyncClient();
 
// Create the buffered client
final AmazonSQSAsync bufferedSqs = new AmazonSQSBufferedAsyncClient(sqsAsync);
				After you create the new AmazonSQSBufferedAsyncClient, you can
					use it to send multiple requests to Amazon SQS (just as you can with
						AmazonSQSAsyncClient), for example:
				final CreateQueueRequest createRequest = new CreateQueueRequest().withQueueName("MyQueue");
 
final CreateQueueResult res = bufferedSqs.createQueue(createRequest);
 
final SendMessageRequest request = new SendMessageRequest();
final String body = "Your message text" + System.currentTimeMillis();
request.setMessageBody( body );
request.setQueueUrl(res.getQueueUrl());
 
final Future<SendMessageResult> sendResult = bufferedSqs.sendMessageAsync(request);
 
final ReceiveMessageRequest receiveRq = new ReceiveMessageRequest()
    .withMaxNumberOfMessages(1)
    .withQueueUrl(queueUrl);
final ReceiveMessageResult rx = bufferedSqs.receiveMessage(receiveRq);
			 
			 
				Configuring
						AmazonSQSBufferedAsyncClient
				AmazonSQSBufferedAsyncClient is preconfigured with settings that
					work for most use cases. You can further configure
						AmazonSQSBufferedAsyncClient, for example:
				
						Create an instance of the QueueBufferConfig class with
							the required configuration parameters.
					
						Provide the instance to the AmazonSQSBufferedAsyncClient
							constructor.
					
				// Create the basic Amazon SQS async client
final AmazonSQSAsync sqsAsync = new AmazonSQSAsyncClient();
 
final QueueBufferConfig config = new QueueBufferConfig()
    .withMaxInflightReceiveBatches(5)
    .withMaxDoneReceiveBatches(15);
 
// Create the buffered client
final AmazonSQSAsync bufferedSqs = new AmazonSQSBufferedAsyncClient(sqsAsync, config);
				QueueBufferConfig configuration parameters
							
								Parameter
								Default value
								Description
							
						
							
								longPoll
								true
								
									When longPoll is set to true,
											AmazonSQSBufferedAsyncClient attempts to
										use long polling when it consumes messages.
								
							
							
								longPollWaitTimeoutSeconds
								20 s
								
									The maximum amount of time (in seconds) which a
											ReceiveMessage call blocks off on the
										server, waiting for messages to appear in the queue before
										returning with an empty receive result.
									NoteWhen long polling is disabled, this setting has no
											effect.
								
							
							
								maxBatchOpenMs
								200 ms
								
									The maximum amount of time (in milliseconds) that an
										outgoing call waits for other calls with which it batches
										messages of the same type.
									The higher the setting, the fewer batches are required to
										perform the same amount of work (however, the first call in
										a batch has to spend a longer time waiting).
									When you set this parameter to 0, submitted
										requests don't wait for other requests, effectively
										disabling batching.
								
							
							
								maxBatchSize
								10 requests per batch
								
									The maximum number of messages that are batched together
										in a single request. The higher the setting, the fewer
										batches are required to carry out the same number of
										requests.
									Note10 requests per batch is the maximum allowed value for
											Amazon SQS.
								
							
							
								maxBatchSizeBytes
								256 KiB
								
									The maximum size of a message batch, in bytes, that the
										client attempts to send to Amazon SQS.
									Note256 KiB is the maximum allowed value for Amazon SQS.
								
							
							
								maxDoneReceiveBatches
								10 batches
								
									The maximum number of receive batches that
											AmazonSQSBufferedAsyncClient prefetches and
										stores client-side.
									The higher the setting, the more receive requests can be
										satisfied without having to make a call to Amazon SQS (however,
										the more messages are prefetched, the longer they remain in
										the buffer, causing their own visibility timeout to
										expire).
									Note0 indicates that all message pre-fetching
											is disabled and messages are consumed only on
											demand.
								
							
							
								maxInflightOutboundBatches
								5 batches
								
									The maximum number of active outbound batches that can be
										processed at the same time.
									The higher the setting, the faster outbound batches can be
										sent (subject to quotas such as CPU or bandwidth) and the
										more threads are consumed by
											AmazonSQSBufferedAsyncClient.
								
							
							
								maxInflightReceiveBatches
								10 batches
								
									The maximum number of active receive batches that can be
										processed at the same time.
									The higher the setting, the more messages can be received
										(subject to quotas such as CPU or bandwidth), and the more
										threads are consumed by
											AmazonSQSBufferedAsyncClient.
									Note0 indicates that all message pre-fetching
											is disabled and messages are consumed only on
											demand.
								
							
							
								visibilityTimeoutSeconds
								-1
								
									When this parameter is set to a positive, non-zero value,
										the visibility timeout set here overrides the visibility
										timeout set on the queue from which messages are
										consumed.
									Note-1 indicates that the default setting is
											selected for the queue.You can't set visibility timeout to
											0.
								
							
						
			 
			 
				AWS SDK for Java
						2.x
				For AWS SDK for Java 2.x, you can create a new
						SqsAsyncBatchManager based on the following example:
				// Create the basic Sqs Async Client
SqsAsyncClient sqs = SqsAsyncClient.builder() 
    .region(Region.US_EAST_1) 
    .build();

// Create the batch manager
SqsAsyncBatchManager sqsAsyncBatchManager = sqs.batchManager();
				After you create the new SqsAsyncBatchManager, you can use it to
					send multiple requests to Amazon SQS (just as you can with
						SqsAsyncClient), for example:
				final String queueName = "MyAsyncBufferedQueue" + UUID.randomUUID();
final CreateQueueRequest request = CreateQueueRequest.builder().queueName(queueName).build();
final String queueUrl = sqs.createQueue(request).join().queueUrl();
System.out.println("Queue created: " + queueUrl);


// Send messages
CompletableFuture<SendMessageResponse> sendMessageFuture;
for (int i = 0; i < 10; i++) {
    final int index = i;
    sendMessageFuture = sqsAsyncBatchManager.sendMessage(
            r -> r.messageBody("Message " + index).queueUrl(queueUrl));
    SendMessageResponse response= sendMessageFuture.join();
    System.out.println("Message " + response.messageId() + " sent!");
}

// Receive messages with customized configurations
CompletableFuture<ReceiveMessageResponse> receiveResponseFuture = customizedBatchManager.receiveMessage(
        r -> r.queueUrl(queueUrl)
                .waitTimeSeconds(10)
                .visibilityTimeout(20)
                .maxNumberOfMessages(10)
);
System.out.println("You have received " + receiveResponseFuture.join().messages().size() + " messages in total.");

// Delete messages
DeleteQueueRequest deleteQueueRequest =  DeleteQueueRequest.builder().queueUrl(queueUrl).build();
int code = sqs.deleteQueue(deleteQueueRequest).join().sdkHttpResponse().statusCode();
System.out.println("Queue is deleted, with statusCode " + code);
			 
			 
				Configuring
						SqsAsyncBatchManager
				SqsAsyncBatchManager is preconfigured with settings that work for
					most use cases. You can further configure SqsAsyncBatchManager, for
					example:
				Creating custom configuration via
					SqsAsyncBatchManager.Builder:
				SqsAsyncBatchManager customizedBatchManager = SqsAsyncBatchManager.builder() 
    .client(sqs)
    .scheduledExecutor(Executors.newScheduledThreadPool(5))
    .overrideConfiguration(b -> b 
        .maxBatchSize(10)
        .sendRequestFrequency(Duration.ofMillis(200))
        .receiveMessageMinWaitDuration(Duration.ofSeconds(10))
        .receiveMessageVisibilityTimeout(Duration.ofSeconds(20)) 
        .receiveMessageAttributeNames(Collections.singletonList("*"))
        .receiveMessageSystemAttributeNames(Collections.singletonList(MessageSystemAttributeName.ALL)))
    .build();
				BatchOverrideConfiguration parameters
							
								Parameter
								Default value
								Description
							
						
							
								maxBatchSize
								
									10 requests per batch
								
								The maximum number of messages that are batched
										together in a single request. The higher the setting, the
										fewer batches are required to carry out the same number of
										requests.
									NoteThe maximum allowed value for Amazon SQS is 10 requests per
											batch.
							
							
								sendRequestFrequency
								
									200 ms
								
								The maximum amount of time (in milliseconds) that an
										outgoing call waits for other calls with which it batches
										messages of the same type.
									The higher the setting, the fewer batches are required to
										perform the same amount of work (however, the first call in
										a batch has to spend a longer time waiting).
									When you set this parameter to 0, submitted
										requests don't wait for other requests, effectively
										disabling batching.
							
							
								receiveMessageVisibilityTimeout
								
									-1
								
								When this parameter is set to a positive, non-zero
										value, the visibility timeout set here overrides the
										visibility timeout set on the queue from which messages are
										consumed.
									Note
											1 indicates that the default setting is
											selected for the queue. You can't set visibility timeout
											to 0.
								
							
							
								receiveMessageMinWaitDuration
								
									50 ms
								
								The minimal amount of time (in milliseconds) that a
											receiveMessage call waits for available
										messages to be fetched. The higher the setting, the fewer
										batches are required to carry out the same number of
										request.
								
							
						
			 
		Document ConventionsBatch actionsIncreasing throughput
				using horizontal scaling and action batching with Amazon SQSDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS delay queuesDelay queues let you postpone the delivery of new messages to consumers for a number of seconds, for example, when your consumer
    application needs additional time to process messages. If you create a delay queue, any messages that you send to the queue remain invisible to consumers
    for the duration of the delay period. The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes. For information about configuring delay queues using the console
        see Configuring queue parameters using the Amazon SQS
      console.NoteFor standard queues, the per-queue delay setting is not
                retroactive—changing the setting doesn't affect the delay of
            messages already in the queue.For FIFO queues, the per-queue delay setting is retroactive—changing the setting affects the delay of messages
            already in the queue.Delay queues are similar to visibility
            timeouts because both features make messages unavailable to consumers for a
        specific period of time. The difference between the two is that, for delay queues, a message
        is hidden when it is first added to queue, whereas for visibility timeouts a message is
        hidden only after it is consumed from the queue. The following diagram illustrates the
        relationship between delay queues and visibility timeouts. 
         
            
         
         
    Extended scheduling optionsWhile Amazon SQS delay queues and message timers allow scheduling of message delivery up to 15
        minutes in the future, you may require more flexible scheduling capabilities. In such cases,
        consider using EventBridge Scheduler, which enables you
        to schedule billions of one-time or recurring API actions without time limitations. EventBridge Scheduler is the recommended solution for advanced message scheduling use cases.To set delay seconds on individual messages, rather than on an entire queue, use message timers to allow Amazon SQS to use the message
        timer's DelaySeconds value instead of the delay queue's
            DelaySeconds value. EventBridge Scheduler also supports
        scheduling individual messages.Document ConventionsVisibility timeoutTemporary queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuidePrerequisitesAWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messagesManaging large Amazon SQS messages using Java and Amazon S3Use the Amazon SQS Extended Client Library for Java with Amazon S3 to manage large Amazon SQS
        messages, particularly for payloads ranging from 256 KB to 2 GB. The library stores the
        message payload in an Amazon S3 bucket and sends a message containing a reference to the
        stored object in the Amazon SQS queue.With the Amazon SQS Extended Client Library for Java, you can:
         
         
         
         
    
            Specify whether messages are always stored in Amazon S3 or only when the size of a
                message exceeds 256 KB
        
            Send a message that references a single message object stored in an S3 bucket
            
        
            Retrieve the message object from an Amazon S3 bucket
        
            Delete the message object from an Amazon S3 bucket
        
        Prerequisites
        
        The following example uses the AWS Java SDK. To install and set up the SDK,
		see Set up the AWS SDK for Java
		in the AWS SDK for Java Developer Guide.
        Before you run the example code, configure your AWS credentials. For
		more information, see Set up AWS Credentials and Region for Development
		in the AWS SDK for Java Developer Guide.
		
        The SDK for Java and Amazon SQS Extended Client Library for Java require the J2SE Development Kit 8.0 or later.
        NoteYou can use the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages using
                Amazon S3 only with the AWS SDK for Java. You can't do this
                with the AWS CLI, the Amazon SQS console, the Amazon SQS HTTP API, or any of the other AWS
                SDKs.
     
        AWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messages
        The following SDK for Java 2.x example creates an Amazon S3 bucket with a random name and adds a
            lifecycle rule to permanently delete objects after 14 days. It also creates a queue
            named MyQueue and sends a random message that is stored in an Amazon S3 bucket
            and is more than 256 KB to the queue. Finally, the code retrieves the message, returns
            information about it, and then deletes the message, the queue, and the bucket.
        /*
 * Copyright 2010-2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *  https://aws.amazon.com/apache2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 *
 */
	            
	            import com.amazon.sqs.javamessaging.AmazonSQSExtendedClient;
import com.amazon.sqs.javamessaging.ExtendedClientConfiguration;
import org.joda.time.DateTime;
import org.joda.time.format.DateTimeFormat;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.BucketLifecycleConfiguration;
import software.amazon.awssdk.services.s3.model.CreateBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;
import software.amazon.awssdk.services.s3.model.ExpirationStatus;
import software.amazon.awssdk.services.s3.model.LifecycleExpiration;
import software.amazon.awssdk.services.s3.model.LifecycleRule;
import software.amazon.awssdk.services.s3.model.LifecycleRuleFilter;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsRequest;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsResponse;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;
import software.amazon.awssdk.services.s3.model.PutBucketLifecycleConfigurationRequest;
import software.amazon.awssdk.services.sqs.SqsClient;
import software.amazon.awssdk.services.sqs.model.CreateQueueRequest;
import software.amazon.awssdk.services.sqs.model.CreateQueueResponse;
import software.amazon.awssdk.services.sqs.model.DeleteMessageRequest;
import software.amazon.awssdk.services.sqs.model.DeleteQueueRequest;
import software.amazon.awssdk.services.sqs.model.Message;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageRequest;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageResponse;
import software.amazon.awssdk.services.sqs.model.SendMessageRequest;

import java.util.Arrays;
import java.util.List;
import java.util.UUID;


/**
 * Examples of using Amazon SQS Extended Client Library for Java 2.x
 *
 */
public class SqsExtendedClientExamples {
    // Create an Amazon S3 bucket with a random name.
    private final static String amzn-s3-demo-bucket = UUID.randomUUID() + "-"
            + DateTimeFormat.forPattern("yyMMdd-hhmmss").print(new DateTime());

    public static void main(String[] args) {

        /*
         * Create a new instance of the builder with all defaults (credentials
         * and region) set automatically. For more information, see
         * Creating Service Clients in the AWS SDK for Java Developer Guide.
         */
        final S3Client s3 = S3Client.create();

        /*
         * Set the Amazon S3 bucket name, and then set a lifecycle rule on the
         * bucket to permanently delete objects 14 days after each object's
         * creation date.
         */
        final LifecycleRule lifeCycleRule = LifecycleRule.builder()
                .expiration(LifecycleExpiration.builder().days(14).build())
                .filter(LifecycleRuleFilter.builder().prefix("").build())
                .status(ExpirationStatus.ENABLED)
                .build();
        final BucketLifecycleConfiguration lifecycleConfig = BucketLifecycleConfiguration.builder()
                .rules(lifeCycleRule)
                .build();

        // Create the bucket and configure it
        s3.createBucket(CreateBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
        s3.putBucketLifecycleConfiguration(PutBucketLifecycleConfigurationRequest.builder()
                .bucket(amzn-s3-demo-bucket)
                .lifecycleConfiguration(lifecycleConfig)
                .build());
        System.out.println("Bucket created and configured.");

        // Set the Amazon SQS extended client configuration with large payload support enabled
        final ExtendedClientConfiguration extendedClientConfig = new ExtendedClientConfiguration().withPayloadSupportEnabled(s3, amzn-s3-demo-bucket);

        final SqsClient sqsExtended = new AmazonSQSExtendedClient(SqsClient.builder().build(), extendedClientConfig);

        // Create a long string of characters for the message object
        int stringLength = 300000;
        char[] chars = new char[stringLength];
        Arrays.fill(chars, 'x');
        final String myLongString = new String(chars);

        // Create a message queue for this example
        final String queueName = "MyQueue-" + UUID.randomUUID();
        final CreateQueueResponse createQueueResponse = sqsExtended.createQueue(CreateQueueRequest.builder().queueName(queueName).build());
        final String myQueueUrl = createQueueResponse.queueUrl();
        System.out.println("Queue created.");

        // Send the message
        final SendMessageRequest sendMessageRequest = SendMessageRequest.builder()
                .queueUrl(myQueueUrl)
                .messageBody(myLongString)
                .build();
        sqsExtended.sendMessage(sendMessageRequest);
        System.out.println("Sent the message.");

        // Receive the message
        final ReceiveMessageResponse receiveMessageResponse = sqsExtended.receiveMessage(ReceiveMessageRequest.builder().queueUrl(myQueueUrl).build());
        List<Message> messages = receiveMessageResponse.messages();

        // Print information about the message
        for (Message message : messages) {
            System.out.println("\nMessage received.");
            System.out.println("  ID: " + message.messageId());
            System.out.println("  Receipt handle: " + message.receiptHandle());
            System.out.println("  Message body (first 5 characters): " + message.body().substring(0, 5));
        }

        // Delete the message, the queue, and the bucket
        final String messageReceiptHandle = messages.get(0).receiptHandle();
        sqsExtended.deleteMessage(DeleteMessageRequest.builder().queueUrl(myQueueUrl).receiptHandle(messageReceiptHandle).build());
        System.out.println("Deleted the message.");

        sqsExtended.deleteQueue(DeleteQueueRequest.builder().queueUrl(myQueueUrl).build());
        System.out.println("Deleted the queue.");

        deleteBucketAndAllContents(s3);
        System.out.println("Deleted the bucket.");

    }

    private static void deleteBucketAndAllContents(S3Client client) {
        ListObjectsV2Response listObjectsResponse = client.listObjectsV2(ListObjectsV2Request.builder().bucket(amzn-s3-demo-bucket).build());

        listObjectsResponse.contents().forEach(object -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(object.key()).build());
        });

        ListObjectVersionsResponse listVersionsResponse = client.listObjectVersions(ListObjectVersionsRequest.builder().bucket(amzn-s3-demo-bucket).build());

        listVersionsResponse.versions().forEach(version -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(version.key()).versionId(version.versionId()).build());
        });

        client.deleteBucket(DeleteBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
    }
}
        

         You can use Apache Maven to configure and build Amazon SQS Extended Client for your Java
            project, or to build the SDK itself. Specify individual modules from the SDK that you
            use in your application. 
        
<properties>
    <aws-java-sdk.version>2.20.153</aws-java-sdk.version>
</properties>

<dependencies>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>sqs</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>s3</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>amazon-sqs-java-extended-client-lib</artifactId>
      <version>2.0.4</version>
    </dependency>

    <dependency>
      <groupId>joda-time</groupId>
      <artifactId>joda-time</artifactId>
      <version>2.12.6</version>
    </dependency>
</dependencies>
	        

    Document ConventionsManaging large
            messagesUsing the Extended Client Library for PythonDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse ElementsErrorsExamplesSee AlsoSetQueueAttributesSets the value of one or more queue attributes, like a policy. When you change a
            queue's attributes, the change can take up to 60 seconds for most of the attributes to
            propagate throughout the Amazon SQS system. Changes made to the
                MessageRetentionPeriod attribute can take up to 15 minutes and will
            impact existing messages in the queue potentially causing them to be expired and deleted
            if the MessageRetentionPeriod is reduced below the age of existing
            messages.Note
          
          
          
      
            In the future, new attributes might be added. If you write code that calls this action, we recommend that you structure your code so that it can handle new attributes gracefully.
         
            Cross-account permissions don't apply to this action. For more information, 
see Grant 
cross-account permissions to a role and a username in the Amazon SQS Developer Guide.
         
            To remove the ability to change queue permissions, you must deny permission to the AddPermission, RemovePermission, and SetQueueAttributes actions in your IAM policy.
         
      Request Syntax
      {
   "Attributes": { 
      "string" : "string" 
   },
   "QueueUrl": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
      
            
               
                  Attributes
               
            
            
               A map of attributes to set.
               The following lists the names, descriptions, and values of the special request
            parameters that the SetQueueAttributes action uses:
               
                   
                   
                   
                   
                   
                   
               
                     
                        DelaySeconds – The length of time, in seconds, for which the
                    delivery of all messages in the queue is delayed. Valid values: An integer from
                    0 to 900 (15 minutes). Default: 0. 
                  
                     
                        MaximumMessageSize – The limit of how many bytes a message
                    can contain before Amazon SQS rejects it. Valid values: An integer from 1,024 bytes
                    (1 KiB) up to 262,144 bytes (256 KiB). Default: 262,144 (256 KiB). 
                  
                     
                        MessageRetentionPeriod – The length of time, in seconds, for
                    which Amazon SQS retains a message. Valid values: An integer representing seconds,
                    from 60 (1 minute) to 1,209,600 (14 days). Default: 345,600 (4 days). When you
                    change a queue's attributes, the change can take up to 60 seconds for most of
                    the attributes to propagate throughout the Amazon SQS system. Changes made to the
                        MessageRetentionPeriod attribute can take up to 15 minutes and
                    will impact existing messages in the queue potentially causing them to be
                    expired and deleted if the MessageRetentionPeriod is reduced below
                    the age of existing messages.
                  
                     
                        Policy – The queue's policy. A valid AWS policy. For more
                    information about policy structure, see Overview of AWS IAM
                        Policies in the 
                           AWS Identity and Access Management User
                        Guide. 
                  
                     
                        ReceiveMessageWaitTimeSeconds – The length of time, in
                    seconds, for which a 
                           ReceiveMessage
                         action waits
                    for a message to arrive. Valid values: An integer from 0 to 20 (seconds).
                    Default: 0. 
                  
                     
                        VisibilityTimeout – The visibility timeout for the queue, in
                    seconds. Valid values: An integer from 0 to 43,200 (12 hours). Default: 30. For
                    more information about the visibility timeout, see Visibility Timeout in the Amazon SQS Developer
                        Guide.
                  
               The following attributes apply only to dead-letter queues:
               
               
                   
                   
               
                     
                        RedrivePolicy – The string that includes the parameters for the dead-letter queue functionality 
            of the source queue as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              deadLetterTargetArn – The Amazon Resource Name (ARN) of the dead-letter queue to 
                  which Amazon SQS moves messages after the value of maxReceiveCount is exceeded.
                        
                           
                              maxReceiveCount – The number of times a message is delivered to the source queue before being 
                 moved to the dead-letter queue. Default: 10. When the ReceiveCount for a message exceeds the maxReceiveCount 
                 for a queue, Amazon SQS moves the message to the dead-letter-queue.
                        
                  
                     
                        RedriveAllowPolicy – The string that includes the parameters for the permissions for the dead-letter
            queue redrive permission and which source queues can specify dead-letter queues as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              redrivePermission – The permission type that defines which source queues can 
                    specify the current queue as the dead-letter queue. Valid values are:
                           
                               
                               
                               
                           
                                 
                                    allowAll – (Default) Any source queues in this AWS account in the same Region can 
                          specify this queue as the dead-letter queue.
                              
                                 
                                    denyAll – No source queues can specify this queue as the dead-letter
                          queue.
                              
                                 
                                    byQueue – Only queues specified by the sourceQueueArns parameter can specify 
                         this queue as the dead-letter queue.
                              
                        
                           
                              sourceQueueArns – The Amazon Resource Names (ARN)s of the source queues that can specify 
                    this queue as the dead-letter queue and redrive messages. You can specify this parameter only when the 
                    redrivePermission parameter is set to byQueue. You can specify up to 10 source queue ARNs. 
                    To allow more than 10 source queues to specify dead-letter queues, set the redrivePermission parameter
                    to allowAll.
                        
                  
               NoteThe dead-letter queue of a 
              FIFO queue must also be a FIFO queue. Similarly, the dead-letter 
              queue of a standard queue must also be a standard queue.
               The following attributes apply only to server-side-encryption:
               
                   
                   
                   
               
                     
                        KmsMasterKeyId – The ID of an AWS managed customer master
                    key (CMK) for Amazon SQS or a custom CMK. For more information, see Key Terms. While the alias of the AWS-managed CMK for Amazon SQS is
                    always alias/aws/sqs, the alias of a custom CMK can, for example,
                    be alias/MyAlias
                        . For more examples, see
                        KeyId in the 
                           AWS Key Management Service API
                        Reference. 
                  
                     
                        KmsDataKeyReusePeriodSeconds – The length of time, in
                    seconds, for which Amazon SQS can reuse a data key to
                    encrypt or decrypt messages before calling AWS KMS again. An integer
                    representing seconds, between 60 seconds (1 minute) and 86,400 seconds (24
                    hours). Default: 300 (5 minutes). A shorter time period provides better security
                    but results in more calls to KMS which might incur charges after Free Tier. For
                    more information, see How Does the Data Key Reuse Period Work?. 
                  
                     
                        SqsManagedSseEnabled – Enables server-side queue encryption
                    using SQS owned encryption keys. Only one server-side encryption option is
                    supported per queue (for example, SSE-KMS or SSE-SQS).
                  
               The following attribute applies only to FIFO (first-in-first-out)
                queues:
               
                   
               
                     
                        ContentBasedDeduplication – Enables content-based
                    deduplication. For more information, see Exactly-once processing in the Amazon SQS Developer
                        Guide. Note the following: 
                     
                         
                         
                         
                     
                           Every message must have a unique
                            MessageDeduplicationId.
                           
                               
                               
                               
                               
                           
                                 You may provide a MessageDeduplicationId
                                    explicitly.
                              
                                 If you aren't able to provide a
                                        MessageDeduplicationId and you enable
                                        ContentBasedDeduplication for your queue, Amazon SQS
                                    uses a SHA-256 hash to generate the
                                        MessageDeduplicationId using the body of the
                                    message (but not the attributes of the message). 
                              
                                 If you don't provide a MessageDeduplicationId and
                                    the queue doesn't have ContentBasedDeduplication
                                    set, the action fails with an error.
                              
                                 If the queue has ContentBasedDeduplication set,
                                    your MessageDeduplicationId overrides the generated
                                    one.
                              
                        
                           When ContentBasedDeduplication is in effect, messages
                            with identical content sent within the deduplication interval are
                            treated as duplicates and only one copy of the message is
                            delivered.
                        
                           If you send one message with ContentBasedDeduplication
                            enabled and then another message with a
                                MessageDeduplicationId that is the same as the one
                            generated for the first MessageDeduplicationId, the two
                            messages are treated as duplicates and only one copy of the message is
                            delivered. 
                        
                  
               The following attributes apply only to 
high throughput
for FIFO queues:
               
                   
                   
               
                     
                        DeduplicationScope – Specifies whether message deduplication occurs at the 
      message group or queue level. Valid values are messageGroup and queue.
                  
                     
                        FifoThroughputLimit – Specifies whether the FIFO queue throughput 
      quota applies to the entire queue or per message group. Valid values are perQueue and perMessageGroupId. 
      The perMessageGroupId value is allowed only when the value for DeduplicationScope is messageGroup.
                  
               To enable high throughput for FIFO queues, do the following:
               
                   
                   
               
                     Set DeduplicationScope to messageGroup.
                  
                     Set FifoThroughputLimit to perMessageGroupId.
                  
               If you set these attributes to anything other than the values shown for enabling high
  throughput, normal throughput is in effect and deduplication occurs as specified.
               For information on throughput quotas, 
  see Quotas related to messages 
  in the Amazon SQS Developer Guide.
               Type: String to string map
               Valid Keys: All | Policy | VisibilityTimeout | MaximumMessageSize | MessageRetentionPeriod | ApproximateNumberOfMessages | ApproximateNumberOfMessagesNotVisible | CreatedTimestamp | LastModifiedTimestamp | QueueArn | ApproximateNumberOfMessagesDelayed | DelaySeconds | ReceiveMessageWaitTimeSeconds | RedrivePolicy | FifoQueue | ContentBasedDeduplication | KmsMasterKeyId | KmsDataKeyReusePeriodSeconds | DeduplicationScope | FifoThroughputLimit | RedriveAllowPolicy | SqsManagedSseEnabled
               
               Required: Yes
            
          
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue whose attributes are set.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
         
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAttributeName
               
            
            
               The specified attribute doesn't exist.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAttributeValue
               
            
            
               A queue attribute value is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  OverLimit
               
            
            
               The specified action violates a limit. For example, ReceiveMessage
            returns this error if the maximum number of in flight messages is reached and
                AddPermission returns this error if the maximum number of permissions
            for the queue is reached.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example query request sets a policy that gives all users 
            ReceiveMessage
          permission for a queue named
                    MyQueue. For more examples of policies, see Custom Amazon SQS Access Policy Language Examples in the Amazon SQS
                    Developer Guide. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive {
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Attributes": {
        "Policy": "{\"Version\":\"2012-10-17\",\"Id\":\"Policy1677095510157\",\"Statement\":[{\"Sid\":\"Stmt1677095506939\",\"Effect\":\"Allow\",\"Principal\":\"*\",\"Action\":\"sqs:ReceiveMessage\",\"Resource\":\"arn:aws:sqs:us-east-1:555555555555:MyQueue6\"}]}"
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: 0
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SetQueueAttributes
&Attribute.Name=Policy
&Attribute.Value=%7B%22Version%22%3A%222012-10-17%22%2C%22Id%22%3A%22UseCase1%22%2C%22Statement%22%3A%5B%7B%22Sid%22%3A%22Queue1ReceiveMessage%22%2C%22Effect%22%3A%22Allow%22%2C%22Principal%22%3A%7B%22AWS%22%3A%22*%22%7D%2C%22Action%22%3A%22SQS%3AReceiveMessage%22%2C%22Resource%22%3A%22arn%3Aaws%3Asqs%3Aus-east-1%3A555555555555%3AMyQueue6%22%7D%5D%7D
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>5798727f-61f0-5457-99f0-2e0fa7fce329</RequestId>
    </ResponseMetadata>
</SetQueueAttributesResponse>
          
       
       
         Example
         The following example query request sets the visibility timeout to 35 seconds
                    for a queue named MyQueue. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
               AWS General Reference.
         NoteAn Amazon SQS message has three basic states:
                
                
                
            
                  Sent to a queue by a producer.
               
                  Received from the queue by a consumer.
               
                  Deleted from the queue.
               A message is considered to be stored after it is sent to a queue by a producer, but not yet received from the queue by a consumer (that is, between states 1 and 2). There is no limit to the number of stored messages.
    A message is considered to be in flight after it is received from a queue by a consumer, but not yet deleted from the queue (that is, between states 2 and 3). There is a limit to the number of in flight messages.Limits that apply to in flight messages are unrelated to the unlimited number of stored messages.For most standard queues (depending on queue traffic and message backlog), there can be a maximum of approximately 120,000 in flight messages (received from a queue by a consumer, but not yet deleted from the queue). 
    If you reach this limit, Amazon SQS returns the OverLimit error message.
    To avoid reaching the limit, you should delete messages from the queue after they're processed. You can also increase the number of queues you use to process your messages.
    To request a limit increase, file a support request.For FIFO queues, there can be a maximum of 120,000 in flight messages (received from a queue by a consumer, but not yet deleted from the queue). If you reach this limit, Amazon SQS returns no error messages.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive {
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Attributes": {
        "VisibilityTimeout": "35"
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: 0
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SetQueueAttributes
&Attribute.Name=VisibilityTimeout
&Attribute.Value=35
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>e5cca473-4fc0-4198-a451-8abb94d02c75</RequestId>
    </ResponseMetadata>
</SetQueueAttributesResponse>
          
       
       
         Example
         The following example sets a queue named MyDeadLetterQueue as the
                    dead-letter queue for a queue name MySourceQueue by calling the
                        SetQueueAttributes action with the configuration details for
                    the dead-letter queue.
         NoteQueue URLs and names are case-sensitive.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive {
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Attributes": {
        "RedrivePolicy": "{\"maxReceiveCount\":\"5\",\"deadLetterTargetArn\":\"arn:aws:sqs:us-east-1:555555555555:MyDeadLetterQueue\"}"
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: 0
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SetQueueAttributes
&Attribute.Name=RedrivePolicy
&Attribute.Value=%7B%22maxReceiveCount%22%3A%225%22%2C%20%22deadLetterTargetArn%22%3A%22arn%3Aaws%3Asqs%3Aus-east-1%3A555555555555%3AMyDeadLetterQueue%22%7D
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>627e8ac6-73bf-515c-a359-d654eebaa6c3</RequestId>
    </ResponseMetadata>
</SetQueueAttributesResponse>
          
       
       
         Example
         The following example enables long polling by calling the
                        SetQueueAttributes action with the
                        ReceiveMessageWaitTimeSeconds parameter set to 20
                    seconds.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive {
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Attributes": {
        "ReceiveMessageWaitTimeSeconds": "20"    
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: 0
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SetQueueAttributes
&Attribute.Name=ReceiveMessageWaitTimeSeconds
&Attribute.Value=20
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>3949c1a7-1e69-564c-ad00-9d3583174f09</RequestId>
    </ResponseMetadata>
</SetQueueAttributesResponse>
          
       
       
         Example
         The following example changes an existing queue into a delay queue by calling
                    the SetQueueAttributes action with the DelaySeconds
                    attribute set to 45 seconds. Changing the DelaySeconds attribute
                    from its default value of 0 to a positive integer less than or
                    equal to 900 changes the queue into a delay queue.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive {
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Attributes": {
        "DelaySeconds": "45"    
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: 0
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SetQueueAttributes
&Attribute.Name=DelaySeconds
&Attribute.Value=45
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>e4761152-39b6-556e-84a0-4dc0a78f4927</RequestId>
    </ResponseMetadata>
</SetQueueAttributesResponse>
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsSendMessageBatchStartMessageMoveTaskDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Data FirehoseDeveloper GuideLearn key conceptsUnderstand data flow in Amazon Data FirehoseWhat is Amazon Data Firehose?Amazon Data Firehose is a fully managed service for delivering real-time streaming data to destinations such as
        Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon OpenSearch Service, Amazon OpenSearch Serverless, Splunk, Apache Iceberg
        Tables, and any custom HTTP endpoint or HTTP endpoints owned by supported third-party
        service providers, including Datadog, Dynatrace, LogicMonitor, MongoDB, New Relic,
        Coralogix, and Elastic. With Amazon Data Firehose, you don't need to write applications or manage
        resources. You configure your data producers to send data to Amazon Data Firehose, and it automatically
        delivers the data to the destination that you specified. You can also configure Amazon Data Firehose to
        transform your data before delivering it.For more information about AWS big data solutions, see Big Data on AWS. For more information about
        AWS streaming data solutions, see What is
            Streaming Data?NoteNote the latest AWS Streaming Data Solution for Amazon MSK that provides AWS
            CloudFormation templates where data flows through producers, streaming storage,
            consumers, and destinations.
        Learn key concepts

        As you get started with Amazon Data Firehose, you can benefit from understanding the following
            concepts.
        
             
             
             
             
        
                Firehose stream
                
                    The underlying entity of Amazon Data Firehose. You use Amazon Data Firehose by creating a Firehose stream and
                        then sending data to it. For more information, see Tutorial: Create a Firehose stream from console and Send data to a Firehose stream.
                
            
                Record
                
                    The data of interest that your data producer sends to a Firehose stream. A
                        record can be as large as 1,000 KB.
                
            
                Data producer
                
                    Producers send records to Firehose streams. For example, a web server that
                        sends log data to a Firehose stream is a data producer. You can also
                        configure your Firehose stream to automatically read data from an existing Kinesis
                        data stream, and load it into destinations. For more information, see Send data to a Firehose stream.
                
            
                Buffer size and buffer interval
                
                    Amazon Data Firehose buffers incoming streaming data to a certain size or for a certain
                        period of time before delivering it to destinations. Buffer
                            Size is in MBs and Buffer Interval is in
                        seconds.
                
            

     
        Understand data flow in Amazon Data Firehose


        For Amazon S3 destinations, streaming data is delivered to your S3 bucket. If data
            transformation is enabled, you can optionally back up source data to another Amazon S3
            bucket.

        
             
                
             
             
        

        For Amazon Redshift destinations, streaming data is delivered to your S3 bucket first. Amazon Data Firehose then
            issues an Amazon Redshift COPY command to load data from your S3 bucket to your
            Amazon Redshift cluster. If data transformation is enabled, you can optionally back up source data
            to another Amazon S3 bucket.

        
             
                
             
             
        

        For OpenSearch Service destinations, streaming data is delivered to your OpenSearch
            Service cluster, and it can optionally be backed up to your S3 bucket
            concurrently.

        
             
                
             
             
        

        For Splunk destinations, streaming data is delivered to Splunk, and it can optionally
            be backed up to your S3 bucket concurrently. 

        
             
                
             
             
        

    Document ConventionsWorking with AWS SDKsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS LambdaDeveloper GuideWhen to use LambdaKey featuresWhat is AWS Lambda?You can use AWS Lambda to run code without provisioning or managing servers. Lambda runs your code
    on a high-availability compute infrastructure and performs all of the administration of the compute resources,
    including server and operating system maintenance, capacity provisioning and automatic scaling, and
    logging. With Lambda, all you need to do is supply your code in one of the language runtimes that Lambda supports.You organize your code into Lambda functions. The Lambda service runs your function only when needed and scales automatically. You only pay for the compute time that you consume—there is no charge when your code is not running. For more information, see AWS Lambda Pricing.TipTo learn how to build serverless solutions, check out the Serverless Developer Guide.
    When to use Lambda
    Lambda is an ideal compute service for application scenarios that need to scale up rapidly, and scale down to
      zero when not in demand. For example, you can use Lambda for:
  
     
     
     
     
     
  
      File processing: Use Amazon Simple Storage Service (Amazon S3) to trigger Lambda data processing in real time after an upload.
    
      Stream processing: Use Lambda and Amazon Kinesis to process real-time streaming data for application activity tracking, transaction order processing, clickstream analysis, data cleansing, log filtering, indexing, social media analysis, Internet of Things (IoT) device data telemetry, and metering.
    
      Web applications: Combine Lambda with other AWS services to build powerful web applications that automatically scale up and down and run in a highly available configuration across multiple data centers.
    
      IoT backends: Build serverless backends using Lambda to handle web, mobile, IoT, and third-party API requests.
    
      Mobile backends: Build backends using Lambda and Amazon API Gateway  to authenticate and process API requests. Use AWS Amplify to easily integrate with your iOS, Android, Web, and React Native frontends.
    
    When using Lambda, you are responsible only for your code. Lambda manages the compute fleet that offers a
      balance of memory, CPU, network, and other resources to run your code. Because Lambda manages these resources, you
      cannot log in to compute instances or customize the operating system on provided
        runtimes. Lambda performs operational and administrative activities on your behalf, including managing
      capacity, monitoring, and logging your Lambda functions.
   
    Key features
    The following key features help you develop Lambda applications that are scalable, secure, and easily
      extensible:

    
    
       

       
      
       
      
       
      
       
  
       
      
       
           
       

       
      
       

       

       
      
    
        Environment variables
        
          Use environment variables to adjust your function's behavior without updating code.
        
      
        Versions
        
          Manage the deployment of your functions with versions, so that, for example, a new function can be used for beta testing without affecting users of the stable production version.
        
      
        Container images
        
          Create a container image for a Lambda function by using an AWS provided base image or an alternative base
            image so that you can reuse your existing container tooling or deploy larger workloads that rely on sizable dependencies, such as machine learning.
        
      
        Lambda layers
        
          Package libraries and other dependencies to reduce the size of deployment archives and makes it faster to deploy your code.
        
      
        Lambda extensions
        
          Augment your Lambda functions with tools for monitoring, observability, security, and governance.
        
      
        Function URLs
        
          Add a dedicated HTTP(S) endpoint to your Lambda function.
        
      
        Response streaming
        
          Configure your Lambda function URLs to stream response payloads back to clients from Node.js functions, to improve time to first byte (TTFB) performance or to return larger payloads.
        
      
        Concurrency and scaling controls
        
          Apply fine-grained control over the scaling and responsiveness of your production applications.
        
      
        Code signing
        
          Verify that only approved developers publish unaltered, trusted code in your Lambda functions 
        
      
        Private networking
        
          Create a private network for resources such as databases, cache instances, or internal services.
        
      
        File system
        
          Configure a function to mount an Amazon Elastic File System (Amazon EFS) to a local directory, so that your function code can access and modify shared resources safely and at high concurrency.
        
      
        Lambda SnapStart
        
          Lambda SnapStart can provide as low as sub-second startup performance, typically with no changes to your function code.
        
      
  Document ConventionsCreate your first functionDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationReference guideAWS security credentialsAWS IP address rangesAWS APIsAWS services endpoints and quotasAWS GlossaryAWS General ReferenceThe AWS General Reference provides AWS service endpoint and quota information for Amazon Web Services. Additionally, you can find links to other common topics.ContentsAWS security credentialsAWS IP address rangesAWS APIsAWS services endpoints and quotasAWS Glossary
    AWS security credentials
    
    When you interact with AWS, you specify your AWS security
      credentials to verify who you are and whether you have permission to access the
      resources that you are requesting. AWS uses the security credentials to authenticate and
      authorize your requests.
 
    For more information, see the following resources:
        
    
       
       
      
    
      
      AWS security credentials in the
        IAM User GuideAWS
        security audit guidelines in the
        IAM User Guide
    
   
    AWS IP address ranges
    
    AWS publishes its current IP address ranges in JSON format. You can download
      a .json file to view current ranges. 
    The IP address ranges that you bring to AWS through bring your own IP addresses (BYOIP)
      are not included in the .json file.
    For more information, see the following resources:
    
    
       
       
    AWS IP address ranges in the
        Amazon VPC User GuideAWS services that support IPv6 in the
        Amazon VPC User Guide
   
    AWS APIs
    
    The following pages provide information that is useful when using an AWS API:
    
    
       
       
    Retry behavior in the
        AWS SDKs and Tools Reference GuideSigning AWS API requests in the
        IAM User Guide
    
   
    AWS services endpoints and quotas
    
    You can learn about the endpoints and service quotas in the following pages:
    
    
       
       
       
       
    AWS service endpointsAWS service quotasService endpoints and quotasSpecifying which AWS Regions your account can use in the AWS Account Management Guide
    
    
    
    
    
    
    
   
    AWS Glossary
    
    For the latest AWS terminology, see the AWS Glossary.  
  Document ConventionsAWS service endpointsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUsing policies for dead-letter
                queuesUnderstanding message
                retention periods for dead-letter queuesUsing dead-letter queues in Amazon SQS Amazon SQS supports dead-letter queues (DLQs), which source queues can target for messages that
        are not processed successfully. DLQs are useful for debugging your application because you
        can isolate unconsumed messages to determine why processing did not succeed. For optimal
        performance, it is a best practice to keep the source queue and DLQ within the same
        AWS account and Region. Once messages are in a dead-letter queue, you can:
         
         
         
         
    
            Examine logs for exceptions that might have caused messages to be moved to a
                dead-letter queue.
        
            Analyze the contents of messages moved to the dead-letter queue to diagnose
                application issues.
        
            Determine whether you have given your consumer sufficient time to process
                messages.
        
            Move messages out of the dead-letter queue using dead-letter queue
                redrive.
        You must first create a new queue before configuring it as a dead-letter queue. For
        information about configuring a dead-letter queue using the Amazon SQS console, see Configure a dead-letter queue using the
			Amazon SQS console. For help with dead-letter queues,
        such as how to configure an alarm for any messages moved to a dead-letter queue, see Creating alarms for dead-letter
            queues using Amazon CloudWatch.NoteDon't use a dead-letter queue with a FIFO queue if you don't want to break the exact
            order of messages or operations. For example, don't use a dead-letter queue with
            instructions in an Edit Decision List (EDL) for a video editing suite, where changing
            the order of edits changes the context of subsequent edits.
        Using policies for dead-letter
                queues
        Use a redrive policy to specify the
                maxReceiveCount. The maxReceiveCount is the number of
            times a consumer can receive a message from a source queue before it is moved to a
            dead-letter queue. For example, if the maxReceiveCount is set to a low
            value such as 1, one failure to receive a message would cause the message to move to the
            dead-letter queue. To ensure that your system is resilient against errors, set the
                maxReceiveCount high enough to allow for sufficient retries. 
        The redrive allow policy specifies which source
            queues can access the dead-letter queue. You can choose whether to allow all source
            queues, allow specific source queues, or deny all source queues use of the dead-letter
            queue. The default allows all source queues to use the dead-letter queue. If you choose
            to allow specific queues using the byQueue option, you can specify up to 10
            source queues using the source queue Amazon Resource Name (ARN). If you specify
                denyAll, the queue cannot be used as a dead-letter queue. 
     
        Understanding message
                retention periods for dead-letter queues
        For standard queues, the expiration of a message is always based on its original
            enqueue timestamp. When a message is moved to a dead-letter queue, the enqueue timestamp
            is unchanged. The ApproximateAgeOfOldestMessage metric indicates when the
            message moved to the dead-letter queue, not when the message was originally sent. For
            example, assume that a message spends 1 day in the original queue before it's moved to a
            dead-letter queue. If the dead-letter queue's retention period is 4 days, the message is
            deleted from the dead-letter queue after 3 days and the
                ApproximateAgeOfOldestMessage is 3 days. Thus, it is a best practice to
            always set the retention period of a dead-letter queue to be longer than the retention
            period of the original queue.
        For FIFO queues, the enqueue timestamp resets when the message is moved to a
            dead-letter queue. The ApproximateAgeOfOldestMessage metric indicates when
            the message moved to the dead-letter queue. In the same example above, the message is
            deleted from the dead-letter queue after four days and the
                ApproximateAgeOfOldestMessage is four days. 
    Document ConventionsFeatures and capabilitiesConfiguring a dead-letter queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUsing policies for dead-letter
                queuesUnderstanding message
                retention periods for dead-letter queuesUsing dead-letter queues in Amazon SQS Amazon SQS supports dead-letter queues (DLQs), which source queues can target for messages that
        are not processed successfully. DLQs are useful for debugging your application because you
        can isolate unconsumed messages to determine why processing did not succeed. For optimal
        performance, it is a best practice to keep the source queue and DLQ within the same
        AWS account and Region. Once messages are in a dead-letter queue, you can:
         
         
         
         
    
            Examine logs for exceptions that might have caused messages to be moved to a
                dead-letter queue.
        
            Analyze the contents of messages moved to the dead-letter queue to diagnose
                application issues.
        
            Determine whether you have given your consumer sufficient time to process
                messages.
        
            Move messages out of the dead-letter queue using dead-letter queue
                redrive.
        You must first create a new queue before configuring it as a dead-letter queue. For
        information about configuring a dead-letter queue using the Amazon SQS console, see Configure a dead-letter queue using the
			Amazon SQS console. For help with dead-letter queues,
        such as how to configure an alarm for any messages moved to a dead-letter queue, see Creating alarms for dead-letter
            queues using Amazon CloudWatch.NoteDon't use a dead-letter queue with a FIFO queue if you don't want to break the exact
            order of messages or operations. For example, don't use a dead-letter queue with
            instructions in an Edit Decision List (EDL) for a video editing suite, where changing
            the order of edits changes the context of subsequent edits.
        Using policies for dead-letter
                queues
        Use a redrive policy to specify the
                maxReceiveCount. The maxReceiveCount is the number of
            times a consumer can receive a message from a source queue before it is moved to a
            dead-letter queue. For example, if the maxReceiveCount is set to a low
            value such as 1, one failure to receive a message would cause the message to move to the
            dead-letter queue. To ensure that your system is resilient against errors, set the
                maxReceiveCount high enough to allow for sufficient retries. 
        The redrive allow policy specifies which source
            queues can access the dead-letter queue. You can choose whether to allow all source
            queues, allow specific source queues, or deny all source queues use of the dead-letter
            queue. The default allows all source queues to use the dead-letter queue. If you choose
            to allow specific queues using the byQueue option, you can specify up to 10
            source queues using the source queue Amazon Resource Name (ARN). If you specify
                denyAll, the queue cannot be used as a dead-letter queue. 
     
        Understanding message
                retention periods for dead-letter queues
        For standard queues, the expiration of a message is always based on its original
            enqueue timestamp. When a message is moved to a dead-letter queue, the enqueue timestamp
            is unchanged. The ApproximateAgeOfOldestMessage metric indicates when the
            message moved to the dead-letter queue, not when the message was originally sent. For
            example, assume that a message spends 1 day in the original queue before it's moved to a
            dead-letter queue. If the dead-letter queue's retention period is 4 days, the message is
            deleted from the dead-letter queue after 3 days and the
                ApproximateAgeOfOldestMessage is 3 days. Thus, it is a best practice to
            always set the retention period of a dead-letter queue to be longer than the retention
            period of the original queue.
        For FIFO queues, the enqueue timestamp resets when the message is moved to a
            dead-letter queue. The ApproximateAgeOfOldestMessage metric indicates when
            the message moved to the dead-letter queue. In the same example above, the message is
            deleted from the dead-letter queue after four days and the
                ApproximateAgeOfOldestMessage is four days. 
    Document ConventionsFeatures and capabilitiesConfiguring a dead-letter queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfigure a dead-letter queue using the
			Amazon SQS consoleA dead-letter queue (DLQ) is a queue that receives messages that were not successfully
		processed from another queue, known as the source queue. Amazon SQS does not create the dead-letter queue automatically.
    You must first create the queue before using it as a dead-letter queue.
		When configuring a DLQ, the queue type must match the source queue type—a FIFO queue can only use a FIFO DLQ, and a standard queue can only use a standard DLQ. You can
		configure a dead-letter queue when you create or edit a queue. For more details, see Using dead-letter queues in Amazon SQS .To configure a dead-letter queue for an existing queue (console)Open the Amazon SQS console at
         https://console.aws.amazon.com/sqs/.
			In the navigation pane, choose Queues. 
		
			Select the source queue (the queue that will send
				failed messages to the dead-letter queue), then choose Edit.
			
		
			Scroll to the Dead-letter queue section and toggle
					Enabled.
		
			Under Dead-letter queue settings, choose the
				Amazon Resource Name (ARN) of an existing queue that you want to use as the
					dead-letter queue.
		
			Set the Maximum receives value, which defines how
				many times a message can be received before being sent to the dead-letter queue
				(valid range: 1 to 1,000).
		
			Choose Save.
		Document ConventionsDead-letter queuesConfiguring a
			dead-letter queue redriveDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideCreating alarms for dead-letter
            queues using Amazon CloudWatchSet up a CloudWatch alarm to monitor messages in a dead-letter queue using the ApproximateNumberOfMessagesVisible metric. For detailed
        instructions, see Creating CloudWatch alarms for Amazon SQS
        metrics. When the alarm triggers, indicating
        messages have been moved to the dead-letter queue, you can poll the queue to review and retrieve
        them.Document ConventionsCloudTrail update and permission
            requirementsMessage metadata for Amazon SQSDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring cost allocation tags for a queue using
			the Amazon SQS consoleTo organize and identify your Amazon SQS queues, you can add cost allocation tags. For more
		information, see Amazon SQS cost allocation tags.
		 
		 
	
			The Tagging tab on the Details page displays the queue's tags.
		
			You can add or modify tags when creating or editing a queue.
		To configure tags for an existing queue (console)Open the Amazon SQS console at
         https://console.aws.amazon.com/sqs/.
			In the navigation pane, choose Queues. 
		
			Choose a queue and choose Edit. 
		
			Scroll to the Tags section.
		
			Add, modify, or remove the queue tags:
			
					To add a tag, choose Add new tag, enter a
							Key and Value, and then choose
							Add new tag.
				
					To update a tag, change its Key and
							Value.
				
					To remove a tag, choose Remove next to its key-value
						pair.
				
		
			When you finish configuring the tags, choose Save.
		Document ConventionsConfiguring SSE-KMS for a queueSubscribing a queue to a topicDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Billing and Cost ManagementUser GuideSetting up a monthly cost allocation
                    reportGetting an hourly cost allocation reportViewing a cost allocation reportUsing the monthly cost allocation reportThe monthly cost allocation report lists the AWS usage for your account by product
            category and linked account user. This report contains the same line items as the
            detailed AWS Cost and Usage Report and additional columns for your tag keys. We recommend that you
            use AWS Cost and Usage Report instead. For more information about the monthly allocation report, see the following
            topics.TopicsSetting up a monthly cost allocation
                    reportGetting an hourly cost allocation reportViewing a cost allocation report
            Setting up a monthly cost allocation
                    report
            By default, new tag keys that you add using the API or the AWS Management Console are
                automatically excluded from the cost allocation report. You can add them using the
                procedures described in this topic.
            When you select tag keys to include in your cost allocation report, each key
                becomes an additional column that lists the value for each corresponding line item.
                Because you might use tags for more than just your cost allocation report (for
                example, tags for security or operational reasons), you can include or exclude
                individual tag keys for the report. This ensures that you're seeing meaningful
                billing information that helps organize your costs. A small number of consistent tag
                keys makes it easier to track your costs. For more information, see Viewing a cost allocation report.
            NoteAWS stores billing reports in an Amazon S3 bucket that you create and own. You
                    can retrieve these reports from the bucket using the Amazon S3 API, AWS Management Console for
                    Amazon S3, or the AWS Command Line Interface. You can't download the cost allocation report from the
                        Account Activity page of the Billing and Cost Management
                    console. 
             To set up the cost allocation report and activate tagsSign in to the AWS Management Console and open the AWS Billing and Cost Management console at
       https://console.aws.amazon.com/costmanagement/.
                    Under Detailed billing reports (legacy), choose
                            Edit, and then select Legacy report
                            delivery to S3.
                
                    Choose Configure an S3 bucket to activate to specify
                        where your reports are delivered.
                
                    In the Configure S3 Bucket dialog box, choose one of
                        the following options:
                    
                        
                            To use an existing S3 bucket, choose Use an existing S3
                                    bucket, and then select the S3 bucket.
                        
                        
                            To create a new S3 bucket, choose Create a new S3
                                    bucket, and then for S3 bucket
                                    name, enter the name, and then choose the
                                    Region.
                        
                    
                
                    Choose Next.
                
                    Verify the default IAM policy and then select I have confirmed
                            that this policy is correct.
                
                    Choose Save.
                
                    In the Report list, select the check box for
                            Cost allocation report, and then choose
                            Activate.
                
                    Choose Manage Report Tags.
                    The page displays a list of tags that you've created using either the API
                        or the console for the applicable AWS service. Tag keys that currently
                        appear in the report are selected. Tag keys that are excluded aren't
                        selected.
                
                    You can filter tags that are Inactive in the dropdown
                        list, and then select the tags that you want to activate for your
                        report.
                
                    Choose Activate.
                
            If you own the management account in an organization, your cost allocation report
                includes all the usage, costs, and tags for the member accounts. By default, all
                keys registered by member accounts are available for you to include or exclude from
                your report. The detailed billing report with resources and tags also includes any
                cost allocation tag keys that you select using the preceding steps. 
         
            Getting an hourly cost allocation report
            The cost allocation report is one of several reports that AWS publishes to an
                Amazon S3 bucket several times a day. 
            NoteDuring the current billing period (monthly), AWS generates an estimated cost
                    allocation report. The current month's file is overwritten throughout the
                    billing period until a final report is generated at the end of the billing
                    period. Then a new file is created for the next billing period. The reports for
                    the previous months remain in the designated Amazon S3 bucket.
         
            Viewing a cost allocation report
            The following example tracks the charges for several cost centers and
                applications. Resources (such as Amazon EC2 instances and Amazon S3 buckets) are assigned tags
                like "Cost Center"="78925" and "Application"="Widget1". In the cost allocation
                report, the user-defined tag keys have the prefix user, such as
                    user:Cost Center and user:Application. AWS-generated tag keys
                have the prefix aws. The keys are column headings identifying each
                tagged line item's value, such as "78925".
            
                 
                    
                 
                 
            
            Pick your keys carefully so that you have a consistent hierarchy of values.
                Otherwise, your report won't group costs effectively, and you will have many line
                items.
            NoteIf you add or change the tags on a resource partway through a billing period,
                    costs are split into two separate lines in your cost allocation report. The
                    first line shows costs before the update, and the second line shows costs after
                    the update.
             
                Unallocated resources in your
                        report
                Any charges that cannot be grouped by tags in your cost allocation report
                    default to the standard billing aggregation (organized by Account/Product/Line
                    Item) and are included in your report. Situations where you can have unallocated
                    costs include:
                
                     
                     
                     
                     
                     
                    
                
                        You signed up for a cost allocation report mid-month.
                    
                        Some resources aren't tagged for part, or all, of the billing
                            period.
                    
                        You are using services that currently don't support tagging.
                    
                        Subscription-based charges, such as AWS Support and AWS Marketplace monthly
                            fees, can't be allocated.
                    
                        One-time fees, such as Amazon EC2 Reserved Instance upfront charges, can't
                            be allocated.
                    
             
             
                Unexpected costs associated with tagged
                        resources
                You can use cost allocation tags to see what resources are contributing to your
                    usage and costs, but deleting or deactivating the resources doesn't always
                    reduce your costs. For more information on reducing unexpected costs, see Understanding unexpected charges.
             
        Document ConventionsBackfill cost allocation tagsUnderstanding dates for cost allocation
                tagsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS standard queue quotasThe following table lists quotas related to standard queues.
					
						Quota
						Description
					
				
					
						Delay queue
						The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes.
					
					
						Listed queues
						1,000 queues per ListQueues request.
					
					
						Long polling wait time
						The maximum long polling wait time is 20 seconds.
					
					
						Messages per queue (backlog)
						The number of messages that an Amazon SQS queue can store is unlimited.
					
					
						Messages per queue (in flight)
						
							For most standard queues (depending on queue traffic and message backlog), there can be a maximum of approximately 120,000 in flight messages (received from a queue by a consumer, but not yet deleted from the queue).
    If you reach this quota while using short polling, Amazon SQS returns the OverLimit error message. If you use long polling, Amazon SQS returns no error messages.
    To avoid reaching the quota, you should delete messages from the queue after they're processed. You can also increase the number of queues you use to process your messages.
    To request a quota increase, submit a support request.
						
					
					
						Queue name
						
							A queue name can have up to 80 characters. The following characters are accepted: alphanumeric characters, hyphens (-), and underscores (_).
							NoteQueue names are case-sensitive (for example,
										Test-queue and test-queue are
									different queues).
						
					
					
						Queue tag
						We don't recommend adding more than 50 tags to a queue. Tagging supports Unicode characters in UTF-8.
					
					
						The tag Key is required, but the tag Value
							is optional.
					
					
						The tag Key and tag Value are
							case-sensitive.
					
					
						The tag Key and tag Value can include
							Unicode alphanumeric characters in UTF-8 and whitespaces. The following
							special characters are allowed: _ . : / = + - @
					
					
						The tag Key or Value must not include the
							reserved prefix aws: (you can't delete tag keys or values
							with this prefix).
					
					
						The maximum tag Key length is 128 Unicode characters in
							UTF-8. The tag Key must not be empty or null.
					
					
						The maximum tag Value length is 256 Unicode characters
							in UTF-8. The tag Value may be empty or null.
					
					
						Tagging actions are limited to 30 TPS per AWS account. If your application requires a higher throughput, submit a request.
					
				Document ConventionsFIFO queue quotasMessage quotasDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAudienceAuthenticating with identitiesManaging access using policiesIdentity and access management in
			Amazon SQSAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely control access
      to AWS resources. IAM administrators control who can be authenticated (signed in) and authorized
      (have permissions) to use Amazon SQS resources. IAM is an AWS service that you can
      use with no additional charge.
      Audience 
      
   
      How you use AWS Identity and Access Management (IAM) differs, depending on the work that you do in Amazon SQS.
      Service user – If you use the Amazon SQS service to do your job, then your administrator provides you
         with the credentials and permissions that you need. As you use more Amazon SQS features to do your work, you might need additional permissions.
         Understanding how access is managed can help you request the right permissions from your administrator. If you cannot access a feature in
         Amazon SQS, see Troubleshooting Amazon Simple Queue Service identity and
				access.
      Service administrator – If you're in charge of Amazon SQS resources at your company, you probably have
         full access to Amazon SQS. It's your job to determine which Amazon SQS features and resources your service users should access. You must then
         submit requests to your IAM administrator to change the permissions of your service users. Review the information on this page to understand the
         basic concepts of IAM. To learn more about how your company can use IAM with Amazon SQS, see How Amazon Simple Queue Service works with
				IAM.
      IAM administrator – If you're an IAM administrator, you might want to learn details about how you can
         write policies to manage access to Amazon SQS. To view example Amazon SQS identity-based policies that you can use in IAM, see Policy best
						practices.
   
    
      Authenticating with identities 
      
   
Authentication is how you sign in to AWS using your identity credentials. You must be
authenticated (signed in to AWS) as the AWS account root user, as an
IAM user, or by assuming an IAM role.

You can sign in to AWS as a federated identity by using credentials provided through an identity source.
AWS IAM Identity Center (IAM Identity Center) users, your company's single sign-on authentication, and your Google or Facebook
credentials are examples of federated identities. When you sign in as a federated identity, your administrator previously set up identity federation using IAM roles. When you access AWS by using federation, you are indirectly assuming a role.

Depending on the type of user you are, you can sign in to the AWS Management Console or the AWS access
portal. For more information about signing in to AWS, see How to sign in to your AWS account
in the AWS Sign-In User Guide.

If you access AWS programmatically, AWS provides a software development kit (SDK) and a command line 
interface (CLI) to cryptographically sign your requests by using your credentials. If you don't use AWS tools, 
you must sign requests yourself. For more information about using the recommended method to sign requests yourself, see 
AWS Signature Version 4 for API requests 
in the IAM User Guide.

Regardless of the authentication method that you use, you might be required to provide
additional security information. For example, AWS recommends that you use multi-factor
authentication (MFA) to increase the security of your account. To learn more, see Multi-factor authentication in the
AWS IAM Identity Center User Guide and AWS Multi-factor authentication in IAM in the IAM User Guide.


   
       
         AWS account root user
         

 When you create an AWS account, you begin with one sign-in identity that has complete access to all AWS services
 and resources in the account. This identity is called the AWS account root user and is accessed by
 signing in with the email address and password that you used to create the account. We 
 strongly recommend that you don't use the root user for your everyday tasks. Safeguard your root user credentials and use them to
 perform the tasks that only the root user can perform. For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials in the IAM User Guide.
 
       
       
         Federated identity 
         

As a best practice, require human users, including users that require administrator access, to use federation with an identity provider to access AWS services by using temporary credentials.

A federated identity is a user from your enterprise user directory, a web identity provider, the AWS Directory Service, the Identity Center directory, or any user that
accesses AWS services by using credentials provided through an identity source. When federated identities access AWS accounts, they assume roles, and the roles provide temporary credentials.

For centralized access management, we recommend that you use AWS IAM Identity Center. You can create users and groups in IAM Identity Center, or you can connect and synchronize 
to a set of users and groups in your own identity source for use across all your AWS accounts and applications. For information 
about IAM Identity Center, see What is IAM Identity Center? in the AWS IAM Identity Center User Guide.
 
       
      
         IAM users and groups 
         
   
         An IAM user is an identity within your AWS account that has specific permissions for a single person or application. Where possible, we recommend relying on temporary credentials instead of creating IAM users who have long-term credentials such as passwords and access keys. However, if you have specific use cases that require long-term credentials with IAM users, we recommend that you rotate access keys. For more information, see Rotate access keys regularly for use cases that require long-term credentials in the IAM User Guide.
         
         An IAM group is an identity that specifies a collection of IAM users.
            You can't sign in as a group. You can use groups to specify permissions for multiple users at a time. Groups make permissions easier to manage for
            large sets of users. For example, you could have a group named IAMAdmins and give that group permissions to administer IAM
            resources.
         Users are different from roles. A user is uniquely associated with one person or application, but a role is intended to be assumable by anyone
            who needs it. Users have permanent long-term credentials, but roles provide temporary credentials. To learn more, see Use cases for IAM users in the
               IAM User Guide.
   
       
      
       
         IAM roles 
         
   
         An IAM role is an identity within your AWS account that
            has specific permissions. It is similar to an IAM user, but is not associated with a specific person. To temporarily assume an IAM role in
            the AWS Management Console, you can switch from a user to an IAM role (console). You can assume a role by calling an AWS CLI
            or AWS API operation or by using a custom URL. For more information about methods for using roles, see Methods to assume a role in the IAM User Guide.
         IAM roles with temporary credentials are useful in the following situations:
         
            
             
             
             
             
             
         
               Federated user access – 

To assign permissions to a federated identity, you create a role and define permissions for the role. When a federated identity authenticates, the identity is associated with the role and is granted the permissions that are defined by the role. For information about roles for federation, see 
Create a role for a third-party identity provider (federation) in the IAM User Guide.

If you use IAM Identity Center, you configure a permission set. To control what your identities can access after they authenticate, IAM Identity Center correlates the permission set to a role in IAM. 
For information about permissions sets, see 
Permission sets in the AWS IAM Identity Center User Guide.

            
               Temporary IAM user permissions – An IAM user or role can assume an IAM role to temporarily take on
            different permissions for a specific task.
            
               Cross-account access – You can use an
                  IAM role to allow someone (a trusted principal) in a different account to access
                  resources in your account. Roles are the primary way to grant cross-account
                  access. However, with some AWS services, you can attach a policy directly to a
                  resource (instead of using a role as a proxy). To learn the difference between
                  roles and resource-based policies for cross-account access, see Cross account resource access in IAM in the
                     IAM User Guide.
            
               Cross-service access –

      Some AWS services use features in other AWS services. For example, when you make a call in a service, 
      it's common for that service to run applications in Amazon EC2 or store objects in Amazon S3. A service might do this 
      using the calling principal's permissions, using a service role, or using a service-linked role.
  
                  
                      
                      
                      
                  
                        Forward access sessions (FAS) –

      When you use an IAM user or role to perform actions in AWS, you are considered a principal. When you use some services, you might perform an action that then initiates
      another action in a different service. FAS uses the permissions of the principal calling an AWS service, combined with the requesting AWS service to make requests to downstream services.
      FAS requests are only made when a service receives a request that requires interactions with other AWS services or resources to complete. In this case, you must have permissions to
      perform both actions. For policy details
      when making FAS requests, see Forward access sessions.
 
                     
                        Service role –

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
                     
                        Service-linked role –

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
                     
            
               Applications running on Amazon EC2 –

      You can use an IAM role to manage temporary credentials for applications that are running on an EC2 instance and making AWS CLI or AWS API requests. 
      This is preferable to storing access keys within the EC2 instance. To assign an AWS role to an EC2 instance and make it 
      available to all of its applications, you create an instance profile that is attached to the 
      instance. An instance profile contains the role and enables programs that are running on the EC2 instance to
      get temporary credentials. For more information, see Use an IAM role to grant permissions to applications running on Amazon EC2 instances in the 
      IAM User Guide.
 
            
   
       
    
      Managing access using policies 
      
   
 You control access in AWS by creating policies and attaching them to AWS identities or resources. A policy is an object in AWS that,
 when associated with an identity or resource, defines their permissions. AWS evaluates these policies when a principal (user, root user, or role session) makes a request. 
 Permissions in the policies determine whether the request is allowed or denied. 
 Most policies are stored in AWS as JSON documents. For more information about the structure and contents 
 of JSON policy documents, see Overview of JSON policies in the 
 IAM User Guide.

 
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  

By default, users and roles have no permissions. To grant users permission to perform actions on the resources that they need, an 
IAM administrator can create IAM policies. The administrator can then add the IAM policies to roles, and users can assume the roles.
 IAM policies define permissions for an action regardless of the method that you use to perform the operation. For example, suppose that you have a
 policy that allows the iam:GetRole action. A user with that policy can get role information from the AWS Management Console, the AWS CLI, or the AWS
 API.
   
       
         Identity-based
               policies 
         
   
         
   
         Identity-based policies are JSON permissions policy documents that you can attach to an identity, such as an IAM user, group of users, or role. These
            policies control what actions users and roles can perform, on which resources, and under what conditions. To learn how to create an identity-based
            policy, see Define custom IAM permissions with customer managed policies in the
            IAM User Guide.
  
         Identity-based policies can be further categorized as inline policies or managed
               policies. Inline policies are embedded directly into a single user, group, or role. Managed policies are standalone policies that you
            can attach to multiple users, groups, and roles in your AWS account. Managed policies include AWS managed policies and customer managed
            policies. To learn how to choose between a managed policy or an inline policy, see Choose between managed policies and inline policies in the IAM User Guide.
   
       
       
         Resource-based
               policies 
         
   
   
   
         Resource-based policies are JSON policy documents that you attach to a resource. Examples of resource-based policies are 
         IAM role trust policies and Amazon S3 bucket policies. In services that support resource-based policies, service 
         administrators can use them to control access to a specific resource. For the resource where the policy is attached, the policy defines what actions
            a specified principal can perform on that resource and under what conditions. You must specify a principal in a resource-based policy. Principals 
            can include accounts, users, roles, federated users, or AWS services.
  
   Resource-based policies are inline policies that are located in that service. You can't use AWS managed policies from IAM in a 
   resource-based policy.
   
       
       
         Access control lists (ACLs) 
         
   
      
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
      Amazon S3, AWS WAF, and Amazon VPC
            are examples of services that support ACLs. To learn more about ACLs, see Access control list (ACL)
               overview in the Amazon Simple Storage Service Developer Guide.
   
       
       
         Other policy types 
         
   
         AWS supports additional, less-common policy types. These policy types can set the maximum permissions granted to you by the more common policy
            types. 
         
             
             
             
             
         
               Permissions boundaries – A permissions
                  boundary is an advanced feature in which you set the maximum permissions that an
                  identity-based policy can grant to an IAM entity (IAM user or role). You can
                  set a permissions boundary for an entity. The resulting permissions are the
                  intersection of an entity's identity-based policies and its permissions boundaries.
                  Resource-based policies that specify the user or role in the
                     Principal field are not limited by the permissions boundary. An
                  explicit deny in any of these policies overrides the allow. For more information
                  about permissions boundaries, see Permissions boundaries for
                     IAM entities in the IAM User Guide.
            
               Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions for
                  an organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a service for grouping and centrally managing multiple AWS accounts that your business owns. If you enable all features in an organization, then you can apply service control policies (SCPs) to any or all of
                  your accounts. The SCP limits permissions for entities in member accounts, including each AWS account root user. For more information about Organizations and
                  SCPs, see Service control policies in the AWS Organizations User Guide.
            
            Resource control policies (RCPs) – RCPs
                are JSON policies that you can use to set the maximum available permissions for
                resources in your accounts without updating the IAM policies attached to each
                resource that you own. The RCP limits permissions for resources in member accounts
                and can impact the effective permissions for identities, including the AWS account root user,
                regardless of whether they belong to your organization. For more information about
                Organizations and RCPs, including a list of AWS services that support RCPs, see Resource
                    control policies (RCPs) in the AWS Organizations User Guide.
            
               Session policies – Session policies are
                  advanced policies that you pass as a parameter when you programmatically create a
                  temporary session for a role or federated user. The resulting session's
                  permissions are the intersection of the user or role's identity-based policies and
                  the session policies. Permissions can also come from a resource-based policy. An
                  explicit deny in any of these policies overrides the allow. For more information,
                  see Session
                     policies in the IAM User Guide. 
            
   
       
       
         Multiple policy
               types 
         
   
         When multiple types of policies apply to a request, the resulting permissions are more complicated to understand. To learn how AWS determines
            whether to allow a request when multiple policy types are involved, see Policy
               evaluation logic in the IAM User Guide.
   
       
   Document ConventionsInternetwork traffic privacyOverviewDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAudienceAuthenticating with identitiesManaging access using policiesIdentity and access management in
			Amazon SQSAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely control access
      to AWS resources. IAM administrators control who can be authenticated (signed in) and authorized
      (have permissions) to use Amazon SQS resources. IAM is an AWS service that you can
      use with no additional charge.
      Audience 
      
   
      How you use AWS Identity and Access Management (IAM) differs, depending on the work that you do in Amazon SQS.
      Service user – If you use the Amazon SQS service to do your job, then your administrator provides you
         with the credentials and permissions that you need. As you use more Amazon SQS features to do your work, you might need additional permissions.
         Understanding how access is managed can help you request the right permissions from your administrator. If you cannot access a feature in
         Amazon SQS, see Troubleshooting Amazon Simple Queue Service identity and
				access.
      Service administrator – If you're in charge of Amazon SQS resources at your company, you probably have
         full access to Amazon SQS. It's your job to determine which Amazon SQS features and resources your service users should access. You must then
         submit requests to your IAM administrator to change the permissions of your service users. Review the information on this page to understand the
         basic concepts of IAM. To learn more about how your company can use IAM with Amazon SQS, see How Amazon Simple Queue Service works with
				IAM.
      IAM administrator – If you're an IAM administrator, you might want to learn details about how you can
         write policies to manage access to Amazon SQS. To view example Amazon SQS identity-based policies that you can use in IAM, see Policy best
						practices.
   
    
      Authenticating with identities 
      
   
Authentication is how you sign in to AWS using your identity credentials. You must be
authenticated (signed in to AWS) as the AWS account root user, as an
IAM user, or by assuming an IAM role.

You can sign in to AWS as a federated identity by using credentials provided through an identity source.
AWS IAM Identity Center (IAM Identity Center) users, your company's single sign-on authentication, and your Google or Facebook
credentials are examples of federated identities. When you sign in as a federated identity, your administrator previously set up identity federation using IAM roles. When you access AWS by using federation, you are indirectly assuming a role.

Depending on the type of user you are, you can sign in to the AWS Management Console or the AWS access
portal. For more information about signing in to AWS, see How to sign in to your AWS account
in the AWS Sign-In User Guide.

If you access AWS programmatically, AWS provides a software development kit (SDK) and a command line 
interface (CLI) to cryptographically sign your requests by using your credentials. If you don't use AWS tools, 
you must sign requests yourself. For more information about using the recommended method to sign requests yourself, see 
AWS Signature Version 4 for API requests 
in the IAM User Guide.

Regardless of the authentication method that you use, you might be required to provide
additional security information. For example, AWS recommends that you use multi-factor
authentication (MFA) to increase the security of your account. To learn more, see Multi-factor authentication in the
AWS IAM Identity Center User Guide and AWS Multi-factor authentication in IAM in the IAM User Guide.


   
       
         AWS account root user
         

 When you create an AWS account, you begin with one sign-in identity that has complete access to all AWS services
 and resources in the account. This identity is called the AWS account root user and is accessed by
 signing in with the email address and password that you used to create the account. We 
 strongly recommend that you don't use the root user for your everyday tasks. Safeguard your root user credentials and use them to
 perform the tasks that only the root user can perform. For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials in the IAM User Guide.
 
       
       
         Federated identity 
         

As a best practice, require human users, including users that require administrator access, to use federation with an identity provider to access AWS services by using temporary credentials.

A federated identity is a user from your enterprise user directory, a web identity provider, the AWS Directory Service, the Identity Center directory, or any user that
accesses AWS services by using credentials provided through an identity source. When federated identities access AWS accounts, they assume roles, and the roles provide temporary credentials.

For centralized access management, we recommend that you use AWS IAM Identity Center. You can create users and groups in IAM Identity Center, or you can connect and synchronize 
to a set of users and groups in your own identity source for use across all your AWS accounts and applications. For information 
about IAM Identity Center, see What is IAM Identity Center? in the AWS IAM Identity Center User Guide.
 
       
      
         IAM users and groups 
         
   
         An IAM user is an identity within your AWS account that has specific permissions for a single person or application. Where possible, we recommend relying on temporary credentials instead of creating IAM users who have long-term credentials such as passwords and access keys. However, if you have specific use cases that require long-term credentials with IAM users, we recommend that you rotate access keys. For more information, see Rotate access keys regularly for use cases that require long-term credentials in the IAM User Guide.
         
         An IAM group is an identity that specifies a collection of IAM users.
            You can't sign in as a group. You can use groups to specify permissions for multiple users at a time. Groups make permissions easier to manage for
            large sets of users. For example, you could have a group named IAMAdmins and give that group permissions to administer IAM
            resources.
         Users are different from roles. A user is uniquely associated with one person or application, but a role is intended to be assumable by anyone
            who needs it. Users have permanent long-term credentials, but roles provide temporary credentials. To learn more, see Use cases for IAM users in the
               IAM User Guide.
   
       
      
       
         IAM roles 
         
   
         An IAM role is an identity within your AWS account that
            has specific permissions. It is similar to an IAM user, but is not associated with a specific person. To temporarily assume an IAM role in
            the AWS Management Console, you can switch from a user to an IAM role (console). You can assume a role by calling an AWS CLI
            or AWS API operation or by using a custom URL. For more information about methods for using roles, see Methods to assume a role in the IAM User Guide.
         IAM roles with temporary credentials are useful in the following situations:
         
            
             
             
             
             
             
         
               Federated user access – 

To assign permissions to a federated identity, you create a role and define permissions for the role. When a federated identity authenticates, the identity is associated with the role and is granted the permissions that are defined by the role. For information about roles for federation, see 
Create a role for a third-party identity provider (federation) in the IAM User Guide.

If you use IAM Identity Center, you configure a permission set. To control what your identities can access after they authenticate, IAM Identity Center correlates the permission set to a role in IAM. 
For information about permissions sets, see 
Permission sets in the AWS IAM Identity Center User Guide.

            
               Temporary IAM user permissions – An IAM user or role can assume an IAM role to temporarily take on
            different permissions for a specific task.
            
               Cross-account access – You can use an
                  IAM role to allow someone (a trusted principal) in a different account to access
                  resources in your account. Roles are the primary way to grant cross-account
                  access. However, with some AWS services, you can attach a policy directly to a
                  resource (instead of using a role as a proxy). To learn the difference between
                  roles and resource-based policies for cross-account access, see Cross account resource access in IAM in the
                     IAM User Guide.
            
               Cross-service access –

      Some AWS services use features in other AWS services. For example, when you make a call in a service, 
      it's common for that service to run applications in Amazon EC2 or store objects in Amazon S3. A service might do this 
      using the calling principal's permissions, using a service role, or using a service-linked role.
  
                  
                      
                      
                      
                  
                        Forward access sessions (FAS) –

      When you use an IAM user or role to perform actions in AWS, you are considered a principal. When you use some services, you might perform an action that then initiates
      another action in a different service. FAS uses the permissions of the principal calling an AWS service, combined with the requesting AWS service to make requests to downstream services.
      FAS requests are only made when a service receives a request that requires interactions with other AWS services or resources to complete. In this case, you must have permissions to
      perform both actions. For policy details
      when making FAS requests, see Forward access sessions.
 
                     
                        Service role –

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
                     
                        Service-linked role –

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
                     
            
               Applications running on Amazon EC2 –

      You can use an IAM role to manage temporary credentials for applications that are running on an EC2 instance and making AWS CLI or AWS API requests. 
      This is preferable to storing access keys within the EC2 instance. To assign an AWS role to an EC2 instance and make it 
      available to all of its applications, you create an instance profile that is attached to the 
      instance. An instance profile contains the role and enables programs that are running on the EC2 instance to
      get temporary credentials. For more information, see Use an IAM role to grant permissions to applications running on Amazon EC2 instances in the 
      IAM User Guide.
 
            
   
       
    
      Managing access using policies 
      
   
 You control access in AWS by creating policies and attaching them to AWS identities or resources. A policy is an object in AWS that,
 when associated with an identity or resource, defines their permissions. AWS evaluates these policies when a principal (user, root user, or role session) makes a request. 
 Permissions in the policies determine whether the request is allowed or denied. 
 Most policies are stored in AWS as JSON documents. For more information about the structure and contents 
 of JSON policy documents, see Overview of JSON policies in the 
 IAM User Guide.

 
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  

By default, users and roles have no permissions. To grant users permission to perform actions on the resources that they need, an 
IAM administrator can create IAM policies. The administrator can then add the IAM policies to roles, and users can assume the roles.
 IAM policies define permissions for an action regardless of the method that you use to perform the operation. For example, suppose that you have a
 policy that allows the iam:GetRole action. A user with that policy can get role information from the AWS Management Console, the AWS CLI, or the AWS
 API.
   
       
         Identity-based
               policies 
         
   
         
   
         Identity-based policies are JSON permissions policy documents that you can attach to an identity, such as an IAM user, group of users, or role. These
            policies control what actions users and roles can perform, on which resources, and under what conditions. To learn how to create an identity-based
            policy, see Define custom IAM permissions with customer managed policies in the
            IAM User Guide.
  
         Identity-based policies can be further categorized as inline policies or managed
               policies. Inline policies are embedded directly into a single user, group, or role. Managed policies are standalone policies that you
            can attach to multiple users, groups, and roles in your AWS account. Managed policies include AWS managed policies and customer managed
            policies. To learn how to choose between a managed policy or an inline policy, see Choose between managed policies and inline policies in the IAM User Guide.
   
       
       
         Resource-based
               policies 
         
   
   
   
         Resource-based policies are JSON policy documents that you attach to a resource. Examples of resource-based policies are 
         IAM role trust policies and Amazon S3 bucket policies. In services that support resource-based policies, service 
         administrators can use them to control access to a specific resource. For the resource where the policy is attached, the policy defines what actions
            a specified principal can perform on that resource and under what conditions. You must specify a principal in a resource-based policy. Principals 
            can include accounts, users, roles, federated users, or AWS services.
  
   Resource-based policies are inline policies that are located in that service. You can't use AWS managed policies from IAM in a 
   resource-based policy.
   
       
       
         Access control lists (ACLs) 
         
   
      
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
      Amazon S3, AWS WAF, and Amazon VPC
            are examples of services that support ACLs. To learn more about ACLs, see Access control list (ACL)
               overview in the Amazon Simple Storage Service Developer Guide.
   
       
       
         Other policy types 
         
   
         AWS supports additional, less-common policy types. These policy types can set the maximum permissions granted to you by the more common policy
            types. 
         
             
             
             
             
         
               Permissions boundaries – A permissions
                  boundary is an advanced feature in which you set the maximum permissions that an
                  identity-based policy can grant to an IAM entity (IAM user or role). You can
                  set a permissions boundary for an entity. The resulting permissions are the
                  intersection of an entity's identity-based policies and its permissions boundaries.
                  Resource-based policies that specify the user or role in the
                     Principal field are not limited by the permissions boundary. An
                  explicit deny in any of these policies overrides the allow. For more information
                  about permissions boundaries, see Permissions boundaries for
                     IAM entities in the IAM User Guide.
            
               Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions for
                  an organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a service for grouping and centrally managing multiple AWS accounts that your business owns. If you enable all features in an organization, then you can apply service control policies (SCPs) to any or all of
                  your accounts. The SCP limits permissions for entities in member accounts, including each AWS account root user. For more information about Organizations and
                  SCPs, see Service control policies in the AWS Organizations User Guide.
            
            Resource control policies (RCPs) – RCPs
                are JSON policies that you can use to set the maximum available permissions for
                resources in your accounts without updating the IAM policies attached to each
                resource that you own. The RCP limits permissions for resources in member accounts
                and can impact the effective permissions for identities, including the AWS account root user,
                regardless of whether they belong to your organization. For more information about
                Organizations and RCPs, including a list of AWS services that support RCPs, see Resource
                    control policies (RCPs) in the AWS Organizations User Guide.
            
               Session policies – Session policies are
                  advanced policies that you pass as a parameter when you programmatically create a
                  temporary session for a role or federated user. The resulting session's
                  permissions are the intersection of the user or role's identity-based policies and
                  the session policies. Permissions can also come from a resource-based policy. An
                  explicit deny in any of these policies overrides the allow. For more information,
                  see Session
                     policies in the IAM User Guide. 
            
   
       
       
         Multiple policy
               types 
         
   
         When multiple types of policies apply to a request, the resulting permissions are more complicated to understand. To learn how AWS determines
            whether to allow a request when multiple policy types are involved, see Policy
               evaluation logic in the IAM User Guide.
   
       
   Document ConventionsInternetwork traffic privacyOverviewDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAudienceAuthenticating with identitiesManaging access using policiesIdentity and access management in
			Amazon SQSAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely control access
      to AWS resources. IAM administrators control who can be authenticated (signed in) and authorized
      (have permissions) to use Amazon SQS resources. IAM is an AWS service that you can
      use with no additional charge.
      Audience 
      
   
      How you use AWS Identity and Access Management (IAM) differs, depending on the work that you do in Amazon SQS.
      Service user – If you use the Amazon SQS service to do your job, then your administrator provides you
         with the credentials and permissions that you need. As you use more Amazon SQS features to do your work, you might need additional permissions.
         Understanding how access is managed can help you request the right permissions from your administrator. If you cannot access a feature in
         Amazon SQS, see Troubleshooting Amazon Simple Queue Service identity and
				access.
      Service administrator – If you're in charge of Amazon SQS resources at your company, you probably have
         full access to Amazon SQS. It's your job to determine which Amazon SQS features and resources your service users should access. You must then
         submit requests to your IAM administrator to change the permissions of your service users. Review the information on this page to understand the
         basic concepts of IAM. To learn more about how your company can use IAM with Amazon SQS, see How Amazon Simple Queue Service works with
				IAM.
      IAM administrator – If you're an IAM administrator, you might want to learn details about how you can
         write policies to manage access to Amazon SQS. To view example Amazon SQS identity-based policies that you can use in IAM, see Policy best
						practices.
   
    
      Authenticating with identities 
      
   
Authentication is how you sign in to AWS using your identity credentials. You must be
authenticated (signed in to AWS) as the AWS account root user, as an
IAM user, or by assuming an IAM role.

You can sign in to AWS as a federated identity by using credentials provided through an identity source.
AWS IAM Identity Center (IAM Identity Center) users, your company's single sign-on authentication, and your Google or Facebook
credentials are examples of federated identities. When you sign in as a federated identity, your administrator previously set up identity federation using IAM roles. When you access AWS by using federation, you are indirectly assuming a role.

Depending on the type of user you are, you can sign in to the AWS Management Console or the AWS access
portal. For more information about signing in to AWS, see How to sign in to your AWS account
in the AWS Sign-In User Guide.

If you access AWS programmatically, AWS provides a software development kit (SDK) and a command line 
interface (CLI) to cryptographically sign your requests by using your credentials. If you don't use AWS tools, 
you must sign requests yourself. For more information about using the recommended method to sign requests yourself, see 
AWS Signature Version 4 for API requests 
in the IAM User Guide.

Regardless of the authentication method that you use, you might be required to provide
additional security information. For example, AWS recommends that you use multi-factor
authentication (MFA) to increase the security of your account. To learn more, see Multi-factor authentication in the
AWS IAM Identity Center User Guide and AWS Multi-factor authentication in IAM in the IAM User Guide.


   
       
         AWS account root user
         

 When you create an AWS account, you begin with one sign-in identity that has complete access to all AWS services
 and resources in the account. This identity is called the AWS account root user and is accessed by
 signing in with the email address and password that you used to create the account. We 
 strongly recommend that you don't use the root user for your everyday tasks. Safeguard your root user credentials and use them to
 perform the tasks that only the root user can perform. For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials in the IAM User Guide.
 
       
       
         Federated identity 
         

As a best practice, require human users, including users that require administrator access, to use federation with an identity provider to access AWS services by using temporary credentials.

A federated identity is a user from your enterprise user directory, a web identity provider, the AWS Directory Service, the Identity Center directory, or any user that
accesses AWS services by using credentials provided through an identity source. When federated identities access AWS accounts, they assume roles, and the roles provide temporary credentials.

For centralized access management, we recommend that you use AWS IAM Identity Center. You can create users and groups in IAM Identity Center, or you can connect and synchronize 
to a set of users and groups in your own identity source for use across all your AWS accounts and applications. For information 
about IAM Identity Center, see What is IAM Identity Center? in the AWS IAM Identity Center User Guide.
 
       
      
         IAM users and groups 
         
   
         An IAM user is an identity within your AWS account that has specific permissions for a single person or application. Where possible, we recommend relying on temporary credentials instead of creating IAM users who have long-term credentials such as passwords and access keys. However, if you have specific use cases that require long-term credentials with IAM users, we recommend that you rotate access keys. For more information, see Rotate access keys regularly for use cases that require long-term credentials in the IAM User Guide.
         
         An IAM group is an identity that specifies a collection of IAM users.
            You can't sign in as a group. You can use groups to specify permissions for multiple users at a time. Groups make permissions easier to manage for
            large sets of users. For example, you could have a group named IAMAdmins and give that group permissions to administer IAM
            resources.
         Users are different from roles. A user is uniquely associated with one person or application, but a role is intended to be assumable by anyone
            who needs it. Users have permanent long-term credentials, but roles provide temporary credentials. To learn more, see Use cases for IAM users in the
               IAM User Guide.
   
       
      
       
         IAM roles 
         
   
         An IAM role is an identity within your AWS account that
            has specific permissions. It is similar to an IAM user, but is not associated with a specific person. To temporarily assume an IAM role in
            the AWS Management Console, you can switch from a user to an IAM role (console). You can assume a role by calling an AWS CLI
            or AWS API operation or by using a custom URL. For more information about methods for using roles, see Methods to assume a role in the IAM User Guide.
         IAM roles with temporary credentials are useful in the following situations:
         
            
             
             
             
             
             
         
               Federated user access – 

To assign permissions to a federated identity, you create a role and define permissions for the role. When a federated identity authenticates, the identity is associated with the role and is granted the permissions that are defined by the role. For information about roles for federation, see 
Create a role for a third-party identity provider (federation) in the IAM User Guide.

If you use IAM Identity Center, you configure a permission set. To control what your identities can access after they authenticate, IAM Identity Center correlates the permission set to a role in IAM. 
For information about permissions sets, see 
Permission sets in the AWS IAM Identity Center User Guide.

            
               Temporary IAM user permissions – An IAM user or role can assume an IAM role to temporarily take on
            different permissions for a specific task.
            
               Cross-account access – You can use an
                  IAM role to allow someone (a trusted principal) in a different account to access
                  resources in your account. Roles are the primary way to grant cross-account
                  access. However, with some AWS services, you can attach a policy directly to a
                  resource (instead of using a role as a proxy). To learn the difference between
                  roles and resource-based policies for cross-account access, see Cross account resource access in IAM in the
                     IAM User Guide.
            
               Cross-service access –

      Some AWS services use features in other AWS services. For example, when you make a call in a service, 
      it's common for that service to run applications in Amazon EC2 or store objects in Amazon S3. A service might do this 
      using the calling principal's permissions, using a service role, or using a service-linked role.
  
                  
                      
                      
                      
                  
                        Forward access sessions (FAS) –

      When you use an IAM user or role to perform actions in AWS, you are considered a principal. When you use some services, you might perform an action that then initiates
      another action in a different service. FAS uses the permissions of the principal calling an AWS service, combined with the requesting AWS service to make requests to downstream services.
      FAS requests are only made when a service receives a request that requires interactions with other AWS services or resources to complete. In this case, you must have permissions to
      perform both actions. For policy details
      when making FAS requests, see Forward access sessions.
 
                     
                        Service role –

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
                     
                        Service-linked role –

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
                     
            
               Applications running on Amazon EC2 –

      You can use an IAM role to manage temporary credentials for applications that are running on an EC2 instance and making AWS CLI or AWS API requests. 
      This is preferable to storing access keys within the EC2 instance. To assign an AWS role to an EC2 instance and make it 
      available to all of its applications, you create an instance profile that is attached to the 
      instance. An instance profile contains the role and enables programs that are running on the EC2 instance to
      get temporary credentials. For more information, see Use an IAM role to grant permissions to applications running on Amazon EC2 instances in the 
      IAM User Guide.
 
            
   
       
    
      Managing access using policies 
      
   
 You control access in AWS by creating policies and attaching them to AWS identities or resources. A policy is an object in AWS that,
 when associated with an identity or resource, defines their permissions. AWS evaluates these policies when a principal (user, root user, or role session) makes a request. 
 Permissions in the policies determine whether the request is allowed or denied. 
 Most policies are stored in AWS as JSON documents. For more information about the structure and contents 
 of JSON policy documents, see Overview of JSON policies in the 
 IAM User Guide.

 
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  

By default, users and roles have no permissions. To grant users permission to perform actions on the resources that they need, an 
IAM administrator can create IAM policies. The administrator can then add the IAM policies to roles, and users can assume the roles.
 IAM policies define permissions for an action regardless of the method that you use to perform the operation. For example, suppose that you have a
 policy that allows the iam:GetRole action. A user with that policy can get role information from the AWS Management Console, the AWS CLI, or the AWS
 API.
   
       
         Identity-based
               policies 
         
   
         
   
         Identity-based policies are JSON permissions policy documents that you can attach to an identity, such as an IAM user, group of users, or role. These
            policies control what actions users and roles can perform, on which resources, and under what conditions. To learn how to create an identity-based
            policy, see Define custom IAM permissions with customer managed policies in the
            IAM User Guide.
  
         Identity-based policies can be further categorized as inline policies or managed
               policies. Inline policies are embedded directly into a single user, group, or role. Managed policies are standalone policies that you
            can attach to multiple users, groups, and roles in your AWS account. Managed policies include AWS managed policies and customer managed
            policies. To learn how to choose between a managed policy or an inline policy, see Choose between managed policies and inline policies in the IAM User Guide.
   
       
       
         Resource-based
               policies 
         
   
   
   
         Resource-based policies are JSON policy documents that you attach to a resource. Examples of resource-based policies are 
         IAM role trust policies and Amazon S3 bucket policies. In services that support resource-based policies, service 
         administrators can use them to control access to a specific resource. For the resource where the policy is attached, the policy defines what actions
            a specified principal can perform on that resource and under what conditions. You must specify a principal in a resource-based policy. Principals 
            can include accounts, users, roles, federated users, or AWS services.
  
   Resource-based policies are inline policies that are located in that service. You can't use AWS managed policies from IAM in a 
   resource-based policy.
   
       
       
         Access control lists (ACLs) 
         
   
      
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
      Amazon S3, AWS WAF, and Amazon VPC
            are examples of services that support ACLs. To learn more about ACLs, see Access control list (ACL)
               overview in the Amazon Simple Storage Service Developer Guide.
   
       
       
         Other policy types 
         
   
         AWS supports additional, less-common policy types. These policy types can set the maximum permissions granted to you by the more common policy
            types. 
         
             
             
             
             
         
               Permissions boundaries – A permissions
                  boundary is an advanced feature in which you set the maximum permissions that an
                  identity-based policy can grant to an IAM entity (IAM user or role). You can
                  set a permissions boundary for an entity. The resulting permissions are the
                  intersection of an entity's identity-based policies and its permissions boundaries.
                  Resource-based policies that specify the user or role in the
                     Principal field are not limited by the permissions boundary. An
                  explicit deny in any of these policies overrides the allow. For more information
                  about permissions boundaries, see Permissions boundaries for
                     IAM entities in the IAM User Guide.
            
               Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions for
                  an organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a service for grouping and centrally managing multiple AWS accounts that your business owns. If you enable all features in an organization, then you can apply service control policies (SCPs) to any or all of
                  your accounts. The SCP limits permissions for entities in member accounts, including each AWS account root user. For more information about Organizations and
                  SCPs, see Service control policies in the AWS Organizations User Guide.
            
            Resource control policies (RCPs) – RCPs
                are JSON policies that you can use to set the maximum available permissions for
                resources in your accounts without updating the IAM policies attached to each
                resource that you own. The RCP limits permissions for resources in member accounts
                and can impact the effective permissions for identities, including the AWS account root user,
                regardless of whether they belong to your organization. For more information about
                Organizations and RCPs, including a list of AWS services that support RCPs, see Resource
                    control policies (RCPs) in the AWS Organizations User Guide.
            
               Session policies – Session policies are
                  advanced policies that you pass as a parameter when you programmatically create a
                  temporary session for a role or federated user. The resulting session's
                  permissions are the intersection of the user or role's identity-based policies and
                  the session policies. Permissions can also come from a resource-based policy. An
                  explicit deny in any of these policies overrides the allow. For more information,
                  see Session
                     policies in the IAM User Guide. 
            
   
       
       
         Multiple policy
               types 
         
   
         When multiple types of policies apply to a request, the resulting permissions are more complicated to understand. To learn how AWS determines
            whether to allow a request when multiple policy types are involved, see Policy
               evaluation logic in the IAM User Guide.
   
       
   Document ConventionsInternetwork traffic privacyOverviewDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideI am not authorized to
					perform an action in Amazon SQSI am not authorized to perform
					iam:PassRoleI want to allow
					people outside of my AWS account to access my Amazon SQS resourcesI want to unlock my queueTroubleshooting Amazon Simple Queue Service identity and
				accessUse the following information to help you diagnose and fix common issues that you might
         encounter when working with Amazon SQS and IAM.
			I am not authorized to
					perform an action in Amazon SQS
			
			If you receive an error that you're not authorized to perform an action, your
				policies must be updated to allow you to perform the action.
			The following example error occurs when the mateojackson user tries
				to use the console to view details about a fictional
						my-example-widget resource but does
				not have the fictional
					sqs:GetWidget
				permissions.
			User: arn:aws:iam::123456789012:user/mateojackson is not authorized to perform: sqs:GetWidget on resource: my-example-widget
			In this case, Mateo's policy must be updated to allow him to access the
						my-example-widget resource using the
						sqs:GetWidget
				action.
			If you need help, contact your AWS administrator. Your administrator is the
				person who provided you with your sign-in credentials.
		 
			I am not authorized to perform
					iam:PassRole
			
    
 If you receive an error that you're not authorized to perform the iam:PassRole action, your policies must be updated to allow you to pass a role to Amazon SQS.
 Some AWS services allow you to pass an existing role to that service instead of creating a new service role or service-linked role. To do
 this, you must have permissions to pass the role to the service.
 The following example error occurs when an IAM user named marymajor tries to use the console to perform an action in
 Amazon SQS. However, the action requires the service to have permissions that are granted by a service role. Mary does not have permissions to pass the
 role to the service.
 User: arn:aws:iam::123456789012:user/marymajor is not authorized to perform: iam:PassRole
 In this case, Mary's policies must be updated to allow her to perform the iam:PassRole action.
 If you need help, contact your AWS administrator. Your administrator is the person who provided you with your sign-in credentials.
  
		 
			I want to allow
					people outside of my AWS account to access my Amazon SQS resources
			
   
   You can create a role that users in other accounts or people outside of your organization can use to access your resources. You can specify who
            is trusted to assume the role. For services that support resource-based policies or access control lists (ACLs), you can use those policies to grant
            people access to your resources.
         To learn more, consult the following:
         
             
             
             
             
             
         
               To learn whether Amazon SQS supports these features, see How Amazon Simple Queue Service works with
				IAM.
            
               To learn how to provide access to your resources across AWS accounts that you own, see Providing access to an IAM user in another AWS account that you
                     own in the IAM User Guide.
            
               To learn how to provide access to your resources to third-party AWS accounts, see Providing access to AWS accounts owned by third parties in the
                     IAM User Guide.
            
               To learn how to provide access through identity federation, see Providing access to externally authenticated users (identity federation) in the IAM User Guide.
            
               To learn the difference between using roles and resource-based policies for cross-account access, see Cross account resource access in IAM in the
                     IAM User Guide.
            
  
		 
  I want to unlock my queue
  If your AWS account belongs to an organization, AWS Organizations policies can block you from
    accessing Amazon SQS resources. By default, AWS Organizations policies don't block any requests to Amazon SQS.
    However, make sure that your AWS Organizations policies haven’t been configured to block access to Amazon SQS
    queues. For instructions on how to check your AWS Organizations policies, see Listing all policies in the AWS Organizations User Guide.
  Additionally, if you incorrectly configured your queue policy for a member account to deny
    all users access to your Amazon SQS queue, you can unlock the queue by launching a privileged session
    for the member account in IAM. Once you launch a privileged session, you can delete the
    misconfigured queue policy to regain access to the queue. For more information, see Perform a
      privileged task on an AWS Organizations member account in the IAM User
      Guide.
Document ConventionsAWS managed policiesUsing policiesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAccess controlIdentity-based policiesResource-based policiesPolicy actionsPolicy resourcesPolicy condition keysACLsABACTemporary credentialsForward access sessionsService rolesService-linked rolesHow Amazon Simple Queue Service works with
				IAMBefore you use IAM to manage access to Amazon SQS, learn what IAM features are
         available to use with Amazon SQS.IAM features you can use with Amazon Simple Queue Service
					
						IAM feature
						Amazon SQS support
					
				
					
						
							Identity-based policies
						
						
							
     
     Yes
						
					
					
						
							Resource-based policies
						
						
							Yes
						
					
					
						
							Policy actions
						
						
							
     
     Yes
						
					
					
						
							Policy resources
						
						
							
     
     Yes
						
					
					
						
							Policy condition keys (service-specific)
						
						
							
     
     Yes
						
					
					
						
							ACLs
						
						
							
     
     No
    
						
					
					
						
							ABAC (tags in
									policies)
						
						
							
     
     Partial
						
					
					
						
							Temporary credentials
						
						
							
     
     Yes
						
					
					
						
							Forward access sessions (FAS)
						
						
							
     
     Yes
						
					
					
						
							Service roles
						
						
							
     
     Yes
						
					
					
						
							Service-linked roles
						
						
							
     
     No
    
						
					
				To get a high-level view of how Amazon SQS and other AWS services work with most
			IAM features, see AWS services
				that work with IAM in the IAM User Guide.
			Access control
			
   
      
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
      Amazon S3, AWS WAF, and Amazon VPC
            are examples of services that support ACLs. To learn more about ACLs, see Access control list (ACL)
               overview in the Amazon Simple Storage Service Developer Guide.
  
			NoteIt is important to understand that all AWS accounts can delegate their
					permissions to users under their accounts. Cross-account access allows you to
					share access to your AWS resources without having to manage additional users.
					For information about using cross-account access, see Enabling Cross-Account Access in
					the IAM User Guide. See Limitations of Amazon SQS custom
						policies for further details on
					cross-content permissions and condition keys within Amazon SQS custom policies.
				
		 
			Identity-based
					policies for Amazon SQS
			
     
        Supports identity-based policies:
            
     
     Yes
  
			
     
         
   
         Identity-based policies are JSON permissions policy documents that you can attach to an identity, such as an IAM user, group of users, or role. These
            policies control what actions users and roles can perform, on which resources, and under what conditions. To learn how to create an identity-based
            policy, see Define custom IAM permissions with customer managed policies in the
            IAM User Guide.
  
         With IAM identity-based policies, you can specify allowed or denied actions and
            resources as well as the conditions under which actions are allowed or denied.  You
            can't specify the principal in an identity-based policy because it applies to the user
            or role to which it is attached. To learn about all of the elements that you can use in a
            JSON policy, see IAM JSON
               policy elements reference in the
            IAM User Guide.
  
			 
				
						Identity-based policy examples for Amazon SQS
				
				
    
         To view examples of Amazon SQS identity-based policies, see Policy best
						practices.
  
			 
		 
			Resource-based policies within Amazon SQS
			
     
        Supports resource-based policies:
            
     
     Yes
  
			
    
         
   
         Resource-based policies are JSON policy documents that you attach to a resource. Examples of resource-based policies are 
         IAM role trust policies and Amazon S3 bucket policies. In services that support resource-based policies, service 
         administrators can use them to control access to a specific resource. For the resource where the policy is attached, the policy defines what actions
            a specified principal can perform on that resource and under what conditions. You must specify a principal in a resource-based policy. Principals 
            can include accounts, users, roles, federated users, or AWS services.
  
         To enable cross-account access, you can specify an entire account or IAM entities
            in another account as the principal in a
               resource-based policy. Adding a cross-account principal to a resource-based
            policy is only half of establishing the trust relationship. When the principal and the
            resource are in different AWS accounts, an IAM administrator in the trusted account 
            must also grant the principal entity (user or role) permission to access the resource. They grant 
            permission by attaching an identity-based policy to the entity. However, if a resource-based 
            policy grants access to a principal in the same account, no additional identity-based policy is 
            required. For more information, see Cross account resource access in IAM in the
               IAM User Guide.
  
			
			
		 
			Policy
					actions for Amazon SQS
			
     
        Supports policy actions:
            
     
     Yes
  
			
   
            
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  
            The Action element of a JSON policy describes the
               actions that you can use to allow or deny access in a policy. Policy
               actions usually have the same name as the associated AWS API operation. There are some exceptions, such as permission-only 
               actions that don't have a matching API operation. There are also some operations that require multiple actions in a policy. 
               These additional actions are called dependent actions.
            Include actions in a policy to grant permissions to perform the associated operation.
  
			
			To see a list of Amazon SQS actions, see Resources Defined by Amazon Simple Queue Service in the
					Service Authorization Reference.
			Policy actions in Amazon SQS use the following prefix before the action:
			sqs
			To specify multiple actions in a single statement, separate them with
				commas.
			"Action": [
      "sqs:action1",
      "sqs:action2"
         ]
			
			
			
			
			
    
         To view examples of Amazon SQS identity-based policies, see Policy best
						practices.
  
			
		 
			Policy
					resources for Amazon SQS
			
     
        Supports policy resources:
            
     
     Yes
  
			
   
            
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  
            The Resource JSON policy element specifies the object or objects to which the action applies. Statements must include either a
                  Resource or a NotResource element. As a best practice, specify a resource using its Amazon Resource Name (ARN). You can do this for actions that support a 
                  specific resource type, known as resource-level permissions.
            For actions that don't support resource-level permissions, such as listing operations,
                  use a wildcard (*) to indicate that the statement applies to all resources.
         "Resource": "*"
  
			To see a list of Amazon SQS resource types and their ARNs, see
				Actions Defined by Amazon Simple Queue Service in the Service Authorization Reference. To learn with
				which actions you can specify the ARN of each resource, see
				Resources Defined by Amazon Simple Queue Service.
			
			
			
			
			
    
         To view examples of Amazon SQS identity-based policies, see Policy best
						practices.
  
			
		 
			Policy condition keys for Amazon SQS
			
     
      Supports service-specific policy condition keys:
          
     
     Yes
   
			
   
            
   
      Administrators can use AWS JSON policies to specify who has access to what. That is, which principal can perform 
         actions on what resources, and under what conditions.
  
            The Condition element (or Condition
               block) lets you specify conditions in which a
               statement is in effect. The Condition element is optional. You can create
               conditional expressions that use condition
                  operators, such as equals or less than, to match the condition in the
               policy with values in the request. 
            If you specify multiple Condition elements in a statement, or
               multiple keys in a single Condition element, AWS evaluates them using
               a logical AND operation. If you specify multiple values for a single
               condition key, AWS evaluates the condition using a logical OR
               operation. All of the conditions must be met before the statement's permissions are
               granted.
             You can also use placeholder variables when you specify conditions. For example,
               you can grant an IAM user permission to access a resource only if it is tagged with
               their IAM user name. For more information, see IAM policy elements:
                  variables and tags in the IAM User Guide. 
            AWS supports global condition keys and service-specific condition keys. To see all AWS global
               condition keys, see AWS global condition context keys in the
               IAM User Guide.
  
			To see a list of Amazon SQS condition keys, see Condition Keys for Amazon Simple Queue Service in the
					Service Authorization Reference. To learn with which actions and resources
				you can use a condition key, see Resources Defined by Amazon Simple Queue Service.

			
			
			
			
    
         To view examples of Amazon SQS identity-based policies, see Policy best
						practices.
  
			
		 
			ACLs in Amazon SQS
			
     
      Supports ACLs: 
          
     
     No
    
  
			
     
            
   
   Access control lists (ACLs) control which principals (account members, users, or roles) have permissions to access a resource. ACLs are
            similar to resource-based policies, although they do not use the JSON policy document format.
  
  
			
			
		 
			ABAC with Amazon SQS
			
     
      Supports ABAC (tags in policies):
          
     
     Partial
  
			
   
      Attribute-based access control (ABAC) is an authorization strategy that defines permissions
      based on attributes. In AWS, these attributes are called tags. You can attach tags to IAM entities (users
      or roles) and to many AWS resources. Tagging entities and resources is the first step of ABAC. Then you 
      design ABAC policies to allow operations when the principal's tag matches the tag on the resource that they 
      are trying to access.
      ABAC is helpful in environments that are growing rapidly and helps with situations where policy management becomes cumbersome.
      To control access based on tags, you provide tag information in the condition
         element of a policy using the
         aws:ResourceTag/key-name,
         aws:RequestTag/key-name, or
         aws:TagKeys condition keys.
           If a service supports all three condition keys for every resource type, then the value is Yes for the service. 
  If a service supports all three condition keys for only some resource types, then the value is Partial.
  For more information about ABAC, see Define permissions with ABAC authorization in the IAM User Guide. To view a tutorial with steps for setting up ABAC, see 
  Use attribute-based access control (ABAC) in the IAM User Guide.
  
			
			
		 
			Using temporary
					credentials with Amazon SQS
			
     
      Supports temporary credentials:
          
     
     Yes
  
			
   
         Some AWS services don't work when you sign in using temporary credentials. For additional 
         information, including which AWS services work with temporary credentials, see AWS services
               that work with IAM in the IAM User Guide.
         You are using temporary credentials if you sign in to the AWS Management Console using any method
            except a user name and password. For example, when you access AWS using your
            company's single sign-on (SSO) link, that process automatically creates temporary credentials.
            You also automatically create temporary credentials when you sign in to the console as a user and
            then switch roles. For more information about switching roles, see Switch from a user to an IAM role
               (console) in the IAM User Guide.
         You can manually create temporary credentials using the AWS CLI or AWS API. You can
            then use those temporary credentials to access AWS. AWS recommends that you
            dynamically generate temporary credentials instead of using long-term access keys. For
            more information, see Temporary
               security credentials in IAM.
  
		 
			Forward access
					sessions for Amazon SQS
			
     
      Supports forward access sessions (FAS): 
          
     
     Yes
  
			
   
         

      When you use an IAM user or role to perform actions in AWS, you are considered a principal. When you use some services, you might perform an action that then initiates
      another action in a different service. FAS uses the permissions of the principal calling an AWS service, combined with the requesting AWS service to make requests to downstream services.
      FAS requests are only made when a service receives a request that requires interactions with other AWS services or resources to complete. In this case, you must have permissions to
      perform both actions. For policy details
      when making FAS requests, see Forward access sessions.
 
  
		 
			Service roles for
					Amazon SQS
			
     
      Supports service roles: 
          
     
     Yes
  
			
   
         

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
  
			
			WarningChanging the permissions for a service role might break Amazon SQS
					functionality. Edit service roles only when Amazon SQS provides guidance to do
					so.
			
			
		 
			Service-linked
					roles for Amazon SQS
			
     
      Supports service-linked roles:
          
     
     No
    
  
			
   
         

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
  
			
			
			For details about creating or managing service-linked roles, see AWS
					services that work with IAM. Find a service in the table that includes
				a Yes in the Service-linked role column. Choose
				the Yes link to view the service-linked role documentation for
				that service.
			
		Document ConventionsOverviewAWS managed policiesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuidePolicy best
						practicesUsing the consoleAllow users to view their own permissionsAllow a user to create queuesAllow developers to write
						messages to a shared queueAllow managers to get the general size of
						queuesAllow a partner to send
						messages to a specific queueIdentity-based policy examples
					for Amazon SQSBy default, users and roles don't have permission to create or modify Amazon SQS
 resources. They also can't perform tasks by using the AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS API. To grant users permission to perform actions on the 
 resources that they need, an IAM administrator can create IAM policies. The administrator can then add the IAM policies to roles, and users can assume the roles.To learn how to create an IAM identity-based policy by using these example JSON policy
 documents, see Create IAM policies (console) in the
 IAM User Guide.For details about actions and resource types defined by Amazon SQS, including the format of the ARNs for each of the resource types, see Actions, Resources, and Condition Keys for Amazon Simple Queue Service in the Service Authorization Reference.NoteWhen you configure lifecycle hooks for Amazon EC2 Auto Scaling, you don't need to write a
					policy to send messages to an Amazon SQS queue. For more information, see Amazon EC2 Auto Scaling Lifecycle Hooks in
					the Amazon EC2 User Guide.
				Policy best
						practices
				
				
   
 Identity-based policies determine whether someone can create, access, or delete Amazon SQS resources in your
      account. These actions can incur costs for your AWS account. When you create or edit identity-based policies, follow these guidelines and
      recommendations:
   
       
       
       
       
       
   
         Get started with AWS managed policies and move toward least-privilege permissions
            – To get started granting permissions to your users and workloads, use the AWS
            managed policies that grant permissions for many common use cases. They are
            available in your AWS account. We recommend that you reduce permissions further by
            defining AWS customer managed policies that are specific to your use cases. For more information, see 
            AWS managed policies or AWS managed policies for job functions in the IAM User Guide.
      
         Apply least-privilege permissions – 
            When you set permissions with IAM policies, grant only the permissions required to
            perform a task. You do this by defining the actions that can be taken on specific resources
            under specific conditions, also known as least-privilege permissions.
            For more information about using IAM to apply permissions, see 
            Policies and permissions in IAM in the IAM User Guide.
      
         Use conditions in IAM policies to further restrict access
            – You can add a condition to your policies to limit access to actions and resources. For example, you can write a policy condition to specify that all requests must
            be sent using SSL. You can also use conditions to grant access to service actions
            if they are used through a specific AWS service, such as AWS CloudFormation. For more information, see
            
            IAM JSON policy elements: Condition in the IAM User Guide.
      
         Use IAM Access Analyzer to validate your IAM policies to ensure secure and functional permissions
            – IAM Access Analyzer validates new and existing policies so that the policies adhere to the IAM policy language (JSON) and IAM best practices.
            IAM Access Analyzer provides more than 100 policy checks and actionable recommendations to help
            you author secure and functional policies. For more information, see Validate policies with IAM Access Analyzer in the IAM User Guide.
      
         Require multi-factor authentication (MFA) –
            If you have a scenario that requires IAM users or a root user in your AWS account, turn on MFA for additional security. To require
            MFA when API operations are called, add MFA conditions to your policies. For
            more information, see 
            Secure API access with MFA in the IAM User Guide.
      
 For more information about best practices in IAM, see Security best practices in IAM in the IAM User Guide.

			 
				Using the
						Amazon SQS console
				
   
        To access the Amazon Simple Queue Service console, you must have a minimum set of permissions.
            These permissions must allow you to list and view details about the Amazon SQS resources
            in your AWS account. If you create an identity-based policy that is more restrictive
            than the minimum required permissions, the console won't function as intended for
            entities (users or roles) with that policy. 
        You don't need to allow minimum console permissions for users that are making calls
            only to the AWS CLI or the AWS API. Instead, allow access to only the actions that match
            the API operation that they're trying to perform.
  
				To ensure that users and roles can still use the Amazon SQS console, also
					attach the Amazon SQS AmazonSQSReadOnlyAccess AWS managed policy
					to the entities. For more information, see Adding permissions to a user in the
						IAM User Guide.
			 
				Allow users to view their own permissions
				
   
         This example shows how you might create a policy that allows IAM users to view the inline and managed policies that are attached to their user
            identity. This policy includes permissions to complete this action on the console or programmatically using the AWS CLI or AWS API.
         {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "ViewOwnUserInfo",
            "Effect": "Allow",
            "Action": [
                "iam:GetUserPolicy",
                "iam:ListGroupsForUser",
                "iam:ListAttachedUserPolicies",
                "iam:ListUserPolicies",
                "iam:GetUser"
            ],
            "Resource": ["arn:aws:iam::*:user/${aws:username}"]
        },
        {
            "Sid": "NavigateInConsole",
            "Effect": "Allow",
            "Action": [
                "iam:GetGroupPolicy",
                "iam:GetPolicyVersion",
                "iam:GetPolicy",
                "iam:ListAttachedGroupPolicies",
                "iam:ListGroupPolicies",
                "iam:ListPolicyVersions",
                "iam:ListPolicies",
                "iam:ListUsers"
            ],
            "Resource": "*"
        }
    ]
}
  
			 
				Allow a user to create queues
				In the following example, we create a policy for Bob that lets him access all
					Amazon SQS actions, but only with queues whose names are prefixed with the literal
					string alice_queue_.
				Amazon SQS doesn't automatically grant the creator of a queue permissions to use
					the queue. Therefore, we must explicitly grant Bob permissions to use all Amazon SQS
					actions in addition to CreateQueue action in the IAM
					policy.
				{
   "Version": "2012-10-17",
   "Statement": [{
      "Effect": "Allow",
      "Action": "sqs:*",
      "Resource": "arn:aws:sqs:*:123456789012:alice_queue_*"
   }]
}

			 
				Allow developers to write
						messages to a shared queue
				In the following example, we create a group for developers and attach a policy
					that lets the group use the Amazon SQS SendMessage action, but only with
					the queue that belongs to the specified AWS account and is named
						MyCompanyQueue.
				{
   "Version": "2012-10-17",
   "Statement": [{
      "Effect": "Allow",
      "Action": "sqs:SendMessage",
      "Resource": "arn:aws:sqs:*:123456789012:MyCompanyQueue"
   }]
}
				You can use * instead of SendMessage to grant the
					following actions to a principal on a shared queue:
						ChangeMessageVisibility, DeleteMessage,
						GetQueueAttributes, GetQueueUrl,
						ReceiveMessage, and SendMessage.
				NoteAlthough * includes access provided by other permission
						types, Amazon SQS considers permissions separately. For example, it is possible
						to grant both * and SendMessage permissions to a
						user, even though a * includes the access provided by
							SendMessage.This concept also applies when you remove a permission. If a principal has
						only a * permission, requesting to remove a
							SendMessage permission doesn't leave
						the principal with an everything-but permission.
						Instead, the request has no effect, because the principal doesn't possess an
						explicit SendMessage permission. To leave the principal with
						only the ReceiveMessage permission, first add the
							ReceiveMessage permission and then remove the
							* permission.

			 
				Allow managers to get the general size of
						queues
				In the following example, we create a group for managers and attach a policy
					that lets the group use the Amazon SQS GetQueueAttributes action with
					all of the queues that belong to the specified AWS account.
				{
   "Version": "2012-10-17",
   "Statement": [{
      "Effect": "Allow",
      "Action": "sqs:GetQueueAttributes",
      "Resource": "*"   
   }]
}
			 
				Allow a partner to send
						messages to a specific queue
				You can accomplish this task using an Amazon SQS policy or an IAM policy. If your
					partner has an AWS account, it might be easier to use an Amazon SQS policy.
					However, any user in the partner's company who possesses the AWS security
					credentials can send messages to the queue. If you want to limit access to a
					particular user or application, you must treat the partner like a user in your
					own company and use an IAM policy instead of an Amazon SQS policy.
				This example performs the following actions:
				
						Create a group called WidgetCo to represent the partner
							company.
					
						Create a user for the specific user or application at the partner's
							company who needs access.
					
						Add the user to the group.
					
						Attach a policy that gives the group access only to the
								SendMessage action for only the queue named
								WidgetPartnerQueue.
					
				{
   "Version": "2012-10-17",
   "Statement": [{
         "Effect": "Allow",
         "Action": "sqs:SendMessage",
         "Resource": "arn:aws:sqs:*:123456789012:WidgetPartnerQueue"
   }]
}
			Document ConventionsUsing policiesBasic Amazon SQS policy examplesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Sign-InUser GuideSign in to the AWS Management ConsoleWhen you sign in to the AWS Management Console from the main AWS sign-in URL (https://console.aws.amazon.com/) you must choose your user type, either Root user or IAM user. If you're not sure
  what kind of user you are, see Determine your user type. The root user has unrestricted account access and is associated with the person who created the
  AWS account. The root user then creates other types of users, such as IAM users and
  users in AWS IAM Identity Center, and assigns them access credentials.An IAM user
  is an identity within your AWS account that has specific custom permissions. When an IAM user
  signs in, they can use a sign-in URL that includes their AWS account or alias, such as 
    https://account_alias_or_id.signin.aws.amazon.com/console/
  instead of the main AWS sign in URL https://console.aws.amazon.com/.You can sign in to up 5 different identities simultaneously in a single browser in the
  AWS Management Console. These can be a combination of root users, IAM users, or federated roles in different
  accounts or in the same account. For details, see Signing in to multiple accounts in
  the AWS Management Console Getting Started Guide.TutorialsSign in to the AWS Management Console as the
    root userSign in to the AWS Management Console as an
    IAM userIf you're not sure what kind of user you are, see Determine your user type.
  Tutorials
   
   
 
   Sign in to the AWS Management Console as the
     root user
  
   Sign in to the AWS Management Console as an
     IAM user
  Document ConventionsSecurity best practicesSign in as the root userDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideHow AWS SigV4 worksHow AWS SigV4a worksWhen to sign requestsWhy requests are signedAdditional resourcesAWS Signature Version 4 for API requestsImportantIf you use an AWS SDK (see Sample Code and
                Libraries) or AWS Command Line Interface (AWS CLI) tool to send API requests to AWS, you can
            skip the signature process, as the SDK and CLI clients authenticate your requests by
            using the access keys that you provide. Unless you have a good reason not to, we
            recommend that you always use an SDK or the CLI.In Regions that support multiple signature versions, manually signing requests means
            you must specify which signature version to use. When you supply requests to
            Multi-Region Access Points, SDKs and the CLI automatically switch to using Signature
            Version 4A without additional configuration.Authentication information that you send in a request must include a signature. AWS
        Signature Version 4 (SigV4) is the AWS signing protocol for adding authentication
        information to AWS API requests.You don't use your secret access key to sign API requests. Instead, you use the SigV4
        signing process. Signing requests involves:
         
         
         
    
            Creating a canonical request based on the request details.
        
            Calculating a signature using your AWS credentials.
        
            Adding this signature to the request as an Authorization header.
        AWS then replicates this process and verifies the signature, granting or denying access
        accordingly.Symmetric SigV4 requires you to derive a key that is scoped to a single AWS service, in
        a single AWS region, on a particular day. This makes the key and calculated signature
        different for each region, meaning you must know the region the signature is destined
        for.Asymmetric Signature Version 4 (SigV4a) is an extension that supports signing with a new
        algorithm, and generating individual signatures that are verifiable in more than one AWS
        region. With SigV4a, you can sign a request for multiple regions, with seamless routing and
        failover between regions. When you use the AWS SDK or AWS CLI to invoke functionality that
        requires multi-region signing, the signature type is automatically changed to use SigV4a.
        For details, see How AWS SigV4a works.
        How AWS SigV4 works
        The following steps describe the general process of computing a signature with SigV4:
        
             
             
             
        
                The string to sign depends on the request
                    type. For example, when you use the HTTP Authorization header or the query
                    parameters for authentication, you use a combination of request elements to
                    create the string to sign. For an HTTP POST request, the POST
                    policy in the request is the string you sign.
            
                The signing key is a series of calculations,
                    with the result of each step fed into the next. The final step is the signing
                    key.
            
                When an AWS service receives an authenticated request, it recreates the
                        signature using the authentication
                    information contained in the request. If the signatures match, the service
                    processes the request. Otherwise, it rejects the request.
            
        For more information, see Elements of an AWS API request
            signature.
     
        How AWS SigV4a works        
        SigV4a uses asymmetric signatures based on public-private key cryptography. SigV4a
            goes through a similar scoped credentials derivation process as SigV4, except Sigv4a
            uses the same key to sign all requests without needing to derive a distinct signing key
            based on the date, service, and region. An Elliptic Curve Digital Signature
                Algorithm (ECDSA) keypair can be derived from your existing AWS secret
            access key.
        The system uses asymmetric cryptography to verify multi-region signatures, so that
            AWS only needs to store your public keys. Public keys are not secret and can't be used
            to sign requests. Asymmetric signatures are required for multi-region API requests, such
            as with Amazon S3 Multi-Region Access Points.
        The following steps describe the general process of computing a signature with SigV4a:
        
             
             
             
        
                The string to sign depends on the request
                    type. For example, when you use the HTTP Authorization header or the query
                    parameters for authentication, you use a combination of request elements to
                    create the string to sign. For an HTTP POST request, the POST
                    policy in the request is the string you sign.
            
                The signing key is derived from an AWS
                    secret access key through a series of calculations, with the result of each step
                    fed into the next. The final step produces the keypair.
            
                When an AWS service receives a request signed with Sigv4a, AWS verifies
                    the signature using only the public half of the keypair. If the signature is
                    valid, the request is authenticated and the service processes the request.
                    Requests with invalid signatures is rejected.
            

        For more information about SigV4a for multi-Region API requests, see the sigv4a-signing-examples project on GitHub.
     
        When to sign requests

        When you write custom code that sends API requests to AWS, you must include code
            that signs the requests. You might write custom code because:
        
             
             
        
                You are working with a programming language for which there is no AWS
                    SDK.
            
                You need complete control over how requests are sent to AWS.
            
        While API requests authenticate access with AWS SigV4, AWS SDKs and the AWS CLI
            authenticate your requests by using the access keys that you provide. For more
            information about authenticating with AWS SDKs and the AWS CLI, see Additional resources.
     
        Why requests are signed
        The signing process helps secure requests in the following ways:
        
             
             
             
        
                Verify the identity of the requester
                Authenticated requests require a signature that you create by using your
                    access keys (access key ID, secret access key). If you are using temporary
                    security credentials, the signature calculations also require a security token.
                    For more information, see AWS security credentials programmatic access.
            
                Protect data in transit
                To prevent tampering with a request while it's in transit, some of the request
                    elements are used to calculate a hash (digest) of the request, and the resulting
                    hash value is included as part of the request. When an AWS service receives
                    the request, it uses the same information to calculate a hash and matches it
                    against the hash value in your request. If the values don't match, AWS denies
                    the request.
            
                Protect against potential replay attacks
                In most cases, a request must reach AWS within five minutes of the time
                    stamp in the request. Otherwise, AWS denies the request.
            
        AWS SigV4 can be expressed in the HTTP Authorization header or as a query string in
            the URL. For more information, see Authentication methods.
     
        Additional resources
        
             
             
             
        
                For more information about the SigV4 signing process for different services,
                    see Request signature examples.
            
                To configure credentials for programmatic access for the AWS CLI, see Authentication and access credentials in the AWS
                        Command Line Interface User Guide.
            
                The AWS SDKs include source code on GitHub for signing AWS API requests.
                    For code samples, see Example projects in AWS samples
                    repository.
                
                     
                     
                     
                     
                     
                     
                     
                     
                
                        AWS SDK for .NET – AWS4Signer.cs
                    
                        AWS SDK for C++ – AWSAuthV4Signer.cpp
                    
                        AWS SDK for Go – sigv4.go
                    
                        AWS SDK for Java – BaseAws4Signer.java
                    
                        AWS SDK for JavaScript – signature-v4
                    
                        AWS SDK for PHP – SignatureV4.php
                    
                        AWS SDK for Python (Boto) – signers.py
                    
                        AWS SDK for Ruby – signer.rb
                    
            
    Document ConventionsServices that work with IAMSigV4 request
            elementsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS IAM Identity CenterUser GuideMulti-factor authentication for Identity Center usersIAM Identity Center comes preconfigured with multi-factor authentication (MFA) turned on by default so
        that all users must sign in with MFA in addition to their user name and password. This
        ensures that users must sign in to the AWS access portal using the following two factors:
         
         
    
            Their user name and password. This is the first factor and is something users
                know.
        
            Either a code, security key, or biometrics. This is the second factor and is
                something users have (possession) or are (biometric). The second factor might be
                either an authentication code generated from their mobile device, a security key
                connected to their computer, or user’s biometric scan. 
        Together, these multiple factors provide increased security by preventing unauthorized
        access to your AWS resources unless a valid MFA challenge has been successfully
        completed.Each user can register up to two virtual authenticator apps, which are one-time password
        authenticator applications installed on your mobile device or tablet, and six FIDO
        authenticators, which include built-in authenticators and security keys, for a total of
            eight MFA devices. Learn more about Available MFA types for IAM Identity Center.TopicsAvailable MFA types for IAM Identity CenterConfigure MFA in IAM Identity CenterRegister an MFA device for usersRenaming and deleting MFA devices in
                IAM Identity CenterDocument ConventionsCustomizing the AWS access portal URLAvailable MFA typesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideMFA typesMFA recommendationsAdditional resourcesAWS Multi-factor authentication in IAMFor increased security, we recommend that you configure multi-factor authentication (MFA) to
    help protect your AWS resources. You can enable MFA for the AWS account root user of all AWS accounts,
    including standalone accounts, management accounts, and member accounts, as well as for your
    IAM users.MFA is enforced for all account types for their root user. For more information, see Secure your AWS Organizations account root user credentials. When you enable MFA for the root user, it affects only the root user credentials. IAM users in
    the account are distinct identities with their own credentials, and each identity has its own
    MFA configuration. For more information about using MFA to protect the root user, see Multi-factor authentication for AWS account root user.Your AWS account root user and IAM users can register up to eight MFA devices of any type.
    Registering multiple MFA devices can provide flexibility and help you reduce the risk of access
    interruption if a device is lost or broken. You only need one MFA device to sign in to the
    AWS Management Console or create a session through the AWS CLI.NoteWe recommend that you require your human users to use temporary credentials when accessing AWS. Have you considered using AWS IAM Identity Center? You can use IAM Identity Center to centrally manage access to multiple AWS accounts and provide users with MFA-protected, single sign-on access to all their assigned accounts from one place. With IAM Identity Center, you can create and manage user identities in IAM Identity Center or easily connect to your existing SAML 2.0 compatible identity provider. For more information, see What is IAM Identity Center? in the AWS IAM Identity Center User Guide.MFA adds extra security that requires users to provide unique authentication from an AWS
    supported MFA mechanism in addition to their sign-in credentials when they access AWS websites
    or services.
    MFA types
    AWS supports the following MFA types:
    ContentsPasskeys and security keysVirtual authenticator applicationsHardware TOTP tokens

     
      Passkeys and security keys
      AWS Identity and Access Management supports passkeys and security keys for MFA. Based on FIDO standards, passkeys
        use public key cryptography to provide strong, phishing-resistant authentication that is
        more secure than passwords. AWS supports two types of passkeys: device-bound passkeys
        (security keys) and synced passkeys.
      
         
         
      
          Security keys: These are physical devices, like a
            YubiKey, used as a second factor for authentication. A single security key can support
            multiple root user accounts and IAM users.
        
          Synced passkeys: These use credential managers from
            providers such as Google, Apple, Microsoft accounts, and third-party services like
            1Password, Dashlane, and Bitwarden as a second factor.
        
      You can use built-in biometric authenticators, like Touch ID on Apple MacBooks, to
        unlock your credential manager and sign in to AWS. Passkeys are created with your chosen
        provider using your fingerprint, face, or device PIN. You can sync passkeys across your
        devices to facilitate sign-ins with AWS, enhancing usability and recoverability.
      IAM does not support local passkey registration for Windows Hello. To create and use
        passkeys, Windows users should use cross-device authentication (CDA). You can use a CDA passkey from one device,
        like a mobile device or hardware security key, to sign in on another device like a
        laptop.
      The FIDO Alliance maintains a list of all FIDO Certified
          products that are compatible with FIDO specifications.
      For more information about enabling passkeys and security keys, see Enable a passkey or security key for the root user
          (console).
     

     
      Virtual authenticator applications
      A virtual authenticator application runs on a phone or other device and emulates a
        physical device. Virtual authenticator apps implement the time-based one-time password (TOTP)
          algorithm and support multiple tokens on a single device. The user must type a
        valid code from the device when prompted during sign-in. Each token assigned to a user must
        be unique. A user can't type a code from another user's token to authenticate.
      We do recommend that you use a virtual MFA device while waiting for hardware purchase
        approval or while you wait for your hardware to arrive. For a list of a few supported apps
        that you can use as virtual MFA devices, see Multi-Factor Authentication
          (MFA).
      For instructions on setting up a virtual MFA device for an IAM user, see Assign a virtual MFA device in the
         AWS Management Console.
      
       NoteUnassigned virtual MFA devices in your AWS account are deleted when you’re adding
          new virtual MFA devices either via the AWS Management Console or during the sign-in process. Unassigned
          virtual MFA devices are devices in your account but not used by account root user or
          IAM users for the sign-in process. They’re deleted so new virtual MFA devices can be
          added to your account. It also allows you to reuse device names.
           
           
           
        
            To view unassigned virtual MFA devices in your account, you can use either the
                list-virtual-mfa-devices AWS CLI command or API
              call.
          
            To deactivate a virtual MFA device, you can use either the deactivate-mfa-device AWS CLI command or API call. The
              device will become unassigned.
          
            To attach an unassigned virtual MFA device to your AWS account root user or
              IAM users, you'll need the authentication code generated by the device along with
              either the enable-mfa-device AWS CLI command or API call.
          
 
     

     
      Hardware TOTP tokens
      A hardware device generates a six-digit numeric code based on the time-based one-time password (TOTP)
          algorithm. The user must type a valid code from the device on a second webpage
        during sign-in.
      These tokens are used exclusively with AWS accounts. You can only use tokens that have
        their unique token seeds shared securely with AWS. Token seeds are secret keys generated
        at the time of token production. Tokens purchased from other sources will not function with
        IAM. To ensure compatibility, you must purchase your hardware MFA device from one of the
        following links: OTP
          token or OTP
          display card.
      
         
         
      
          Each MFA device assigned to a user must be unique. A user cannot type a code from
            another user's device to be authenticated. For information on supported hardware MFA
            devices, see Multi-Factor Authentication (MFA).
        
          If you want to use a physical MFA device, we recommend that you use security keys as
            an alternative to hardware TOTP devices. Security keys have no battery requirements, are
            phishing resistant, and support multiple users on a single device.
        
      You can enable a passkey or security key from the AWS Management Console only, not from the AWS CLI or
        AWS API. Before you can enable a security key, you must have physical access to the
        device.
      For instructions on setting up a hardware TOTP token for an IAM user, see Assign a hardware TOTP token in the
      AWS Management Console.
     

    NoteSMS text message-based MFAAWS ended support for
        enabling SMS multi-factor authentication (MFA). We recommend that customers who have
        IAM users that use SMS text message-based MFA switch to one of the following alternative
        methods: Passkey or security key,
          virtual (software-based) MFA
          device, or hardware MFA
          device. You can identify the users in your account with an assigned SMS MFA device.
        In the IAM console, choose Users from the navigation pane, and look
        for users with SMS in the MFA column of the
        table.
   
    MFA recommendations
    To help secure your AWS identities, follow these recommendations for MFA authentication. 
    
       
       
       
       
       
    
        We recommend that you enable multiple MFA devices to the AWS account root user and IAM users in
          your AWS accounts. This allows you to raise the security bar in your AWS accounts and
          simplify managing access to highly privileged users, such as the AWS account root user.
      
        You can register up to eight MFA devices of any
          combination of the  currently
            supported MFA types with your AWS account root user and IAM users. With multiple MFA
          devices, you only need one MFA device to sign in to the AWS Management Console or create a session
          through the AWS CLI as that user. An IAM user must authenticate with an existing MFA
          device to enable or disable an additional MFA device.
      
        In the event of a lost, stolen, or inaccessible MFA device you can use one of the
          remaining MFA devices to access the AWS account without performing the AWS account
          recovery procedure. If an MFA device is lost or stolen, it should be disassociated from
          the IAM principal with which it is associated.
      
        The use of multiple MFAs allows your employees in geographically dispersed locations
          or working remotely to use hardware-based MFA to access AWS without having to coordinate
          the physical exchange of a single hardware device between employees.
      
        The use of additional MFA devices for IAM principals allows you to use one or more
          MFAs for everyday usage, while also maintaining physical MFA devices in a secure physical
          location such as a vault or safe for backup and redundancy.
      
    Notes
         
         
         
      
          You cannot pass the MFA information for a FIDO security key to AWS STS API operations
            to request temporary credentials.
        
          You cannot use AWS CLI commands or AWS API operations to enable FIDO security keys.
        
          You cannot use the same name for more than one root user or IAM MFA device.
        
   
    Additional resources
    The following resources can help you learn more about MFA.
    
       
       
    
        For more information about using MFA to access AWS, see MFA enabled sign-in.
      
         You can leverage IAM Identity Center to enable secure MFA access to your AWS access portal, IAM Identity Center
          integrated apps, and the AWS CLI. For more information, see Enable MFA in
          IAM Identity Center.
      
  Document ConventionsUse IAM with Amazon KeyspacesAssign a passkey or security
      keyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideCentrally manage root access for member
        accountsTasks that require root user credentialsAdditional resourcesAWS account root userWhen you first create an Amazon Web Services (AWS) account, you begin with a single sign-in identity
    that has complete access to all AWS services and resources in the account. This identity is
    called the AWS account root user. The email address and password that you
    used to create your AWS account are the credentials you use to sign in as your root user.
     
     
     
  
      Use the root user only to perform the tasks that require root-level permissions.
        
  For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials.
 
    
      Follow the root user best practices for your
          AWS account.
    
      If you're having trouble signing in, see Sign in to the
          AWS Management Console.
    ImportantWe strongly recommend that you don't use the root user for your everyday tasks and that
      you follow the root user best practices for your
        AWS account. Safeguard your root user credentials and use them to perform the tasks
      that only the root user can perform. 
  For the complete list of tasks that require you to sign in as the root user, see Tasks that require root user credentials.
 While MFA is enforced for root users by default, it requires customer action to add MFA during
    the initial account creation or as prompted during sign-in. For more information about using MFA
    to protect the root user, see Multi-factor authentication for AWS account root user.
    Centrally manage root access for member
        accounts
    
    To help you manage credentials at scale, you can centrally secure access to root user
      credentials for member accounts in AWS Organizations. When you enable AWS Organizations, you combine all your
      AWS accounts into an organization for central management. Centralizing root access lets you
      remove root user credentials and perform the following privileged tasks on member
      accounts.
    
       
       
       
    
        Remove member account root user credentials
        
          After you centralize root access for
              member accounts, you can choose to delete root user credentials from member
            accounts in your AWS Organizations. You can remove the root user password, access keys, signing
            certificates, and deactivate multi-factor authentication (MFA). New accounts you create
            in AWS Organizations have no root user credentials by default. Member accounts can't sign in to
            their root user or perform password recovery for their root user unless account recovery is
            enabled.
        
      
        Perform privileged tasks that require root user credentials
        
          Some tasks can only be performed when you sign in as the root user of an account. Some
            of these Tasks that require root user credentials can be
            performed by the management account or delegated administrator for IAM. To learn more
            about taking privileged actions on member accounts, see Perform a privileged
            task.
        
      
        Enable account recovery of the root user
        
          If you need to recover root user credentials for a member account, the Organizations
            management account or delegated administrator can perform the Allow password
              recovery privileged task. The person with access to the root user email inbox
            for the member account can reset the root user password
            to recover root user credentials. We recommend deleting root user credentials once you
            complete the task that requires access to the root user.
        
      
   
    Tasks that require root user credentials
    We recommend that you configure an
        administrative user in AWS IAM Identity Center to perform daily tasks and access AWS resources.
      However, you can perform the tasks listed below only when you sign in as the root user of an
      account.

    To simplify managing privileged root user credentials across member accounts in AWS Organizations, you
      can enable centralized root access to help you centrally secure highly privileged access to
      your AWS accounts. Centrally manage root access for member
        accounts lets you centrally remove and prevent
      long-term root user credential recovery, improving account security in your organization. After
      you enable this feature, you can perform the following privileged tasks on member
      accounts.
    
       
       
       
    
        Remove member account root user credentials to prevent account recovery of the root user.
          You can also allow password recovery to recover root user credentials for a member
          account.
      
        Remove a misconfigured bucket policy that denies all principals from accessing an Amazon S3
          bucket.
      
        Delete an Amazon Simple Queue Service resource-based policy that denies all principals from accessing an
          Amazon SQS queue.
      

    
      Account Management Tasks
       
       
       
    
        Change your
            AWS account settings. Standalone AWS accounts that are not part of AWS Organizations
          require root credentials to update the email address, root user password, and root user access
          keys. Other account settings, such as account name, contact information, alternate
          contacts, payment currency preference, and AWS Regions, don't require root user
          credentials.
        NoteAWS Organizations, with all features enabled, can be used to manage member account settings
            centrally from the management account and delegated admin accounts. Authorized
            IAM users or IAM roles in both the management account and delegated admin accounts
            can close member accounts and update the root email addresses, account names, contact
            information, alternate contacts, and AWS Regions of member accounts. 
      
        Close your AWS account.
          Standalone AWS accounts that are not part of AWS Organizations require root credentials to close
          the account. With AWS Organizations, you can close the member accounts centrally from the
          management account and delegated admin accounts.
      
        Restore IAM user
            permissions. If the only IAM administrator accidentally revokes their own
          permissions, you can sign in as the root user to edit policies and restore those
          permissions.
      

    
      Billing Tasks
       
       
       
    
        Activate IAM access to the Billing and Cost Management console.
      
        Some Billing tasks are limited to the root user. See Managing an
            AWS account in AWS Billing User Guide for more information.
      
        View certain tax invoices. An IAM user with the aws-portal:ViewBilling permission can view and download VAT invoices from AWS
          Europe, but not AWS Inc. or Amazon Internet Services Private Limited (AISPL).
      

    
      AWS GovCloud (US) Tasks
       
       
    
        Sign up for
            AWS GovCloud (US).
      
        Request AWS GovCloud (US) account root user access keys from AWS Support.
      

    
      Amazon EC2 Task
       
    
        Register as a seller in the
          Reserved Instance Marketplace.
      
    
      AWS KMS Task
       
    
        In the event that an AWS Key Management Service key becomes unmanageable, an administrator can recover
          it by contacting Support; however, Support responds to your root user's primary phone number for
          authorization by confirming the ticket OTP.
      
    
      Amazon Mechanical Turk Task
       
    
        
          Link Your AWS account to your MTurk Requester account.
      
    
      Amazon Simple Storage Service Tasks
       
       
    
        Configure an Amazon S3 bucket
            to enable MFA (multi-factor authentication).
      
        Edit or
            delete an Amazon S3 bucket policy that denies all principals.
        You can use privileged actions to unlock an Amazon S3 bucket with a misconfigured bucket
          policy. For details, see Perform a privileged task on an AWS Organizations
            member account.
      

    
      Amazon Simple Queue Service Task
       
    
        Edit or delete
            an Amazon SQS resource-based policy that denies all principals.
        You can use privileged actions to unlock an Amazon SQS queue with a misconfigured
          resource-based policy. For details, see Perform a privileged task on an AWS Organizations
            member account.
      
   
    Additional resources
    For more information about the AWS root user, see the following resources:
    
       
       
    
        For help with root user issues, see Troubleshoot issues with the root user.
      
        To centrally manage root user email addresses in AWS Organizations, see Updating the root user email address for a member account in the
            AWS Organizations User Guide.
      
    The following articles provide additional information about working with the
      root user.
    
       
       
       
       
    
        What are some
            best practices for securing my AWS account and its resources?
      
        How can I create an EventBridge event rule to notify me that my root user was used?
        
      
        Monitor and notify on AWS account root user activity
        
      
        Monitor
            IAM root user activity
        
      
  Document ConventionsIdentitiesCentralize root
            accessDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS IAM Identity CenterUser GuideWhy use IAM Identity Center?IAM Identity Center renameWhat is IAM Identity Center?AWS IAM Identity Center is the AWS solution for connecting your workforce users to AWS managed
    applications such as Amazon Q Developer and Amazon QuickSight, and other AWS resources. You can connect your
    existing identity provider and synchronize users and groups from your directory, or create and
    manage your users directly in IAM Identity Center. You can then use IAM Identity Center for either or both of the
    following:
     
     
  
      User access to applications
    
      User access to AWS accounts
    Already using IAM for access to AWS accounts?You don’t need to make any changes to your current AWS account workflows to use IAM Identity Center for access to AWS managed applications. If you’re using federation with IAM or IAM users for AWS account access, your users can continue to access 
    AWS accounts in the same way they always have, and you can continue to use your existing workflows to manage that access.
    Why use IAM Identity Center?
    IAM Identity Center streamlines and simplifies workforce user access to applications or AWS accounts,
      or both, through the following key capabilities.

    

       

       

       

       

       

       

    
        Integration with AWS managed
          applications
        

          AWS managed applications such as Amazon Q Developer and
            Amazon Redshift integrate with IAM Identity Center. IAM Identity Center provides AWS managed applications
            with a common view of users and groups.
        
      
        Trusted
            identity propagation across applications
        
        

          With trusted identity propagation, AWS managed applications such as Amazon QuickSight can
            securely share a user’s identity with other AWS managed applications such as
            Amazon Redshift and authorize access to AWS resources based on the user’s
            identity. You can more easily audit user activity because CloudTrail events are logged based
            on the user and the actions the user initiated. This makes it easier to understand who
            accessed what. For information about supported use cases, including end-to-end
            configuration guidance, see Trusted identity
                    propagation use cases.
        
      
        One place to assign permissions to multiple
          AWS accounts
        

          With multi-account permissions, IAM Identity Center provides a single place for you to assign
            permissions to groups of users in multiple AWS accounts. You can create permissions
            based on common job functions or define custom permissions that meet your security
            needs. You can then assign those permissions to workforce users to control their access
            to specific AWS accounts. 

          This optional feature is available only for organization instances of
            IAM Identity Center.
        
      
        One point of federation to simplify user access to
          AWS
        
          By providing one point of federation, IAM Identity Center reduces the administrative effort
            required to use multiple AWS managed applications and AWS accounts. With IAM Identity Center, you
            only federate once, and you have only one certificate to manage when using a SAML 2.0 identity
            provider. IAM Identity Center provides AWS managed applications with a common view of users and
            groups for trusted identity propagation use cases, or when users share access to AWS
            resources with other people.

          For information about how to configure commonly used identity providers to work with
            IAM Identity Center, see IAM Identity Center identity source tutorials. If you don’t have an
            existing identity provider, you can create and
              manage users directly in IAM Identity Center.
        
      
        Two modes of deployment
        
          IAM Identity Center supports two types of instances: organization
              instances and account instances. An
            organization instance is the best practice. It's the only instance that enables you to
            manage access to AWS accounts and it's recommended for all production use of
            applications. An organization instance is deployed in the AWS Organizations management account and
            gives you a single point from which to manage user access across AWS. 
          Account instances are bound to the AWS account in which they are enabled. Use
            account instances of IAM Identity Center only to support isolated deployments of select AWS managed
            applications. For more information, see Organization and account instances of IAM Identity Center.
        
      
        User-friendly web portal access for your users
        

          The AWS access portal is a user-friendly web portal that provides your users with seamless
            access to all their assigned applications, AWS accounts, or both.
        
      
   
    IAM Identity Center rename
    On July 26, 2022, AWS Single Sign-On was renamed to AWS IAM Identity Center.

     
      Legacy namespaces remain the same
      
      The sso and identitystore API namespaces along with the
        following related namespaces remain unchanged for backward
        compatibility purposes.
      
      
         
         
         
         
         
         
         
      
          CLI commands
          
             
             
             
             
             
          
              aws configure sso
            
              identitystore
            
              sso
            
              sso-admin
            
              sso-oidc
            
        
          Managed
              policies containing AWSSSO and AWSIdentitySync
            prefixes
        
          Service
              endpoints containing sso and identitystore
        
          AWS CloudFormation resources containing AWS::SSO prefixes
        
          Service-linked role containing AWSServiceRoleForSSO
        
          Console URLs containing sso and singlesignon
        
          Documentation URLs containing singlesignon
        
     
  Document ConventionsEnable IAM Identity CenterDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideHow AWS identifies an IAM userIAM users and credentialsIAM users and permissionsIAM users and accountsIAM users as service accountsIAM usersImportant IAM best
        practices recommend that you require
      human users to use federation with an identity provider to access AWS using temporary
      credentials instead of using IAM users with long-term credentials. We recommend that you only use IAM users 
      for specific use cases not supported by federated users.An IAM user is an entity that you create in your AWS account. The
    IAM user represents the human user or workload who uses the IAM user to interact with AWS resources.
    An IAM user consists of a name and credentials.An IAM user with administrator permissions is not the same thing as the AWS account root user. For
    more information about the root user, see AWS account root user.
    How AWS identifies an IAM user

    When you create an IAM user, IAM creates these ways to identify that user:
    
       
       
       
    
        A "friendly name" for the IAM user, which is the name that you specified when you
          created the IAM user, such as Richard or Anaya. These are the
          names you see in the AWS Management Console. 
      
        An Amazon Resource Name (ARN) for the IAM user. You use the ARN when you need to
          uniquely identify the IAM user across all of AWS. For example, you could use an ARN to
          specify the IAM user as a Principal in an IAM policy for an Amazon S3 bucket.
          An ARN for an IAM user might look like the following: 
        arn:aws:iam::account-ID-without-hyphens:user/Richard
      
        A unique identifier for the IAM user. This ID is returned only when you use the API,
          Tools for Windows PowerShell, or AWS CLI to create the IAM user; you do not see this ID in the console.
      
    For more information about these identifiers, see IAM identifiers.
   
    IAM users and credentials

    You can access AWS in different ways depending on the IAM user credentials:
    
       
       
       
       
    
        Console
              password: A password that the IAM user can type to sign in to
          interactive sessions such as the AWS Management Console. Disabling the password (console access) for an
          IAM user prevents them from signing in to the AWS Management Console using their sign-in credentials.
          It does not change their permissions or prevent them from accessing the console using an
          assumed role.
      
        Access
              keys: Used to make programmatic calls to AWS. However, there are
          more secure alternatives to consider before you create access keys for IAM users. For
          more information, see Considerations and alternatives for long-term access keys in the
            AWS General Reference. If the IAM user has active access keys, they
          continue to function and allow access through the AWS CLI, Tools for Windows PowerShell,
          AWS API, or the AWS Console Mobile Application.
      
        SSH keys for use with
              CodeCommit: An SSH public key in the OpenSSH format that can be used to
          authenticate with CodeCommit.
      
        Server
              certificates: SSL/TLS certificates that you can use to authenticate
          with some AWS services. We recommend that you use AWS Certificate Manager (ACM) to provision,
          manage, and deploy your server certificates. Use IAM only when you must support HTTPS
          connections in a region that is not supported by ACM. To learn which regions support
          ACM, see AWS Certificate Manager endpoints and quotas in
          the AWS General Reference.
      
    You can choose the credentials that are right for your IAM user. When you use the
      AWS Management Console to create an IAM user, you must choose to at least include a console password or
      access keys. By default, a brand new IAM user created using the AWS CLI or AWS API has no
      credentials of any kind. You must create the type of credentials for an IAM user based on
      your use case. 
    You have the following options to administer passwords, access keys, and multi-factor
      authentication (MFA) devices:
    
       
       
       
       
       
    
        Manage passwords for
              your IAM users. Create and change the passwords that permit access
          to the AWS Management Console. Set a password policy to enforce a minimum password complexity. Allow
          IAM users to change their own passwords. 
      
        Manage access keys
              for your IAM users. Create and update access keys for programmatic
          access to the resources in your account. 
      
        Enable multi-factor
              authentication (MFA) for the IAM user. 
  As a best practice, we recommend that you require multi-factor authentication for all IAM users in your account. 
   With
          MFA, IAM users must provide two forms of identification: First, they provide the credentials
          that are part of their user identity (a password or access key). In addition, they provide
          a temporary numeric code that's generated on a hardware device or by an application on a
          smartphone or tablet.
      
        Find unused
              passwords and access keys. Anyone who has a password or access keys
          for your account or an IAM user in your account has access to your AWS resources. The
          security best
            practice is to remove passwords and access keys when IAM users no longer need
          them.
      
        Download a
              credential report for your account. You can generate and download a
          credential report that lists all IAM users in your account and the status of their
          various credentials, including passwords, access keys, and MFA devices. For passwords and
          access keys, the credential report shows how recently the password or access key has been
          used.
      
   
    IAM users and permissions
    By default, a new IAM user has no permissions to do
      anything. They are not authorized to perform any AWS operations or to access any AWS
      resources. An advantage of having individual IAM users is that you can assign permissions
      individually to each user. You might assign administrative permissions to a few users, who
      then can administer your AWS resources and can even create and manage other IAM users. In
      most cases, however, you want to limit a user's permissions to just the tasks (AWS actions
      or operations) and resources that are needed for the job. 
    Imagine a user named Diego. When you create the IAM user Diego, you create
      a password for him and attach permissions that let him launch a specific Amazon EC2 instance and
      read (GET) information from a table in an Amazon RDS database. For procedures on how
      to create IAM users and grant them initial credentials and permissions, see Create an IAM user in your AWS account. For procedures on how to change
      the permissions for existing users, see Change permissions for an IAM user. For procedures on how to change the user's
      password or access keys, see User passwords in AWS and Manage access keys for IAM users.
    You can also add a permissions boundary to your IAM users. A permissions boundary is an
      advanced feature that allows you to use AWS managed policies to limit the maximum
      permissions that an identity-based policy can grant to an IAM user or role. For more information
      about policy types and uses, see Policies and permissions in AWS Identity and Access Management.
   
    IAM users and accounts


    Each IAM user is associated with one and only one AWS account. Because IAM users are
      defined within your AWS account, they don't need to have a payment method on file with
      AWS. Any AWS activity performed by IAM users in your account is billed to your account.
    The number and size of IAM resources in an AWS account are limited. For more information, see IAM and AWS STS quotas.
   
    IAM users as service accounts


    An IAM user is a resource in IAM that has associated credentials and permissions. An
      IAM user can represent a person or an application that uses its credentials to make AWS
      requests. This is typically referred to as a service account. If you
      choose to use the long-term credentials of an IAM user in your application, do not embed access keys directly into your application code. The
      AWS SDKs and the AWS Command Line Interface allow you to put access keys in known locations so that you do
      not have to keep them in code. For more information, see Manage IAM
        User Access Keys Properly in the AWS General Reference. Alternatively,
      and as a best practice, you can use temporary security
        credentials (IAM roles) instead of long-term access keys.
  Document ConventionsDelete access keys for the root userHow IAM users sign in to AWSDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideRequire human users to use federation with an
        identity provider to access AWS using temporary credentialsRequire workloads to use temporary credentials with
        IAM roles to access AWSRequire multi-factor authentication
        (MFA)Update access keys when needed for use cases that require
        long-term credentialsFollow best practices to protect your root user
        credentialsApply least-privilege permissionsGet started with AWS managed policies and move
        toward least-privilege permissionsUse IAM Access Analyzer to generate
        least-privilege policies based on access activityRegularly review and remove unused users, roles,
        permissions, policies, and credentialsUse conditions in IAM policies to further restrict
        accessVerify public and cross-account access to resources with
        IAM Access AnalyzerUse IAM Access Analyzer to validate your IAM
        policies to ensure secure and functional permissionsEstablish permissions guardrails across multiple
        accountsUse permissions boundaries to delegate permissions
        management within an accountSecurity best practices in IAMTo help secure your AWS resources, follow these best practices for AWS Identity and Access Management
    (IAM).TopicsRequire human users to use federation with an
        identity provider to access AWS using temporary credentialsRequire workloads to use temporary credentials with
        IAM roles to access AWSRequire multi-factor authentication
        (MFA)Update access keys when needed for use cases that require
        long-term credentialsFollow best practices to protect your root user
        credentialsApply least-privilege permissionsGet started with AWS managed policies and move
        toward least-privilege permissionsUse IAM Access Analyzer to generate
        least-privilege policies based on access activityRegularly review and remove unused users, roles,
        permissions, policies, and credentialsUse conditions in IAM policies to further restrict
        accessVerify public and cross-account access to resources with
        IAM Access AnalyzerUse IAM Access Analyzer to validate your IAM
        policies to ensure secure and functional permissionsEstablish permissions guardrails across multiple
        accountsUse permissions boundaries to delegate permissions
        management within an account
    Require human users to use federation with an
        identity provider to access AWS using temporary credentials
    Human users, also known as human identities, are the people,
      administrators, developers, operators, and consumers of your applications. They must have an
      identity to access your AWS environments and applications. Human users that are members of
      your organization are also known as workforce identities. Human users can
      also be external users with whom you collaborate, and who interact with your AWS resources.
      They can do this via a web browser, client application, mobile app, or interactive
      command-line tools.
    Require your human users to use temporary credentials when accessing AWS. You can use an
      identity provider for your human users to provide federated access to AWS accounts by
      assuming roles, which provide temporary credentials. For centralized access management, we
      recommend that you use AWS IAM Identity Center
        (IAM Identity Center) to manage access to your accounts and permissions within those accounts. You
      can manage your user identities with IAM Identity Center, or manage access permissions for user identities
      in IAM Identity Center from an external identity provider. For more information, see What is
        AWS IAM Identity Center in the AWS IAM Identity Center User Guide.
    For more information about roles, see Roles terms and concepts.
   
    Require workloads to use temporary credentials with
        IAM roles to access AWS
    A workload is a collection of resources and code that delivers
      business value, such as an application or backend process. Your workload can have
      applications, operational tools, and components that require credentials to make requests to
      AWS services, such as requests to read data from Amazon S3. 
    When you're building on an AWS compute service, such as Amazon EC2 or Lambda, AWS delivers the temporary credentials of an IAM role to that compute resource. Applications written using an AWS SDK will discover and use these temporary credentials to access AWS resources, and there is no need to distribute long lived credentials for an IAM user to your workloads running on AWS.
    
    Workloads that run on outside of AWS, such as your on-premises servers, servers from other cloud providers, or managed continuous integration and continuous delivery (CI/CD) platforms, can still use temporary credentials. However, you'll need to deliver these temporary credentials to your workload. The following are ways you can deliver temporary credentials to your workloads:
    
    
       
       
       
       
    
        You can use IAM Roles Anywhere to request temporary AWS credentials for your workload using an X.509 Certificate from your public key infrastructure (PKI).
      
        You can call the AWS AWS STSAssumeRoleWithSAML API to request temporary AWS credentials for your workload using a SAML assertion from an external identity provider (IdP) that is configured within your AWS account.
      
        You can call the AWS AWS STS AssumeRoleWithWebIdentity API to request temporary AWS credentials for your workload using a JSON web token (JWT) from an IdP that is configured within your AWS account.
      
        You can requests temporary AWS credentials from your IoT device using Mutual Transport Layer Security (MTLS) authentication using AWS IoT Core.
      
    
    Some AWS services also support integrations to deliver temporary credentials to your workloads running outside of AWS:
    
    
       
       
       
    
        Amazon Elastic Container Service (Amazon ECS) Anywhere
          lets you run Amazon ECS tasks on your own compute resources, and delivers temporary AWS
          credentials to your Amazon ECS tasks running on those compute resources.
      
        Amazon Elastic Kubernetes Service Hybrid Nodes lets you join your compute resources
          running outside of AWS as nodes to an Amazon EKS cluster. Amazon EKS can deliver temporary
          credentials to the Amazon EKS pods running on your compute resources.
      
        AWS Systems ManagerHybrid Activations lets you manage your compute
          resources running outside of AWS using SSM, and delivers temporary AWS credentials
          to the SSM agent running on your compute resources.
      
   
    Require multi-factor authentication
        (MFA)
    
    We recommend using IAM roles for human users and workloads that access your AWS
      resources so that they use temporary credentials. However, for scenarios in which you need an
      IAM user or root user in your account, require MFA for additional security. With MFA, users
      have a device that generates a response to an authentication challenge. Each user's
      credentials and device-generated response are required to complete the sign-in process. For
      more information, see AWS Multi-factor authentication in IAM.
    If you use IAM Identity Center for centralized access management for human users, you can use the IAM Identity Center
      MFA capabilities when your identity source is configured with the IAM Identity Center identity store, AWS
      Managed Microsoft AD, or AD Connector. For more information about MFA in IAM Identity Center see Multi-factor
        authentication in the AWS IAM Identity Center User Guide.
   
    Update access keys when needed for use cases that require
        long-term credentials
    Where possible, we recommend relying on temporary credentials instead of creating
      long-term credentials such as access keys. However, for scenarios in which you need IAM
      users with programmatic access and long-term credentials, we recommend that you update the
      access keys when needed, such as when an employee leaves your company. We recommend that you
      use IAM access last used information to update and remove access keys
      safely. For more information, see Update access keys.
    There are specific use cases that require long-term credentials with IAM users in AWS.
      Some of the use cases include the following:
    
       
       
       
       
    
        Workloads that cannot use IAM roles – You
          might run a workload from a location that needs to access AWS. In some situations, you
          can't use IAM roles to provide temporary credentials, such as for WordPress plugins.
          In these situations, use IAM user long-term access keys for that workload to
          authenticate to AWS.
      
        Third-party AWS clients – If you are using
          tools that don’t support access with IAM Identity Center, such as third-party AWS clients or vendors
          that are not hosted on AWS, use IAM user long-term access keys.
      
        AWS CodeCommit access – If you are using CodeCommit to
          store your code, you can use an IAM user with either SSH keys or service-specific
          credentials for CodeCommit to authenticate to your repositories. We recommend that you do this
          in addition to using a user in IAM Identity Center for normal authentication. Users in IAM Identity Center are the
          people in your workforce who need access to your AWS accounts or to your cloud
          applications. To give users access to your CodeCommit repositories without configuring IAM
          users, you can configure the git-remote-codecommit utility. For more
          information about IAM and CodeCommit, see IAM credentials for CodeCommit: Git credentials, SSH keys, and
      AWS access keys. For more information about configuring the
            git-remote-codecommit utility, see Connecting to AWS CodeCommit repositories with rotating credentials in the
            AWS CodeCommit User Guide.
      
        Amazon Keyspaces (for Apache Cassandra) access – In a situation where you are
          unable to use users in IAM Identity Center, such as for testing purposes for Cassandra compatibility,
          you can use an IAM user with service-specific credentials to authenticate with Amazon Keyspaces.
          Users in IAM Identity Center are the people in your workforce who need access to your AWS accounts or
          to your cloud applications. You can also connect to Amazon Keyspaces using temporary credentials. For
          more information, see Using
            temporary credentials to connect to Amazon Keyspaces using an IAM role and the SigV4
            plugin in the Amazon Keyspaces (for Apache Cassandra) Developer
          Guide.
      
   
    Follow best practices to protect your root user
        credentials
    When you create an AWS account, you establish root user credentials to sign in to the
      AWS Management Console. Safeguard your root user credentials the same way you would protect other sensitive
      personal information. To better understand how to secure and scale your root user processes, see
        Root user best practices for your
      AWS account.
   
    Apply least-privilege permissions
    When you set permissions with IAM policies, grant only the permissions required to
      perform a task. You do this by defining the actions that can be taken on specific resources
      under specific conditions, also known as least-privilege permissions. You
      might start with broad permissions while you explore the permissions that are required for
      your workload or use case. As your use case matures, you can work to reduce the permissions
      that you grant to work toward least privilege. For more information about using IAM to apply
      permissions, see Policies and permissions in AWS Identity and Access Management.
   
    Get started with AWS managed policies and move
        toward least-privilege permissions
    To get started granting permissions to your users and workloads, use the AWS
        managed policies that grant permissions for many common use cases. They are
      available in your AWS account. Keep in mind that AWS managed policies might not grant
      least-privilege permissions for your specific use cases because they are available for use by
      all AWS customers. As a result, we recommend that you reduce permissions further by defining
        customer managed policies that are specific to your use cases. For more
      information, see AWS managed policies.
      For more information about AWS managed policies that are designed for specific job
      functions, see AWS managed policies for job functions.
   
    Use IAM Access Analyzer to generate
        least-privilege policies based on access activity
    To grant only the permissions required to perform a task, you can generate policies based
      on your access activity that is logged in AWS CloudTrail. IAM Access Analyzer analyzes the
      services and actions that your IAM roles use, and then generates a fine-grained policy
      that you can use. After you test each generated policy, you can deploy the policy to your
      production environment. This ensures that you grant only the required permissions to your
      workloads. For more information about policy generation, see IAM Access Analyzer policy
        generation.
   
    Regularly review and remove unused users, roles,
        permissions, policies, and credentials
    You might have IAM users, roles, permissions, policies, or credentials that you no
      longer need in your AWS account. IAM provides last accessed
        information to help you identify the users, roles, permissions, policies, and
      credentials that you no longer need so that you can remove them. This helps you reduce the
      number of users, roles, permissions, policies, and credentials that you have to monitor. You
      can also use this information to refine your IAM policies to better adhere to
      least-privilege permissions. For more information, see Refine permissions in AWS using last
         accessed information.
    
   
    Use conditions in IAM policies to further restrict
        access
    You can specify conditions under which a policy statement is in effect. That way, you can
      grant access to actions and resources, but only if the access request meets specific
      conditions. For example, you can write a policy condition to specify that all requests must be
      sent using TLS. You can also use conditions to grant access to service actions, but only if
      they are used through a specific AWS service, such as AWS CloudFormation. For more information, see IAM JSON policy elements:
        Condition.
   
    Verify public and cross-account access to resources with
        IAM Access Analyzer
    Before you grant permissions for public or cross-account access in AWS, we recommend
      that you verify if such access is required. You can use IAM Access Analyzer to help you preview and
      analyze public and cross-account access for supported resource types. You do this by reviewing
      the findings that IAM Access Analyzer generates. These findings help you verify that your
      resource access controls grant the access that you expect. Additionally, as you update public
      and cross-account permissions, you can verify the effect of your changes before deploying new
      access controls to your resources. IAM Access Analyzer also monitors supported resource types
      continuously and generates a finding for resources that allow public or cross-account access.
      For more information, see Previewing access with
        IAM Access Analyzer APIs.
   
    Use IAM Access Analyzer to validate your IAM
        policies to ensure secure and functional permissions
    Validate the policies you create to ensure that they adhere to the IAM policy language (JSON) and IAM best practices.
      You can validate your policies by using IAM Access Analyzer policy validation. IAM Access Analyzer
      provides more than 100 policy checks and actionable recommendations to help you author secure
      and functional policies. As you author new policies or edit existing policies in the console,
      IAM Access Analyzer provides recommendations to help you refine and validate your policies before
      you save them. Additionally, we recommend that you review and validate all of your existing
      policies. For more information, see IAM Access Analyzer policy
        validation. For more information about policy checks provided by IAM Access Analyzer, see
        IAM Access Analyzer policy
        check reference.
   
    Establish permissions guardrails across multiple
        accounts
    As you scale your workloads, separate them by using multiple accounts that are managed
      with AWS Organizations. We recommend that you use AWS Organizations service control
        policies (SCPs) to establish permissions guardrails to control access for all
      principals (IAM roles and users) across your accounts. We recommend that you use AWS Organizations resource control policies (RCPs) to establish permissions guardrails to control
      access for AWS resources across your organization. SCPs and RCPs are types of organization
      policies that you can use to manage permissions in your organization at the AWS
      organization, organizational unit (OU), or account level.
    However, SCPs and RCPs alone are insufficient to grant permissions to principals and
      resources in your organization. No permissions are granted by SCPs and RCPs. To grant
      permissions, you must attach identity-based or resource-based policies to IAM users, IAM roles, or the
      resources in your accounts. For more information, see SRA
        building blocks — AWS Organizations, accounts, and guardrails.
   
    Use permissions boundaries to delegate permissions
        management within an account
    In some scenarios, you might want to delegate permissions management within an account to
      others. For example, you could allow developers to create and manage roles for their
      workloads. When you delegate permissions to others, use permissions
        boundaries to set the maximum permissions that you delegate. A permissions
      boundary is an advanced feature for using a managed policy to set the maximum permissions that
      an identity-based policy can grant to an IAM role. A permissions boundary does not grant
      permissions on its own. For more information, see Permissions boundaries for IAM
            entities.
  Document ConventionsSecurity best practices and use casesRoot user best practicesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideIAM user groupsAn IAM user group is a collection of
    IAM users. User groups let you specify permissions for multiple users, which can make it
    easier to manage the permissions for those users. For example, you could have a user group
    called Admins and give that user group typical administrator permissions.
    Any user in that user group automatically has Admins group
    permissions. If a new user joins your organization and needs administrator privileges you can
    assign the appropriate permissions by adding the user to the Admins user group. If a person changes jobs in your organization, instead of
    editing that user's permissions you can remove them from the old IAM groups and add them to the
    appropriate new IAM groups. You can attach an identity-based policy to a user group so that all of the users in the user
    group receive the policy's permissions. You cannot identify a user group as a
      Principal in a policy (such as a resource-based policy) because groups relate to
    permissions, not authentication, and principals are authenticated IAM entities. For more
    information about policy types, see Identity-based policies and
         resource-based policies.Here are some important characteristics of IAM groups:
     
     
     
     
  
      A user group can contain many users, and a user can belong to multiple user
        groups.
    
      User groups can't be nested; they can contain only users, not other IAM groups.
    
      There is no default user group that automatically includes all users in the
        AWS account. If you want to have a user group like that, you must create it and assign
        each new user to it.
    
      The number and size of IAM resources in an AWS account, such as the number of
        groups, and the number of groups that a user can be a member of, are limited. For more
        information, see IAM and AWS STS quotas.
    The following diagram shows a simple example of a small company. The company owner creates
    an Admins user group for users to create and manage other users as the company
    grows. The Admins user group creates a Developers user group and a
      Test user group. Each of these IAM groups consists of users (humans and
    applications) that interact with AWS (Jim, Brad, DevApp1, and so on). Each user has an
    individual set of security credentials. In this example, each user belongs to a single user
    group. However, users can belong to multiple IAM groups.
     
      
     
     
  Document ConventionsManage server certificatesCreate IAM groupsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideUse cases for IAM usersIAM users that you create in your AWS account have long-term credentials that you
        manage directly.When it comes to managing access in AWS, IAM users are generally not the best choice.
        There are a few key reasons why you should avoid relying on IAM users for most of your use
        cases.First, IAM users are designed for individual accounts, so they don't scale well as your
        organization grows. Managing permissions and security for a large number of IAM users can
        quickly become a challenge.IAM users also lack the centralized visibility and auditing capabilities that you get
        with other AWS identity management solutions. This can make it more challenging to
        maintain security and regulatory compliance.Finally, implementing security best practices like multi-factor authentication, password
        policies, and role separation is much easier with more scalable identity management
        approaches.Instead of relying on IAM users, we recommend using more robust solutions like IAM Identity Center with AWS Organizations, or federated identities from external providers. These options will give you
        better control, security, and operational efficiency as your AWS environment grows.As a result, we recommend that you only use IAM users for use cases not supported by
            federated users. The following list identifies the specific use cases that require long-term credentials
        with IAM users in AWS. You can use IAM to create these IAM users under the
        umbrella of your AWS account, and use IAM to manage their permissions. 
         
         
         
         
    
            Emergency access to your AWS account
        
            Workloads that can't use IAM roles
            
                 
                 
            
                    AWS CodeCommit access
                
                    Amazon Keyspaces (for Apache Cassandra) access
                
        
            Third-party AWS clients
        
            AWS IAM Identity Center isn't available for your account and you have no other identity
                provider
        Document ConventionsPlan access to your AWS accountCreate an IAM user for emergency
      accessDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideWhen to create an IAM user (instead of a role)Roles terms and conceptsAdditional resourcesIAM rolesAn IAM role is an IAM identity that you can create in your account
    that has specific permissions. An IAM role is similar to an IAM user, in that it is an AWS
    identity with permission policies that determine what the identity can and cannot do in AWS.
    However, instead of being uniquely associated with one person, a role is intended to be
    assumable by anyone who needs it. Also, a role does not have standard long-term credentials such
    as a password or access keys associated with it. Instead, when you assume a role, it provides
    you with temporary security credentials for your role session.You can use roles to delegate access to users, applications, or services that don't normally
    have access to your AWS resources. For example, you might want to grant users in your AWS
    account access to resources they don't usually have, or grant users in one AWS account access
    to resources in another account. Or you might want to allow a mobile app to use AWS resources,
    but not want to embed AWS keys within the app (where they can be difficult to update and where
    users can potentially extract them). Sometimes you want to give AWS access to users who
    already have identities defined outside of AWS, such as in your corporate directory. Or, you
    might want to grant access to your account to third parties so that they can perform an audit on
    your resources.For these scenarios, you can delegate access to AWS resources using an IAM
      role. This section introduces roles and the different ways you can use them, when
    and how to choose among approaches, and how to create, manage, switch to (or assume), and delete
    roles.NoteWhen you first create your AWS account, no roles are created by default. As you add
      services to your account, they may add service-linked roles to support their use cases.

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 Before you can delete service-linked roles you must first delete their related resources.
      This protects your resources because you can't inadvertently remove permission to access the
      resources.For information about which services support using service-linked roles, see AWS services that work with
      IAM and look for the services that
      have Yes in the Service-Linked
        Role column. Choose a Yes with a link to view
      the service-linked role documentation for that service.TopicsWhen to create an IAM user (instead of a role)Roles terms and conceptsAdditional resourcesThe confused deputy problemCommon scenarios for IAM rolesIAM role creationIAM role managementMethods to assume a role
    When to create an IAM user (instead of a role)
    We recommend you only use IAM users for use cases not supported by federated users. Some
      of the use cases include the following:
    
       
       
       
       
       
    
        Workloads that cannot use IAM roles – You
          might run a workload from a location that needs to access AWS. In some situations, you
          can't use IAM roles to provide temporary credentials, such as for WordPress plugins.
          In these situations, use IAM user long-term access keys for that workload to
          authenticate to AWS.
      
        Third-party AWS clients – If you are using
          tools that don’t support access with IAM Identity Center, such as third-party AWS clients or vendors
          that aren't hosted on AWS, use IAM user long-term access keys.
      
        AWS CodeCommit access – If you are using CodeCommit to
          store your code, you can use an IAM user with either SSH keys or service-specific
          credentials for CodeCommit to authenticate to your repositories. We recommend that you do this
          in addition to using a user in IAM Identity Center for normal authentication. Users in IAM Identity Center are the
          people in your workforce who need access to your AWS accounts or to your cloud
          applications. To give users access to your CodeCommit repositories without configuring IAM
          users, you can configure the git-remote-codecommit utility. For more
          information about IAM and CodeCommit, see IAM credentials for CodeCommit: Git credentials, SSH keys, and
      AWS access keys. For more information about configuring the
            git-remote-codecommit utility, see Connecting to AWS CodeCommit repositories with rotating credentials in the
            AWS CodeCommit User Guide.
      
        Amazon Keyspaces (for Apache Cassandra) access – In a situation where you are
          unable to use users in IAM Identity Center, such as for testing purposes for Cassandra compatibility,
          you can use an IAM user with service-specific credentials to authenticate with Amazon Keyspaces.
          Users in IAM Identity Center are the people in your workforce who need access to your AWS accounts or
          to your cloud applications. You can also connect to Amazon Keyspaces using temporary credentials. For
          more information, see Using
            temporary credentials to connect to Amazon Keyspaces using an IAM role and the SigV4
            plugin in the Amazon Keyspaces (for Apache Cassandra) Developer
          Guide.
      
        Emergency access – In a situation where you
          can't access your identity provider and you must take action in your AWS account.
          Establishing emergency access IAM users can be part of your resiliency plan. We
          recommend that the emergency user credentials be tightly controlled and secured using
          multi-factor authentication (MFA).
      
   
    Roles terms and concepts
    Here are some basic terms to help you get started with roles.
    
       

      
       

       
       
       

       
       
    
        Role
        

          
          
          An IAM identity that you can create in your account that has specific permissions.
            An IAM role has some similarities to an IAM user. Roles and users are both AWS
            identities with permissions policies that determine what the identity can and cannot do
            in AWS. However, instead of being uniquely associated with one person, a role is
            intended to be assumable by anyone who needs it. Also, a role does not have standard
            long-term credentials such as a password or access keys associated with it. Instead,
            when you assume a role, it provides you with temporary security credentials for your
            role session.
          Roles can be assumed by the following:
          
             
             
             
             
          
              An IAM user in the same AWS account or another AWS account
            
              IAM roles in the same account
            
              Service principals, for use with AWS services and features like:
              
                 
                 
                 
              
                  Services that allow you to run code on compute services, like Amazon EC2 or
                    AWS Lambda
                
                  Features that perform actions to your resources on your behalf, like Amazon S3
                    object replication
                
                  Services that deliver temporary security credentials to your applications
                    that run outside of AWS, such as IAM Roles Anywhere or Amazon ECS Anywhere
                
            
              An external user authenticated by an external identity provider (IdP) service
                that is compatible with SAML 2.0 or OpenID Connect
            
        
      
        AWS service role
        
          

      A service role is an IAM role that a service assumes to perform 
      actions on your behalf. An IAM administrator can create, modify, and delete a service role from within IAM. For 
      more information, see Create a role to delegate permissions to an AWS service in the IAM User Guide.
 
        
      
        AWS service-linked role
        
          

      A service-linked role is a type of service role that is linked to an AWS service. The service can assume the role to perform an action on your behalf. 
      Service-linked roles appear in your AWS account and are owned by the service. An IAM administrator can view, 
      but not edit the permissions for service-linked roles. 
 
          NoteIf you are already using a service when it begins supporting service-linked roles,
              you might receive an email announcing a new role in your account. In this case, the
              service automatically created the service-linked role in your account. You don't need
              to take any action to support this role, and you should not manually delete it. For
              more information, see A new role appeared in my AWS
        account.
          For information about which services support using service-linked roles, see AWS services that work with
      IAM and look for the services
            that have Yes in the Service-Linked Role column. Choose a Yes
            with a link to view the service-linked role documentation for that service. For more
            information, see Create a service-linked role.
        
      
        Role chaining
        
          Role chaining is when you use a role to assume a second role through the AWS CLI or
            API. For example, RoleA has permission to assume RoleB. You
            can enable User1 to assume RoleA by using their long-term user credentials
            in the AssumeRole API operation. This returns RoleA short-term credentials.
            With role chaining, you can use RoleA's short-term credentials to enable
            User1 to assume RoleB.
          When you assume a role, you can pass a session tag and set the tag as transitive.
            Transitive session tags are passed to all subsequent sessions in a role chain. To learn
            more about session tags, see Pass session tags in AWS STS.
          Role chaining limits your AWS CLI or AWS API role session to a maximum of one hour.
            When you use the AssumeRole API
            operation to assume a role, you can specify the duration of your role session with the
              DurationSeconds parameter. You can specify a parameter value of up to
            43200 seconds (12 hours), depending on the maximum session duration setting for
            your role. However, if you assume a role using role chaining and provide a
              DurationSeconds parameter value greater than one hour, the operation
            fails.
        
      
        Delegation
        
          The granting of permissions to someone to allow access to resources that you
            control. Delegation involves setting up a trust between two accounts. The first is the
            account that owns the resource (the trusting account). The second is the account that
            contains the users that need to access the resource (the trusted account). The trusted
            and trusting accounts can be any of the following:
          
             
             
             
          
              The same account.
            
              Separate accounts that are both under your organization's control.
            
              Two accounts owned by different organizations.
            
          To delegate permission to access a resource, you create an IAM role in the trusting account
            that has two policies attached. The permissions
              policy grants the user of the role the needed permissions to carry out the
            intended tasks on the resource. The trust policy
            specifies which trusted account members are allowed to assume the role.
          When you create a trust policy, you cannot specify a wildcard (*) as part of and ARN
            in the principal element. The trust policy is attached to the role in the trusting
            account, and is one-half of the permissions. The other half is a permissions policy
            attached to the user in the trusted account that allows that user to switch to, or assume
              the role. A user who assumes a role temporarily gives up his or her own
            permissions and instead takes on the permissions of the role. When the user exits, or
            stops using the role, the original user permissions are restored. An additional
            parameter called external ID
            helps ensure secure use of roles between accounts that are not controlled by the same
            organization.
        
      
        Trust policy
        
          A JSON policy document in which
            you define the principals that you trust to assume
            the role. A role trust policy is a required resource-based policy that is attached to a role in IAM. The principals that you can specify
            in the trust policy include users, roles, accounts, and services. For more information,
            see How to
              use trust policies in IAM roles in AWS Security
              Blog.
        
      
        Role for cross-account access
        
          A role that grants access to resources in one account to a trusted principal in a
            different account. Roles are the primary way to grant cross-account access. However,
            some AWS services allow you to attach a policy directly to a resource (instead of
            using a role as a proxy). These are called resource-based policies, and you can use them
            to grant principals in another AWS account access to the resource. Some of these
            resources include Amazon Simple Storage Service (S3) buckets, S3 Glacier vaults, Amazon Simple Notification Service (SNS) topics, and
            Amazon Simple Queue Service (SQS) queues. To learn which services support resource-based policies, see
              AWS services that work with
      IAM. For more information
            about resource-based policies, see Cross account resource
            access in IAM.
        
      
   
    Additional resources
    The following resources can help you learn more about IAM terminology related to IAM
      roles.
    
       
       
       
       
       
    
        Principals are entities in AWS that can perform
          actions and access resources. A principal can be an AWS account root user, an IAM user, or a role.
          A principal that represents the identity of an AWS service is a service principal. Use the Principal element in role
          trust policies to define the principals that you trust to assume the role.
         For more information and examples of principals you can allow to assume a role, see
            AWS JSON policy elements:
        Principal. 
      
        Identity federation creates a trust relationship
          between an external identity provider and AWS. You can use your existing OpenID Connect
          (OIDC) or Security Assertion Markup Language (SAML) 2.0 provider to manage who can access
          AWS resources. When you use OIDC and SAML 2.0 to configure a trust relationship between
          these external identity providers and AWS , the user is assigned to an IAM role. The
          user also receives temporary credentials that allow the user to access your AWS
          resources.
        For more information about federated users, see Identity providers and federation.
      
        
        Federated users are existing identities from AWS Directory Service, your
          enterprise user directory, or an OIDC provider. These are known as federated
            users. AWS assigns a role to a federated user when access is requested
          through an identity provider. 
        For more information about federated users, see Federated users and roles.
      
        Permissions policies are identity-based policies that
          define what actions and resources the role can use. The document is written according to
          the rules of the IAM policy language. 
        For more information, see IAM JSON policy reference.
      
        Permissions boundaries are an advanced feature in
          which you use policies to limit the maximum permissions that an identity-based policy can
          grant to a role. You cannot apply a permissions boundary to a service-linked role.
        For more information, see Permissions boundaries for IAM
            entities.
      
  Document ConventionsDelete an IAM groupThe confused deputy problemDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideRole sessionsConsiderationsTo switch to a roleAdditional
        resourcesSwitch from a user to an IAM role
      (console)You can switch roles when you sign in as an IAM user, a user in IAM Identity Center, a SAML-federated
    role, or a web-identity federated role. A role specifies a set of
    permissions that you can use to access AWS resources that you need. However, you don't sign in
    to a role, but once signed in as an IAM user you can switch to an IAM role. This temporarily
    sets aside your original user permissions and instead gives you the permissions assigned to the
    role. The role can be in your own account or any other AWS account. For more information about
    roles, their benefits, and how to create them, see IAM roles, and IAM role creation.The permissions of your user and any roles that you switch to aren't cumulative. Only one
    set of permissions is active at a time. When you switch to a role, you temporarily give up your
    user permissions and work with the permissions that are assigned to the role. When you exit the
    role, your user permissions are automatically restored.When you switch roles in the AWS Management Console, the console always uses your original credentials to
    authorize the switch. For example, if you switch to RoleA, IAM uses your original credentials
    to determine whether you are allowed to assume RoleA. If you then switch to RoleB while you are using RoleA, AWS still uses your original credentials to authorize the switch, not the credentials for
    RoleA.NoteWhen you sign in as a user in IAM Identity Center, as a SAML-federated role, or as a web-identity
      federated role you assume an IAM role when you start your session. For example, when a
      user in IAM Identity Center signs in to the AWS access portal they must choose a permission set that correlates to
      a role before they can access AWS resources.
    Role sessions

    When you switch roles, your AWS Management Console session lasts for 1 hour by default. IAM user
      sessions are 12 hours by default, other users might have different session durations defined.
      When you switch roles in the console you are granted the role maximum session duration, or the
      remaining time in your user session, whichever is less. You can't extend your session duration
      by assuming a role. For example, assume that a maximum session duration of 10 hours is set for
      a role. You have been signed in to the console for 8 hours when you decide to switch to the
      role. There are 4 hours remaining in your user session, so the allowed role session duration
      is 4 hours, not the maximum session duration of 10 hours. The following table shows how to
      determine the session duration for an IAM user when switching roles in the console.
    
          
            IAM user session time remaining is…
            Role session duration is…
          
        
          
            Less than role maximum session duration
            Time remaining in user session
          
          
            Greater than role maximum session duration
            Maximum session duration value
          
          
            Equal to role maximum session duration
            Maximum session duration value (approximate)
          
        
    NoteSome AWS service consoles can autorenew your role session when it expires without you
        taking any action. Some might prompt you to reload your browser page to reauthenticate your
        session.
   
    Considerations

    
       
       
       
    
        You can't switch roles if you sign in as the AWS account root user. 
      
        Users must be granted permission to switch roles by policy. For instructions, see
            Grant a user permissions to switch
      roles.
      
        You can't switch roles in the AWS Management Console to a role that requires an ExternalId value. You can switch to
          such a role only by calling the AssumeRole API that supports the ExternalId
          parameter.
      

   
    To switch to a role

    
        Follow the sign-in procedure appropriate to your user type as described in the topic How to sign in to AWS in the AWS Sign-In User
            Guide.
      
        On the IAM Console Home page, in the left navigation pane, enter your query in the Search IAM text box.
      
        In the AWS Management Console, choose your user name on the navigation bar in the upper right. It
          typically looks like this:
              username@account_ID_number_or_alias.
      
        Select one of the following methods to switch roles:
        
          
            Choose Switch Role.
          
          
            If you have opted in to multi-session support, choose Add
                session and select Switch Role.
            NoteYou can sign in to up to five different identities simultaneously in a single
                web browser in the AWS Management Console. For details, see Signing in to multiple
                  accounts in the AWS Management Console Getting Started
                Guide.
          
        
      
        On the Switch Role page, type the account ID number or the
          account alias and the name of the role that was provided by your administrator.
        NoteIf your administrator created the role with a path, such as
              division_abc/subdivision_efg/roleToDoX, then you must type that complete
            path and name in the Role box. If you type only the role name, or
            if the combined Path and RoleName exceed 64 characters, the
            role switch fails. This is a limit of the browser cookies that store the role name. If
            this happens, contact your administrator and ask them to reduce the size of the path and
            role name.
      
        (Optional)You can enter a display name and select a display color that will highlight
          the role in the console navigation bar.
        
           
           
        
            For Display name, type text that you want to appear on the
              navigation bar in place of your user name when this role is active. A name is
              suggested, based on the account and role information, but you can change it to
              whatever has meaning for you. 
          
            For Display color, select a color to highlight the display
              name.
          
        The name and color can help remind you when this role is active, which changes your
          permissions. For example, for a role that gives you access to the test environment, you
          might specify a Display name of Test and
          select the green Color. For the role that gives you access to
          production, you might specify a Display name of
            Production and select red as the
          Color.
      
        Choose Switch Role. The display name and color replace your user
          name on the navigation bar, and you can start using the permissions that the role grants
          you.
      
        After you have completed the tasks that require the IAM role you can switch back to
          your original session. This will remove the additional permissions provided by the role
          and return you to your standard permissions.
        
            In the IAM console, choose your role's Display name on the
              navigation bar in the upper right.
          
            Choose Switch back.
            For example, assume you are signed in to account number
                123456789012 using the user name RichardRoe. After
              you use the admin-role role, you want to stop using the role and return
              to your original permissions. To stop using the role, you choose admin-role
                @ 123456789012, and then choose Switch
              back.
            
               
                
                
               
               
            
          
      

    TipThe last several roles that you used appear on the menu. The next time you want to
        switch to one of those roles, you can simply choose the role you want. You are only required
        to type the account and role information manually if the role isn't displayed on the
        menu.
   
    Additional
        resources

    
       
       
       
       
       
    
        Grant a user permissions to switch
      roles
      
        Grant a user permissions to pass a role to an AWS
      service
      
        Create a role to give permissions to an IAM
      user
      
        Create a role to delegate permissions to an
      AWS service
      
        Troubleshoot IAM roles
      
  Document ConventionsMethods to assume a roleSwitch roles (AWS CLI)Did this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideMethods to assume a roleBefore a user, application, or service can use a role that you created, you must grant
    permissions to switch to the role. You can use any policy attached to groups or users to grant
    the necessary permissions. After permissions are granted, the user can assume a role from the AWS Management Console, the Tools for Windows PowerShell, the AWS Command Line Interface
    (AWS CLI) and the AssumeRole
    API.ImportantWhen you create a role programmatically instead of in the IAM console, you have an
      option to add a Path of up to 512 characters in addition to the
        RoleName, which can be up to 64 characters long. However, if you intend to use
      a role with the Switch Role feature in the AWS Management Console, then the combined
        Path and RoleName cannot exceed 64 characters.The method used to assume the role determines who can assume the role
    and how long the role session can last. When using AssumeRole* API operations, the
    IAM role that you assume is the resource. The user or role that calls AssumeRole*
    API operations is the principal.The following table compares methods for assuming roles.
        
           Method of assuming the role
          
            Who can assume the role
          
          Method to specify credential lifetime
          
            Credential lifetime (min | max | default)
          
        
      
        
          AWS Management Console
          User (by switching
            roles)
          Maximum session duration on the Role
            Summary page
          15m | Maximum session duration setting² | 1hr
        
        
          assume-role CLI
            or AssumeRole API
            operation
           User or role¹
          duration-seconds CLI or DurationSeconds API
            parameter
          15m | Maximum session duration setting² | 1hr 
        
        
          assume-role-with-saml CLI or AssumeRoleWithSAML
            API operation
          Any user authenticated using SAML
          duration-seconds CLI or DurationSeconds API
            parameter
          15m | Maximum session duration setting² | 1hr 
        
        
          assume-role-with-web-identity CLI or AssumeRoleWithWebIdentity API operation
          Any user authenticated using an OIDC provider
          duration-seconds CLI or DurationSeconds API
            parameter
          15m | Maximum session duration setting² | 1hr 
        
        
          Console URL
            constructed with AssumeRole
          
          User or role
          SessionDuration HTML parameter in the URL
          15m | 12hr | 1hr 
        
        
          Console URL
            constructed with AssumeRoleWithSAML
          
          Any user authenticated using SAML
          SessionDuration HTML parameter in the URL
          15m | 12hr | 1hr
        
        
          Console URL
            constructed with AssumeRoleWithWebIdentity
          
          Any user authenticated using an OIDC provider
          SessionDuration HTML parameter in the URL
          15m | 12hr | 1hr 
        
      ¹ Using the credentials for one role to assume a different role is called role chaining. When
    you use role chaining, your new credentials are limited to a maximum duration of one hour. When
    you use roles to grant permissions to applications
      that run on EC2 instances, those applications are not subject to this
    limitation.² This setting can have a value from 1 hour to 12 hours. For details about modifying
    the maximum session duration setting, see IAM role management. This setting determines the maximum session duration
    that you can request when you get the role credentials. For example, when you use the AssumeRole* API operations to assume a role,
    you can specify a session length using the DurationSeconds parameter. Use this
    parameter to specify the length of the role session from 900 seconds (15 minutes) up to the
    maximum session duration setting for the role. IAM users who switch roles in the console are
    granted the maximum session duration, or the remaining time in their user session, whichever is
    less. Assume that you set a maximum duration of 5 hours on a role. An IAM user that has been
    signed into the console for 10 hours (out of the default maximum of 12) switches to the role.
    The available role session duration is 2 hours. To learn how to view the maximum value for your
    role, see Update the maximum session duration
                for a role later in this page.Notes
       
       
       
    
        The maximum session duration setting does not limit sessions that are assumed by AWS
          services.
      
        Amazon EC2 IAM role credentials are not subject to maximum session durations configured
          in the role.
      
        To allow users to assume the current role again within a role session, specify the
          role ARN or AWS account ARN as a principal in the role trust policy. AWS services that
          provide compute resources such as Amazon EC2, Amazon ECS, Amazon EKS, and Lambda provide temporary
          credentials and automatically update these credentials. This ensures that you always have
          a valid set of credentials. For these services, it's not necessary to assume the current
          role again to obtain temporary credentials. However, if you intend to pass session tags or a session policy, you need to assume the current role again. To learn how to
          modify a role trust policy to add the principal role ARN or AWS account ARN, see Update a role trust policy .
      TopicsSwitch from a user to an IAM role
      (console)Switch to an IAM role (AWS CLI)Switch to an IAM role (Tools for Windows PowerShell)Switch to an IAM role (AWS API)Use an IAM role to grant permissions to
      applications running on Amazon EC2 instancesUse instance profilesDocument ConventionsDelete roles or instance profilesSwitch from a user to a roleDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideCreating a role for federated
        users (console)Creating a role for federated access
        (AWS CLI)Creating a role for federated access
        (AWS API)Create a role for a third-party identity provider
      (federation)You can use identity providers instead of creating IAM users in your AWS account. With
    an identity provider (IdP), you can manage your user identities outside of AWS and give these
    external user identities permissions to access AWS resources in your account. For more
    information about federation and identity providers, see Identity providers and federation.
    Creating a role for federated
        users (console)
    The procedures for creating a role for federated users depend on your choice of
      third party providers:
    
       
       
    
        For OpenID Connect (OIDC), see Create a role for OpenID Connect federation
      (console).
      
        For SAML 2.0, see Create a role for SAML 2.0 federation
      (console).
      
   
    Creating a role for federated access
        (AWS CLI)
    The steps to create a role for the supported identity providers (OIDC or SAML) from the
      AWS CLI are identical. The difference is in the contents of the trust policy that you create in
      the prerequisite steps. Begin by following the steps in the Prerequisites section for the type of provider you are using:
    
       
       
    
        For an OIDC provider, see Prerequisites for creating a role for OIDC.
      
        For a SAML provider, see Prerequisites for creating a role for SAML.
      
    Creating a role from the AWS CLI involves multiple steps. When you use the console to create
      a role, many of the steps are done for you, but with the AWS CLI you must explicitly perform
      each step yourself. You must create the role and then assign a permissions policy to the role.
      Optionally, you can also set the permissions
        boundary for your role.
    To create a role for identity
        federation (AWS CLI)
        Create a role: aws iam
            create-role
      
        Attach a permissions policy to the role: aws iam attach-role-policy
         or
        Create an inline permissions policy for the role: aws iam put-role-policy
      
        (Optional) Add custom attributes to the role by attaching tags: aws iam tag-role
        For more information, see Managing tags on IAM roles (AWS CLI or
                AWS API).
      
        (Optional) Set the permissions
            boundary for the role: aws iam
            put-role-permissions-boundary
        A permissions boundary controls the maximum permissions that a role can have.
          Permissions boundaries are an advanced AWS feature.
      
    The following example shows the first two, and most common, steps for creating an identity
      provider role in a simple environment. This example allows any user in the
        123456789012 account to assume the role and view the
        example_bucket Amazon S3 bucket. This example also assumes that you are running the
      AWS CLI on a computer running Windows, and have already configured the AWS CLI with your
      credentials. For more information, see Configuring the
        AWS Command Line Interface.
    The following example trust policy is designed for a mobile app if the user signs in using
      Amazon Cognito. In this example, us-east:12345678-ffff-ffff-ffff-123456
      represents the identity pool ID assigned by Amazon Cognito.
    {
    "Version": "2012-10-17",
    "Statement": {
        "Sid": "RoleForCognito",
        "Effect": "Allow",
        "Principal": {"Federated": "cognito-identity.amazonaws.com"},
        "Action": "sts:AssumeRoleWithWebIdentity",
        "Condition": {"StringEquals": {"cognito-identity.amazonaws.com:aud": "us-east:12345678-ffff-ffff-ffff-123456"}}
    }
}
    The following permissions policy allows anyone who assumes the role to perform only the
        ListBucket action on the example_bucket Amazon S3 bucket.
    {
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "s3:ListBucket",
    "Resource": "arn:aws:s3:::example_bucket"
  }
}
    To create this Test-Cognito-Role role, you must first save the previous trust
      policy with the name trustpolicyforcognitofederation.json and the previous
      permissions policy with the name permspolicyforcognitofederation.json to the
        policies folder in your local C: drive. You can then use the
      following commands to create the role and attach the inline policy.
    # Create the role and attach the trust policy that enables users in an account to assume the role.
$ aws iam create-role --role-name Test-Cognito-Role --assume-role-policy-document file://C:\policies\trustpolicyforcognitofederation.json

# Attach the permissions policy to the role to specify what it is allowed to do.
aws iam put-role-policy --role-name Test-Cognito-Role --policy-name Perms-Policy-For-CognitoFederation --policy-document file://C:\policies\permspolicyforcognitofederation.json
   
    Creating a role for federated access
        (AWS API)
    The steps to create a role for the supported identity providers (OIDC or SAML) from the
      AWS CLI are identical. The difference is in the contents of the trust policy that you create in
      the prerequisite steps. Begin by following the steps in the Prerequisites section for the type of provider you are using:
    
       
       
    
        For an OIDC provider, see Prerequisites for creating a role for OIDC.
      
        For a SAML provider, see Prerequisites for creating a role for SAML.
      
    To create a role for identity
        federation (AWS API)
        Create a role: CreateRole
      
        Attach a permissions policy to the role:AttachRolePolicy
         or
        Create an inline permissions policy for the role: PutRolePolicy
      
        (Optional) Add custom attributes to the user by attaching tags: TagRole
        For more information, see Managing tags on IAM users (AWS CLI or
                AWS API).
      
        (Optional) Set the permissions
            boundary for the role: PutRolePermissionsBoundary
        A permissions boundary controls the maximum permissions that a role can have.
          Permissions boundaries are an advanced AWS feature.
      
  Document ConventionsCreate a service-linked roleCreate a role for OIDC federationDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS IAM Identity CenterUser GuideManage AWS accounts with permission
                setsA permission set is a template that you create and maintain that defines a collection
            of one or more IAM
                policies. Permission sets simplify the assignment of AWS account access
            for users and groups in your organization. For example, you can create a Database Admin permission set that includes policies for
            administering AWS RDS, DynamoDB, and Aurora services, and use that single permission set
            to grant access to a list of target AWS accounts within your AWS Organization for your
            database administrators.IAM Identity Center assigns access to a user or group in one or more AWS accounts with permission
            sets. When you assign a permission set, IAM Identity Center creates corresponding IAM Identity Center-controlled
            IAM roles in each account, and attaches the policies specified in the permission set
            to those roles. IAM Identity Center manages the role, and allows the authorized users you’ve defined
            to assume the role, by using the IAM Identity Center User Portal or AWS CLI.  As you modify the
            permission set, IAM Identity Center ensures that the corresponding IAM policies and roles are
            updated accordingly.You can add AWS managed policies, customer managed policies, inline policies, and AWS managed policies
                for job functions to your permission sets. You can also assign an AWS
            managed policy or a customer managed policy as a permissions
                boundary.To create a permission set, see Create, manage, and delete permission sets.TopicsPredefined permissions for
                    AWS managed policiesCustom permissions for AWS managed and
                    customer managed policiesCreate, manage, and delete permission setsConfigure permission set propertiesDocument ConventionsDelegate who can assign single
                    sign-on accessPredefined permissionsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideCross-account access using
                rolesCross-account access using resource-based policiesResource-based policies to delegate AWS permissionsCross account resource
            access in IAMFor some AWS services, you can grant cross-account access to your resources using IAM.
        To do this, you can attach a resource policy directly to the resource that you want to
        share, or use a role as a proxy.To share the resource directly, the resource that you want to share must support resource-based policies. Unlike an identity-based policy for a role, a
        resource-based policy specifies who (which principal) can access that resource.Use a role as a proxy when you want to access resources in another account that do not
        support resource-based policies.For details about the differences between these policy types, see Identity-based policies and
         resource-based policies.NoteIAM roles and resource-based policies delegate access across accounts only within a
            single partition. For example, you have an account in US West (N. California) in the standard
                aws partition. You also have an account in China in the
                aws-cn partition. You can't use a resource-based policy in your account
            in China to allow access for users in your standard AWS account.
        Cross-account access using
                roles
        Not all AWS services support resource-based policies. For these services, you can
            use cross-account IAM roles to centralize permission management when providing
            cross-account access to multiple services. A cross-account IAM role is an IAM role
            that includes a trust policy that
            allows IAM principals in another AWS account to assume the role. Put simply, you can
            create a role in one AWS account that delegates specific permissions to another AWS
            account.
        For information about attaching a policy to an IAM identity, see Manage IAM policies.
        NoteWhen a principal switches to a role to temporarily use the permissions of the
                role, they give up their original permissions and take on the permissions assigned
                to the role they’ve assumed.
        Let’s take a look at the overall process as it applies to APN Partner software that
            needs to access a customer account.
        
                The customer creates an IAM role in their own account with a policy that
                    allows access the Amazon S3 resources that the APN partner requires. In this example,
                    the role name is APNPartner.
                {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::bucket-name"
            ]
        }
    ]
}
            
                Then, the customer specifies that the role can be assumed by the partner’s
                    AWS account by providing the APN Partner’s AWS account ID in the trust
                        policy for the APNPartner role.
                {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::APN-account-ID:role/APN-user-name"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}
            
                The customer gives the Amazon Resource Name (ARN) of the role to the APN
                    partner. The ARN is the fully qualified name of the role.
                arn:aws:iam::Customer-Account-ID:role/APNPartner
                NoteWe recommend using an external ID in multi-tenant situations. For details,
                        see Access to AWS accounts owned by third
      parties.
            
                When the APN Partner’s software needs to access the customer’s account, the
                    software calls the AssumeRole API in
                    the AWS Security Token Service with the ARN of the role in the customer’s account. STS returns a
                    temporary AWS credential that allows the software to do its work.
            
        For another example of granting cross-account access using roles, see Access for an IAM user in another
      AWS account that you own. You can also follow the
                IAM tutorial: Delegate access across
         AWS accounts using IAM roles.
     
        Cross-account access using resource-based policies
        When an account accesses a resource through another account using a resource-based
            policy, the principal still works in the trusted account and does not have to give up
            their permissions to receive the role permissions. In other words, the principal
            continues to have access to resources in the trusted account while having access to the
            resource in the trusting account. This is useful for tasks such as copying information
            to or from the shared resource in the other account.
        The principals that you can specify in a resource based policy include accounts, IAM
            users, federated users, IAM roles, assumed-role sessions, or AWS services. For more
            information, see Specifying a principal.
        To learn whether principals in accounts outside of your zone of trust (trusted
            organization or account) have access to assume your roles, see Identifying resources shared with an external entity.
        The following list includes some of the AWS services that support resource-based
            policies. For a complete list of the growing number of AWS services that support
            attaching permission policies to resources instead of principals, see AWS services that work with
      IAM and look for the
            services that have Yes in the Resource Based column.
        
             
             
             
        
                Amazon S3 buckets — The policy is attached
                    to the bucket, but the policy controls access to both the bucket and the objects
                    in it. For more information, see Bucket policies for
                        Amazon S3 in the Amazon Simple Storage Service User Guide. In some cases,
                    it may be best to use roles for cross-account access to Amazon S3. For more
                    information, see the example walkthroughs in the Amazon Simple Storage Service User
                        Guide.
            
                Amazon Simple Notification Service (Amazon SNS) topics — For more
                    information, go to Example cases for
                        Amazon SNS access control in the Amazon Simple Notification Service Developer
                        Guide.
            
                Amazon Simple Queue Service (Amazon SQS) queues – For more
                    information, go to Appendix: The Access Policy Language in the
                        Amazon Simple Queue Service Developer Guide. 
            
     
        Resource-based policies to delegate AWS permissions
        If a resource grants permissions to principals in your account, you can then delegate
            those permissions to specific IAM identities. Identities are users, groups of users,
            or roles in your account. You delegate permissions by attaching a policy to the
            identity. You can grant up to the maximum permissions that are allowed by the
            resource-owning account.
        ImportantIn cross account access, a principal needs an Allow in the identity
                policy and the resource-based policy.
        Assume that a resource-based policy allows all principals in your account full
            administrative access to a resource. Then you can delegate full access, read-only
            access, or any other partial access to principals in your AWS account. Alternatively,
            if the resource-based policy allows only list permissions, then you can delegate only
            list access. If you try to delegate more permissions than your account has, your
            principals will still have only list access.
        For more information about how these decisions are made, see Determining whether a request is allowed or denied within an
            account.
        NoteIAM roles and resource-based policies delegate access across accounts only
                within a single partition. For example, you can't add cross-account access between
                an account in the standard aws partition and an account in the
                    aws-cn partition. 
        For example, assume that you manage AccountA and AccountB.
            In AccountA, you have an Amazon S3 bucket named BucketA.
        
             
                
             
             
        
        
                You attach a resource-based policy to BucketA that allows all
                    principals in AccountB full access to objects in your bucket. They can create,
                    read, or delete any objects in that bucket. 
                {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PrincipalAccess",
            "Effect": "Allow",
            "Principal": {"AWS": "arn:aws:iam::AccountB:root"},
            "Action": "s3:*",
            "Resource": "arn:aws:s3:::BucketA/*"
            }
        ]
}
                AccountA gives AccountB full access to BucketA by naming AccountB as a
                    principal in the resource-based policy. As a result, AccountB is authorized to
                    perform any action on BucketA, and the AccountB administrator can delegate
                    access to its users in AccountB.
                The AccountB root user has all of the permissions that are granted to the
                    account. Therefore, the root user has full access to BucketA.
            
                In AccountB, attach a policy to the IAM user named User2. That policy allows
                    the user read-only access to the objects in BucketA. That means that User2 can
                    view the objects, but not create, edit, or delete them. 
                {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect" : "Allow", 
            "Action" : [ 
                "s3:Get*", 
                "s3:List*" ], 
                "Resource" : "arn:aws:s3:::BucketA/*" 
        } 
    ]
}
                The maximum level of access that AccountB can delegate is the access level
                    that is granted to the account. In this case, the resource-based policy granted
                    full access to AccountB, but User2 is granted only read-only access.
                The AccountB administrator does not give access to User1. By default, users do
                    not have any permissions except those that are explicitly granted, so User1 does
                    not have access to BucketA.
            
        IAM evaluates a principal's permissions at the time the principal makes a request.
            If you use wildcards (*) to give users full access to your resources, principals can
            access any resources that your AWS account has access to. This is true even for
            resources you add or gain access to after creating the user's policy.
        In the preceding example, if AccountB had attached a policy to User2 that allowed full
            access to all resources in all accounts, User2 would automatically have access to any
            resources that AccountB has access to. This includes the BucketA access and access to
            any other resources granted by resource-based policies in AccountA.
        For more information about complex uses of roles, such as granting access to
            applications and services, see Common scenarios for IAM roles.
        ImportantGive access only to entities you trust, and give the minimum level of access
                necessary. Whenever the trusted entity is another AWS account, any IAM principal
                can be granted access to your resource. The trusted AWS account can delegate
                access only to the extent that it has been granted access; it cannot delegate more
                access than the account itself has been granted.
        For information about permissions, policies, and the permission policy language that
            you use to write policies, see Access management for AWS resources.
    Document ConventionsControl access to AWS resources using tagsForward access sessionsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideFAS Requests and IAM policy
                conditionsExample: Allow Amazon S3 access from a VPC or with
                FASForward access sessionsForward access sessions (FAS) is an IAM technology used by AWS services to pass your
        identity, permissions, and session attributes when an AWS service makes a request on your
        behalf. FAS uses the permissions of the identity calling an AWS service, combined with an
        AWS service’s identity to make requests to downstream services. FAS requests are only made
        to AWS services on behalf of an IAM principal after a service has received a request
        that requires interactions with other AWS services or resources to complete. When a FAS
        request is made:
         
         
    
            The service that receives the initial request from an IAM principal checks the
                permissions of the IAM principal.
        
            The service that receives a subsequent FAS request also checks the permissions of
                the same IAM principal.
        For example, FAS is used by Amazon S3 to make calls to AWS Key Management Service to decrypt an object when
            SSE-KMS was used to encrypt it. When downloading an SSE-KMS encrypted object, a
        role named data-reader calls GetObject on the object against Amazon S3, and
        does not call AWS KMS directly. After receiving the GetObject request and authorizing
        data-reader, Amazon S3 then makes a FAS request to AWS KMS in order to decrypt the Amazon S3 object.
        When KMS receives the FAS request it checks the permissions of the role and only authorizes
        the decryption request if data-reader has the correct permissions on the KMS key. The
        requests to both Amazon S3 and AWS KMS are authorized using the role’s permissions and is only
        successful if data-reader has permissions to both the Amazon S3 object and the
        AWS KMS key.
         
            
         
         
    NoteAdditional FAS requests can be made by services who have received a FAS request. In
            such cases, the requesting principal must have permissions for all services called by
            FAS.
        FAS Requests and IAM policy
                conditions
        When FAS requests are made, aws:CalledVia, aws:CalledViaFirst, and aws:CalledViaLast condition keys are populated with the service principal of the service that initiated
            the FAS call. The aws:ViaAWSService condition key value is set to
                true whenever a FAS request is made. In the following diagram, the
            request to CloudFormation directly does not have any aws:CalledVia or
                aws:ViaAWSService condition keys set. When CloudFormation and DynamoDB make
            downstream FAS requests on the behalf of the role, the values for these condition keys
            are populated.
        
             
                
             
             
        
        To allow a FAS request to be made when it would otherwise be denied by a Deny policy
            statement with a condition key testing Source IP addresses or Source VPCs, you must use
            condition keys to provide an exception for FAS requests in your Deny policy. This can be
            done for all FAS requests by using the aws:ViaAWSService condition key. To
            allow only specific AWS services to make FAS requests, use
            aws:CalledVia.
        ImportantWhen a FAS request is made after an initial request is made through a VPC
                endpoint, the condition key values for aws:SourceVpce, aws:SourceVpc, and aws:VpcSourceIp from the initial request
                are not used in FAS requests. When writing policies using
                    aws:VPCSourceIP or aws:SourceVPCE to conditionally
                grant access, you must also use aws:ViaAWSService or
                    aws:CalledVia to allow FAS requests. When a FAS request is made
                after an initial request is received by a public AWS service endpoint, subsequent
                FAS requests will be made with the same aws:SourceIP condition key
                value.
     
        Example: Allow Amazon S3 access from a VPC or with
                FAS
        In the following IAM policy example, Amazon S3 GetObject and Athena requests are only
            allowed if they originate from VPC endpoints attached to
                example_vpc, or if the request is a FAS request made by
            Athena.
        {
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "OnlyAllowMyIPs",
      "Effect": "Allow",
      "Action": [
        "s3:GetObject*",
        "athena:StartQueryExecution",
        "athena:GetQueryResults",
        "athena:GetWorkGroup",
        "athena:StopQueryExecution",
        "athena:GetQueryExecution"
      ],
      "Resource": "*",
      "Condition": {
        "StringEquals": {
          "aws:SourceVPC": [
            "example_vpc"
          ]
        }
      }
    },
    {
      "Sid": "OnlyAllowFAS",
      "Effect": "Allow",
      "Action": [
        "s3:GetObject*"
      ],
      "Resource": "*",
      "Condition": {
        "ForAnyValue:StringEquals": {
          "aws:CalledVia": "athena.amazonaws.com"
        }
      }
    }
  ]
}
        For additional examples of using condition keys to allow FAS access, see the  data perimeter example
                policy repo.
    Document ConventionsCross account
            resource accessExample policiesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideService role permissionsCreating a role for an AWS service
        (console)Creating a role for a service (AWS CLI)Creating a role for a service (AWS
        API)Create a role to delegate permissions to an
      AWS serviceMany AWS services require that you
    use roles to allow the service to access resources in other services on your behalf. A role that
    a service assumes to perform actions on your behalf is called a service role. When a role serves a specialized purpose
    for a service, it is categorized as a service-linked role. To see what services support using service-linked roles, or
    whether a service supports any form of temporary credentials, see AWS services that work with
      IAM. To learn how an individual
    service uses roles, choose the service name in the table to view the documentation for that
    service.When setting the PassRole permission, you should make sure that a user doesn’t
    pass a role where the role has more permissions than you want the user to have. For example,
    Alice might not be allowed to perform any Amazon S3 actions. If Alice could pass a role to a service
    that allows Amazon S3 actions, the service could perform Amazon S3 actions on behalf of Alice when
    executing the job.For information about how roles help you to delegate permissions, see Roles terms and concepts.
    Service role permissions
    You must configure permissions to allow an IAM entity (user or role) to create or edit a
      service role.
    NoteThe ARN for a service-linked role includes a service principal, which is indicated in
        the following policies as
        SERVICE-NAME.amazonaws.com. Do not try to guess the
        service principal, because it is case-sensitive and the format can vary across AWS
        services. To view the service principal for a service, see its service-linked role
        documentation.
    To allow an IAM entity to create a specific service
        role
    Add the following policy to the IAM entity that needs to create the service role. This
      policy allows you to create a service role for the specified service and with a specific name.
      You can then attach managed or inline policies to that role. 
    {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "iam:AttachRolePolicy",
                "iam:CreateRole",
                "iam:PutRolePolicy"
            ],
            "Resource": "arn:aws:iam::*:role/SERVICE-ROLE-NAME"
        }
    ]
}
    To allow an IAM entity to create any service
      role
    AWS recommends that you allow only administrative users to create any service role. A
      person with permissions to create a role and attach any policy can escalate their own
      permissions. Instead, create a policy that allows them to create only the roles that they need
      or have an administrator create the service role on their behalf.
    To attach a policy that allows an administrator to access your entire AWS account, use
      the AdministratorAccess AWS managed policy.

    To allow an IAM entity to edit a service role
    Add the following policy to the IAM entity that needs to edit the service role.
    {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "EditSpecificServiceRole",
            "Effect": "Allow",
            "Action": [
                "iam:AttachRolePolicy",
                "iam:DeleteRolePolicy",
                "iam:DetachRolePolicy",
                "iam:GetRole",
                "iam:GetRolePolicy",
                "iam:ListAttachedRolePolicies",
                "iam:ListRolePolicies",
                "iam:PutRolePolicy",
                "iam:UpdateRole",
                "iam:UpdateRoleDescription"
            ],
            "Resource": "arn:aws:iam::*:role/SERVICE-ROLE-NAME"
        },
        {
            "Sid": "ViewRolesAndPolicies",
            "Effect": "Allow",
            "Action": [
                "iam:GetPolicy",
                "iam:ListRoles"
            ],
            "Resource": "*"
        }
    ]
}
    To allow an IAM entity to delete a specific service
        role
    Add the following statement to the permissions policy for the IAM entity that needs to
      delete the specified service role.
    {
    "Effect": "Allow",
    "Action": "iam:DeleteRole",
    "Resource": "arn:aws:iam::*:role/SERVICE-ROLE-NAME"
}
    To allow an IAM entity to delete any service
      role
    AWS recommends that you allow only administrative users to delete any service role.
      Instead, create a policy that allows them to delete only the roles that they need or have an
      administrator delete the service role on their behalf.
    To attach a policy that allows an administrator to access your entire AWS account, use
      the AdministratorAccess AWS managed policy.
   
    Creating a role for an AWS service
        (console)
    You can use the AWS Management Console to create a role for a service. Because some services support
      more than one service role, see the AWS documentation
      for your service to see which use case to choose. You can learn how to assign the necessary
      trust and permissions policies to the role so that the service can assume the role on your
      behalf. The steps that you can use to control the permissions for your role can vary,
      depending on how the service defines the use cases, and whether or not you create a
      service-linked role.
    
      
      classic IAM console

To create a role for an AWS service (IAM console)Sign in to the AWS Management Console and open the IAM console at https://console.aws.amazon.com/iam/.
        In the navigation pane of the IAM console, choose Roles, and
            then choose Create role.
    
        For Trusted entity type, choose AWS service.
    
        For Service or use case, choose a service, and then choose the use case. Use cases are defined by the service to include the trust policy
            that the service requires.
    
        Choose Next.
    
        For Permissions policies, the options depend on the use case that you selected:
        
             
             
             
             
        
                If the service defines the permissions for the role, you can't select permissions policies.
            
                Select from a limited set of permission polices.
            
                Select from all permission policies.
            
                Select no permissions policies, create the policies after the role is created, and then attach the policies to the role.
            
    
        (Optional) Set a permissions
            boundary. This is an advanced feature that is available for service roles, but
            not service-linked roles.
        
                Open the Set permissions boundary section, and then choose
                    Use a permissions boundary to control the maximum role
                permissions. 
                
                IAM includes a list of the AWS managed and customer-managed policies in your account.
            Select the policy to use for the permissions boundary.
    
        Choose Next.
    
        For Role name, the options depend on the service:
            
                 
                 
                 
            
                    If the service defines the role name, you can't edit the role name.
                
                    If the service defines a prefix for the role name, you can enter an optional suffix.
                
                    If the service doesn't define the role name, you can name the role.
                    ImportantWhen you name a role, note the following:
                             
                             
                        
                                Role names must be unique within your AWS account, and can't be made unique by case.
                                For example, don't create roles named both PRODROLE and
                                    prodrole. When a role name is used in a policy or as part of an ARN, the role name is case sensitive, however when a role name appears to customers in the console, such as during the sign-in process, the role name is case insensitive.
                            
                                You can't edit the name of the role after it's created because other entities might reference the role.
                            
                
        
    
        (Optional) For Description, enter a description for the role.
    
        (Optional) To edit
            the use cases and permissions for the role, in the Step 1: Select trusted
                entities or Step 2: Add permissions sections, choose Edit.
    
        (Optional) To help identify, organize, or search for the role, add tags as key-value pairs. For more
            information about using tags in IAM, see Tags for AWS Identity and Access Management resources in the IAM User Guide.
    
        Review the role, and then choose Create role.
    

    
    
    
   
    Creating a role for a service (AWS CLI)
    Creating a role from the AWS CLI involves multiple steps. When you use the console to create
      a role, many of the steps are done for you, but with the AWS CLI you must explicitly perform
      each step yourself. You must create the role and then assign a permissions policy to the role.
      If the service you are working with is Amazon EC2, then you must also create an instance profile
      and add the role to it. Optionally, you can also set the permissions boundary for your role.
    To create a role for an AWS service from the AWS CLI
        The following create-role command creates a role named Test-Role
          and attaches a trust policy to it:
        aws iam create-role --role-name Test-Role --assume-role-policy-document
            file://Test-Role-Trust-Policy.json

      
        Attach a managed permissions policy to the role: aws iam
          attach-role-policy.
        For example, the following attach-role-policy command attaches the AWS
          managed policy named ReadOnlyAccess to the IAM role named
            ReadOnlyRole:
        aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/ReadOnlyAccess
            --role-name ReadOnlyRole
         or
        Create an inline permissions policy for the role: aws iam put-role-policy
        To add an inline permissions policy, see the following example:
        
          aws iam put-role-policy --role-name Test-Role --policy-name ExamplePolicy
            --policy-document file://AdminPolicy.json
      
        (Optional) Add custom attributes to the role by attaching tags: aws iam tag-role
        For more information, see Managing tags on IAM roles (AWS CLI or
                AWS API).
      
        (Optional) Set the permissions
            boundary for the role: aws iam
            put-role-permissions-boundary
        A permissions boundary controls the maximum permissions that a role can have.
          Permissions boundaries are an advanced AWS feature.
      
    If you are going to use the role with Amazon EC2 or another AWS service that uses Amazon EC2, you
      must store the role in an instance profile. An instance profile is a container for a role that
      can be attached to an Amazon EC2 instance when launched. An instance profile can contain only one
      role, and that limit cannot be increased. If you create the role using the AWS Management Console, the
      instance profile is created for you with the same name as the role. For more information about
      instance profiles, see Use instance profiles. For information about how
      to launch an EC2 instance with a role, see Controlling Access to
        Amazon EC2 Resources in the Amazon EC2 User Guide.
    To create an instance profile and store the role in it (AWS CLI)
        Create an instance profile: aws iam create-instance-profile
      
        Add the role to the instance profile: aws iam
            add-role-to-instance-profile
      
    The AWS CLI example command set below demonstrates the first two steps for creating a role
      and attaching permissions. It also shows the two steps for creating an instance profile and
      adding the role to the profile. This example trust policy allows the Amazon EC2 service to assume
      the role and view the example_bucket Amazon S3 bucket. The example also assumes that
      you are running on a client computer running Windows and have already configured your command
      line interface with your account credentials and Region. For more information, see Configuring the AWS Command Line
        Interface.
    In this example, include the following trust policy in the first command when you create
      the role. This trust policy allows the Amazon EC2 service to assume the role. 
    {
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Principal": {"Service": "ec2.amazonaws.com"},
    "Action": "sts:AssumeRole"
  }
}
    When you use the second command, you must attach a permissions policy to the role. The
      following example permissions policy allows the role to perform only the
        ListBucket action on the example_bucket Amazon S3 bucket.
    {
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "s3:ListBucket",
    "Resource": "arn:aws:s3:::example_bucket"
  }
}
    To create this Test-Role-for-EC2 role, you must first save the previous trust
      policy with the name trustpolicyforec2.json and the previous permissions policy
      with the name permissionspolicyforec2.json to the policies directory
      in your local C: drive. You can then use the following commands to create the
      role, attach the policy, create the instance profile, and add the role to the instance
      profile.
    # Create the role and attach the trust policy that allows EC2 to assume this role.
$ aws iam create-role --role-name Test-Role-for-EC2 --assume-role-policy-document file://C:\policies\trustpolicyforec2.json

# Embed the permissions policy (in this example an inline policy) to the role to specify what it is allowed to do.
$ aws iam put-role-policy --role-name Test-Role-for-EC2 --policy-name Permissions-Policy-For-Ec2 --policy-document file://C:\policies\permissionspolicyforec2.json

# Create the instance profile required by EC2 to contain the role
$ aws iam create-instance-profile --instance-profile-name EC2-ListBucket-S3

# Finally, add the role to the instance profile
$ aws iam add-role-to-instance-profile --instance-profile-name EC2-ListBucket-S3 --role-name Test-Role-for-EC2
    When you launch the EC2 instance, specify the instance profile name in the
        Configure Instance Details page if you use the AWS console. If you
      use the aws ec2 run-instances CLI command, specify the
        --iam-instance-profile parameter.
   
    Creating a role for a service (AWS
        API)
     
      Creating a role from the AWS API involves multiple steps. When you use the console to
        create a role, many of the steps are done for you, but with the API you must explicitly
        perform each step yourself. You must create the role and then assign a permissions policy to
        the role. If the service you are working with is Amazon EC2, then you must also create an
        instance profile and add the role to it. Optionally, you can also set the permissions boundary for your role.
      To create a role for an AWS service (AWS API)
          Create a role: CreateRole
          For the role's trust policy, you can specify a file location.
        
          Attach a managed permissions policy to the role: AttachRolePolicy
           or
          Create an inline permissions policy for the role: PutRolePolicy
        
          (Optional) Add custom attributes to the user by attaching tags: TagRole
          For more information, see Managing tags on IAM users (AWS CLI or
                AWS API).
        
          (Optional) Set the permissions
              boundary for the role: PutRolePermissionsBoundary
          A permissions boundary controls the maximum permissions that a role can have.
            Permissions boundaries are an advanced AWS feature.
        
      If you are going to use the role with Amazon EC2 or another AWS service that uses Amazon EC2,
        you must store the role in an instance profile. An instance profile is a container for a
        role. Each instance profile can contain only one role, and that limit cannot be increased.
        If you create the role in the AWS Management Console, the instance profile is created for you with the
        same name as the role. For more information about instance profiles, see Use instance profiles. For information about
        how to launch an Amazon EC2 instance with a role, see Controlling Access
          to Amazon EC2 Resources in the Amazon EC2 User Guide. 
      To create an instance profile and store the role in it (AWS API)
          Create an instance profile: CreateInstanceProfile
        
          Add the role to the instance profile: AddRoleToInstanceProfile
        
     
  Document ConventionsCreate a role for an IAM userCreate a service-linked roleDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideHow do roles for Amazon EC2 instances
        work?Permissions required for using roles
        with Amazon EC2How do I get started?Related informationUse an IAM role to grant permissions to
      applications running on Amazon EC2 instancesApplications that run on an Amazon EC2 instance must include AWS credentials in the AWS API
    requests. You could have your developers store AWS credentials directly within the Amazon EC2
    instance and allow applications in that instance to use those credentials. But developers would
    then have to manage the credentials and ensure that they securely pass the credentials to each
    instance and update each Amazon EC2 instance when it's time to update the credentials. That's a lot
    of additional work.Instead, you can and should use an IAM role to manage temporary credentials for applications that run on an Amazon EC2 instance. When you use
    a role, you don't have to distribute long-term credentials (such as sign-in credentials or
    access keys) to an Amazon EC2 instance. Instead, the role supplies temporary permissions that
    applications can use when they make calls to other AWS resources. When you launch an Amazon EC2
    instance, you specify an IAM role to associate with the instance. Applications that run on the
    instance can then use the role-supplied temporary credentials to sign API requests.Using roles to grant permissions to applications that run on Amazon EC2 instances requires a bit
    of extra configuration. An application running on an Amazon EC2 instance is abstracted from AWS by
    the virtualized operating system. Because of this extra separation, you need an additional step
    to assign an AWS role and its associated permissions to an Amazon EC2 instance and make them
    available to its applications. This extra step is the creation of an instance
        profile attached to the instance. The instance profile contains the role
    and can provide the role's temporary credentials to an application that runs on the instance.
    Those temporary credentials can then be used in the application's API calls to access resources
    and to limit access to only those resources that the role specifies.NoteOnly one role can be assigned to an Amazon EC2 instance at a time, and all applications on the
      instance share the same role and permissions. When you leverage Amazon ECS to manage your Amazon EC2
      instances, you can assign roles to Amazon ECS tasks that can be distinguished from the role of the
      Amazon EC2 instance that it's running on. Assigning each task a role aligns with the principle of
      least privileged access and allows for greater granular control over actions and
      resources.For more information, see Using IAM roles with
        Amazon ECS tasks in the Amazon Elastic Container Service Best Practices Guide.Using roles in this way has several benefits. Because role credentials are temporary and
    updated automatically, you don't have to manage credentials, and you don't have to worry about
    long-term security risks. In addition, if you use a single role for multiple instances, you can
    make a change to that one role and the change propagates automatically to all the instances. NoteAlthough a role is usually assigned to an Amazon EC2 instance when you launch it, a role can
      also be attached to an Amazon EC2 instance currently running. To learn how to attach a role to a
      running instance, see IAM Roles for Amazon EC2.TopicsHow do roles for Amazon EC2 instances
        work?Permissions required for using roles
        with Amazon EC2How do I get started?Related information
    How do roles for Amazon EC2 instances
        work?
    In the following figure, a developer runs an application on an Amazon EC2 instance that
      requires access to the S3 bucket named amzn-s3-demo-bucket-photos. An
      administrator creates the Get-pics service role and attaches the role to the
      Amazon EC2 instance. The role includes a permissions policy that grants read-only access to the
      specified S3 bucket. It also includes a trust policy that allows the Amazon EC2 instance to assume
      the role and retrieve the temporary credentials. When the application runs on the instance, it
      can use the role's temporary credentials to access the photos bucket. The administrator
      doesn't have to grant the developer permission to access the photos bucket, and the developer
      never has to share or manage credentials.
    
       
        
       
       
    
    
       
       
       
       
    
        The administrator uses IAM to create the Get-pics role. In
          the role's trust policy, the administrator specifies that only Amazon EC2 instances can assume
          the role. In the role's permission policy, the administrator specifies read-only
          permissions for the amzn-s3-demo-bucket-photos bucket.
      
        A developer launches an Amazon EC2 instance and assigns the Get-pics role to
          that instance.
        NoteIf you use the IAM console, the instance profile is managed for you and is mostly
            transparent to you. However, if you use the AWS CLI or API to create and manage the role
            and Amazon EC2 instance, then you must create the instance profile and assign the role to it
            as separate steps. Then, when you launch the instance, you must specify the instance
            profile name instead of the role name.
      
        When the application runs, it obtains temporary security credentials from Amazon EC2 instance metadata, as described
          in Retrieving Security Credentials from Instance Metadata. These are temporary security credentials that represent the
          role and are valid for a limited period of time. 
        With some AWS SDKs, the developer can
          use a provider that manages the temporary security credentials transparently. (The
          documentation for individual AWS SDKs describes the features supported by that SDK for
          managing credentials.)
        Alternatively, the application can get the temporary credentials directly from the
          instance metadata of the Amazon EC2 instance. Credentials and related values are available from
          the iam/security-credentials/role-name category
          (in this case, iam/security-credentials/Get-pics) of the metadata. If the
          application gets the credentials from the instance metadata, it can cache the
          credentials.
      
        Using the retrieved temporary credentials, the application accesses the photo bucket.
          Because of the policy attached to the Get-pics role, the
          application has read-only permissions. 
        The temporary security credentials available on the instance automatically update
          before they expire so that a valid set is always available. The application just needs to
          make sure that it gets a new set of credentials from the instance metadata before the
          current ones expire. It is possible to use the AWS SDK to manage credentials so the
          application does not need to include additional logic to refresh the credentials. For
          example, instantiating clients with Instance Profile Credential Providers. However, if the
          application gets temporary security credentials from the instance metadata and has cached
          them, it should get a refreshed set of credentials every hour, or at least 15 minutes
          before the current set expires. The expiration time is included in the information
          returned in the iam/security-credentials/role-name
          category. 
      
   
    Permissions required for using roles
        with Amazon EC2
    To launch an instance with a role, the developer must have permission to launch Amazon EC2
      instances and permission to pass IAM roles.
    The following sample policy allows users to use the AWS Management Console to launch an instance with a
      role. The policy includes wildcards (*) to allow a user to pass any role and to
      perform the listed Amazon EC2 actions. The ListInstanceProfiles action allows users to
      view all of the roles available in the AWS account.
    Example policy that grants a user permission to use the Amazon EC2 console to launch an
        instance with any role{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "IamPassRole",
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "iam:PassedToService": "ec2.amazonaws.com"
                }
            }
        },
        {
            "Sid": "ListEc2AndListInstanceProfiles",
            "Effect": "Allow",
            "Action": [
                "iam:ListInstanceProfiles",
                "ec2:Describe*",
                "ec2:Search*",
                "ec2:Get*"
            ],
            "Resource": "*"
        }
    ]
}

     
      Restricting which roles can be passed
          to Amazon EC2 instances (using PassRole)
      You can use the PassRole permission to restrict which role a user can pass
        to an Amazon EC2 instance when the user launches the instance. This helps prevent the user from
        running applications that have more permissions than the user has been granted—that
        is, from being able to obtain elevated privileges. For example, imagine that user Alice has
        permissions only to launch Amazon EC2 instances and to work with Amazon S3 buckets, but the role she
        passes to an Amazon EC2 instance has permissions to work with IAM and Amazon DynamoDB. In that case,
        Alice might be able to launch the instance, log into it, get temporary security credentials,
        and then perform IAM or DynamoDB actions that she's not authorized for.
      To restrict which roles a user can pass to an Amazon EC2 instance, you create a policy that
        allows the PassRole action. You then attach the policy to the user (or to an
        IAM group that the user belongs to) who will launch Amazon EC2 instances. In the
          Resource element of the policy, you list the role or roles that the user is
        allowed to pass to Amazon EC2 instances. When the user launches an instance and associates a role
        with it, Amazon EC2 checks whether the user is allowed to pass that role. Of course, you should
        also ensure that the role that the user can pass does not include more permissions than the
        user is supposed to have.
      NotePassRole is not an API action in the same way that
            RunInstances or ListInstanceProfiles is. Instead, it's a
          permission that AWS checks whenever a role ARN is passed as a parameter to an API (or
          the console does this on the user's behalf). It helps an administrator to control which
          roles can be passed by which users. In this case, it ensures that the user is allowed to
          attach a specific role to an Amazon EC2 instance.
      Example policy that grants a user permission to launch an Amazon EC2 instance with a
          specific roleThe following sample policy allows users to use the Amazon EC2 API to launch an instance
          with a role. The Resource element specifies the Amazon Resource Name (ARN) of
          a role. By specifying the ARN, the policy grants the user the permission to pass only the
            Get-pics role. If the user tries to specify a different role when launching
          an instance, the action fails. The user does have permissions to run any instance,
          regardless of whether they pass a role.{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "ec2:RunInstances",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "iam:PassRole",
      "Resource": "arn:aws:iam::account-id:role/Get-pics"
    }
  ]
}
     
     
      Allowing an instance profile role to
          switch to a role in another account
      You can allow an application running on an Amazon EC2 instance to run commands in another
        account. To do this, you must allow the Amazon EC2 instance role in the first account to switch
        to a role in the second account.
      Imagine that you are using two AWS accounts and you want to allow an application
        running on an Amazon EC2 instance to run AWS CLI
        commands in both accounts. Assume that the Amazon EC2 instance exists in account
          111111111111. That instance includes the abcd instance
        profile role that allows the application to perform read-only Amazon S3 tasks on the
          amzn-s3-demo-bucket1 bucket within the same
          111111111111 account. However, the application must also be allowed
        to assume the efgh cross-account role to access the
          amzn-s3-demo-bucket2 Amazon S3 bucket in account
          222222222222.
      
         
          
         
         
      
      The abcd Amazon EC2 instance profile role must have the following permissions
        policy to allow the application to access the amzn-s3-demo-bucket1 Amazon S3
        bucket:
      Account 111111111111
              abcd Role Permissions Policy
      {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowAccountLevelS3Actions",
            "Effect": "Allow",
            "Action": [
                "s3:GetBucketLocation",
                "s3:GetAccountPublicAccessBlock",
                "s3:ListAccessPoints",
                "s3:ListAllMyBuckets"
            ],
            "Resource": "arn:aws:s3:::*"
        },
        {
            "Sid": "AllowListAndReadS3ActionOnMyBucket",
            "Effect": "Allow",
            "Action": [
                "s3:Get*",
                "s3:List*"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket1/*",
                "arn:aws:s3:::amzn-s3-demo-bucket1"
            ]
        },
        {
            "Sid": "AllowIPToAssumeCrossAccountRole",
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Resource": "arn:aws:iam::222222222222:role/efgh"
        }
    ]
}
      The abcd role must trust the Amazon EC2 service to assume the role. To do this,
        the abcd role must have the following trust policy:
      Account 111111111111
              abcd Role Trust Policy
      {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "abcdTrustPolicy",
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Principal": {"Service": "ec2.amazonaws.com"}
        }
    ]
}
      Assume that the efgh cross-account role allows read-only Amazon S3 tasks on the
          amzn-s3-demo-bucket2 bucket within the same
          222222222222 account. To do this, the efgh
        cross-account role must have the following permissions policy:
      Account 222222222222
              efgh Role Permissions Policy
      {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowAccountLevelS3Actions",
            "Effect": "Allow",
            "Action": [
                "s3:GetBucketLocation",
                "s3:GetAccountPublicAccessBlock",
                "s3:ListAccessPoints",
                "s3:ListAllMyBuckets"
            ],
            "Resource": "arn:aws:s3:::*"
        },
        {
            "Sid": "AllowListAndReadS3ActionOnMyBucket",
            "Effect": "Allow",
            "Action": [
                "s3:Get*",
                "s3:List*"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket2/*",
                "arn:aws:s3:::amzn-s3-demo-bucket2"
            ]
        }
    ]
}
      The efgh role must trust the abcd instance profile role to
        assume it. To do this, the efgh role must have the following trust
        policy:
      Account 222222222222
              efgh Role Trust Policy
      {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "efghTrustPolicy",
            "Effect": "Allow",
            "Action": "sts:AssumeRole",
            "Principal": {"AWS": "arn:aws:iam::111111111111:role/abcd"}
        }
    ]
}
     
   
    How do I get started?
    To understand how roles work with Amazon EC2 instances, you need to use the IAM console to
      create a role, launch an Amazon EC2 instance that uses that role, and then examine the running
      instance. You can examine the instance metadata to see how the role's temporary credentials are made available to
      an instance. You can also see how an application that runs on an instance can use the role.
      Use the following resources to learn more. 
    
       
       
    
        IAM Roles
            on Amazon EC2 Instances Tutorial. The linked video shows how to use an IAM role with
          an Amazon EC2 instance to control what an application can do when it runs on the instance. The
          video shows how the application (written in the AWS SDK) can get temporary security
          credentials through the role. 
      
        SDK walkthroughs. The AWS SDK documentation includes walkthroughs that show an
          application running on an Amazon EC2 instance that uses temporary credentials for roles to read
          an Amazon S3 bucket. Each of the following walkthroughs presents similar steps with a different
          programming language:
        
           
           
           
        
            Configure IAM Roles for Amazon EC2 with
                the SDK for Java in the AWS SDK for Java Developer Guide
            
          
            Launch an Amazon EC2 Instance using the SDK
                for .NET in the AWS SDK for .NET Developer Guide
          
            Creating an Amazon EC2
                Instance with the SDK for Ruby in the
              AWS SDK for Ruby Developer Guide
          
      
   
    Related information
    For more information about creating roles or roles for Amazon EC2 instances, see the following
      information:
    
       
       
       
       
       
    
        For more information about using IAM roles with Amazon EC2 instances, go to the
            Amazon EC2 User Guide.
      
        To create a role, see IAM role creation
      
        For more information about using temporary security credentials, see Temporary security credentials in IAM.
      
        If you work with the IAM API or CLI, you must create and manage IAM instance
          profiles. For more information about instance profiles, see Use instance profiles.
      
        For more information about temporary security credentials for roles in the instance
          metadata, see Retrieving Security Credentials from Instance Metadata in the Amazon EC2 User Guide.
      
  Document ConventionsSwitch roles (AWS API)Use instance profilesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuidePolicy typesPolicies and the root userOverview of JSON policiesGrant least privilegePolicies and permissions in AWS Identity and Access ManagementManage access in AWS by creating policies and attaching them to IAM identities (users,
    groups of users, or roles) or AWS resources. A policy is an object in AWS that, when
    associated with an identity or resource, defines their permissions. AWS evaluates these
    policies when an IAM principal (user or role) makes a request. Permissions in the policies
    determine whether the request is allowed or denied. Most policies are stored in AWS as JSON
    documents. AWS supports seven types of policies: identity-based policies, resource-based
    policies, permissions boundaries, AWS Organizations service control policies (SCPs), AWS Organizations resource control
    policies (RCPs), access control lists (ACLs), and session policies.IAM policies define permissions for an action regardless of the method that you use to
    perform the operation. For example, if a policy allows the GetUser action, then a user with that policy can
    get user information from the AWS Management Console, the AWS CLI, or the AWS API. When you create an IAM
    user, you can choose to allow console or programmatic access. If console access is allowed, the
    IAM user can sign in to the console using their sign-in credentials. If programmatic access is
    allowed, the user can use access keys to work with the CLI or API.
    Policy types
    The following policy types, listed in order from most frequently used to less frequently
      used, are available for use in AWS. For more details, see the sections below for each policy
      type.
    
       
       
       
       
       
       
       
    
        Identity-based
            policies – Attach managed
          and inline policies to IAM identities (users, groups to
          which users belong, or roles). Identity-based policies grant permissions to an
          identity.
      
        Resource-based
              policies – Attach inline policies to resources. The most
          common examples of resource-based policies are Amazon S3 bucket policies and IAM role trust
          policies. Resource-based policies grant permissions to the principal that is specified in
          the policy. Principals can be in the same account as the resource or in other
          accounts.
      
        Permissions
            boundaries – Use a managed policy as the permissions boundary
          for an IAM entity (user or role). That policy defines the maximum permissions that the
          identity-based policies can grant to an entity, but does not grant permissions.
          Permissions boundaries do not define the maximum permissions that a resource-based policy
          can grant to an entity.
      
        AWS Organizations SCPs
          – Use an AWS Organizations service control policy (SCP) to define the maximum permissions
          for IAM users and IAM roles within accounts in your organization or organizational
          unit (OU). SCPs limit permissions that identity-based policies or resource-based policies
          grant to IAM users or IAM roles within the account. SCPs do not grant
          permissions.
      
        AWS Organizations RCPs
          – Use an AWS Organizations resource control policy (RCP) to define the maximum permissions
          for resources within accounts in your organization or organizational unit (OU). RCPs limit
          permissions that identity-based and resource-based policies can grant to resources in
          accounts within your organization. RCPs do not grant permissions.
      
        Access control lists
            (ACLs) – Use ACLs to control which principals in other accounts
          can access the resource to which the ACL is attached. ACLs are similar to resource-based
          policies, although they are the only policy type that does not use the JSON policy
          document structure. ACLs are cross-account permissions policies that grant permissions to
          the specified principal. ACLs cannot grant permissions to entities within the same
          account.
      
        Session
            policies – Pass advanced session policies when you use the
          AWS CLI or AWS API to assume a role or a federated user. Session policies limit the
          permissions that the role or user's identity-based policies grant to the session. Session
          policies limit permissions for a created session, but do not grant permissions. For more
          information, see Session
            Policies.
      
     
      Identity-based policies
      Identity-based policies are JSON permissions policy documents that control what actions
        an identity (users, groups of users, and roles) can perform, on which resources, and under
        what conditions. Identity-based policies can be further categorized:
      
         
         
      
          Managed
              policies – Standalone identity-based policies that you can attach to
            multiple users, groups, and roles in your AWS account. There are two types of managed
            policies:
          
             
             
          
              AWS managed policies – Managed
                policies that are created and managed by AWS.
            
              Customer managed policies – Managed
                policies that you create and manage in your AWS account. Customer managed policies
                provide more precise control over your policies than AWS managed policies.
            
        
          Inline
              policies – Policies that you add directly to a single user, group,
            or role. Inline policies maintain a strict one-to-one relationship between a policy and
            an identity. They are deleted when you delete the identity.
        
      To learn how to choose between managed and inline policies, see Choose between managed policies
            and inline policies.
     
     
      Resource-based policies
      Resource-based policies are JSON policy documents that you attach to a resource such as
        an Amazon S3 bucket. These policies grant the specified principal permission to perform specific
        actions on that resource and defines under what conditions this applies. Resource-based
        policies are inline policies. There are no managed resource-based policies. 
      To enable cross-account access, you can specify an entire account or IAM entities in
        another account as the principal in a resource-based policy. Adding a cross-account
        principal to a resource-based policy is only half of establishing the trust relationship.
        When the principal and the resource are in separate AWS accounts, you must also use an
        identity-based policy to grant the principal access to the resource. However, if a
        resource-based policy grants access to a principal in the same account, no additional
        identity-based policy is required. For step-by step instructions for granting cross-service
        access, see IAM tutorial: Delegate access across
         AWS accounts using IAM roles.
      The IAM service supports only one type of resource-based policy called a role
          trust policy, which is attached to an IAM role. An
        IAM role is both an identity and a resource that supports resource-based policies. For
        that reason, you must attach both a trust policy and an identity-based policy to an IAM
        role. Trust policies define which principal entities (accounts, users, roles, and federated
        users) can assume the role. To learn how IAM roles are different from other
        resource-based policies, see Cross account resource
            access in IAM.
      To see which other services support resource-based policies, see AWS services that work with
      IAM. To learn more about
        resource-based policies, see Identity-based policies and
         resource-based policies. 
To learn whether principals in accounts outside of your zone of trust (trusted organization or account) have access to assume your roles, see 
What is IAM Access Analyzer?.
     
     
      IAM permissions boundaries
      A permissions boundary is an advanced feature in which you set the maximum permissions
        that an identity-based policy can grant to an IAM entity. When you set a permissions
        boundary for an entity, the entity can perform only the actions that are allowed by both its
        identity-based policies and its permissions boundaries. If you specify a role session or
        user in the principal element of a resource-based policy, an explicit allow in the
        permission boundary is not required. However, if you specify a role ARN in the principal
        element of a resource-based policy, an explicit allow in the permission boundary is
        required. In both cases, an explicit deny in the permission boundary is effective. An
        explicit deny in any of these policies overrides the allow. For more information about
        permissions boundaries, see Permissions boundaries for IAM
            entities.
     
     
      AWS Organizations service control policies (SCPs)
      If you enable all features in an organization, then you can apply service control
        policies (SCPs) to any or all of your accounts. SCPs are JSON policies that specify the
        maximum permissions for IAM users and IAM roles within accounts of an organization or
        organizational unit (OU). The SCP limits permissions for principals in member accounts,
        including each AWS account root user. An explicit deny in any of these policies overrides an allow in
        other policies.
      For more information about AWS Organizations and SCPs, see Service control
          policies (SCPs) in the AWS Organizations User Guide.
     
     
      AWS Organizations resource control policies (RCPs)
      If you enable all features in an organization, then you can use resource control
        policies (RCPs) to centrally apply access controls on resources across multiple
        AWS accounts. RCPs are JSON policies that you can use to set the maximum available
        permissions for resources in your accounts without updating the IAM policies attached to
        each resource that you own. The RCP limits permissions for resources in member accounts and
        can impact the effective permissions for identities, including the AWS account root user, regardless of
        whether they belong to your organization. An explicit deny in any applicable RCP overrides
        an allow in other policies that might be attached to individual identities or
        resources.
      For more information about AWS Organizations and RCPs including a list of AWS services that support
        RCPs, see Resource control
          policies (RCPs) in the AWS Organizations User Guide.
     
     
      Access control lists (ACLs)
      Access control lists (ACLs) are service policies that allow you to control which
        principals in another account can access a resource. ACLs cannot be used to control access
        for a principal within the same account. ACLs are similar to resource-based policies,
        although they are the only policy type that does not use the JSON policy document format.
        Amazon S3, AWS WAF, and Amazon VPC are examples of services that support ACLs. To learn more about ACLs,
        see Access
          Control List (ACL) overview in the Amazon Simple Storage Service Developer
          Guide.
     
     
      Session policies
      Session policies are advanced policies that you pass as a parameter when you
        programmatically create a temporary session for a role or federated user. The permissions
        for a session are the intersection of the identity-based policies for the IAM entity (user
        or role) used to create the session and the session policies. Permissions can also come from
        a resource-based policy. An explicit deny in any of these policies overrides the
        allow.
      You can create role session and pass session policies programmatically using the
          AssumeRole, AssumeRoleWithSAML, or
          AssumeRoleWithWebIdentity API operations. You can pass a single JSON inline
        session policy document using the Policy parameter. You can use the
          PolicyArns parameter to specify up to 10 managed session policies. For more
        information about creating a role session, see Permissions for temporary security
      credentials.
      When you create a federated user session, you use the access keys of the IAM user to
        programmatically call the GetFederationToken API operation. You must also pass
        session policies. The resulting session's permissions are the intersection of the
        identity-based policy and the session policy. For more information about creating a
        federated user session, see Requesting credentials through a custom identity
        broker.
      A resource-based policy can specify the ARN of the user or role as a principal. In that
        case, the permissions from the resource-based policy are added to the role or user's
        identity-based policy before the session is created. The session policy limits the total
        permissions granted by the resource-based policy and the identity-based policy. The
        resulting session's permissions are the intersection of the session policies and the
        resource-based policies plus the intersection of the session policies and identity-based
        policies.
      
         
          
         
         
      
      A resource-based policy can specify the ARN of the session as a principal. In that case,
        the permissions from the resource-based policy are added after the session is created. The
        resource-based policy permissions are not limited by the session policy. The resulting
        session has all the permissions of the resource-based policy plus the intersection of the identity-based policy and the session
        policy.
      
         
          
         
         
      
      A permissions boundary can set the maximum permissions for a user or role that is used
        to create a session. In that case, the resulting session's permissions are the intersection
        of the session policy, the permissions boundary, and the identity-based policy. However, a
        permissions boundary does not limit permissions granted by a resource-based policy that
        specifies the ARN of the resulting session.
      
         
          
         
         
      
     
   
    Policies and the root user
    The AWS account root user is affected by some policy types but not others. You cannot attach
      identity-based policies to the root user, and you cannot set the permissions boundary for the
      root user. However, you can specify the root user as the principal in a resource-based policy or an
      ACL. A root user is still the member of an account. If that account is a member of an
      organization in AWS Organizations, the root user is affected by SCPs and RCPs for the account.
   
    Overview of JSON policies
    Most policies are stored in AWS as JSON documents. Identity-based policies and policies
      used to set permissions boundaries are JSON policy documents that you attach to a user or
      role. Resource-based policies are JSON policy documents that you attach to a resource. SCPs
      and RCPs are JSON policy documents with restricted syntax that you attach to the AWS Organizations'
      organization root, organizational unit (OU), or an account. ACLs are also attached to a
      resource, but you must use a different syntax. Session policies are JSON policies that you
      provide when you assume a role or federated user session.
    It is not necessary for you to understand the JSON syntax. You can use the visual editor
      in the AWS Management Console to create and edit customer managed policies without ever using JSON.
      However, if you use inline policies for groups or complex policies, you must still create and
      edit those policies in the JSON editor using the console. For more information about using the
      visual editor, see Define custom IAM permissions with customer managed
      policies and Edit IAM policies.
    
When you create or edit a JSON policy, IAM can perform policy validation to help you create an effective policy. IAM identifies JSON syntax errors, while IAM Access Analyzer provides 
additional policy checks with recommendations to help you further refine your policies. To learn more about policy validation, see IAM policy validation. To learn more about IAM Access Analyzer policy checks and actionable recommendations, see 
IAM Access Analyzer policy validation.

     
      JSON policy document structure
       
        As illustrated in the following figure, a JSON policy document includes these
          elements:
       
      
         
         
      
          Optional policy-wide information at the top of the document
        
          One or more individual statements
        
      Each statement includes information about a single permission. If a policy includes
        multiple statements, AWS applies a logical OR across the statements when
        evaluating them. If multiple policies apply to a request, AWS applies a logical
          OR across all of those policies when evaluating them. 
      
         
          
         
         
      
      The information in a statement is contained within a series of elements.
      
         
         
         
         
         
         
         
         
      
          Version – Specify the version
            of the policy language that you want to use. We recommend that you use the latest
              2012-10-17 version. For more information, see IAM JSON policy elements:
        Version
        
          Statement – Use this main
            policy element as a container for the following elements. You can include more than one
            statement in a policy.
        
          Sid (Optional) – Include an
            optional statement ID to differentiate between your statements.
        
          Effect – Use
              Allow or Deny to indicate whether the policy allows or
            denies access.
        
          Principal (Required in some
            circumstances) – If you create a resource-based policy, you must indicate the
            account, user, role, or federated user to which you would like to allow or deny access.
            If you are creating an IAM permissions policy to attach to a user or role, you cannot
            include this element. The principal is implied as that user or role.
        
          Action – Include a list of
            actions that the policy allows or denies.
        
          Resource (Required in some
            circumstances) – If you create an IAM permissions policy, you must specify a
            list of resources to which the actions apply. If you create a resource-based policy, it
            depends on the resource you're using as to whether this element is required or
            not.
        
          Condition (Optional) –
            Specify the circumstances under which the policy grants permission.
        
      To learn about these and other more advanced policy elements, see IAM JSON policy element reference.
      
     
     
      Multiple statements and multiple
          policies
       
        If you want to define more than one permission for an entity (user or role), you can
          use multiple statements in a single policy. You can also attach multiple policies. If you
          try to define multiple permissions in a single statement, your policy might not grant the
          access that you expect. We recommend that you break up policies by resource type. 
       
      Because of the limited size of policies, it
        might be necessary to use multiple policies for more complex permissions. It's also a good
        idea to create functional groupings of permissions in a separate customer managed policy.
        For example, Create one policy for IAM user management, one for self-management, and
        another policy for S3 bucket management. Regardless of the combination of multiple
        statements and multiple policies, AWS evaluates your policies the same way.
      For example, the following policy has three statements, each of which defines a separate
        set of permissions within a single account. The statements define the following:
      
         
         
         
      
          The first statement, with an Sid (Statement ID) of
              FirstStatement, lets the user with the attached policy change their own
            password. The Resource element in this statement is "*" (which
            means "all resources"). But in practice, the ChangePassword API operation
            (or equivalent change-password CLI command) affects only the password for
            the user who makes the request. 
        
          The second statement lets the user list all the Amazon S3 buckets in their AWS account.
            The Resource element in this statement is "*" (which means
            "all resources"). But because policies don't grant access to resources in other
            accounts, the user can list only the buckets in their own AWS account. 
        
          The third statement lets the user list and retrieve any object that is in a bucket
            named amzn-s3-demo-bucket-confidential-data, but only when the user is
            authenticated with multi-factor authentication (MFA). The Condition element
            in the policy enforces the MFA authentication.
          When a policy statement contains a Condition element, the statement is
            only in effect when the Condition element evaluates to true. In this case,
            the Condition evaluates to true when the user is MFA-authenticated. If the
            user is not MFA-authenticated, this Condition evaluates to false. In that
            case, the third statement in this policy does not apply and the user does not have
            access to the amzn-s3-demo-bucket-confidential-data bucket.
        
      {
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "FirstStatement",
      "Effect": "Allow",
      "Action": ["iam:ChangePassword"],
      "Resource": "*"
    },
    {
      "Sid": "SecondStatement",
      "Effect": "Allow",
      "Action": "s3:ListAllMyBuckets",
      "Resource": "*"
    },
    {
      "Sid": "ThirdStatement",
      "Effect": "Allow",
      "Action": [
        "s3:List*",
        "s3:Get*"
      ],
      "Resource": [
        "arn:aws:s3:::amzn-s3-demo-bucket-confidential-data",
        "arn:aws:s3:::amzn-s3-demo-bucket-confidential-data/*"
      ],
      "Condition": {"Bool": {"aws:MultiFactorAuthPresent": "true"}}
    }
  ]
}
     
     
      Examples of JSON policy syntax
      The following identity-based policy allows the implied principal to list a single Amazon S3
        bucket named amzn-s3-demo-bucket: 
      {
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "s3:ListBucket",
    "Resource": "arn:aws:s3:::amzn-s3-demo-bucket"
  }
}
      The following resource-based policy can be attached to an Amazon S3 bucket. The policy allows
        members of a specific AWS account to perform any Amazon S3 actions in the bucket named
          amzn-s3-demo-bucket. It allows any action that can be performed on a bucket
        or the objects within it. (Because the policy grants trust only to the account, individual
        users in the account must still be granted permissions for the specified Amazon S3 actions.) 
      {
  "Version": "2012-10-17",
  "Statement": [{
    "Sid": "1",
    "Effect": "Allow",
    "Principal": {"AWS": ["arn:aws:iam::account-id:root"]},
    "Action": "s3:*",
    "Resource": [
      "arn:aws:s3:::amzn-s3-demo-bucket",
      "arn:aws:s3:::amzn-s3-demo-bucket/*"
    ]
  }]
}
      To view example policies for common scenarios, see Example IAM identity-based policies.
     
   
    Grant least privilege
    When you create IAM policies, follow the standard security advice of granting
            least privilege, or granting only the permissions required to
        perform a task. Determine what users and roles need to do and then craft policies that allow
        them to perform only those tasks. 
    Start with a minimum set of permissions and grant additional permissions as necessary.
        Doing so is more secure than starting with permissions that are too lenient and then trying
        to tighten them later.
    As an alternative to least privilege, you can use AWS managed policies or policies with wildcard * permissions to
        get started with policies. Consider the security risk of granting your principals more
        permissions than they need to do their job. Monitor those principals to learn which
        permissions they are using. Then write least privilege policies.
    IAM provides several options to help you refine the permissions that you grant.
    
         
         
         
         
         
    
            Understand access level groupings – You
                can use access level groupings to understand the level of access that a policy
                grants. Policy actions are
                classified as List, Read, Write,
                    Permissions management, or Tagging. For example, you
                can choose actions from the List and Read access levels to
                grant read-only access to your users. To learn how to use policy summaries to
                understand access level permissions, see Access levels
      in policy summaries.
        
            Validate your policies – You can perform
                policy validation using IAM Access Analyzer when you create and edit JSON policies. We
                recommend that you review and validate all of your existing policies. IAM Access Analyzer
                provides over 100 policy checks to validate your policies. It generates security
                warnings when a statement in your policy allows access we consider overly
                permissive. You can use the actionable recommendations that are provided through the
                security warnings as you work toward granting least privilege. To learn more about
                policy checks provided by IAM Access Analyzer, see IAM Access Analyzer policy
                    validation.
        
            Generate a policy based on access activity
                – To help you refine the permissions that you grant, you can generate an
                IAM policy that is based on the access activity for an IAM entity (user or
                role). IAM Access Analyzer reviews your AWS CloudTrail logs and generates a policy template that
                contains the permissions that have been used by the entity in your specified time
                frame. You can use the template to create a managed policy with fine-grained
                permissions and then attach it to the IAM entity. That way, you grant only the
                permissions that the user or role needs to interact with AWS resources for your
                specific use case. To learn more, see IAM Access Analyzer
                    policy generation.
        
            Use last accessed information – Another
                feature that can help with least privilege is last accessed
                    information. View this information on the Access
                    Advisor tab on the IAM console details page for an IAM user,
                group, role, or policy. Last accessed information also includes information about
                the actions that were last accessed for some services, such as Amazon EC2, IAM, Lambda,
                and Amazon S3. If you sign in using AWS Organizations management account credentials, you can view
                service last accessed information in the AWS Organizations section of
                the IAM console. You can also use the AWS CLI or AWS API to retrieve a report for
                last accessed information for entities or policies in IAM or AWS Organizations. You can use
                this information to identify unnecessary permissions so that you can refine your
                IAM or AWS Organizations policies to better adhere to the principle of least privilege. For
                more information, see Refine permissions in AWS using last
         accessed information.
        
            Review account events in AWS CloudTrail – To
                further reduce permissions, you can view your account's events in AWS CloudTrail
                    Event history. CloudTrail event logs include detailed event
                information that you can use to reduce the policy's permissions. The logs include
                only the actions and resources that your IAM entities need. For more information,
                see Viewing CloudTrail
                    Events in the CloudTrail Console in the AWS CloudTrail User
                    Guide.
        
    
    For more information, see the following policy topics for individual services, which
        provide examples of how to write policies for service-specific resources.
    
         
         
         
    
            Using resource-based policies for DynamoDB in the
                    Amazon DynamoDB Developer Guide
        
            Bucket policies for Amazon S3 in the
                Amazon Simple Storage Service User Guide
        
            Access Control List (ACL) overview in the
                    Amazon Simple Storage Service User Guide
        
Document ConventionsAccess managementManaged policies and inline policiesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideDefine custom IAM permissions with customer managed
      policiesPolicies define permissions for identities or
    resources in AWS. You can create customer managed policies
    in IAM using the AWS Management Console, AWS CLI, or AWS API. Customer managed policies are standalone
    policies that you manage in your own AWS account. You can then attach the policies to
    identities (users, groups, and roles) in your AWS account.An identity-based policy is a policy attached to an
    identity in IAM. Identity-based policies can include AWS managed policies, customer managed
    policies, and inline policies. AWS managed policies are created and managed by AWS, and you
    can use them but not manage them. An inline policy is one that you create and embed directly to
    an IAM user group, user, or role. Inline policies can't be reused on other identities or
    managed outside of the identity where they exist. For more information, see Adding and removing IAM identity
      permissions.It's generally better to use customer managed policies instead of inline policies or
    AWS managed policies. AWS managed policies usually provide broad administrative or read-only
    permissions. For the greatest security, grant the least
      privilege, which means granting only the permissions required to perform specific job
    tasks.When you create or edit IAM policies, AWS can automatically perform policy validation to
    help you create an effective policy with least privilege in mind. In the AWS Management Console, IAM
    identifies JSON syntax errors, while IAM Access Analyzer provides additional policy checks with
    recommendations to help you further refine your policies. To learn more about policy validation,
    see IAM policy validation. To learn more about IAM Access Analyzer policy
    checks and actionable recommendations, see IAM Access Analyzer policy
      validation.You can use the AWS Management Console, AWS CLI, or AWS API to create customer managed policies in IAM.
    For more information about using AWS CloudFormation templates to add or update policies, see AWS Identity and Access Management resource
      type reference in the AWS CloudFormation User Guide.TopicsCreate IAM policies (console)Create IAM policies (AWS CLI)Create IAM policies (AWS API)Document ConventionsManage IAM policiesCreate IAM policies (console)Did this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideGet started with managed
                policiesUsing inline policiesChoose between managed policies
            and inline policiesConsider your use cases when deciding between managed and inline policies. In most cases,
        we recommend that you use managed policies instead of inline policies.NoteYou can use both managed and inline policies together to define common and unique
            permissions for a principal entity.Managed policies provide the following features:
         
         
         
         
         
         

    
            Reusability
            
                A single managed policy can be attached to multiple principal entities (users,
                    groups, and roles). You can create a library of policies that define useful
                    permissions for your AWS account, and then attach these policies to principal
                    entities as needed.
            
        
            Central change management
            
                When you change a managed policy, the change is applied to all principal
                    entities that the policy is attached to. For example, if you want to add
                    permission for a new AWS API, you can update a customer managed policy or
                    associate an AWS managed policy to add the permission. If you're using an
                    AWS managed policy, AWS updates the policy. When a managed policy is
                    updated, the changes are applied to all principal entities that the managed
                    policy is attached to. In contrast, to change an inline policy, you must
                    individually edit each identity that contains the inline policy. For example, if
                    a group and a role both contain the same inline policy, you must individually
                    edit both principal entities to change that policy. 
            
        
            Versioning and rolling back
            
                When you change a customer managed policy, the changed policy doesn't
                    overwrite the existing policy. Instead, IAM creates a new version of the
                    managed policy. IAM stores up to five versions of your customer managed
                    policies. You can use policy versions to revert a policy to an earlier version
                    as needed. 
                NoteA policy version is different from a Version policy element.
                        The Version policy element is used within a policy and defines
                        the version of the policy language. To learn more about policy versions, see
                            Versioning IAM policies. To learn more
                        about the Version policy element see IAM JSON policy elements:
        Version.
            
        
            Delegating permissions management
            
                You can allow users in your AWS account to attach and detach policies while
                    maintaining control over the permissions defined in those policies. To do this,
                    designate some users as full administrators—that is, administrators that
                    can create, update, and delete policies. You can then designate other users as
                    limited administrators. Those limited administrators can attach policies to
                    other principal entities, but only the policies that you have allowed them to
                    attach.
                For more information about delegating permissions management, see Controlling access to policies. 
            
        
            Larger policy character limits
            
                The maximum character size limit for managed policies is greater than the
                    character limit for group inline policies. If you reach the inline policy's character
                    size limit, you can create more IAM groups and attach the managed policy to
                    the group.
                For more information on quotas and limits, see IAM and AWS STS quotas.
                
            
        
            Automatic updates for AWS managed policies
            
                AWS maintains AWS managed policies and updates them when necessary, for
                    example, to add permissions for new AWS services, without you having to make
                    changes. The updates are automatically applied to the principal entities that
                    you have attached the AWS managed policy to. 
            
        
        Get started with managed
                policies
        We recommend using policies that grant least
                privilege, or granting only the permissions required to perform a task. The
            most secure way to grant least privilege is to write a customer managed policy with only
            the permissions needed by your team. You must create a process to allow your team to
            request more permissions when necessary. It takes time and expertise to create IAM customer managed
                policies that provide your team with only the permissions they need.
        To get started adding permissions to your IAM identities (users, groups of users,
            and roles), you can use AWS managed policies. AWS managed policies don't grant least
            privilege permissions. You must consider the security risk of granting your principals
            more permissions than they need to do their job.
        
        You can attach AWS managed policies, including job functions, to any IAM identity.
            For more information, see Adding and removing IAM identity
      permissions.
        To switch to least privilege permissions, you can run AWS Identity and Access Management and Access Analyzer to monitor
            the principals with AWS managed policies. After learning which permissions they are
            using, then you can write or generate a customer managed policy with only the required
            permissions for your team. This is less secure, but provides more flexibility as you
            learn how your team is using AWS. For more information, see IAM Access Analyzer policy generation.
        AWS managed policies are designed to provide permissions for many common use cases.
            For more information about AWS managed policies that are designed for specific job
            functions, see AWS managed policies for job functions.
        
        For a list of AWS managed policies, see AWS
                Managed Policy Reference Guide.
     
        Using inline policies
        Inline policies are useful if you want to maintain a strict one-to-one relationship
            between a policy and the identity to which it is applied. For example, if you want to be
            sure that the permissions in a policy are not inadvertently assigned to an identity
            other than the one they're intended for. When you use an inline policy, the permissions
            in the policy cannot be inadvertently attached to the wrong identity. In addition, when
            you use the AWS Management Console to delete that identity, the policies embedded in the identity are
            deleted as well because they are part of the principal entity.
    Document ConventionsManaged policies and inline policiesConvert inline
            policy to managedDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideHow to specify a principalAWS account principalsIAM role principalsRole session principalsIAM user principalsIdentity Center principalsFederated user session principalsAWS service principalsAWS service principals in opt-in
        RegionsAll principalsMore informationAWS JSON policy elements:
        PrincipalUse the Principal element in a resource-based JSON policy to specify the
    principal that is allowed or denied access to a resource. You must use the Principal element in resource-based policies. Several
    services support resource-based policies, including IAM. The IAM resource-based policy type
    is a role trust policy. In IAM roles, use the Principal element in the role trust
    policy to specify who can assume the role. For cross-account access, you must specify the
    12-digit identifier of the trusted account. 
To learn whether principals in accounts outside of your zone of trust (trusted organization or account) have access to assume your roles, see 
What is IAM Access Analyzer?.NoteAfter you create the role, you can change the account to "*" to allow everyone to assume
      the role. If you do this, we strongly recommend that you limit who can access the role through
      other means, such as a Condition element that limits access to only certain IP
      addresses. Do not leave your role accessible to everyone!Other examples of resources that support resource-based policies include an Amazon S3 bucket or
    an AWS KMS key.You cannot use the Principal element in an identity-based policy.
    Identity-based policies are permissions policies that you attach to IAM identities (users,
    groups, or roles). In those cases, the principal is implicitly the identity where the policy is
    attached.TopicsHow to specify a principalAWS account principalsIAM role principalsRole session principalsIAM user principalsIAM Identity Center principalsAWS STS federated user session principalsAWS service principalsAWS service principals in opt-in
        RegionsAll principalsMore information
    How to specify a principal
    You specify a principal in the Principal element of a resource-based policy
      or in condition keys that support principals.
    You can specify any of the following principals in a policy:
    
       
       
       
       
       
       
       
    
        AWS account and root user
      
        IAM roles
      
        Role sessions 
      
        IAM users
      
        Federated user sessions
      
        AWS services
      
        All principals
      
    You cannot identify a user group as a principal in a policy (such as a resource-based
      policy) because groups relate to permissions, not authentication, and principals are
      authenticated IAM entities.
    You can specify more than one principal for each of the principal types in following
      sections using an array. Arrays can take one or more values. When you specify more than one
      principal in an element, you grant permissions to each principal. This is a logical
        OR and not a logical AND, because you authenticate as one
      principal at a time. If you include more than one value, use square brackets ([
      and ]) and comma-delimit each entry for the array. The following example policy
      defines permissions for the 123456789012 account or the 555555555555
      account.
    "Principal" : { 
"AWS": [ 
  "123456789012",
  "555555555555" 
  ]
}
    NoteYou cannot use a wildcard to match part of a principal name or ARN. 
   
    AWS account principals
    You can specify AWS account identifiers in the Principal element of a
      resource-based policy or in condition keys that support principals. This delegates authority
      to the account. When you allow access to a different account, an administrator in that account
      must then grant access to an identity (IAM user or role) in that account. When you specify
      an AWS account, you can use the account ARN
        (arn:aws:iam::account-ID:root), or a shortened form that
      consists of the "AWS": prefix followed by the account ID.
    For example, given an account ID of 123456789012, you can use either
      of the following methods to specify that account in the Principal element:
    "Principal": { "AWS": "arn:aws:iam::123456789012:root" }
    "Principal": { "AWS": "123456789012" }
    The account ARN and the shortened account ID behave the same way. Both delegate
      permissions to the account. Using the account ARN in the Principal element does
      not limit permissions to only the root user of the account. 
    NoteWhen you save a resource-based policy that includes the shortened account ID, the
        service might convert it to the principal ARN. This does not change the functionality of the
        policy.
    Some AWS services support additional options for specifying an account principal. For
      example, Amazon S3 lets you specify a canonical user ID using
      the following format:
    "Principal": { "CanonicalUser": "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be" }
    You can also specify more than one AWS account, (or canonical user ID) as a principal
      using an array. For example, you can specify a principal in a bucket policy using all three
      methods.
    "Principal": { 
  "AWS": [
    "arn:aws:iam::123456789012:root",
    "999999999999"
  ],
  "CanonicalUser": "79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be"
}
   
    IAM role principals
    You can specify IAM role principal ARNs in the Principal element of a
      resource-based policy or in condition keys that support principals. IAM roles are
      identities. In IAM, identities are resources to which you can assign permissions. Roles
      trust another authenticated identity to assume that role. This includes a principal in AWS
      or a user from an external identity provider (IdP). When a principal or identity assumes a
      role, they receive temporary security credentials with the assumed role’s permissions. When
      they use those session credentials to perform operations in AWS, they become a
        role session principal. 
    IAM roles are identities that exist in IAM. Roles trust another authenticated
      identity, such as a principal in AWS or a user from an external identity provider. When a
      principal or identity assumes a role, they receive temporary security credentials. They can
      then use those credentials as a role session principal to perform operations in AWS. 
    When you specify a role principal in a resource-based policy, the effective permissions
      for the principal are limited by any policy types that limit permissions for the role. This
      includes session policies and permissions boundaries. For more information about how the
      effective permissions for a role session are evaluated, see Policy evaluation logic.
    To specify the role ARN in the Principal element, use the following
      format:
    "Principal": { "AWS": "arn:aws:iam::AWS-account-ID:role/role-name" }
    ImportantIf your Principal element in a role trust policy contains an ARN that
        points to a specific IAM role, then that ARN transforms to the role unique principal ID
        when you save the policy. This helps mitigate the risk of someone escalating their
        privileges by removing and recreating the role. You don't normally see this ID in the
        console, because IAM uses a reverse transformation back to the role ARN when the trust
        policy is displayed. However, if you delete the role, then you break the relationship. The
        policy no longer applies, even if you recreate the role because the new role has a new
        principal ID that does not match the ID stored in the trust policy. When this happens, the
        principal ID appears in resource-based policies because AWS can no longer map it back to a
        valid ARN. The end result is that if you delete and recreate a role referenced in a trust
        policy's Principal element, you must edit the role in the policy to replace the
        principal ID with the correct ARN. The ARN once again transforms into the role's new
        principal ID when you save the policy. For more information, see Understanding AWS's Handling of Deleted IAM roles in Policies.
    Alternatively, you can specify the role principal as the principal in a resource-based
      policy or create a broad-permission policy that
      uses the aws:PrincipalArn condition key. When you use this key, the role session
      principal is granted the permissions based on the ARN of role that was assumed, and not the
      ARN of the resulting session. Because AWS does not convert condition key ARNs to IDs,
      permissions granted to the role ARN persist if you delete the role and then create a new role
      with the same name. Identity-based policy types, such as permissions boundaries or session
      policies, do not limit permissions granted using the aws:PrincipalArn condition
      key with a wildcard(*) in the Principal element, unless the identity-based
      policies contain an explicit deny.
   
    Role session principals
    You can specify role sessions in the Principal element of a resource-based
      policy or in condition keys that support principals. When a principal or identity assumes a
      role, they receive temporary security credentials with the assumed role’s permissions. When
      they use those session credentials to perform operations in AWS, they become a
        role session principal.
    The format that you use for a role session principal depends on the AWS STS operation that
      was used to assume the role.
    Additionally, administrators can design a process to control how role sessions are issued.
      For example, they can provide a one-click solution for their users that creates a predictable
      session name. If your administrator does this, you can use role session principals in your
      policies or condition keys. Otherwise, you can specify the role ARN as a principal in the
        aws:PrincipalArn condition key. How you specify the role as a principal can
      change the effective permissions for the resulting session. For more information, see IAM role principals. 
     
      Assumed-role session principals
      An assumed-role session principal is a session principal that
        results from using the AWS STS AssumeRole operation. For more information about
        which principals can assume a role using this operation, see Compare AWS STS credentials.
      To specify the assumed-role session ARN in the Principal element, use the
        following format:
      "Principal": { "AWS": "arn:aws:sts::AWS-account-ID:assumed-role/role-name/role-session-name" }
      When you specify an assumed-role session in a Principal element, you cannot
        use a wildcard "*" to mean all sessions. Principals must always name a specific
        session.
     
     
      OIDC federated principals
      A federated principal is a session principal that results from
        using the AWS STS AssumeRoleWithWebIdentity operation. You can use an external
        OIDC provider (IdP) to sign in, and then assume an IAM role using this operation. This
        leverages identity federation and issues a role session. For more information about which
        principals can assume a role using this operation, see Compare AWS STS credentials.
      When you issue a role from an OIDC provider, you get this special type of session
        principal that includes information about the OIDC provider. 
      Use this principal type in your policy to allow or deny access based on the built-in
        trusted web identity provider. To specify the OIDC role session ARN in the
          Principal element of a role trust policy, use the following format:
      "Principal": { "Federated": "cognito-identity.amazonaws.com" }
      "Principal": { "Federated": "www.amazon.com" }
      "Principal": { "Federated": "graph.facebook.com" }
      "Principal": { "Federated": "accounts.google.com" }
      Use this principal type in your policy to allow or deny access based on custom trusted
        web identity provider. For example, if GitHub was the trusted web identity
        provider, the OIDC role session ARN in the Principal element of a role trust policy, uses
        the following format:
      "Principal": { "Federated": "arn:aws:iam::AWS-account-ID:oidc-provider/tokens.actions.githubusercontent.com" }
     
     
      SAML federated principals
      A SAML federated principal is a session principal that results from
        using the AWS STS AssumeRoleWithSAML operation. You can use an external SAML
        identity provider (IdP) to sign in, and then assume an IAM role using this operation. This
        leverages identity federation and issues a role session. For more information about which
        principals can assume a role using this operation, see Compare AWS STS credentials.
      When you issue a role from a SAML identity provider, you get this special type of
        session principal that includes information about the SAML identity provider.
      Use this principal type in your policy to allow or deny access based on the trusted SAML
        identity provider. To specify the SAML identity role session ARN in the
          Principal element of a role trust policy, use the following format:
      "Principal": { "Federated": "arn:aws:iam::AWS-account-ID:saml-provider/provider-name" }
     
   
    IAM user principals
    You can specify IAM users in the Principal element of a resource-based
      policy or in condition keys that support principals.
    NoteIn a Principal element, the user name part of the Amazon Resource Name (ARN) is case
        sensitive.
    "Principal": { "AWS": "arn:aws:iam::AWS-account-ID:user/user-name" }
    "Principal": {
  "AWS": [
    "arn:aws:iam::AWS-account-ID:user/user-name-1", 
    "arn:aws:iam::AWS-account-ID:user/user-name-2"
  ]
}
    When you specify users in a Principal element, you cannot use a wildcard
        (*) to mean "all users". Principals must always name specific users. 
    ImportantIf your Principal element in a role trust policy contains an ARN that
        points to a specific IAM user, then IAM transforms the ARN to the user's unique
        principal ID when you save the policy. This helps mitigate the risk of someone escalating
        their privileges by removing and recreating the user. You don't normally see this ID in the
        console, because there is also a reverse transformation back to the user's ARN when the
        trust policy is displayed. However, if you delete the user, then you break the relationship.
        The policy no longer applies, even if you recreate the user. That's because the new user has
        a new principal ID that does not match the ID stored in the trust policy. When this happens,
        the principal ID appears in resource-based policies because AWS can no longer map it back
        to a valid ARN. The result is that if you delete and recreate a user referenced in a trust
        policy Principal element, you must edit the role to replace the now incorrect
        principal ID with the correct ARN. IAM once again transforms ARN into the user's new
        principal ID when you save the policy.
   
    IAM Identity Center principals
    In IAM Identity Center, the principal in a resource-based policy must be defined as the AWS account
      principal. To specify access, reference the role ARN of the permission set in the condition
      block. For details, see Referencing permission
        sets in resource policies, Amazon EKS, and AWS KMS in the IAM Identity Center User
        Guide.

   
    AWS STS federated user session principals
    You can specify federated user sessions in the Principal
      element of a resource-based policy or in condition keys that support principals.
    ImportantAWS recommends that you use AWS STS federated user sessions only when necessary, such as
        when root user access
          is required. Instead, use roles
          to delegate permissions.
    An AWS STS federated user session principal is a session principal that
      results from using the AWS STS GetFederationToken operation. In this case,
      AWS STS uses identity federation
      as the method to obtain temporary access tokens instead of using IAM roles. 
    In AWS, IAM users or an AWS account root user can authenticate using long-term access keys. For
      more information about which principals can federate using this operation, see Compare AWS STS credentials.
    
       
       
    
        IAM federated user – An IAM user federates
          using the GetFederationToken operation that results in a federated user
          session principal for that IAM user.
      
        Federated root user – A root user federates using
          the GetFederationToken operation that results in a federated user session
          principal for that root user.
      
    When an IAM user or root user requests temporary credentials from AWS STS using this
      operation, they begin a temporary federated user session. This session’s ARN is based on the
      original identity that was federated.
    To specify the federated user session ARN in the Principal element, use the
      following format:
    "Principal": { "AWS": "arn:aws:sts::AWS-account-ID:federated-user/user-name" }
   
    AWS service principals
    You can specify AWS services in the Principal element of a resource-based
      policy or in condition keys that support principals. A service principal
      is an identifier for a service. 
    IAM roles that can be assumed by an AWS service are called service roles. Service roles must
      include a trust policy. Trust policies are resource-based
      policies attached to a role that defines which principals can assume the role. Some service
      roles have predefined trust policies. However, in some cases, you must specify the service
      principal in the trust policy. The service principal in an IAM policy can't be
        "Service": "*".
    
    ImportantThe identifier for a service principal includes the service name, and is usually in the
        following format:service-name.amazonaws.com
    The service principal is defined by the service. You can find the service principal for
      some services by opening AWS services that work with
      IAM, checking whether the service
      has Yes in the Service-linked
        role column, and opening the Yes link to view
      the service-linked role documentation for that service. Find the Service-Linked Role
        Permissions section for that service to view the service principal.
    The following example shows a policy that can be attached to a service role. The policy
      enables two services, Amazon ECS and Elastic Load Balancing, to assume the role. The services can then perform any
      tasks granted by the permissions policy assigned to the role (not shown). To specify multiple
      service principals, you do not specify two Service elements; you can have only
      one. Instead, you use an array of multiple service principals as the value of a single
        Service element.
    "Principal": {
    "Service": [
        "ecs.amazonaws.com",
        "elasticloadbalancing.amazonaws.com"
   ]
}
   
    AWS service principals in opt-in
        Regions
    You can launch resources in several AWS Regions and some of those Regions you must opt
      in to. For a complete list of Regions you must opt in to, see Managing AWS Regions in the AWS General Reference guide.
    
    When an AWS service in an opt-in Region makes a request within the same Region, the
      service principal name format is identified as the non-regionalized version of their service
      principal name:
    service-name.amazonaws.com
    When an AWS service in an opt-in Region makes a cross-region request to another Region,
      the service principal name format is identified as the regionalized version of their service
      principal name:
    service-name.{region}.amazonaws.com
    For example, you have an Amazon SNS topic located in Region ap-southeast-1 and an
      Amazon S3 bucket located in opt-in Region ap-east-1. You want to configure S3 bucket
      notifications to publish messages to the SNS topic. To allow the S3 service to post messages
      to the SNS topic you must grant the S3 service principal sns:Publish permission
      via the resource-based access policy of the topic.
    If you specify the non-regionalized version of the S3 service principal,
        s3.amazonaws.com, in the topic access policy, the sns:Publish
      request from the bucket to the topic will fail. The following example specifies the
      non-regionalized S3 service principal in the Principal policy element of the SNS
      topic access policy.
    "Principal": { "Service": "s3.amazonaws.com" }
    Since the bucket is located in an opt-in Region and the request is made outside of that
      same Region, the S3 service principal appears as the regionalized service principal name,
        s3.ap-east-1.amazonaws.com. You must use the regionalized service principal
      name when an AWS service in an opt-in Region makes a request to another Region. After you
      specify the regionalized service principal name, if the bucket makes an
        sns:Publish request to the SNS topic located in another Region, the request
      will be successful. The following example specifies the regionalized S3 service principal in
      the Principal policy element of the SNS topic access policy.
    "Principal": { "Service": "s3.ap-east-1.amazonaws.com" }
    Resource policies or service principal-based allow-lists for cross-Region requests from an
      opt-in Region to another Region will only be successful if you specify the regionalized
      service principal name.
    NoteFor IAM role trust policies, we recommend using the non-regionalized service principal
        name. IAM resources are global and therefore the same role can be used in any
        Region.
   
    All principals
    You can use a wildcard (*) to specify all principals in the Principal element
      of a resource-based policy or in condition keys that support principals. Resource-based policies
      grant permissions and condition keys are used
      to limit the conditions of a policy statement.
    ImportantWe strongly recommend that you do not use a wildcard (*) in the Principal
        element of a resource-based policy with an Allow effect unless you intend to
        grant public or anonymous access. Otherwise, specify intended principals, services, or AWS
        accounts in the Principal element and then further restrict access in the
          Condition element. This is especially true for IAM role trust policies,
        because they allow other principals to become a principal in your account.
    For resource-based policies, using a wildcard (*) with an Allow effect grants
      access to all users, including anonymous users (public access). For IAM users and role
      principals within your account, no other permissions are required. For principals in other
      accounts, they must also have identity-based permissions in their account that allow them to
      access your resource. This is called cross-account
        access.
    For anonymous users, the following elements are equivalent:
    "Principal": "*"
    "Principal" : { "AWS" : "*" }
    You cannot use a wildcard to match part of a principal name or ARN.
    The following example shows a resource-based policy that can be used instead of AWS JSON policy elements:
        NotPrincipal to explicitly deny all principals
        except for the ones specified in the Condition element.
      This policy should be added to an Amazon S3
      bucket.
    {
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "UsePrincipalArnInsteadOfNotPrincipalWithDeny",
      "Effect": "Deny",
      "Action": "s3:*",
      "Principal": "*",
      "Resource": [
        "arn:aws:s3:::amzn-s3-demo-bucket/*",
        "arn:aws:s3:::amzn-s3-demo-bucket"
      ],
      "Condition": {
        "ArnNotEquals": {
          "aws:PrincipalArn": "arn:aws:iam::444455556666:user/user-name"
        }
      }
    }
  ]
}
   
    More information
    For more information, see the following:
    
       
       
       
       
       
       
    
        Bucket policy examples
          in the Amazon Simple Storage Service User Guide
      
        Example policies for
            Amazon SNS in the Amazon Simple Notification Service Developer Guide
      
        Amazon SQS policy examples in the
            Amazon Simple Queue Service Developer Guide
      
        Key policies in the
            AWS Key Management Service Developer Guide
      
        Account identifiers in the
            AWS General Reference
      
        OIDC federation
      
  Document ConventionsEffectNotPrincipalDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Storage Service (S3)User GuideWho is a grantee?What permissions can I grant?aclRequired values for common Amazon S3
					requestsSample ACLCanned ACLAccess control list (ACL) overviewAmazon S3 access control lists (ACLs) enable you to manage access to buckets and objects. Each
			bucket and object has an ACL attached to it as a subresource. It defines which AWS accounts or groups are granted access and the type of access. When a request is received
			against a resource, Amazon S3 checks the corresponding ACL to verify that the requester has
			the necessary access permissions. S3 Object Ownership is an Amazon S3 bucket-level setting that you can use to both control ownership of the objects that are 
    uploaded to your bucket and to disable or enable ACLs. By default, Object Ownership is set to the Bucket owner enforced setting, 
    and all ACLs are disabled. When ACLs are disabled, the bucket owner owns all the objects in the bucket and manages access to them 
    exclusively by using access-management policies. A majority of modern use cases in Amazon S3 no longer require the use of ACLs. We recommend that you keep ACLs disabled, except 
	in unusual circumstances where you need to control access for each object individually. With ACLs disabled, you can use policies 
	to control access to all objects in your bucket, regardless of who uploaded the objects to your bucket. 
	For more information, see Controlling ownership of objects and disabling ACLs
			for your bucket.ImportantIf your general purpose bucket uses the Bucket owner enforced setting for S3 Object Ownership, you must use policies to 
         grant access to your general purpose bucket and the objects in it. With the Bucket owner enforced setting enabled, requests to set 
         access control lists (ACLs) or update ACLs fail and return the AccessControlListNotSupported error code. 
         Requests to read ACLs are still supported.When you create a bucket or an object, Amazon S3 creates a default ACL that grants the resource
			owner full control over the resource. This is shown in the following sample bucket ACL
			(the default object ACL has the same structure):<?xml version="1.0" encoding="UTF-8"?>
<AccessControlPolicy xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
  <Owner>
    <ID>*** Owner-Canonical-User-ID ***</ID>
    <DisplayName>owner-display-name</DisplayName>
  </Owner>
  <AccessControlList>
    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
               xsi:type="Canonical User">
        <ID>*** Owner-Canonical-User-ID ***</ID>
        <DisplayName>display-name</DisplayName>
      </Grantee>
      <Permission>FULL_CONTROL</Permission>
    </Grant>
  </AccessControlList>
</AccessControlPolicy> The sample ACL includes an Owner element that identifies the owner by the
			AWS account's canonical user ID. For instructions on finding your canonical user ID,
			see Finding an AWS account canonical user
						ID. The
				Grant element identifies the grantee (either an AWS account or a
			predefined group) and the permission granted. This default ACL has one
				Grant element for the owner. You grant permissions by adding
				Grant elements, with each grant identifying the grantee and the
			permission. NoteAn ACL can have up to 100 grants.TopicsWho is a grantee?What permissions can I grant?aclRequired values for common Amazon S3
					requestsSample ACLCanned ACLWho is a grantee?
			
			A grantee can be an AWS account or one of the predefined Amazon S3 groups. You grant
				permission to an AWS account using the email address or the canonical user ID.
				However, if you provide an email address in your grant request, Amazon S3 finds the
				canonical user ID for that account and adds it to the ACL. The resulting ACLs always
				contain the canonical user ID for the AWS account, not the email address of the
				AWS account.
			When you grant access rights, you specify each grantee as a
						type="value"
				pair, where type is one of the
				following:
			
				 
				 
				 
			id – If the value specified is the canonical user ID of an AWS accounturi – If you are granting permissions to a predefined groupemailAddress – If the value specified is the email address of an
						AWS account
			    
	ImportantUsing email addresses to specify a grantee is only supported in the following AWS
				Regions:
				 
				 
				 
				 
				 
				 
				 
				 
			
					US East (N. Virginia)
				
					US West (N. California)
				
					US West (Oregon)
				
					Asia Pacific (Singapore)
				
					Asia Pacific (Sydney)
				
					Asia Pacific (Tokyo)
				
					Europe (Ireland)
				
					South America (São Paulo)
				For a list of all the Amazon S3 supported regions and endpoints, 
				see Regions and Endpoints in the
				Amazon Web Services General Reference.
Example: Email addressFor example, the following x-amz-grant-read header grants
				the AWS accounts identified by email addresses permissions to read object
				data and its metadata:x-amz-grant-read: emailAddress="xyz@example.com", emailAddress="abc@example.com"		
	WarningWhen you grant other AWS accounts access to your resources, be aware that the AWS accounts can delegate their permissions to users under their
					accounts. This is known as cross-account
						access. For information about using cross-account access,
					see 
						Creating a Role to Delegate Permissions to an IAM User
					in the IAM User Guide.  
			
			 
				Finding an AWS account canonical user
						ID
				The canonical user ID is associated with your AWS account. This ID is a long
					string of characters, such as:
				79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be
				For information about how to find the canonical user ID for your account, see
						Find the canonical user ID for your AWS account in the AWS Account Management Reference Guide.
				You can also look up the canonical user ID of an AWS account by reading the
					ACL of a bucket or an object to which the AWS account has access permissions.
					When an individual AWS account is granted permissions by a grant request, a
					grant entry is added to the ACL with the account's canonical user ID. 
				NoteIf you make your bucket public (not recommended), any unauthenticated user
						can upload objects to the bucket. These anonymous users don't have an
						AWS account. When an anonymous user uploads an object to your bucket, Amazon S3
						adds a special canonical user ID
							(65a011a29cdf8ec533ec3d1ccaae921c) as the object owner in
						the ACL. For more information, see Amazon S3 bucket and object ownership.
			 

			 
				Amazon S3 predefined
						groups
				
				Amazon S3 has a set of predefined groups. When granting account access to a group, you specify
					one of the Amazon S3 URIs instead of a canonical user ID. Amazon S3 provides the following
					predefined groups:
				
					 
					 
					 
				
						Authenticated Users
								group – Represented by
								http://acs.amazonaws.com/groups/global/AuthenticatedUsers.
						This group represents all AWS accounts. Access permission to this
							group allows any AWS account to access the resource. However, all
							requests must be signed (authenticated).
						WarningWhen you grant access to the Authenticated Users
								group, any AWS authenticated user in the world can
								access your resource. 
						
						All Users group –
							Represented by
								http://acs.amazonaws.com/groups/global/AllUsers.
						Access permission to this group allows anyone in the world access
								to the resource. The requests can be signed
							(authenticated) or unsigned (anonymous). Unsigned requests omit the
							Authentication header in the request.
						WarningWe highly recommend that you never grant the All Users
									group
								WRITE, WRITE_ACP, or
									FULL_CONTROL permissions. For example, although
									WRITE permissions deny non-owners the ability to
								overwrite or delete existing objects, WRITE permissions
								still allow anyone to store objects in your bucket, for which you
								are billed. For more details about these permissions, see the
								following section What permissions can I grant?.
					
						Log Delivery group
							– Represented by
								http://acs.amazonaws.com/groups/s3/LogDelivery.
						WRITE permission on a bucket enables this group to write server access logs
							(see Logging requests with server access logging) to the
							bucket.
					
				NoteWhen using ACLs, a grantee can be an AWS account or one of the predefined Amazon S3 groups.
						However, the grantee cannot be an IAM user. For more information about AWS
						users and permissions within IAM, see Using
							AWS Identity and Access Management.
			 
		 
			What permissions can I grant?
			
			The following table lists the set of permissions that Amazon S3 supports in an ACL. The set of
				ACL permissions is the same for an object ACL and a bucket ACL. However, depending
				on the context (bucket ACL or object ACL), these ACL permissions grant permissions
				for specific buckets or object operations. The table lists the permissions and
				describes what they mean in the context of objects and buckets. 
			For more information about ACL permissions in the Amazon S3 console, see Configuring ACLs.
			
						
							Permission
							When granted on a bucket
							When granted on an object
						
					
						
							READ
							Allows grantee to list the objects in the bucket
							Allows grantee to read the object data and its metadata
						
							
							WRITE
							Allows grantee to create new objects in the bucket. For the bucket and object owners
								of existing objects, also allows deletions and overwrites of those
								objects
							Not applicable
						
						
							READ_ACP
							Allows grantee to read the bucket ACL
							Allows grantee to read the object ACL
						
						
							WRITE_ACP
							Allows grantee to write the ACL for the applicable bucket
							Allows grantee to write the ACL for the applicable object
						
						
							FULL_CONTROL
							Allows grantee the READ, WRITE, READ_ACP, and
									WRITE_ACP permissions on the bucket
							Allows grantee the READ, READ_ACP, and
									WRITE_ACP permissions on the object
						
						
					
			WarningUse caution when granting access permissions to your S3 buckets and objects. For example,
					granting WRITE access to a bucket allows the grantee to create
					objects in the bucket. We highly recommend that you read through the entire
						Access control list (ACL) overview section before
					granting permissions.	 

			 
				Mapping of ACL permissions and access policy
					permissions
				
				As shown in the preceding table, an ACL allows only a finite set of permissions, compared
					to the number of permissions that you can set in an access policy (see Policy actions
               for Amazon S3).
					Each of these permissions allows one or more Amazon S3 operations.
				The following table shows how each ACL permission maps to the corresponding access policy
					permissions. As you can see, access policy allows more permissions than an ACL
					does. You use ACLs primarily to grant basic read/write permissions, similar to
					file system permissions. For more information about when to use an ACL, see
					Identity and Access Management for Amazon S3.
				For more information about ACL permissions in the Amazon S3 console, see Configuring ACLs.
				
							
								ACL permission
								Corresponding access policy permissions when the ACL
									permission is granted on a bucket 
								Corresponding access policy permissions when the ACL
									permission is granted on an object
							
						
							
								READ

								s3:ListBucket,
										s3:ListBucketVersions, and
										s3:ListBucketMultipartUploads
								
								s3:GetObject and s3:GetObjectVersion
							
							
								WRITE

								
										s3:PutObject
									Bucket owner can create, overwrite, and delete any object in the bucket, and object
										owner has FULL_CONTROL over their object. 
									In addition, when the grantee is the bucket owner, granting WRITE permission
										in a bucket ACL allows the s3:DeleteObjectVersion action to
										be performed on any version in that bucket. 
								
								Not applicable
							
							
								READ_ACP

								s3:GetBucketAcl
								
								s3:GetObjectAcl and
										s3:GetObjectVersionAcl
							
							
								WRITE_ACP

								s3:PutBucketAcl
								s3:PutObjectAcl and
										s3:PutObjectVersionAcl
							
							
								FULL_CONTROL

								Equivalent to granting READ, WRITE, READ_ACP,
									and WRITE_ACP ACL permissions. Accordingly, this
									ACL permission maps to a combination of corresponding access
									policy permissions.
								Equivalent to granting READ, READ_ACP, and
										WRITE_ACP ACL permissions. Accordingly, this
									ACL permission maps to a combination of corresponding access
									policy permissions.
							
							
						
			 

			 
				Condition keys
				When you grant access policy permissions, you can use condition keys to constrain the
					value for the ACL on an object using a bucket policy. The following context keys
					correspond to ACLs. You can use these context keys to mandate the use of a
					specific ACL in a request:

					
						 
						 
						 
						 
						 
						 
					s3:x-amz-grant-read ‐ Require read access.s3:x-amz-grant-write ‐ Require write access.s3:x-amz-grant-read-acp ‐ Require read access to the bucket ACL.s3:x-amz-grant-write-acp ‐ Require write access to the bucket ACL.s3:x-amz-grant-full-control ‐ Require full control.s3:x-amz-acl ‐ Require a Canned ACL.

				For example policies that involve ACL-specific headers, see Granting s3:PutObject permission
            with a condition requiring the bucket owner to get full control. For a complete list of
					Amazon S3 specific condition keys, see 
						Actions, resources, and condition keys for Amazon S3 in the Service Authorization 
							Reference.
				For more information about the permissions to S3 API operations by S3 resource types, see Required permissions for Amazon S3 API operations.
				
			 
		 
			aclRequired values for common Amazon S3
					requests
			To identify Amazon S3 requests that required ACLs for authorization, you can use the
					aclRequired value in Amazon S3 server access logs or AWS CloudTrail. The
					aclRequired value that appears in CloudTrail or Amazon S3 server access logs
				depends on which operations were called and certain information about the requester,
				object owner, and bucket owner. If no ACLs were required, or if you are setting the
					bucket-owner-full-control canned ACL, or if the requests are
				allowed by your bucket policy, the aclRequired value string is
					"-" in Amazon S3 server access logs and is absent in CloudTrail.
			The following tables list the expected aclRequired values in CloudTrail or
				Amazon S3 server access logs for the various Amazon S3 API operations. You can use this
				information to understand which Amazon S3 operations depend on ACLs for authorization. In
				the following tables, A, B, and C represent the different accounts associated with
				the requester, object owner, and bucket owner. Entries with an asterisk (*) indicate
				any of accounts A, B, or C. 
			NotePutObject operations in the following table, unless specified
					otherwise, indicate requests that do not set an ACL, unless the ACL is a
						bucket-owner-full-control ACL. A null value for
						aclRequired indicates that aclRequired is absent
					in AWS CloudTrail logs.
			
				The following table shows the aclRequired values for CloudTrail.
			
			
						
							Operation name
							Requester
							Object owner
							Bucket owner 
							Bucket policy grants access
							aclRequired value
							Reason
						
					
						
							GetObject
							A
							A
							A
							Yes or No
							null
							Same-account access
						
						
							GetObject
							A
							B
							A
							Yes or No
							null
							Same-account access with bucket owner enforced
						
						
							GetObject
							A
							A
							B
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							GetObject
							A
							A
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							GetObject
							A
							A
							B
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							GetObject
							A
							B
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							GetObject
							A
							B
							C
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							GetObject
							A
							B
							C
							No
							Yes
							Cross-account access relies on ACL
						
						
							PutObject
							A
							Not applicable
							A
							Yes or No
							null
							Same-account access
						
						
							PutObject
							A
							Not applicable
							B
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							PutObject
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							PutObject with an ACL (except for
									bucket-owner-full-control)
							*
							Not applicable
							*
							Yes or No
							Yes
							Request grants ACL
						
						
							ListObjects
							A
							Not applicable
							A
							Yes or No
							null
							Same-account access
						
						
							ListObjects
							A
							Not applicable
							B
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							ListObjects
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							DeleteObject
							A
							Not applicable
							A
							Yes or No
							null
							Same-account access
						
						
							DeleteObject
							A
							Not applicable
							B
							Yes
							null
							Cross-account access granted by bucket policy
						
						
							DeleteObject
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							PutObjectAcl
							*
							*
							*
							Yes or No
							Yes
							Request grants ACL
						
						
							PutBucketAcl
							*
							Not applicable
							*
							Yes or No
							Yes
							Request grants ACL
						
					
			 
			NoteREST.PUT.OBJECT operations in the following table, unless
					specified otherwise, indicate requests that do not set an ACL, unless the ACL is
					a bucket-owner-full-control ACL. An aclRequired value
					string of "-" indicates a null value in Amazon S3 server access
					logs.
			
				The following table shows the aclRequired values for Amazon S3 server access logs.
			
			
						
							Operation name
							Requester
							Object owner
							Bucket owner 
							Bucket policy grants access
							aclRequired value
							Reason
						
					
						
							REST.GET.OBJECT
							A
							A
							A
							Yes or No
							-
							Same-account access
						
						
							REST.GET.OBJECT
							A
							B
							A
							Yes or No
							-
							Same-account access with bucket owner enforced
						
						
							REST.GET.OBJECT
							A
							A
							B
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.GET.OBJECT
							A
							A
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.GET.OBJECT
							A
							B
							B
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.GET.OBJECT
							A
							B
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.GET.OBJECT
							A
							B
							C
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.GET.OBJECT
							A
							B
							C
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.PUT.OBJECT
							A
							Not applicable
							A
							Yes or No
							-
							Same-account access
						
						
							REST.PUT.OBJECT
							A
							Not applicable
							B
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.PUT.OBJECT
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.PUT.OBJECT with an ACL (except for
									bucket-owner-full-control)
							*
							Not applicable
							*
							Yes or No
							Yes
							Request grants ACL
						
						
							REST.GET.BUCKET
							A
							Not applicable
							A
							Yes or No
							-
							Same-account access
						
						
							REST.GET.BUCKET
							A
							Not applicable
							B
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.GET.BUCKET
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.DELETE.OBJECT
							A
							Not applicable
							A
							Yes or No
							-
							Same-account access
						
						
							REST.DELETE.OBJECT
							A
							Not applicable
							B
							Yes
							-
							Cross-account access granted by bucket policy
						
						
							REST.DELETE.OBJECT
							A
							Not applicable
							B
							No
							Yes
							Cross-account access relies on ACL
						
						
							REST.PUT.ACL
							*
							*
							*
							Yes or No
							Yes
							Request grants ACL
						
					
		Sample ACL
			
			The following sample ACL on a bucket identifies the resource owner and a set of
				grants. The format is the XML representation of an ACL in the Amazon S3 REST API. The
				bucket owner has FULL_CONTROL of the resource. In addition, the ACL
				shows how permissions are granted on a resource to two AWS accounts, identified by
				canonical user ID, and two of the predefined Amazon S3 groups discussed in the preceding
				section.
			<?xml version="1.0" encoding="UTF-8"?>
<AccessControlPolicy xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
  <Owner>
    <ID>Owner-canonical-user-ID</ID>
    <DisplayName>display-name</DisplayName>
  </Owner>
  <AccessControlList>
    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="CanonicalUser">
        <ID>Owner-canonical-user-ID</ID>
        <DisplayName>display-name</DisplayName>
      </Grantee>
      <Permission>FULL_CONTROL</Permission>
    </Grant>
    
    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="CanonicalUser">
        <ID>user1-canonical-user-ID</ID>
        <DisplayName>display-name</DisplayName>
      </Grantee>
      <Permission>WRITE</Permission>
    </Grant>

    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="CanonicalUser">
        <ID>user2-canonical-user-ID</ID>
        <DisplayName>display-name</DisplayName>
      </Grantee>
      <Permission>READ</Permission>
    </Grant>

    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="Group">
        <URI>http://acs.amazonaws.com/groups/global/AllUsers</URI> 
      </Grantee>
      <Permission>READ</Permission>
    </Grant>
    <Grant>
      <Grantee xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="Group">
        <URI>http://acs.amazonaws.com/groups/s3/LogDelivery</URI>
      </Grantee>
      <Permission>WRITE</Permission>
    </Grant>

  </AccessControlList>
</AccessControlPolicy>
		Canned ACL
			
			Amazon S3 supports a set of predefined grants, known as canned ACLs. Each
				canned ACL has a predefined set of grantees and permissions. The following table
				lists the set of canned ACLs and the associated predefined grants. 
			
			
							
								Canned ACL
								Applies to
								Permissions added to ACL
							
						
							
								private
								Bucket and object
								Owner gets FULL_CONTROL. No one else has access
									rights (default).
							
							
								public-read
								Bucket and object
								Owner gets FULL_CONTROL. The AllUsers group (see Who is a grantee?) gets READ access. 
							
							
								public-read-write
								Bucket and object
								Owner gets FULL_CONTROL. The
										AllUsers group gets READ and
										WRITE access. Granting this on a bucket is
									generally not recommended.
							
						  
						    aws-exec-read
						    Bucket and object
						    Owner gets FULL_CONTROL. Amazon EC2 gets READ 
						      access to GET an Amazon Machine Image (AMI) bundle from Amazon S3.
						  
							
								authenticated-read
								Bucket and object
								Owner gets FULL_CONTROL. The
										AuthenticatedUsers group gets READ
									access.
							
							
								bucket-owner-read
								Object
								Object owner gets FULL_CONTROL. Bucket owner
									gets READ access. If you specify this canned ACL
									when creating a bucket, Amazon S3 ignores it.
							
							
								bucket-owner-full-control
								Object 
								Both the object owner and the bucket owner get
										FULL_CONTROL over the object. If you specify
									this canned ACL when creating a bucket, Amazon S3 ignores it.
							
							
								log-delivery-write
								Bucket 
								The LogDelivery group gets WRITE and READ_ACP
								permissions on the bucket. For more information about logs, see
									(Logging requests with server access logging).
							
						
			NoteYou can specify only one of these canned ACLs in your request.
			You specify a canned ACL in your request by using the x-amz-acl request
				header. When Amazon S3 receives a request with a canned ACL in the request, it adds the
				predefined grants to the ACL of the resource. 
		Document ConventionsManaging access with ACLsConfiguring ACLsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideEvaluating effective permissions
                with boundariesDelegating responsibility to
                others using permissions boundariesPermissions boundaries for IAM
            entitiesAWS supports permissions boundaries for IAM
        entities (users or roles). A permissions boundary is an advanced feature for using a managed
        policy to set the maximum permissions that an identity-based policy can grant to an IAM
        entity. An entity's permissions boundary allows it to perform only the actions that are
        allowed by both its identity-based policies and its permissions boundaries.For more information about policy types, see Policy types.ImportantDon't use resource-based policy statements that include a NotPrincipal
            policy element with a Deny effect for IAM users or roles that have a
            permissions boundary policy attached. The NotPrincipal element with a
                Deny effect will always deny any IAM principal that has a permissions
            boundary policy attached, regardless of the values specified in the
                NotPrincipal element. This causes some IAM users or roles that would
            otherwise have access to the resource to lose access. We recommend changing your
            resource-based policy statements to use the condition operator ArnNotEquals with the aws:PrincipalArn context
            key to limit access instead of the NotPrincipal element. For information
            about the NotPrincipal element, see AWS JSON policy elements:
        NotPrincipal.You can use an AWS managed policy or a customer managed policy to set the boundary for
        an IAM entity (user or role). That policy limits the maximum permissions for the user or
        role.For example, assume that the IAM user named ShirleyRodriguez should be
        allowed to manage only Amazon S3, Amazon CloudWatch, and Amazon EC2. To enforce this rule, you can use the
        following policy to set the permissions boundary for the ShirleyRodriguez
        user:{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:*",
                "cloudwatch:*",
                "ec2:*"
            ],
            "Resource": "*"
        }
    ]
}When you use a policy to set the permissions boundary for a user, it limits the user's
        permissions but does not provide permissions on its own. In this example, the policy sets
        the maximum permissions of ShirleyRodriguez as all operations in Amazon S3, CloudWatch,
        and Amazon EC2. Shirley can never perform operations in any other service, including IAM, even
        if she has a permissions policy that allows it. For example, you can add the following
        policy to the ShirleyRodriguez user:{
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "iam:CreateUser",
    "Resource": "*"
  }
}This policy allows creating a user in IAM. If you attach this permissions policy to the
            ShirleyRodriguez user, and Shirley tries to create a user, the operation
        fails. It fails because the permissions boundary does not allow the
            iam:CreateUser operation. Given these two policies, Shirley does not have
        permission to perform any operations in AWS. You must add a different permissions policy
        to allow actions in other services, such as Amazon S3. Alternatively, you could update the
        permissions boundary to allow her to create a user in IAM.
        Evaluating effective permissions
                with boundaries
        The permissions boundary for an IAM entity (user or role) sets the maximum
            permissions that the entity can have. This can change the effective permissions for that
            user or role. The effective permissions for an entity are the permissions that are
            granted by all the policies that affect the user or role. Within an account, the
            permissions for an entity can be affected by identity-based policies, resource-based
            policies, permissions boundaries, AWS Organizations SCPs, or session policies. For more information
            about the different types of policies, see Policies and permissions in AWS Identity and Access Management.
        If any one of these policy types explicitly denies access for an operation, then the
            request is denied. The permissions granted to an entity by multiple permissions types
            are more complex. For more details about how AWS evaluates policies, see Policy evaluation logic.
        Identity-based policies with boundaries –
            Identity-based policies are inline or managed policies that are attached to a user,
            group of users, or role. Identity-based policies grant permission to the entity, and
            permissions boundaries limit those permissions. The effective permissions are the
            intersection of both policy types. An explicit deny in either of these policies
            overrides the allow.
        
             
                
             
             
        
        
            Resource-based policies – Resource-based
                policies control how the specified principal can access the resource to which the
                policy is attached.
             
             
             
        
                Resource-based policies for IAM
                    users
                
                    Within the same account, resource-based policies that grant permissions to
                        an IAM user ARN (that is not a federated user session) are not limited by
                        an implicit deny in an identity-based policy or permissions boundary.
                    
                         
                            
                         
                         
                    
                
             
                Resource-based policies for IAM roles
                    
                
                    IAM role – Resource-based
                        policies that grant permissions to an IAM role ARN are limited by an
                        implicit deny in a permissions boundary or session policy.
                    IAM role session – Within the
                        same account, resource-based policies that grant permissions to an IAM
                        role session ARN grant permissions directly to the assumed role session.
                        Permissions granted directly to a session are not limited by an implicit
                        deny in an identity-based policy, a permissions boundary, or session policy.
                        When you assume a role and make a request, the principal making the request
                        is the IAM role session ARN and not the ARN of the role itself.
                
             
                Resource-based policies for IAM federated user
                        sessions
                
                    IAM federated user sessions – An
                        IAM federated user session is a session created by calling GetFederationToken.
                        When a federated user makes a request, the principal making the request is
                        the federated user ARN and not the ARN of the IAM user who federated.
                        Within the same account, resource-based policies that grant permissions to a
                        federated user ARN grant permissions directly to the session. Permissions
                        granted directly to a session are not limited by an implicit deny in an
                        identity-based policy, a permissions boundary, or session policy.
                    However, if a resource-based policy grants permission to the ARN of the
                        IAM user who federated, then requests made by the federated user during
                        the session are limited by an implicit deny in a permission boundary or
                        session policy.
                
            
        AWS Organizations SCPs – SCPs are applied to an entire
            AWS account. They limit permissions for every request made by a principal within the
            account. An IAM entity (user or role) can make a request that is affected by an SCP, a
            permissions boundary, and an identity-based policy. In this case, the request is allowed
            only if all three policy types allow it. The effective permissions are the intersection
            of all three policy types. An explicit deny in any of these policies overrides the
            allow.
        
             
                
             
             
        
        You can learn whether your account is a member of an organization in AWS Organizations.
            Organization members might be affected by an SCP. To view this data using the AWS CLI
            command or AWS API operation, you must have permissions for the
                organizations:DescribeOrganization action for your AWS Organizations entity. You
            must have additional permissions to perform the operation in the AWS Organizations console. To learn
            whether an SCP is denying access to a specific request, or to change your effective
            permissions, contact your AWS Organizations administrator.
        Session policies – Session policies are
            advanced policies that you pass as a parameter when you programmatically create a
            temporary session for a role or federated user. The permissions for a session come from
            the IAM entity (user or role) used to create the session and from the session policy.
            The entity's identity-based policy permissions are limited by the session policy and the
            permissions boundary. The effective permissions for this set of policy types are the
            intersection of all three policy types. An explicit deny in any of these policies
            overrides the allow. For more information about session policies, see Session
            Policies.
        
             
                
             
             
        
     
        Delegating responsibility to
                others using permissions boundaries
        You can use permissions boundaries to delegate permissions management tasks, such as
            user creation, to IAM users in your account. This permits others to perform tasks on
            your behalf within a specific boundary of permissions.
        For example, assume that María is the administrator of the X-Company AWS account.
            She wants to delegate user creation duties to Zhang. However, she must ensure that Zhang
            creates users that adhere to the following company rules:
        
             
             
             
        
                Users cannot use IAM to create or manage users, groups, roles, or
                    policies.
            
                Users are denied access to the Amazon S3 logs bucket and cannot access
                    the i-1234567890abcdef0 Amazon EC2 instance.
            
                Users cannot remove their own boundary policies.
            
        To enforce these rules, María completes the following tasks, for which details are
            included below:
        
             
             
             
             
        
                María creates the XCompanyBoundaries managed policy to use as a
                    permissions boundary for all new users in the account.
            
                María creates the DelegatedUserBoundary managed policy and
                    assigns it as the permissions boundary for Zhang. Maria makes a note of her
                    admin user's ARN and uses it in the policy to prevent Zhang from accessing
                    it.
            
                María creates the DelegatedUserPermissions managed policy and
                    attaches it as a permissions policy for Zhang.
            
                María tells Zhang about his new responsibilities and limitations.
            
        Task 1: María must first create a managed policy to
            define the boundary for the new users. María will allow Zhang to give users the
            permissions policies they need, but she wants those users to be restricted. To do this,
            she creates the following customer managed policy with the name
                XCompanyBoundaries. This policy does the following:
        
             
             
             
        
                Allows users full access to several services
            
                Allows limited self-managing access in the IAM console. This means they can
                    change their password after signing into the console. They can't set their
                    initial password. To allow this, add the "*LoginProfile" action to
                    the AllowManageOwnPasswordAndAccessKeys statement.
            
                Denies users access to the Amazon S3 logs bucket or the
                        i-1234567890abcdef0 Amazon EC2 instance
            
        {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "ServiceBoundaries",
            "Effect": "Allow",
            "Action": [
                "s3:*",
                "cloudwatch:*",
                "ec2:*",
                "dynamodb:*"
            ],
            "Resource": "*"
        },
        {
            "Sid": "AllowIAMConsoleForCredentials",
            "Effect": "Allow",
            "Action": [
                "iam:ListUsers",
                "iam:GetAccountPasswordPolicy"
            ],
            "Resource": "*"
        },
        {
            "Sid": "AllowManageOwnPasswordAndAccessKeys",
            "Effect": "Allow",
            "Action": [
                "iam:*AccessKey*",
                "iam:ChangePassword",
                "iam:GetUser",
                "iam:*ServiceSpecificCredential*",
                "iam:*SigningCertificate*"
            ],
            "Resource": ["arn:aws:iam::*:user/${aws:username}"]
        },
        {
            "Sid": "DenyS3Logs",
            "Effect": "Deny",
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::logs",
                "arn:aws:s3:::logs/*"
            ]
        },
        {
            "Sid": "DenyEC2Production",
            "Effect": "Deny",
            "Action": "ec2:*",
            "Resource": "arn:aws:ec2:*:*:instance/i-1234567890abcdef0"
        }
    ]
}
        Each statement serves a different purpose:
        
             
             
             
             
             
        
                The ServiceBoundaries statement of this policy allows full access
                    to the specified AWS services. This means that a new user's actions in these
                    services are limited only by the permissions policies that are attached to the
                    user.
            
                The AllowIAMConsoleForCredentials statement allows access to list
                    all IAM users. This access is necessary to navigate the
                        Users page in the AWS Management Console. It also allows viewing the
                    password requirements for the account, which is necessary when changing your own
                    password.
            
                The AllowManageOwnPasswordAndAccessKeys statement allows users to
                    manage only their own console password and programmatic access keys. This is
                    important if Zhang or another administrator assigns a new user a permissions
                    policy with full IAM access. In that case, that user could then change their
                    own or other users' permissions. This statement prevents that from
                    happening.
            
                The DenyS3Logs statement explicitly denies access to the
                        logs bucket.
            
                The DenyEC2Production statement explicitly denies access to the
                        i-1234567890abcdef0 instance.
            
        Task 2: María wants to allow Zhang to create all
            X-Company users, but only with the XCompanyBoundaries permissions boundary.
            She creates the following customer managed policy named
                DelegatedUserBoundary. This policy defines the maximum permissions that
            Zhang can have.
        {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "CreateOrChangeOnlyWithBoundary",
            "Effect": "Allow",
            "Action": [
                "iam:AttachUserPolicy",
                "iam:CreateUser",
                "iam:DeleteUserPolicy",
                "iam:DetachUserPolicy",
                "iam:PutUserPermissionsBoundary",
                "iam:PutUserPolicy"
            ],
            "Resource": "*",
            "Condition": {
               "StringEquals": {
                 "iam:PermissionsBoundary": "arn:aws:iam::123456789012:policy/XCompanyBoundaries"
                }
            }
        },
        {
            "Sid": "CloudWatchAndOtherIAMTasks",
            "Effect": "Allow",
            "Action": [
              "cloudwatch:*",
              "iam:CreateAccessKey",
              "iam:CreateGroup",
              "iam:CreateLoginProfile",
              "iam:CreatePolicy",
              "iam:DeleteGroup",
              "iam:DeletePolicy",
              "iam:DeletePolicyVersion",
              "iam:DeleteUser",
              "iam:GetAccountPasswordPolicy",
              "iam:GetGroup",
              "iam:GetLoginProfile",
              "iam:GetPolicy",
              "iam:GetPolicyVersion",
              "iam:GetRolePolicy",
              "iam:GetUser",
              "iam:GetUserPolicy",
              "iam:ListAccessKeys",
              "iam:ListAttachedRolePolicies",
              "iam:ListAttachedUserPolicies",
              "iam:ListEntitiesForPolicy",
              "iam:ListGroups",
              "iam:ListGroupsForUser",
              "iam:ListMFADevices",
              "iam:ListPolicies",
              "iam:ListPolicyVersions",
              "iam:ListRolePolicies",
              "iam:ListSSHPublicKeys",
              "iam:ListServiceSpecificCredentials",
              "iam:ListSigningCertificates",
              "iam:ListUserPolicies",
              "iam:ListUsers",
              "iam:SetDefaultPolicyVersion",
              "iam:SimulateCustomPolicy",
              "iam:SimulatePrincipalPolicy",
              "iam:UpdateGroup",
              "iam:UpdateLoginProfile",
              "iam:UpdateUser"
            ],
            "NotResource": "arn:aws:iam::123456789012:user/Maria"
        },
        {
            "Sid": "NoBoundaryPolicyEdit",
            "Effect": "Deny",
            "Action": [
                "iam:CreatePolicyVersion",
                "iam:DeletePolicy",
                "iam:DeletePolicyVersion",
                "iam:SetDefaultPolicyVersion"
            ],
            "Resource": [
                "arn:aws:iam::123456789012:policy/XCompanyBoundaries",
                "arn:aws:iam::123456789012:policy/DelegatedUserBoundary"
            ]
        },
        {
            "Sid": "NoBoundaryUserDelete",
            "Effect": "Deny",
            "Action": "iam:DeleteUserPermissionsBoundary",
            "Resource": "*"
        }
    ]
}
        Each statement serves a different purpose:
        
             
             
             
             
        
                The CreateOrChangeOnlyWithBoundary statement allows Zhang to
                    create IAM users but only if he uses the XCompanyBoundaries
                    policy to set the permissions boundary. This statement also allows him to set
                    the permissions boundary for existing users but only using that same policy.
                    Finally, this statement allows Zhang to manage permissions policies for users
                    with this permissions boundary set.
            
                The CloudWatchAndOtherIAMTasks statement allows Zhang to complete
                    other user, group, and policy management tasks. He has permissions to reset
                    passwords and create access keys for any IAM user not listed in the
                        NotResource policy element. This allows him to help users with
                    sign-in issues.
            
                The NoBoundaryPolicyEdit statement denies Zhang access to update
                    the XCompanyBoundaries policy. He is not allowed to change any
                    policy that is used to set the permissions boundary for himself or other
                    users.
            
                The NoBoundaryUserDelete statement denies Zhang access to delete
                    the permissions boundary for himself or other users.
            
        María then assigns the DelegatedUserBoundary policy as the permissions
                boundary for the Zhang user. 
        Task 3: Because the permissions boundary limits the
            maximum permissions, but does not grant access on its own, Maria must create a
            permissions policy for Zhang. She creates the following policy named
                DelegatedUserPermissions. This policy defines the operations that Zhang
            can perform, within the defined boundary.
        {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "IAM",
            "Effect": "Allow",
            "Action": "iam:*",
            "Resource": "*"
        },
        {
            "Sid": "CloudWatchLimited",
            "Effect": "Allow",
            "Action": [
                "cloudwatch:GetDashboard",
                "cloudwatch:GetMetricData",
                "cloudwatch:ListDashboards",
                "cloudwatch:GetMetricStatistics",
                "cloudwatch:ListMetrics"
            ],
            "Resource": "*"
        },
        {
            "Sid": "S3BucketContents",
            "Effect": "Allow",
            "Action": "s3:ListBucket",
            "Resource": "arn:aws:s3:::ZhangBucket"
        }
    ]
}
        Each statement serves a different purpose:
        
             
             
             
        
                The IAM statement of the policy allows Zhang full access to
                    IAM. However, because his permissions boundary allows only some IAM
                    operations, his effective IAM permissions are limited only by his permissions
                    boundary.
            
                The CloudWatchLimited statement allows Zhang to perform five
                    actions in CloudWatch. His permissions boundary allows all actions in CloudWatch, so his
                    effective CloudWatch permissions are limited only by his permissions policy.
            
                The S3BucketContents statement allows Zhang to list the
                        ZhangBucket Amazon S3 bucket. However, his permissions boundary does
                    not allow any Amazon S3 action, so he cannot perform any S3 operations, regardless of
                    his permissions policy.
                NoteZhang's policies allow him to create a user that can then access Amazon S3
                        resources that he can't access. By delegating these administrative actions,
                        Maria effectively trusts Zhang with access to Amazon S3. 
            
        María then attaches the DelegatedUserPermissions policy as the
            permissions policy for the Zhang user. 
        Task 4: She gives Zhang instructions to create a new
            user. She tells him that he can create new users with any permissions that they need,
            but he must assign them the XCompanyBoundaries policy as a permissions
            boundary.
        Zhang completes the following tasks:
        
             
             
             
             
             
             
        
                Zhang creates a user with the
                    AWS Management Console. He types the user name Nikhil and enables console access
                    for the user. He clears the checkbox next to Requires password
                        reset, because the policies above allow users to change their
                    passwords only after they are signed in to the IAM console.
            
                On the Set permissions page, Zhang chooses the
                        IAMFullAccess and 
                        AmazonS3ReadOnlyAccess permissions policies that allow Nikhil to
                    do his work. 
            
                Zhang skips the Set permissions boundary section,
                    forgetting María's instructions.
            
                Zhang reviews the user details and chooses Create
                    user.
                The operation fails and access is denied. Zhang's
                        DelegatedUserBoundary permissions boundary requires that any
                    user he creates have the XCompanyBoundaries policy used as a
                    permissions boundary.
            
                Zhang returns to the previous page. In the Set permissions
                        boundary section, he chooses the XCompanyBoundaries
                    policy. 
            
                Zhang reviews the user details and chooses Create
                    user.
                The user is created. 
            
        When Nikhil signs in, he has access to IAM and Amazon S3, except those operations that
            are denied by the permissions boundary. For example, he can change his own password in
            IAM but can't create another user or edit his policies. Nikhil has read-only access to
            Amazon S3.
        If someone adds a resource-based policy to the logs bucket that allows
            Nikhil to put an object in the bucket, he still cannot access the bucket. The reason is
            that any actions on the logs bucket are explicitly denied by his
            permissions boundary. An explicit deny in any policy type results in a request being
            denied. However, if a resource-based policy attached to a Secrets Manager secret allows
            Nikhil to perform the secretsmanager:GetSecretValue action, then Nikhil can
            retrieve and decrypt the secret. The reason is that Secrets Manager operations are not
            explicitly denied by his permissions boundary, and implicit denies in permissions
            boundaries do not limit resource-based policies.
    Document ConventionsData perimetersIdentity vs resourceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS OrganizationsUser GuideTesting effects of SCPsMaximum size of SCPsAttaching SCPs to different levels in the
                organizationSCP effects on permissionsUsing access data to improve SCPsTasks and entities not restricted by
                SCPsService control policies (SCPs)Service control policies (SCPs) are a type of organization policy that you can use to
        manage permissions in your organization. SCPs offer central control over the maximum
        available permissions for the IAM users and IAM roles in your organization. SCPs help
        you to ensure your accounts stay within your organization’s access control guidelines. SCPs
        are available only in an organization that has all features enabled. SCPs aren't
        available if your organization has enabled only the consolidated billing features. For
        instructions on enabling SCPs, see Enabling a policy type.SCPs do not grant permissions to the IAM users and IAM roles in your organization. No
        permissions are granted by an SCP. An SCP defines a permission guardrail, or sets limits, on
        the actions that the IAM users and IAM roles in your organization can perform. To grant
        permissions, the administrator must attach policies to control access, such as identity-based policies that are attached to IAM users and IAM roles, and resource-based
            policies that are attached to the resources in your accounts. For
        more information, see Identity-based policies and resource-based policies in the
        IAM User Guide.The effective permissions are the logical intersection between what is allowed by
        the SCP and resource control policies (RCPs) and what is allowed by the identity-based and resource-based policies.SCPs don't affect users or roles in the management accountSCPs don't affect users or roles in the management account. They affect only the
            member accounts in your organization. This also means that SCPs apply to member accounts that are designated as delegated administrators.TopicsTesting effects of SCPsMaximum size of SCPsAttaching SCPs to different levels in the
                organizationSCP effects on permissionsUsing access data to improve SCPsTasks and entities not restricted by
                SCPsSCP evaluationSCP syntaxService control
            policy examplesTroubleshooting service control policies (SCPs) with AWS Organizations
        Testing effects of SCPs
        AWS strongly recommends that you don't attach SCPs to the root of your organization
            without thoroughly testing the impact that the policy has on accounts. Instead, create
            an OU that you can move your accounts into one at a time, or at least in small numbers,
            to ensure that you don't inadvertently lock users out of key services. One way to
            determine whether a service is used by an account is to examine the service last accessed data
                in IAM. Another way is to use AWS CloudTrail to log service usage at
                the API level.
        NoteYou should not remove the FullAWSAccess policy unless you
                modify or replace it with a separate policy with allowed actions, otherwise all
                AWS actions from member accounts will fail.
     
        Maximum size of SCPs
        All characters in your SCP count against its maximum
                size. The examples in this guide show the SCPs formatted with extra white
            space to improve their readability. However, to save space if your policy size
            approaches the maximum size, you can delete any white space, such as space characters
            and line breaks that are outside quotation marks.
        TipUse the visual editor to build your SCP. It automatically removes extra white
                space.
     
        Attaching SCPs to different levels in the
                organization
        For a detailed explanation of how SCPs work, see SCP evaluation.
     
        SCP effects on permissions
        SCPs are similar to AWS Identity and Access Management permission policies and use almost the same syntax. However, an SCP never grants permissions. Instead, SCPs are access controls that
            specify the maximum available permissions for the IAM users and IAM roles in your organization. For more information, see Policy Evaluation
                Logic in the IAM User Guide. 
        
             
             
             
             
             
             
             
             
             
             
        
                SCPs affect only IAM users and
                            roles that are managed by accounts that are part
                    of the organization. SCPs don't affect resource-based policies directly. They
                    also don't affect users or roles from accounts outside the organization. For
                    example, consider an Amazon S3 bucket that's owned by account A in an organization.
                    The bucket policy (a resource-based policy) grants access to users from account
                    B outside the organization. Account A has an SCP attached. That SCP doesn't
                    apply to those outside users in account B. The SCP applies only to users that
                    are managed by account A in the organization. 
            
                An SCP restricts permissions for IAM users and roles in member accounts,
                    including the member account's root user. Any account has only those permissions
                    permitted by every parent above it. If a permission is blocked at
                    any level above the account, either implicitly (by not being included in an
                        Allow policy statement) or explicitly (by being included in a
                        Deny policy statement), a user or role in the affected account
                    can't use that permission, even if the account administrator attaches the
                        AdministratorAccess IAM policy with */* permissions to the
                    user.
            
                SCPs affect only member accounts in the organization. They have no
                    effect on users or roles in the management account. This also means that SCPs apply to member accounts that are designated as delegated administrators. For more information, see Best practices for the management
            account.
            
                Users and roles must still be granted permissions with appropriate IAM
                    permission policies. A user without any IAM permission policies has no access,
                    even if the applicable SCPs allow all services and all actions.
            
                If a user or role has an IAM permission policy that grants access to an
                    action that is also allowed by the applicable SCPs, the user or role can perform
                    that action.
            
                If a user or role has an IAM permission policy that grants access to an
                    action that is either not allowed or explicitly denied by the applicable SCPs,
                    the user or role can't perform that action.
            
                SCPs affect all users and roles in attached accounts, including the root user.
                    The only exceptions are those described in Tasks and entities not restricted by
                SCPs.
            
                SCPs do not
                        affect any service-linked role. Service-linked roles
                    enable other AWS services to integrate with AWS Organizations and can't be restricted
                    by SCPs.
            
                When you disable the SCP policy type in a root, all SCPs are automatically
                    detached from all AWS Organizations entities in that root. AWS Organizations entities include
                    organizational units, organizations, and accounts. If you reenable SCPs in a
                    root, that root reverts to only the default FullAWSAccess policy
                    automatically attached to all entities in the root. Any attachments of SCPs to
                    AWS Organizations entities from before SCPs were disabled are lost and aren't
                    automatically recoverable, although you can manually reattach them.
            
                If both a permissions boundary (an advanced IAM feature) and an SCP are
                    present, then the boundary, the SCP, and the identity-based policy must all
                    allow the action.
            
     
        Using access data to improve SCPs
        When signed in with management account credentials, you can view service last accessed
                data for an AWS Organizations entity or policy in the AWS Organizations
            section of the IAM console. You can also use the AWS Command Line Interface (AWS CLI) or AWS API in
            IAM to retrieve service last accessed data. This data includes information about which
            allowed services that the IAM users and roles in an AWS Organizations account last attempted to
            access and when. You can use this information to identify unused permissions so that you
            can refine your SCPs to better adhere to the principle of least
                privilege.
        For example, you might have a deny list SCP that
            prohibits access to three AWS services. All services that aren't listed in the SCP's
                Deny statement are allowed. The service last accessed data in IAM
            tells you which AWS services are allowed by the SCP but are never used. With that
            information, you can update the SCP to deny access to services that you don't
            need.
        For more information, see the following topics in the
                IAM User Guide:
        
             
             
        
                Viewing Organizations Service Last Accessed Data for Organizations
            
                 Using Data to Refine Permissions for an Organizational Unit
                
            
     
        Tasks and entities not restricted by
                SCPs
         
            You can't use
                SCPs to restrict the following tasks:
         
        
             
             
             
            
            
             
             
             
        
                Any action performed by the management account
            
                Any action performed using permissions that are attached to a service-linked
                    role
            
                Register for the Enterprise support plan as the root user
            
                Provide trusted signer functionality for CloudFront private content
            
                Configure reverse DNS for an Amazon Lightsail email server and Amazon EC2 instance
                    as the root user
            
                Tasks on some AWS-related services:
                
                     
                     
                     
                     
                
                        Alexa Top Sites
                    
                        Alexa Web Information Service
                    
                        Amazon Mechanical Turk
                    
                        Amazon Product Marketing API
                     
            
    Document ConventionsAuthorization policiesSCP evaluationDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS OrganizationsUser GuideList of AWS services that support RCPsTesting effects of RCPsMaximum size of RCPsAttaching RCPs to different levels in the
                organizationRCP effects on permissionsResources and entities not restricted by
                RCPsResource control policies (RCPs)Resource control policies (RCPs) are a type of organization policy that you can use to
        manage permissions in your organization. RCPs offer central control over the maximum
        available permissions for resources in your organization. RCPs help you to ensure
        resources in your accounts stay within your organization’s access control guidelines. RCPs are available only in an organization that has all features enabled. RCPs aren't
        available if your organization has enabled only the consolidated billing features. For
        instructions on enabling RCPs, see Enabling a policy type.RCPs alone are not sufficient in granting permissions to the resources in your
        organization. No permissions are granted by an RCP. An RCP defines a permissions guardrail, or sets
        limits, on the actions that identities can take on resources in  your organizations. The
        administrator must still attach identity-based policies to IAM users or roles, or
        resource-based policies to resources in your accounts to actually grant permissions. For
        more information, see Identity-based policies and resource-based policies in the
            IAM User Guide.The effective permissions are the logical intersection between what is allowed by
            the RCPs and service control policies (SCPs) and what is allowed by the identity-based and resource-based policies.RCPs don't affect resources in the management accountRCPs don't affect resources in the management account. They only affect resources in
            the member accounts within your organization. This also means that RCPs apply to member accounts that are designated as delegated administrators.TopicsList of AWS services that support RCPsTesting effects of RCPsMaximum size of RCPsAttaching RCPs to different levels in the
                organizationRCP effects on permissionsResources and entities not restricted by
                RCPsRCP evaluationRCP syntaxResource control
            policy examples
        List of AWS services that support RCPs
        RCPs apply to actions for the following AWS services:
        
        
             
             
             
             
             
        Amazon S3AWS Security Token ServiceAWS Key Management ServiceAmazon SQSAWS Secrets Manager
            

     
        Testing effects of RCPs
        AWS strongly recommends that you don't attach RCPs to the root of your organization
            without thoroughly testing the impact that the policy has on resources in your accounts.
            You can begin by attaching RCPs to individual test accounts, moving them up to OUs lower
            in the hierarchy, and then working your way up through the organization structure as
            needed. One way to determine impact is to review AWS CloudTrail logs for Access Denied errors.
     
        Maximum size of RCPs
        All characters in your RCP count against its maximum
                size. The examples in this guide show the RCPs formatted with extra white
            space to improve their readability. However, to save space if your policy size
            approaches the maximum size, you can delete any white space, such as space characters
            and line breaks that are outside quotation marks.
        TipUse the visual editor to build your RCP. It automatically removes extra white
                space.
     
        Attaching RCPs to different levels in the
                organization
        You can attach RCPs directly to individual accounts, OUs, or the organization root.
            For a detailed explanation of how RCPs work, see RCP evaluation.
     
        RCP effects on permissions
        RCPs are a type of AWS Identity and Access Management (IAM) policy. They are most closely related to resource-based
                policies. However, an RCP never grants permissions.
            Instead, RCPs are access controls that specify the maximum available permissions for
            resources in your organization. For more information, see Policy
                evaluation logic in the IAM User Guide.
        
             
             
             
             
             
             
             
             
        
                RCPs apply to resources for a subset of AWS services. For more information, see List of AWS services that support RCPs.
            
                RCPs affect only
                            resources that are managed by accounts that are
                    part of the organization which has attached the RCPs. They don't affect
                    resources from accounts outside the organization. For example, consider an Amazon S3 bucket that's owned by Account A in an organization.
                    The bucket policy (a resource-based policy) grants access to users from Account B outside the organization. Account A has an RCP attached. That RCP applies to the S3 bucket in Account A even when accessed by users from Account B. However, that RCP does not apply to resources in Account B when accessed by users in Account A.
            
                An RCP restricts permissions for resources in member accounts. Any resource in
                    an account has only those permissions permitted by every parent above it. If
                    a permission is blocked at any level above the account, a resource in the
                    affected account does not have that permission, even if the resource owner
                    attaches a resource-based policy that allows full access to any user.
            
                RCPs apply to the resources that are authorized as part of an operation request.
                    These resources can be found in the “Resource type” column of the Action table
                    in the Service Authorization Reference. If a resource is specified in the "Resource type" column, then the RCPs of the calling principal account are applied.
                    For example, s3:GetObject authorizes the object resource. Whenever a GetObject request is made, an applicable RCP will apply to determine whether the requesting principal can invoke the GetObject operation. An applicable RCP is an
                        RCP that has been attached to an account, to an organizational unit (OU), or to the root of the organization
                        that owns the resource being accessed.
            
                RCPs affect only resources in member accounts in the organization. They have no
                    effect on resources in the management account. This also means that RCPs apply to member accounts that are designated as delegated administrators. For more information, see Best practices for the management
            account.
            
                When a principal makes a request to access a resource within an account that
                    has an attached RCP (a resource with an applicable RCP), the RCP is included in
                    the policy evaluation logic to determine whether the principal is allowed or denied access.
            
                RCPs impact the effective permissions of principals trying to access resources in a member account with an applicable RCP, regardless of whether the principals belong to the same organizations or not. This includes root users.
                    The exception is when principals are service-linked roles because RCPs do not apply to calls made by service-linked roles. Service-linked roles enable AWS services to perform necessary actions on your behalf and can't be restricted by RCPs. 
            
                Users and roles must still be granted permissions with appropriate IAM
                    permission policies, including identity-based and resource-based policies. A user or role without any IAM permission policies has no
                    access, even if an applicable RCP allows all services, all
                    actions, and all resources.
            
     
        Resources and entities not restricted by
                RCPs
         
            You can't use
                RCPs to restrict the following:
         
        
             
             
             
            
             
        
                Any action on resources in the management account.
            
                RCPs do not impact the effective permissions of any service-linked role.
                    Service-linked roles are a unique type of IAM role that is linked directly to
                    an AWS service and include all the permissions that the service requires to
                    call other AWS services on your behalf. The permissions of service-linked
                    roles can't be restricted by RCPs. RCPs also do not impact AWS services'
                    ability to assume a service-linked role; that is, the service-linked role's
                    trust policy is also not impacted by RCPs.
            
                RCPs do not apply to AWS managed keys for AWS Key Management Service. AWS managed keys are created, managed, and used on your behalf by an AWS service. You cannot change or manage their permissions.
            RCPs do not impact following permissions:
           
                
                            
                                Service
                                API
                                Resources not authorized by RCPs
                            
                        
                            
                                AWS Key Management Service
                                kms:RetireGrant
                                RCPs do not impact the kms:RetireGrant permission.
                                    For more information on how permission to kms:RetireGrant is determined, see Retiring and revoking grants in the AWS KMS Developer Guide.
                            
                        
            
    Document ConventionsTroubleshootingRCP evaluationDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuidePolicy typesPolicies and the root userOverview of JSON policiesGrant least privilegePolicies and permissions in AWS Identity and Access ManagementManage access in AWS by creating policies and attaching them to IAM identities (users,
    groups of users, or roles) or AWS resources. A policy is an object in AWS that, when
    associated with an identity or resource, defines their permissions. AWS evaluates these
    policies when an IAM principal (user or role) makes a request. Permissions in the policies
    determine whether the request is allowed or denied. Most policies are stored in AWS as JSON
    documents. AWS supports seven types of policies: identity-based policies, resource-based
    policies, permissions boundaries, AWS Organizations service control policies (SCPs), AWS Organizations resource control
    policies (RCPs), access control lists (ACLs), and session policies.IAM policies define permissions for an action regardless of the method that you use to
    perform the operation. For example, if a policy allows the GetUser action, then a user with that policy can
    get user information from the AWS Management Console, the AWS CLI, or the AWS API. When you create an IAM
    user, you can choose to allow console or programmatic access. If console access is allowed, the
    IAM user can sign in to the console using their sign-in credentials. If programmatic access is
    allowed, the user can use access keys to work with the CLI or API.
    Policy types
    The following policy types, listed in order from most frequently used to less frequently
      used, are available for use in AWS. For more details, see the sections below for each policy
      type.
    
       
       
       
       
       
       
       
    
        Identity-based
            policies – Attach managed
          and inline policies to IAM identities (users, groups to
          which users belong, or roles). Identity-based policies grant permissions to an
          identity.
      
        Resource-based
              policies – Attach inline policies to resources. The most
          common examples of resource-based policies are Amazon S3 bucket policies and IAM role trust
          policies. Resource-based policies grant permissions to the principal that is specified in
          the policy. Principals can be in the same account as the resource or in other
          accounts.
      
        Permissions
            boundaries – Use a managed policy as the permissions boundary
          for an IAM entity (user or role). That policy defines the maximum permissions that the
          identity-based policies can grant to an entity, but does not grant permissions.
          Permissions boundaries do not define the maximum permissions that a resource-based policy
          can grant to an entity.
      
        AWS Organizations SCPs
          – Use an AWS Organizations service control policy (SCP) to define the maximum permissions
          for IAM users and IAM roles within accounts in your organization or organizational
          unit (OU). SCPs limit permissions that identity-based policies or resource-based policies
          grant to IAM users or IAM roles within the account. SCPs do not grant
          permissions.
      
        AWS Organizations RCPs
          – Use an AWS Organizations resource control policy (RCP) to define the maximum permissions
          for resources within accounts in your organization or organizational unit (OU). RCPs limit
          permissions that identity-based and resource-based policies can grant to resources in
          accounts within your organization. RCPs do not grant permissions.
      
        Access control lists
            (ACLs) – Use ACLs to control which principals in other accounts
          can access the resource to which the ACL is attached. ACLs are similar to resource-based
          policies, although they are the only policy type that does not use the JSON policy
          document structure. ACLs are cross-account permissions policies that grant permissions to
          the specified principal. ACLs cannot grant permissions to entities within the same
          account.
      
        Session
            policies – Pass advanced session policies when you use the
          AWS CLI or AWS API to assume a role or a federated user. Session policies limit the
          permissions that the role or user's identity-based policies grant to the session. Session
          policies limit permissions for a created session, but do not grant permissions. For more
          information, see Session
            Policies.
      
     
      Identity-based policies
      Identity-based policies are JSON permissions policy documents that control what actions
        an identity (users, groups of users, and roles) can perform, on which resources, and under
        what conditions. Identity-based policies can be further categorized:
      
         
         
      
          Managed
              policies – Standalone identity-based policies that you can attach to
            multiple users, groups, and roles in your AWS account. There are two types of managed
            policies:
          
             
             
          
              AWS managed policies – Managed
                policies that are created and managed by AWS.
            
              Customer managed policies – Managed
                policies that you create and manage in your AWS account. Customer managed policies
                provide more precise control over your policies than AWS managed policies.
            
        
          Inline
              policies – Policies that you add directly to a single user, group,
            or role. Inline policies maintain a strict one-to-one relationship between a policy and
            an identity. They are deleted when you delete the identity.
        
      To learn how to choose between managed and inline policies, see Choose between managed policies
            and inline policies.
     
     
      Resource-based policies
      Resource-based policies are JSON policy documents that you attach to a resource such as
        an Amazon S3 bucket. These policies grant the specified principal permission to perform specific
        actions on that resource and defines under what conditions this applies. Resource-based
        policies are inline policies. There are no managed resource-based policies. 
      To enable cross-account access, you can specify an entire account or IAM entities in
        another account as the principal in a resource-based policy. Adding a cross-account
        principal to a resource-based policy is only half of establishing the trust relationship.
        When the principal and the resource are in separate AWS accounts, you must also use an
        identity-based policy to grant the principal access to the resource. However, if a
        resource-based policy grants access to a principal in the same account, no additional
        identity-based policy is required. For step-by step instructions for granting cross-service
        access, see IAM tutorial: Delegate access across
         AWS accounts using IAM roles.
      The IAM service supports only one type of resource-based policy called a role
          trust policy, which is attached to an IAM role. An
        IAM role is both an identity and a resource that supports resource-based policies. For
        that reason, you must attach both a trust policy and an identity-based policy to an IAM
        role. Trust policies define which principal entities (accounts, users, roles, and federated
        users) can assume the role. To learn how IAM roles are different from other
        resource-based policies, see Cross account resource
            access in IAM.
      To see which other services support resource-based policies, see AWS services that work with
      IAM. To learn more about
        resource-based policies, see Identity-based policies and
         resource-based policies. 
To learn whether principals in accounts outside of your zone of trust (trusted organization or account) have access to assume your roles, see 
What is IAM Access Analyzer?.
     
     
      IAM permissions boundaries
      A permissions boundary is an advanced feature in which you set the maximum permissions
        that an identity-based policy can grant to an IAM entity. When you set a permissions
        boundary for an entity, the entity can perform only the actions that are allowed by both its
        identity-based policies and its permissions boundaries. If you specify a role session or
        user in the principal element of a resource-based policy, an explicit allow in the
        permission boundary is not required. However, if you specify a role ARN in the principal
        element of a resource-based policy, an explicit allow in the permission boundary is
        required. In both cases, an explicit deny in the permission boundary is effective. An
        explicit deny in any of these policies overrides the allow. For more information about
        permissions boundaries, see Permissions boundaries for IAM
            entities.
     
     
      AWS Organizations service control policies (SCPs)
      If you enable all features in an organization, then you can apply service control
        policies (SCPs) to any or all of your accounts. SCPs are JSON policies that specify the
        maximum permissions for IAM users and IAM roles within accounts of an organization or
        organizational unit (OU). The SCP limits permissions for principals in member accounts,
        including each AWS account root user. An explicit deny in any of these policies overrides an allow in
        other policies.
      For more information about AWS Organizations and SCPs, see Service control
          policies (SCPs) in the AWS Organizations User Guide.
     
     
      AWS Organizations resource control policies (RCPs)
      If you enable all features in an organization, then you can use resource control
        policies (RCPs) to centrally apply access controls on resources across multiple
        AWS accounts. RCPs are JSON policies that you can use to set the maximum available
        permissions for resources in your accounts without updating the IAM policies attached to
        each resource that you own. The RCP limits permissions for resources in member accounts and
        can impact the effective permissions for identities, including the AWS account root user, regardless of
        whether they belong to your organization. An explicit deny in any applicable RCP overrides
        an allow in other policies that might be attached to individual identities or
        resources.
      For more information about AWS Organizations and RCPs including a list of AWS services that support
        RCPs, see Resource control
          policies (RCPs) in the AWS Organizations User Guide.
     
     
      Access control lists (ACLs)
      Access control lists (ACLs) are service policies that allow you to control which
        principals in another account can access a resource. ACLs cannot be used to control access
        for a principal within the same account. ACLs are similar to resource-based policies,
        although they are the only policy type that does not use the JSON policy document format.
        Amazon S3, AWS WAF, and Amazon VPC are examples of services that support ACLs. To learn more about ACLs,
        see Access
          Control List (ACL) overview in the Amazon Simple Storage Service Developer
          Guide.
     
     
      Session policies
      Session policies are advanced policies that you pass as a parameter when you
        programmatically create a temporary session for a role or federated user. The permissions
        for a session are the intersection of the identity-based policies for the IAM entity (user
        or role) used to create the session and the session policies. Permissions can also come from
        a resource-based policy. An explicit deny in any of these policies overrides the
        allow.
      You can create role session and pass session policies programmatically using the
          AssumeRole, AssumeRoleWithSAML, or
          AssumeRoleWithWebIdentity API operations. You can pass a single JSON inline
        session policy document using the Policy parameter. You can use the
          PolicyArns parameter to specify up to 10 managed session policies. For more
        information about creating a role session, see Permissions for temporary security
      credentials.
      When you create a federated user session, you use the access keys of the IAM user to
        programmatically call the GetFederationToken API operation. You must also pass
        session policies. The resulting session's permissions are the intersection of the
        identity-based policy and the session policy. For more information about creating a
        federated user session, see Requesting credentials through a custom identity
        broker.
      A resource-based policy can specify the ARN of the user or role as a principal. In that
        case, the permissions from the resource-based policy are added to the role or user's
        identity-based policy before the session is created. The session policy limits the total
        permissions granted by the resource-based policy and the identity-based policy. The
        resulting session's permissions are the intersection of the session policies and the
        resource-based policies plus the intersection of the session policies and identity-based
        policies.
      
         
          
         
         
      
      A resource-based policy can specify the ARN of the session as a principal. In that case,
        the permissions from the resource-based policy are added after the session is created. The
        resource-based policy permissions are not limited by the session policy. The resulting
        session has all the permissions of the resource-based policy plus the intersection of the identity-based policy and the session
        policy.
      
         
          
         
         
      
      A permissions boundary can set the maximum permissions for a user or role that is used
        to create a session. In that case, the resulting session's permissions are the intersection
        of the session policy, the permissions boundary, and the identity-based policy. However, a
        permissions boundary does not limit permissions granted by a resource-based policy that
        specifies the ARN of the resulting session.
      
         
          
         
         
      
     
   
    Policies and the root user
    The AWS account root user is affected by some policy types but not others. You cannot attach
      identity-based policies to the root user, and you cannot set the permissions boundary for the
      root user. However, you can specify the root user as the principal in a resource-based policy or an
      ACL. A root user is still the member of an account. If that account is a member of an
      organization in AWS Organizations, the root user is affected by SCPs and RCPs for the account.
   
    Overview of JSON policies
    Most policies are stored in AWS as JSON documents. Identity-based policies and policies
      used to set permissions boundaries are JSON policy documents that you attach to a user or
      role. Resource-based policies are JSON policy documents that you attach to a resource. SCPs
      and RCPs are JSON policy documents with restricted syntax that you attach to the AWS Organizations'
      organization root, organizational unit (OU), or an account. ACLs are also attached to a
      resource, but you must use a different syntax. Session policies are JSON policies that you
      provide when you assume a role or federated user session.
    It is not necessary for you to understand the JSON syntax. You can use the visual editor
      in the AWS Management Console to create and edit customer managed policies without ever using JSON.
      However, if you use inline policies for groups or complex policies, you must still create and
      edit those policies in the JSON editor using the console. For more information about using the
      visual editor, see Define custom IAM permissions with customer managed
      policies and Edit IAM policies.
    
When you create or edit a JSON policy, IAM can perform policy validation to help you create an effective policy. IAM identifies JSON syntax errors, while IAM Access Analyzer provides 
additional policy checks with recommendations to help you further refine your policies. To learn more about policy validation, see IAM policy validation. To learn more about IAM Access Analyzer policy checks and actionable recommendations, see 
IAM Access Analyzer policy validation.

     
      JSON policy document structure
       
        As illustrated in the following figure, a JSON policy document includes these
          elements:
       
      
         
         
      
          Optional policy-wide information at the top of the document
        
          One or more individual statements
        
      Each statement includes information about a single permission. If a policy includes
        multiple statements, AWS applies a logical OR across the statements when
        evaluating them. If multiple policies apply to a request, AWS applies a logical
          OR across all of those policies when evaluating them. 
      
         
          
         
         
      
      The information in a statement is contained within a series of elements.
      
         
         
         
         
         
         
         
         
      
          Version – Specify the version
            of the policy language that you want to use. We recommend that you use the latest
              2012-10-17 version. For more information, see IAM JSON policy elements:
        Version
        
          Statement – Use this main
            policy element as a container for the following elements. You can include more than one
            statement in a policy.
        
          Sid (Optional) – Include an
            optional statement ID to differentiate between your statements.
        
          Effect – Use
              Allow or Deny to indicate whether the policy allows or
            denies access.
        
          Principal (Required in some
            circumstances) – If you create a resource-based policy, you must indicate the
            account, user, role, or federated user to which you would like to allow or deny access.
            If you are creating an IAM permissions policy to attach to a user or role, you cannot
            include this element. The principal is implied as that user or role.
        
          Action – Include a list of
            actions that the policy allows or denies.
        
          Resource (Required in some
            circumstances) – If you create an IAM permissions policy, you must specify a
            list of resources to which the actions apply. If you create a resource-based policy, it
            depends on the resource you're using as to whether this element is required or
            not.
        
          Condition (Optional) –
            Specify the circumstances under which the policy grants permission.
        
      To learn about these and other more advanced policy elements, see IAM JSON policy element reference.
      
     
     
      Multiple statements and multiple
          policies
       
        If you want to define more than one permission for an entity (user or role), you can
          use multiple statements in a single policy. You can also attach multiple policies. If you
          try to define multiple permissions in a single statement, your policy might not grant the
          access that you expect. We recommend that you break up policies by resource type. 
       
      Because of the limited size of policies, it
        might be necessary to use multiple policies for more complex permissions. It's also a good
        idea to create functional groupings of permissions in a separate customer managed policy.
        For example, Create one policy for IAM user management, one for self-management, and
        another policy for S3 bucket management. Regardless of the combination of multiple
        statements and multiple policies, AWS evaluates your policies the same way.
      For example, the following policy has three statements, each of which defines a separate
        set of permissions within a single account. The statements define the following:
      
         
         
         
      
          The first statement, with an Sid (Statement ID) of
              FirstStatement, lets the user with the attached policy change their own
            password. The Resource element in this statement is "*" (which
            means "all resources"). But in practice, the ChangePassword API operation
            (or equivalent change-password CLI command) affects only the password for
            the user who makes the request. 
        
          The second statement lets the user list all the Amazon S3 buckets in their AWS account.
            The Resource element in this statement is "*" (which means
            "all resources"). But because policies don't grant access to resources in other
            accounts, the user can list only the buckets in their own AWS account. 
        
          The third statement lets the user list and retrieve any object that is in a bucket
            named amzn-s3-demo-bucket-confidential-data, but only when the user is
            authenticated with multi-factor authentication (MFA). The Condition element
            in the policy enforces the MFA authentication.
          When a policy statement contains a Condition element, the statement is
            only in effect when the Condition element evaluates to true. In this case,
            the Condition evaluates to true when the user is MFA-authenticated. If the
            user is not MFA-authenticated, this Condition evaluates to false. In that
            case, the third statement in this policy does not apply and the user does not have
            access to the amzn-s3-demo-bucket-confidential-data bucket.
        
      {
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "FirstStatement",
      "Effect": "Allow",
      "Action": ["iam:ChangePassword"],
      "Resource": "*"
    },
    {
      "Sid": "SecondStatement",
      "Effect": "Allow",
      "Action": "s3:ListAllMyBuckets",
      "Resource": "*"
    },
    {
      "Sid": "ThirdStatement",
      "Effect": "Allow",
      "Action": [
        "s3:List*",
        "s3:Get*"
      ],
      "Resource": [
        "arn:aws:s3:::amzn-s3-demo-bucket-confidential-data",
        "arn:aws:s3:::amzn-s3-demo-bucket-confidential-data/*"
      ],
      "Condition": {"Bool": {"aws:MultiFactorAuthPresent": "true"}}
    }
  ]
}
     
     
      Examples of JSON policy syntax
      The following identity-based policy allows the implied principal to list a single Amazon S3
        bucket named amzn-s3-demo-bucket: 
      {
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "s3:ListBucket",
    "Resource": "arn:aws:s3:::amzn-s3-demo-bucket"
  }
}
      The following resource-based policy can be attached to an Amazon S3 bucket. The policy allows
        members of a specific AWS account to perform any Amazon S3 actions in the bucket named
          amzn-s3-demo-bucket. It allows any action that can be performed on a bucket
        or the objects within it. (Because the policy grants trust only to the account, individual
        users in the account must still be granted permissions for the specified Amazon S3 actions.) 
      {
  "Version": "2012-10-17",
  "Statement": [{
    "Sid": "1",
    "Effect": "Allow",
    "Principal": {"AWS": ["arn:aws:iam::account-id:root"]},
    "Action": "s3:*",
    "Resource": [
      "arn:aws:s3:::amzn-s3-demo-bucket",
      "arn:aws:s3:::amzn-s3-demo-bucket/*"
    ]
  }]
}
      To view example policies for common scenarios, see Example IAM identity-based policies.
     
   
    Grant least privilege
    When you create IAM policies, follow the standard security advice of granting
            least privilege, or granting only the permissions required to
        perform a task. Determine what users and roles need to do and then craft policies that allow
        them to perform only those tasks. 
    Start with a minimum set of permissions and grant additional permissions as necessary.
        Doing so is more secure than starting with permissions that are too lenient and then trying
        to tighten them later.
    As an alternative to least privilege, you can use AWS managed policies or policies with wildcard * permissions to
        get started with policies. Consider the security risk of granting your principals more
        permissions than they need to do their job. Monitor those principals to learn which
        permissions they are using. Then write least privilege policies.
    IAM provides several options to help you refine the permissions that you grant.
    
         
         
         
         
         
    
            Understand access level groupings – You
                can use access level groupings to understand the level of access that a policy
                grants. Policy actions are
                classified as List, Read, Write,
                    Permissions management, or Tagging. For example, you
                can choose actions from the List and Read access levels to
                grant read-only access to your users. To learn how to use policy summaries to
                understand access level permissions, see Access levels
      in policy summaries.
        
            Validate your policies – You can perform
                policy validation using IAM Access Analyzer when you create and edit JSON policies. We
                recommend that you review and validate all of your existing policies. IAM Access Analyzer
                provides over 100 policy checks to validate your policies. It generates security
                warnings when a statement in your policy allows access we consider overly
                permissive. You can use the actionable recommendations that are provided through the
                security warnings as you work toward granting least privilege. To learn more about
                policy checks provided by IAM Access Analyzer, see IAM Access Analyzer policy
                    validation.
        
            Generate a policy based on access activity
                – To help you refine the permissions that you grant, you can generate an
                IAM policy that is based on the access activity for an IAM entity (user or
                role). IAM Access Analyzer reviews your AWS CloudTrail logs and generates a policy template that
                contains the permissions that have been used by the entity in your specified time
                frame. You can use the template to create a managed policy with fine-grained
                permissions and then attach it to the IAM entity. That way, you grant only the
                permissions that the user or role needs to interact with AWS resources for your
                specific use case. To learn more, see IAM Access Analyzer
                    policy generation.
        
            Use last accessed information – Another
                feature that can help with least privilege is last accessed
                    information. View this information on the Access
                    Advisor tab on the IAM console details page for an IAM user,
                group, role, or policy. Last accessed information also includes information about
                the actions that were last accessed for some services, such as Amazon EC2, IAM, Lambda,
                and Amazon S3. If you sign in using AWS Organizations management account credentials, you can view
                service last accessed information in the AWS Organizations section of
                the IAM console. You can also use the AWS CLI or AWS API to retrieve a report for
                last accessed information for entities or policies in IAM or AWS Organizations. You can use
                this information to identify unnecessary permissions so that you can refine your
                IAM or AWS Organizations policies to better adhere to the principle of least privilege. For
                more information, see Refine permissions in AWS using last
         accessed information.
        
            Review account events in AWS CloudTrail – To
                further reduce permissions, you can view your account's events in AWS CloudTrail
                    Event history. CloudTrail event logs include detailed event
                information that you can use to reduce the policy's permissions. The logs include
                only the actions and resources that your IAM entities need. For more information,
                see Viewing CloudTrail
                    Events in the CloudTrail Console in the AWS CloudTrail User
                    Guide.
        
    
    For more information, see the following policy topics for individual services, which
        provide examples of how to write policies for service-specific resources.
    
         
         
         
    
            Using resource-based policies for DynamoDB in the
                    Amazon DynamoDB Developer Guide
        
            Bucket policies for Amazon S3 in the
                Amazon Simple Storage Service User Guide
        
            Access Control List (ACL) overview in the
                    Amazon Simple Storage Service User Guide
        
Document ConventionsAccess managementManaged policies and inline policiesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideEvaluating identity-based policies with
        resource-based policiesEvaluating identity-based policies with
        permissions boundariesEvaluating identity-based policies with AWS Organizations SCPs
        or RCPsPolicy evaluation logicWhen a principal tries to use the AWS Management Console, the AWS API, or the AWS CLI, that principal
    sends a request to AWS. When an AWS service receives the request, AWS
    completes several steps to determine whether to allow or deny the request.
     
     
     
  
      Authentication – AWS first authenticates the
        principal that makes the request, if necessary. This step is not necessary for a few
        services, such as Amazon S3, that allow some requests from anonymous users.
    
      Processing the
            request context
        – AWS processes the information gathered in the request to determine which policies
        apply to the request.
    
      How AWS
            enforcement code logic evaluates requests to allow or deny access
        – AWS evaluates all of the policy types and the order of the policies affects how
        they are evaluated. AWS then processes the policies against the request context to
        determine whether the request is allowed or denied.
    
    Evaluating identity-based policies with
        resource-based policies
    Identity-based policies and resource-based policies grant permissions to the identities or
      resources to which they are attached. When an IAM entity (user or role) requests access to a
      resource within the same account, AWS evaluates all the permissions granted by the
      identity-based and resource-based policies. The resulting permissions are the union of the
      permissions of the two types. If an action is allowed by an identity-based policy, a
      resource-based policy, or both, then AWS allows the action. An explicit deny in either of
      these policies overrides the allow.
    
       
        
       
       
    
   
    Evaluating identity-based policies with
        permissions boundaries
    When AWS evaluates the identity-based policies and permissions boundary for a user, the
      resulting permissions are the intersection of the two categories. That means that when you add
      a permissions boundary to a user with existing identity-based policies, you might reduce the
      actions that the user can perform. Alternatively, when you remove a permissions boundary from
      a user, you might increase the actions they can perform. An explicit deny in either of these
      policies overrides the allow. To view information about how other policy types are evaluated
      with permissions boundaries, see Evaluating effective permissions
                with boundaries.
    
       
        
        
       
       
    
   
    Evaluating identity-based policies with AWS Organizations SCPs
        or RCPs
    When a user belongs to an account that is a member of an organization and accesses a
      resource that doesn't have a resource-based policy configured, the resulting permissions are
      the intersection of the user's policies, service control policies (SCPs), and resource control
      policy (RCP). This means that an action must be allowed by all three policy types. An explicit
      deny in the identity-based policy, an SCP, or an RCP overrides the allow.
    
       
        
        
       
       
    
    You can learn whether your account is a member of an organization in AWS Organizations. Organization
      members might be affected by an SCP or RCP. To view this data using the AWS CLI command or AWS
      API operation, you must have permissions for the
        organizations:DescribeOrganization action for your AWS Organizations entity. You must have
      additional permissions to perform the operation in the AWS Organizations console. To learn whether an SCP
      or RCP is denying access to a specific request, or to change your effective permissions,
      contact your AWS Organizations administrator.
  Document ConventionsSupported data typesRequest contextDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideEncryption scopeKey termsEncryption at rest in Amazon SQSServer-side encryption (SSE) lets you transmit sensitive data in encrypted
				queues. SSE protects the contents of messages in queues using SQS-managed
				encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS). For
				information about managing SSE using the AWS Management Console, see the following:
				 
				 
			
					Configuring SSE-SQS for a
							queue (console)
				
					Configuring SSE-KMS for a
							queue (console)
				 For information about managing SSE using the AWS SDK for Java (and the CreateQueue,
						SetQueueAttributes, and GetQueueAttributes actions), see the following examples:
				 
				 
			
					Using server-side encryption with Amazon SQS queues
				
					Configuring KMS
							permissions for AWS services
				
				 
					
				 
			SSE encrypts messages as soon as Amazon SQS receives them. The messages are stored in
				encrypted form and Amazon SQS decrypts messages only when they are sent to an authorized
				consumer.ImportantAll requests to queues with SSE enabled must use HTTPS and Signature Version
					4.An encrypted queue
    that uses the default key (AWS managed KMS key for Amazon SQS) cannot invoke a Lambda function in a different AWS account.Some features of AWS services that can send notifications to Amazon SQS using the
					AWS Security Token Service AssumeRole action are compatible with SSE but work
						only with standard queues:
					 
					 
				
						Auto Scaling Lifecycle
								Hooks
					
						AWS Lambda Dead-Letter
								Queues
					For information about compatibility of other services with encrypted queues,
					see Configure KMS permissions
							for AWS services and your service
					documentation.AWS KMS combines secure, highly available hardware and software to provide a key
				management system scaled for the cloud. When you use Amazon SQS with AWS KMS, the data keys that encrypt your message data are
				also encrypted and stored with the data they protect.The following are benefits of using AWS KMS:
				 
				 
				 
			
					You can create and manage AWS KMS keys yourself.
				
					You can also use the AWS managed KMS key for Amazon SQS, which is unique
						for each account and region.
				
					The AWS KMS security standards can help you meet encryption-related
						compliance requirements.
				For more information, see What is
					AWS Key Management Service? in the AWS Key Management Service Developer Guide.
				Encryption scope
				SSE encrypts the body of a message in an Amazon SQS queue.
				SSE doesn't encrypt the following:
				
					 
					 
					 
				
						Queue metadata (queue name and attributes)
					
						Message metadata (message ID, timestamp, and attributes)
					
						Per-queue metrics
					
				Encrypting a message makes its contents unavailable to unauthorized or
					anonymous users. With SSE enabled, anonymous SendMessage and
						ReceiveMessage requests to the encrypted queue will be
					rejected. Amazon SQS security best practices recommends against using anonymous
					requests. If you wish to send anonymous requests to an Amazon SQS queue, make sure
					you disable SSE. This doesn't affect the normal functioning of Amazon SQS:
				
					 
					 
				
						A message is encrypted only if it is sent after the encryption of a
							queue is enabled. Amazon SQS doesn't encrypt backlogged messages.
					
						Any encrypted message remains encrypted even if the encryption of its
							queue is disabled.
					
				Moving a message to a dead-letter
						queue doesn't affect its encryption:
				
					 
					 
				
						When Amazon SQS moves a message from an encrypted source queue to an
							unencrypted dead-letter queue, the message remains encrypted.
					
						When Amazon SQS moves a message from an unencrypted source queue to an
							encrypted dead-letter queue, the message remains unencrypted.
					
			 
				Key terms
				The following key terms can help you better understand the functionality of
					SSE. For detailed descriptions, see the Amazon Simple Queue Service API Reference.
				
					 
					 
					 
					 
				
						Data key
						
							The key (DEK) responsible for encrypting the contents of Amazon SQS
								messages.
							For more information, see Data Keys in
								the AWS Key Management Service Developer Guide in the
									AWS Encryption SDK Developer Guide.
						
					 
						Data key reuse period
						
							The length of time, in seconds, for which Amazon SQS can reuse a data
								key to encrypt or decrypt messages before calling AWS KMS again. An
								integer representing seconds, between 60 seconds (1 minute) and
								86,400 seconds (24 hours). The default is 300 (5 minutes). For more
								information, see Understanding the
						data key reuse period.
							NoteIn the unlikely event of being unable to reach AWS KMS, Amazon SQS
									continues to use the cached data key until a connection is
									reestablished.
						
					 
						KMS key ID
						
							The alias, alias ARN, key ID, or key ARN of an AWS managed
								KMS key or a custom KMS key—in your account or in another
								account. While the alias of the AWS managed KMS key for Amazon SQS is
								always alias/aws/sqs, the alias of a custom KMS key
								can, for example, be
									alias/MyAlias. You can
								use these KMS keys to protect the messages in Amazon SQS queues. 
							NoteKeep the following in mind:
									 
									 
									 
								
										If you don't specify a custom KMS key, Amazon SQS uses
											the AWS managed KMS key for Amazon SQS.
									
										The first time you use the AWS Management Console to specify the
											AWS managed KMS key for Amazon SQS for a queue, AWS KMS
											creates the AWS managed KMS key for Amazon SQS.
									
										Alternatively, the first time you use the
												SendMessage or
												SendMessageBatch action on a queue with
											SSE enabled, AWS KMS creates the AWS managed KMS key
											for Amazon SQS.
									
							You can create KMS keys, define the policies that control how
								KMS keys can be used, and audit KMS key usage using the
									Customer managed keys section of the AWS KMS
								console or the CreateKey AWS KMS action. For more
								information, see KMS keys and Creating Keys in the
									AWS Key Management Service Developer Guide. For more examples of
								KMS key identifiers, see KeyId in the AWS Key Management Service API Reference. For
								information about finding KMS key identifiers, see Find the
									Key ID and ARN in the
									AWS Key Management Service Developer Guide.
							ImportantThere are additional charges for using AWS KMS. For more
									information, see Estimating AWS KMS costs and AWS Key Management Service
									Pricing.
						
					 
						Envelope Encryption
						
							The security of your encrypted data depends in part on protecting
								the data key that can decrypt it. Amazon SQS uses the KMS key to
								encrypt the data key and then the encrypted data key is stored with
								the encrypted message. This practice of using a KMS key to encrypt
								data keys is known as envelope encryption. 
							For more information, see Envelope Encryption in the
									AWS Encryption SDK Developer Guide.
						
					
			Document ConventionsData encryptionKey managementDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideEncryption scopeKey termsEncryption at rest in Amazon SQSServer-side encryption (SSE) lets you transmit sensitive data in encrypted
				queues. SSE protects the contents of messages in queues using SQS-managed
				encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS). For
				information about managing SSE using the AWS Management Console, see the following:
				 
				 
			
					Configuring SSE-SQS for a
							queue (console)
				
					Configuring SSE-KMS for a
							queue (console)
				 For information about managing SSE using the AWS SDK for Java (and the CreateQueue,
						SetQueueAttributes, and GetQueueAttributes actions), see the following examples:
				 
				 
			
					Using server-side encryption with Amazon SQS queues
				
					Configuring KMS
							permissions for AWS services
				
				 
					
				 
			SSE encrypts messages as soon as Amazon SQS receives them. The messages are stored in
				encrypted form and Amazon SQS decrypts messages only when they are sent to an authorized
				consumer.ImportantAll requests to queues with SSE enabled must use HTTPS and Signature Version
					4.An encrypted queue
    that uses the default key (AWS managed KMS key for Amazon SQS) cannot invoke a Lambda function in a different AWS account.Some features of AWS services that can send notifications to Amazon SQS using the
					AWS Security Token Service AssumeRole action are compatible with SSE but work
						only with standard queues:
					 
					 
				
						Auto Scaling Lifecycle
								Hooks
					
						AWS Lambda Dead-Letter
								Queues
					For information about compatibility of other services with encrypted queues,
					see Configure KMS permissions
							for AWS services and your service
					documentation.AWS KMS combines secure, highly available hardware and software to provide a key
				management system scaled for the cloud. When you use Amazon SQS with AWS KMS, the data keys that encrypt your message data are
				also encrypted and stored with the data they protect.The following are benefits of using AWS KMS:
				 
				 
				 
			
					You can create and manage AWS KMS keys yourself.
				
					You can also use the AWS managed KMS key for Amazon SQS, which is unique
						for each account and region.
				
					The AWS KMS security standards can help you meet encryption-related
						compliance requirements.
				For more information, see What is
					AWS Key Management Service? in the AWS Key Management Service Developer Guide.
				Encryption scope
				SSE encrypts the body of a message in an Amazon SQS queue.
				SSE doesn't encrypt the following:
				
					 
					 
					 
				
						Queue metadata (queue name and attributes)
					
						Message metadata (message ID, timestamp, and attributes)
					
						Per-queue metrics
					
				Encrypting a message makes its contents unavailable to unauthorized or
					anonymous users. With SSE enabled, anonymous SendMessage and
						ReceiveMessage requests to the encrypted queue will be
					rejected. Amazon SQS security best practices recommends against using anonymous
					requests. If you wish to send anonymous requests to an Amazon SQS queue, make sure
					you disable SSE. This doesn't affect the normal functioning of Amazon SQS:
				
					 
					 
				
						A message is encrypted only if it is sent after the encryption of a
							queue is enabled. Amazon SQS doesn't encrypt backlogged messages.
					
						Any encrypted message remains encrypted even if the encryption of its
							queue is disabled.
					
				Moving a message to a dead-letter
						queue doesn't affect its encryption:
				
					 
					 
				
						When Amazon SQS moves a message from an encrypted source queue to an
							unencrypted dead-letter queue, the message remains encrypted.
					
						When Amazon SQS moves a message from an unencrypted source queue to an
							encrypted dead-letter queue, the message remains unencrypted.
					
			 
				Key terms
				The following key terms can help you better understand the functionality of
					SSE. For detailed descriptions, see the Amazon Simple Queue Service API Reference.
				
					 
					 
					 
					 
				
						Data key
						
							The key (DEK) responsible for encrypting the contents of Amazon SQS
								messages.
							For more information, see Data Keys in
								the AWS Key Management Service Developer Guide in the
									AWS Encryption SDK Developer Guide.
						
					 
						Data key reuse period
						
							The length of time, in seconds, for which Amazon SQS can reuse a data
								key to encrypt or decrypt messages before calling AWS KMS again. An
								integer representing seconds, between 60 seconds (1 minute) and
								86,400 seconds (24 hours). The default is 300 (5 minutes). For more
								information, see Understanding the
						data key reuse period.
							NoteIn the unlikely event of being unable to reach AWS KMS, Amazon SQS
									continues to use the cached data key until a connection is
									reestablished.
						
					 
						KMS key ID
						
							The alias, alias ARN, key ID, or key ARN of an AWS managed
								KMS key or a custom KMS key—in your account or in another
								account. While the alias of the AWS managed KMS key for Amazon SQS is
								always alias/aws/sqs, the alias of a custom KMS key
								can, for example, be
									alias/MyAlias. You can
								use these KMS keys to protect the messages in Amazon SQS queues. 
							NoteKeep the following in mind:
									 
									 
									 
								
										If you don't specify a custom KMS key, Amazon SQS uses
											the AWS managed KMS key for Amazon SQS.
									
										The first time you use the AWS Management Console to specify the
											AWS managed KMS key for Amazon SQS for a queue, AWS KMS
											creates the AWS managed KMS key for Amazon SQS.
									
										Alternatively, the first time you use the
												SendMessage or
												SendMessageBatch action on a queue with
											SSE enabled, AWS KMS creates the AWS managed KMS key
											for Amazon SQS.
									
							You can create KMS keys, define the policies that control how
								KMS keys can be used, and audit KMS key usage using the
									Customer managed keys section of the AWS KMS
								console or the CreateKey AWS KMS action. For more
								information, see KMS keys and Creating Keys in the
									AWS Key Management Service Developer Guide. For more examples of
								KMS key identifiers, see KeyId in the AWS Key Management Service API Reference. For
								information about finding KMS key identifiers, see Find the
									Key ID and ARN in the
									AWS Key Management Service Developer Guide.
							ImportantThere are additional charges for using AWS KMS. For more
									information, see Estimating AWS KMS costs and AWS Key Management Service
									Pricing.
						
					 
						Envelope Encryption
						
							The security of your encrypted data depends in part on protecting
								the data key that can decrypt it. Amazon SQS uses the KMS key to
								encrypt the data key and then the encrypted data key is stored with
								the encrypted message. This practice of using a KMS key to encrypt
								data keys is known as envelope encryption. 
							For more information, see Envelope Encryption in the
									AWS Encryption SDK Developer Guide.
						
					
			Document ConventionsData encryptionKey managementDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring server-side encryption for a
			queue using SQS-managed encryption keysIn addition to the default Amazon SQS managed server-side encryption (SSE) option, Amazon SQS
		managed SSE (SSE-SQS) lets you create custom managed server-side encryption that uses
		SQS-managed encryption keys to protect sensitive data sent over message queues. With
		SSE-SQS, you don't need to create and manage encryption keys, or modify your code to
		encrypt your data. SSE-SQS lets you transmit data securely and helps you meet strict
		encryption compliance and regulatory requirements at no additional cost.SSE-SQS protects data at rest using 256-bit Advanced Encryption Standard (AES-256)
		encryption. SSE encrypts messages as soon as Amazon SQS receives them. Amazon SQS stores messages in
		encrypted form and decrypts them only when sending them to an authorized consumer.Note
			 
			 
		
				The default SSE option is only effective when you create a queue without
					specifying encryption attributes.
			
				Amazon SQS allows you to turn off all queue encryption. Therefore, turning off
					KMS-SSE, will not automatically enable SQS-SSE. If you wish to enable SQS-SSE
					after turning off KMS-SSE, you must add an attribute change in the
					request.
			To configure SSE-SQS encryption for a queue (console)NoteAny new queue created using the HTTP (non-TLS) endpoint will not enable SSE-SQS
				encryption by default. It is a security best practice to create Amazon SQS queues using
				HTTPS or Signature Version 4
				endpoints.Open the Amazon SQS console at
         https://console.aws.amazon.com/sqs/.
			In the navigation pane, choose Queues.
		
			Choose a queue, and then choose Edit.
		
			Expand Encryption.
		
			For Server-side encryption, choose Enabled
				(default).
			NoteWith SSE enabled, anonymous SendMessage and
						ReceiveMessage requests to the encrypted queue will be
					rejected. Amazon SQS security best practises recommend against using anonymous
					requests. If you wish to send anonymous requests to an Amazon SQS queue, make sure to
					disable SSE.
		
			Select Amazon SQS key (SSE-SQS). There is no additional fee
				for using this option.
		
			Choose Save.
		Document ConventionsConfiguring an access policyConfiguring SSE-KMS for a queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring server-side encryption for a queue
			using the Amazon SQS consoleTo protect the data in a queue’s messages, Amazon SQS has server-side encryption (SSE) enabled
		by default for all newly created queues. Amazon SQS integrates with the Amazon Web Services Key Management
		Service (Amazon Web Services KMS) to manage KMS keys for server-side encryption (SSE). For information about using SSE,
		see Encryption at rest in Amazon SQS.The KMS key that you assign to your queue must have a key policy that includes
		permissions for all principals that are authorized to use the queue. For information, see
			Key Management.If you aren't the owner of the KMS key, or if you log in with an account that doesn't
		have kms:ListAliases and kms:DescribeKey permissions, you won't be
		able to view information about the KMS key on the Amazon SQS console. Ask the owner of the
		KMS key to grant you these permissions. For more information, see Key Management.When you create or edit a queue, you can configure
		SSE-KMS.To configure SSE-KMS for an existing queue (console)Open the Amazon SQS console at
         https://console.aws.amazon.com/sqs/.
			In the navigation pane, choose Queues.
		
			Choose a queue, and then choose Edit.
		
			Expand Encryption.
		
			For Server-side encryption, choose Enabled
				(default).
			NoteWith SSE enabled, anonymous SendMessage and
						ReceiveMessage requests to the encrypted queue will be
					rejected. Amazon SQS security best practises recommend against using anonymous
					requests. If you wish to send anonymous requests to an Amazon SQS queue, make sure to
					disable SSE.
		
			Select AWS Key Management Service key (SSE-KMS).
			The console displays the Description, the
					Account, and the KMS key ARN of the
				KMS key.
		
			Specify the KMS key ID for the queue. For more information, see Key terms.
			
					Choose the Choose a KMS key alias option.
				
					The default key is the Amazon Web Services managed KMS key for Amazon SQS. To use this
						key, choose it from the KMS key list. 
				
					To use a custom KMS key from your Amazon Web Services account, choose it from the
							KMS key list. For instructions on creating custom
						KMS keys, see Creating
							Keys in the Amazon Web Services Key Management Service Developer
							Guide.
				
					To use a custom KMS key that is not in the list, or a custom KMS key
						from another Amazon Web Services account, choose Enter the KMS key
							alias and enter the KMS key Amazon Resource Name
						(ARN).
				
		
			(Optional) For Data key reuse period, specify a value between
				1 minute and 24 hours. The default is 5 minutes. For more information, see Understanding the
						data key reuse period.
		
			When you finish configuring SSE-KMS, choose Save.
		Document ConventionsConfiguring SSE-SQS for a queueConfiguring tags for a queueDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoCreateQueueCreates a new standard or FIFO queue. You can pass one or more attributes in
            the request. Keep the following in mind:
       
       
       
   
         If you don't specify the FifoQueue attribute, Amazon SQS creates a standard queue.
         NoteYou can't change the queue type after you create it and you can't convert
                        an existing standard queue into a FIFO queue. You must either create a new
                        FIFO queue for your application or delete your existing standard queue and
                        recreate it as a FIFO queue. For more information, see Moving From a Standard Queue to a FIFO Queue in the
                            Amazon SQS Developer Guide. 
      
         If you don't provide a value for an attribute, the queue is created with the
                    default value for the attribute.
      
         If you delete a queue, you must wait at least 60 seconds before creating a
                    queue with the same name.
      To successfully create a new queue, you must provide a queue name that adheres to the
                limits
                related to queues and is unique within the scope of your queues.NoteAfter you create a queue, you must wait at least one second after the queue is
                created to be able to use the queue.To retrieve the URL of a queue, use the GetQueueUrl action. This action only requires the QueueName parameter.When creating queues, keep the following points in mind:
       
       
   
         If you specify the name of an existing queue and provide the exact same names
                    and values for all its attributes, the CreateQueue action will return the URL of the
                    existing queue instead of creating a new one.
      
         If you attempt to create a queue with a name that already exists but with
                    different attribute names or values, the CreateQueue action will
                    return an error. This ensures that existing queues are not inadvertently
                    altered.
      NoteCross-account permissions don't apply to this action. For more information, 
see Grant 
cross-account permissions to a role and a username in the Amazon SQS Developer Guide.
      Request Syntax
      {
   "Attributes": { 
      "string" : "string" 
   },
   "QueueName": "string",
   "tags": { 
      "string" : "string" 
   }
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
          
      
            
               
                  Attributes
               
            
            
               A map of attributes with their corresponding values.
               The following lists the names, descriptions, and values of the special request
            parameters that the CreateQueue action uses:
               
                   
                   
                   
                   
                   
                   
               
                     
                        DelaySeconds – The length of time, in seconds, for which the
                    delivery of all messages in the queue is delayed. Valid values: An integer from
                    0 to 900 seconds (15 minutes). Default: 0. 
                  
                     
                        MaximumMessageSize – The limit of how many bytes a message
                    can contain before Amazon SQS rejects it. Valid values: An integer from 1,024 bytes
                    (1 KiB) to 262,144 bytes (256 KiB). Default: 262,144 (256 KiB). 
                  
                     
                        MessageRetentionPeriod – The length of time, in seconds, for
                    which Amazon SQS retains a message. Valid values: An integer from 60 seconds (1
                    minute) to 1,209,600 seconds (14 days). Default: 345,600 (4 days). When you
                    change a queue's attributes, the change can take up to 60 seconds for most of
                    the attributes to propagate throughout the Amazon SQS system. Changes made to the
                        MessageRetentionPeriod attribute can take up to 15 minutes and
                    will impact existing messages in the queue potentially causing them to be
                    expired and deleted if the MessageRetentionPeriod is reduced below
                    the age of existing messages.
                  
                     
                        Policy – The queue's policy. A valid AWS policy. For more
                    information about policy structure, see Overview of AWS IAM
                        Policies in the IAM User Guide. 
                  
                     
                        ReceiveMessageWaitTimeSeconds – The length of time, in
                    seconds, for which a 
                           ReceiveMessage
                         action waits
                    for a message to arrive. Valid values: An integer from 0 to 20 (seconds).
                    Default: 0. 
                  
                     
                        VisibilityTimeout – The visibility timeout for the queue, in
                    seconds. Valid values: An integer from 0 to 43,200 (12 hours). Default: 30. For
                    more information about the visibility timeout, see Visibility Timeout in the Amazon SQS Developer
                        Guide.
                  
               The following attributes apply only to dead-letter queues:
               
               
                   
                   
               
                     
                        RedrivePolicy – The string that includes the parameters for the dead-letter queue functionality 
            of the source queue as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              deadLetterTargetArn – The Amazon Resource Name (ARN) of the dead-letter queue to 
                  which Amazon SQS moves messages after the value of maxReceiveCount is exceeded.
                        
                           
                              maxReceiveCount – The number of times a message is delivered to the source queue before being 
                 moved to the dead-letter queue. Default: 10. When the ReceiveCount for a message exceeds the maxReceiveCount 
                 for a queue, Amazon SQS moves the message to the dead-letter-queue.
                        
                  
                     
                        RedriveAllowPolicy – The string that includes the parameters for the permissions for the dead-letter
            queue redrive permission and which source queues can specify dead-letter queues as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              redrivePermission – The permission type that defines which source queues can 
                    specify the current queue as the dead-letter queue. Valid values are:
                           
                               
                               
                               
                           
                                 
                                    allowAll – (Default) Any source queues in this AWS account in the same Region can 
                          specify this queue as the dead-letter queue.
                              
                                 
                                    denyAll – No source queues can specify this queue as the dead-letter
                          queue.
                              
                                 
                                    byQueue – Only queues specified by the sourceQueueArns parameter can specify 
                         this queue as the dead-letter queue.
                              
                        
                           
                              sourceQueueArns – The Amazon Resource Names (ARN)s of the source queues that can specify 
                    this queue as the dead-letter queue and redrive messages. You can specify this parameter only when the 
                    redrivePermission parameter is set to byQueue. You can specify up to 10 source queue ARNs. 
                    To allow more than 10 source queues to specify dead-letter queues, set the redrivePermission parameter
                    to allowAll.
                        
                  
               NoteThe dead-letter queue of a 
              FIFO queue must also be a FIFO queue. Similarly, the dead-letter 
              queue of a standard queue must also be a standard queue.
               The following attributes apply only to server-side-encryption:
               
                   
                   
                   
               
                     
                        KmsMasterKeyId – The ID of an AWS managed customer master
                    key (CMK) for Amazon SQS or a custom CMK. For more information, see Key Terms. While the alias of the AWS managed CMK for Amazon SQS is
                    always alias/aws/sqs, the alias of a custom CMK can, for example,
                    be alias/MyAlias
                        . For more examples, see
                        KeyId in the 
                           AWS Key Management Service API
                        Reference. 
                  
                     
                        KmsDataKeyReusePeriodSeconds – The length of time, in
                    seconds, for which Amazon SQS can reuse a data key to
                    encrypt or decrypt messages before calling AWS KMS again. An integer
                    representing seconds, between 60 seconds (1 minute) and 86,400 seconds (24
                    hours). Default: 300 (5 minutes). A shorter time period provides better security
                    but results in more calls to KMS which might incur charges after Free Tier. For
                    more information, see How Does the Data Key Reuse Period Work?
                     
                  
                     
                        SqsManagedSseEnabled – Enables server-side queue encryption
                    using SQS owned encryption keys. Only one server-side encryption option is
                    supported per queue (for example, SSE-KMS or SSE-SQS).
                  
               The following attributes apply only to FIFO (first-in-first-out)
                queues:
               
                   
                   
               
                     
                        FifoQueue – Designates a queue as FIFO. Valid values are
                        true and false. If you don't specify the FifoQueue attribute, Amazon SQS creates a standard queue. You
                    can provide this attribute only during queue creation. You can't change it for
                    an existing queue. When you set this attribute, you must also provide the
                        MessageGroupId for your messages explicitly.
                     For more information, see FIFO queue logic in the Amazon SQS Developer
                        Guide.
                  
                     
                        ContentBasedDeduplication – Enables content-based
                    deduplication. Valid values are true and false. For
                    more information, see Exactly-once processing in the Amazon SQS Developer
                        Guide. Note the following: 
                     
                         
                         
                         
                     
                           Every message must have a unique
                            MessageDeduplicationId.
                           
                               
                               
                               
                               
                           
                                 You may provide a MessageDeduplicationId
                                    explicitly.
                              
                                 If you aren't able to provide a
                                        MessageDeduplicationId and you enable
                                        ContentBasedDeduplication for your queue, Amazon SQS
                                    uses a SHA-256 hash to generate the
                                        MessageDeduplicationId using the body of the
                                    message (but not the attributes of the message). 
                              
                                 If you don't provide a MessageDeduplicationId and
                                    the queue doesn't have ContentBasedDeduplication
                                    set, the action fails with an error.
                              
                                 If the queue has ContentBasedDeduplication set,
                                    your MessageDeduplicationId overrides the generated
                                    one.
                              
                        
                           When ContentBasedDeduplication is in effect, messages
                            with identical content sent within the deduplication interval are
                            treated as duplicates and only one copy of the message is
                            delivered.
                        
                           If you send one message with ContentBasedDeduplication
                            enabled and then another message with a
                                MessageDeduplicationId that is the same as the one
                            generated for the first MessageDeduplicationId, the two
                            messages are treated as duplicates and only one copy of the message is
                            delivered. 
                        
                  
               The following attributes apply only to 
high throughput
for FIFO queues:
               
                   
                   
               
                     
                        DeduplicationScope – Specifies whether message deduplication occurs at the 
      message group or queue level. Valid values are messageGroup and queue.
                  
                     
                        FifoThroughputLimit – Specifies whether the FIFO queue throughput 
      quota applies to the entire queue or per message group. Valid values are perQueue and perMessageGroupId. 
      The perMessageGroupId value is allowed only when the value for DeduplicationScope is messageGroup.
                  
               To enable high throughput for FIFO queues, do the following:
               
                   
                   
               
                     Set DeduplicationScope to messageGroup.
                  
                     Set FifoThroughputLimit to perMessageGroupId.
                  
               If you set these attributes to anything other than the values shown for enabling high
  throughput, normal throughput is in effect and deduplication occurs as specified.
               For information on throughput quotas, 
  see Quotas related to messages 
  in the Amazon SQS Developer Guide.
               Type: String to string map
               Valid Keys: All | Policy | VisibilityTimeout | MaximumMessageSize | MessageRetentionPeriod | ApproximateNumberOfMessages | ApproximateNumberOfMessagesNotVisible | CreatedTimestamp | LastModifiedTimestamp | QueueArn | ApproximateNumberOfMessagesDelayed | DelaySeconds | ReceiveMessageWaitTimeSeconds | RedrivePolicy | FifoQueue | ContentBasedDeduplication | KmsMasterKeyId | KmsDataKeyReusePeriodSeconds | DeduplicationScope | FifoThroughputLimit | RedriveAllowPolicy | SqsManagedSseEnabled
               
               Required: No
            
          
            
               
                  QueueName
               
            
            
               The name of the new queue. The following limits apply to this name:
               
                   
                   
                   
               
                     A queue name can have up to 80 characters.
                  
                     Valid values: alphanumeric characters, hyphens (-), and
                    underscores (_).
                  
                     A FIFO queue name must end with the .fifo suffix.
                  
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
          
            
               
                  tags
               
            
            
               Add cost allocation tags to the specified Amazon SQS queue. For an overview, see Tagging 
Your Amazon SQS Queues in the Amazon SQS Developer Guide.
               When you use queue tags, keep the following guidelines in mind:
               
                   
                   
                   
                   
               
                     Adding more than 50 tags to a queue isn't recommended.
                  
                     Tags don't have any semantic meaning. Amazon SQS interprets tags as character strings.
                  
                     Tags are case-sensitive.
                  
                     A new tag with a key identical to that of an existing tag overwrites the existing tag.
                  
               For a full list of tag restrictions, see 
Quotas related to queues 
in the Amazon SQS Developer Guide.
               NoteTo be able to tag a queue on creation, you must have the
                    sqs:CreateQueue and sqs:TagQueue permissions.Cross-account permissions don't apply to this action. For more information, 
see Grant 
cross-account permissions to a role and a username in the Amazon SQS Developer Guide.
               Type: String to string map
               Required: No
            
         
    
      Response Syntax
      {
   "QueueUrl": "string"
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
      
            
               
                  QueueUrl
               
            
            
               The URL of the created Amazon SQS queue.
               Type: String
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAttributeName
               
            
            
               The specified attribute doesn't exist.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAttributeValue
               
            
            
               A queue attribute value is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  QueueDeletedRecently
               
            
            
               You must wait 60 seconds after deleting a queue before you can create another queue
            with the same name.
               HTTP Status Code: 400
            
          
            
               
                  QueueNameExists
               
            
            
               A queue with this name already exists. Amazon SQS returns this error only if the request
            includes attributes whose values differ from those of the existing queue.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example query requests create a new queue named
                MyQueue. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.CreateQueue
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueName":"MyQueue",
    "Attributes": {
        "VisibilityTimeout": "40"
    },
    "tags": {
        "QueueType": "Production"
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
    "QueueUrl":"https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue"
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
Content-Type: application/x-www-form-urlencoded
X-Amz-Date: <Date>
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=CreateQueue
&QueueName=MyQueue
&Attribute.1.Name=VisibilityTimeout
&Attribute.1.Value=40
&Tag.Key=QueueType
&Tag.Value=Production
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<CreateQueueResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <CreateQueueResult>
        <QueueUrl>https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue</QueueUrl>
    </CreateQueueResult>
    <ResponseMetadata>
        <RequestId>9b20926c-8b35-5d8e-9559-ce1c22e754dc</RequestId>
    </ResponseMetadata>
</CreateQueueResponse>
          
       
       
         Example
         The following example creates a delay queue which hides each message from
                    consumers for the first 45 seconds that the message is in the queue by calling
                    the CreateQueue action with the DelaySeconds attribute
                    set to 45 seconds.
         NoteQueue URLs and names are case-sensitive.
          
            Sample Request
            https://sqs.us-east-2.amazonaws.com/123456789012/MyQueue/
?Action=CreateQueue
&QueueName=MyQueue
&Attribute.1.Name=DelaySeconds
&Attribute.1.Value=45
&Expires=2020-12-20T22%3A52%3A43PST
&Version=2012-11-05
&AUTHPARAMS
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsChangeMessageVisibilityBatchDeleteMessageDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoGetQueueAttributesGets attributes for the specified queue.NoteTo determine whether a queue is FIFO, you can check whether QueueName ends with the .fifo suffix.
      Request Syntax
      {
   "AttributeNames": [ "string" ],
   "QueueUrl": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
      
            
               
                  AttributeNames
               
            
            
               A list of attributes for which to retrieve information.
               The AttributeNames parameter is optional, but if you don't specify values
            for this parameter, the request returns empty results.
               NoteIn the future, new attributes might be added. If you write code that calls this action, we recommend that you structure your code so that it can handle new attributes gracefully.
               The following attributes are supported:
               ImportantThe ApproximateNumberOfMessagesDelayed,
                    ApproximateNumberOfMessagesNotVisible, and
                    ApproximateNumberOfMessages metrics may not achieve consistency
                until at least 1 minute after the producers stop sending messages. This period is
                required for the queue metadata to reach eventual consistency. 
               
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
               
                     
                        All – Returns all values. 
                  
                     
                        ApproximateNumberOfMessages – Returns the approximate
                    number of messages available for retrieval from the queue.
                  
                     
                        ApproximateNumberOfMessagesDelayed – Returns the
                    approximate number of messages in the queue that are delayed and not available
                    for reading immediately. This can happen when the queue is configured as a delay
                    queue or when a message has been sent with a delay parameter.
                  
                     
                        ApproximateNumberOfMessagesNotVisible – Returns the
                    approximate number of messages that are in flight. Messages are considered to be
                        in flight if they have been sent to a client but have
                    not yet been deleted or have not yet reached the end of their visibility window.
                
                  
                     
                        CreatedTimestamp – Returns the time when the queue was
                    created in seconds (epoch
                        time).
                  
                     
                        DelaySeconds – Returns the default delay on the queue in
                    seconds.
                  
                     
                        LastModifiedTimestamp – Returns the time when the queue
                    was last changed in seconds (epoch time).
                  
                     
                        MaximumMessageSize – Returns the limit of how many bytes a
                    message can contain before Amazon SQS rejects it.
                  
                     
                        MessageRetentionPeriod – Returns the length of time, in
                    seconds, for which Amazon SQS retains a message. When you change a queue's
                    attributes, the change can take up to 60 seconds for most of the attributes to
                    propagate throughout the Amazon SQS system. Changes made to the
                        MessageRetentionPeriod attribute can take up to 15 minutes and
                    will impact existing messages in the queue potentially causing them to be
                    expired and deleted if the MessageRetentionPeriod is reduced below
                    the age of existing messages.
                  
                     
                        Policy – Returns the policy of the queue.
                  
                     
                        QueueArn – Returns the Amazon resource name (ARN) of the
                    queue.
                  
                     
                        ReceiveMessageWaitTimeSeconds – Returns the length of
                    time, in seconds, for which the ReceiveMessage action waits for a
                    message to arrive. 
                  
                     
                        VisibilityTimeout – Returns the visibility timeout for the
                    queue. For more information about the visibility timeout, see Visibility Timeout in the Amazon SQS Developer
                        Guide. 
                  
               The following attributes apply only to dead-letter queues:
               
               
                   
                   
               
                     
                        RedrivePolicy – The string that includes the parameters for the dead-letter queue functionality 
            of the source queue as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              deadLetterTargetArn – The Amazon Resource Name (ARN) of the dead-letter queue to 
                  which Amazon SQS moves messages after the value of maxReceiveCount is exceeded.
                        
                           
                              maxReceiveCount – The number of times a message is delivered to the source queue before being 
                 moved to the dead-letter queue. Default: 10. When the ReceiveCount for a message exceeds the maxReceiveCount 
                 for a queue, Amazon SQS moves the message to the dead-letter-queue.
                        
                  
                     
                        RedriveAllowPolicy – The string that includes the parameters for the permissions for the dead-letter
            queue redrive permission and which source queues can specify dead-letter queues as a JSON object. The parameters are as follows:
                     
                         
                         
                     
                           
                              redrivePermission – The permission type that defines which source queues can 
                    specify the current queue as the dead-letter queue. Valid values are:
                           
                               
                               
                               
                           
                                 
                                    allowAll – (Default) Any source queues in this AWS account in the same Region can 
                          specify this queue as the dead-letter queue.
                              
                                 
                                    denyAll – No source queues can specify this queue as the dead-letter
                          queue.
                              
                                 
                                    byQueue – Only queues specified by the sourceQueueArns parameter can specify 
                         this queue as the dead-letter queue.
                              
                        
                           
                              sourceQueueArns – The Amazon Resource Names (ARN)s of the source queues that can specify 
                    this queue as the dead-letter queue and redrive messages. You can specify this parameter only when the 
                    redrivePermission parameter is set to byQueue. You can specify up to 10 source queue ARNs. 
                    To allow more than 10 source queues to specify dead-letter queues, set the redrivePermission parameter
                    to allowAll.
                        
                  
               NoteThe dead-letter queue of a 
              FIFO queue must also be a FIFO queue. Similarly, the dead-letter 
              queue of a standard queue must also be a standard queue.
               The following attributes apply only to server-side-encryption:
               
                   
                   
                   
               
                     
                        KmsMasterKeyId – Returns the ID of an AWS managed customer
                    master key (CMK) for Amazon SQS or a custom CMK. For more information, see Key Terms. 
                  
                     
                        KmsDataKeyReusePeriodSeconds – Returns the length of time,
                    in seconds, for which Amazon SQS can reuse a data key to encrypt or decrypt
                    messages before calling AWS KMS again. For more information, see
                        How Does the Data Key Reuse Period Work?. 
                  
                     
                        SqsManagedSseEnabled – Returns information about whether the
                    queue is using SSE-SQS encryption using SQS owned encryption keys. Only one
                    server-side encryption option is supported per queue (for example, SSE-KMS or SSE-SQS).
                  
               The following attributes apply only to FIFO (first-in-first-out)
                queues:
               
                   
                   
               
                     
                        FifoQueue – Returns information about whether the queue is
                    FIFO. For more information, see FIFO queue logic in the Amazon SQS Developer
                        Guide.
                     NoteTo determine whether a queue is FIFO, you can check whether QueueName ends with the .fifo suffix.
                  
                     
                        ContentBasedDeduplication – Returns whether content-based
                    deduplication is enabled for the queue. For more information, see Exactly-once processing in the Amazon SQS Developer
                        Guide. 
                  
               The following attributes apply only to 
high throughput
for FIFO queues:
               
                   
                   
               
                     
                        DeduplicationScope – Specifies whether message deduplication occurs at the 
      message group or queue level. Valid values are messageGroup and queue.
                  
                     
                        FifoThroughputLimit – Specifies whether the FIFO queue throughput 
      quota applies to the entire queue or per message group. Valid values are perQueue and perMessageGroupId. 
      The perMessageGroupId value is allowed only when the value for DeduplicationScope is messageGroup.
                  
               To enable high throughput for FIFO queues, do the following:
               
                   
                   
               
                     Set DeduplicationScope to messageGroup.
                  
                     Set FifoThroughputLimit to perMessageGroupId.
                  
               If you set these attributes to anything other than the values shown for enabling high
  throughput, normal throughput is in effect and deduplication occurs as specified.
               For information on throughput quotas, 
  see Quotas related to messages 
  in the Amazon SQS Developer Guide.
               Type: Array of strings
               Valid Values: All | Policy | VisibilityTimeout | MaximumMessageSize | MessageRetentionPeriod | ApproximateNumberOfMessages | ApproximateNumberOfMessagesNotVisible | CreatedTimestamp | LastModifiedTimestamp | QueueArn | ApproximateNumberOfMessagesDelayed | DelaySeconds | ReceiveMessageWaitTimeSeconds | RedrivePolicy | FifoQueue | ContentBasedDeduplication | KmsMasterKeyId | KmsDataKeyReusePeriodSeconds | DeduplicationScope | FifoThroughputLimit | RedriveAllowPolicy | SqsManagedSseEnabled
               
               Required: No
            
          
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue whose attribute information is retrieved.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
         
    
      Response Syntax
      {
   "Attributes": { 
      "string" : "string" 
   }
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
      
            
               
                  Attributes
               
            
            
               A map of attributes to their respective values.
               Type: String to string map
               Valid Keys: All | Policy | VisibilityTimeout | MaximumMessageSize | MessageRetentionPeriod | ApproximateNumberOfMessages | ApproximateNumberOfMessagesNotVisible | CreatedTimestamp | LastModifiedTimestamp | QueueArn | ApproximateNumberOfMessagesDelayed | DelaySeconds | ReceiveMessageWaitTimeSeconds | RedrivePolicy | FifoQueue | ContentBasedDeduplication | KmsMasterKeyId | KmsDataKeyReusePeriodSeconds | DeduplicationScope | FifoThroughputLimit | RedriveAllowPolicy | SqsManagedSseEnabled
               
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAttributeName
               
            
            
               The specified attribute doesn't exist.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example query request gets all the attribute values for the
                specified queue. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.GetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "AttributeNames": ["All"]
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
    "Attributes": {
       "QueueArn": "arn:aws:sqs:us-east-1:555555555555:MyQueue",
        "ApproximateNumberOfMessages": "0",
        "ApproximateNumberOfMessagesNotVisible": "0",
        "ApproximateNumberOfMessagesDelayed": "0",
        "CreatedTimestamp": "1676665337",
        "LastModifiedTimestamp": "1677096375",
        "VisibilityTimeout": "60",
        "MaximumMessageSize": "12345",
        "MessageRetentionPeriod": "345600",
        "DelaySeconds": "0",
        "Policy": "{\"Version\":\"2012-10-17\",\"Id\":\"Policy1677095510157\",\"Statement\":[{\"Sid\":\"Stmt1677095506939\",\"Effect\":\"Allow\",\"Principal\":\"*\",\"Action\":\"sqs:ReceiveMessage\",\"Resource\":\"arn:aws:sqs:us-east-1:555555555555:MyQueue6\"}]}",
        "RedriveAllowPolicy": "{\"redrivePermission\":\"allowAll\"}",
        "ReceiveMessageWaitTimeSeconds": "2",
        "SqsManagedSseEnabled": "true"
    }
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
Content-Type: application/x-www-form-urlencoded
X-Amz-Date: <Date>
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=GetQueueAttributes
&AttributeName.1=All
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<GetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <GetQueueAttributesResult>
        <Attribute>
            <Name>QueueArn</Name>
            <Value>arn:aws:sqs:us-east-1:555555555555:MyQueue</Value>
        </Attribute>
        <Attribute>
            <Name>ApproximateNumberOfMessages</Name>
            <Value>5</Value>
        </Attribute>
        <Attribute>
            <Name>ApproximateNumberOfMessagesNotVisible</Name>
            <Value>0</Value>
        </Attribute>
        <Attribute>
            <Name>ApproximateNumberOfMessagesDelayed</Name>
            <Value>0</Value>
        </Attribute>
        <Attribute>
            <Name>CreatedTimestamp</Name>
            <Value>1677110910</Value>
        </Attribute>
        <Attribute>
            <Name>LastModifiedTimestamp</Name>
            <Value>1677110910</Value>
        </Attribute>
        <Attribute>
            <Name>VisibilityTimeout</Name>
            <Value>40</Value>
        </Attribute>
        <Attribute>
            <Name>MaximumMessageSize</Name>
            <Value>262144</Value>
        </Attribute>
        <Attribute>
            <Name>MessageRetentionPeriod</Name>
            <Value>345600</Value>
        </Attribute>
        <Attribute>
            <Name>DelaySeconds</Name>
            <Value>0</Value>
        </Attribute>
        <Attribute>
            <Name>ReceiveMessageWaitTimeSeconds</Name>
            <Value>0</Value>
        </Attribute>
        <Attribute>
            <Name>SqsManagedSseEnabled</Name>
            <Value>true</Value>
        </Attribute>
    </GetQueueAttributesResult>
    <ResponseMetadata>
        <RequestId>1cffc414-8cb4-54a8-9519-98644ca5f987</RequestId>
    </ResponseMetadata>
</GetQueueAttributesResponse>
          
       
       
         Example
         The following example query request gets three attribute values for the
                    specified queue. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
               AWS General Reference.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.GetQueueAtrributes
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "AttributeNames": ["VisibilityTimeout", "DelaySeconds", "ReceiveMessageWaitTimeSeconds"]
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
    "Attributes": {
       "VisibilityTimeout": "35",
       "DelaySeconds": "45",
        "ReceiveMessageWaitTimeSeconds": "20"
    }
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
Content-Type: application/x-www-form-urlencoded
X-Amz-Date: <Date>
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=GetQueueAttributes
&AttributeName.1=VisibilityTimeout
&AttributeName.2=DelaySeconds
&AttributeName.3=ReceiveMessageWaitTimeSeconds
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<GetQueueAttributesResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <GetQueueAttributesResult>
        <Attribute>
            <Name>VisibilityTimeout</Name>
            <Value>35</Value>
        </Attribute>
        <Attribute>
            <Name>DelaySeconds</Name>
            <Value>45</Value>
        </Attribute>
        <Attribute>
            <Name>ReceiveMessageWaitTimeSeconds</Name>
            <Value>20</Value>
        </Attribute>
    </GetQueueAttributesResult>
    <ResponseMetadata>
        <RequestId>60462930-c7fd-5ef8-b6a0-75a20b5e17b8</RequestId>
    </ResponseMetadata>
</GetQueueAttributesResponse>
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsDeleteQueueGetQueueUrlDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAdding SSE to an existing
				queueDisabling SSE for a queueCreating a queue with
				SSERetrieving SSE attributesUsing server-side encryption with Amazon SQS queuesUse the AWS SDK for Java to add server-side encryption (SSE) to an Amazon SQS queue. Each queue uses an
		AWS Key Management Service (AWS KMS) KMS key to generate the data encryption keys. This example uses the
		AWS managed KMS key for Amazon SQS.For more information about using SSE and the role of the KMS key, see Encryption at rest in Amazon SQS. 
		Adding SSE to an existing
				queue
		To enable server-side encryption for an existing queue, use the SetQueueAttributes
			method to set the KmsMasterKeyId attribute.
		The following code example sets the AWS KMS key as the AWS managed KMS key for
			Amazon SQS. The example also sets the AWS KMS key reuse
				period to 140 seconds.
		
        Before you run the example code, make sure that you have set your AWS credentials. For
		more information, see Set up AWS Credentials and Region for Development
		in the AWS SDK for Java 2.x Developer Guide.
		

		

		    public static void addEncryption(String queueName, String kmsMasterKeyAlias) {
        SqsClient sqsClient = SqsClient.create();

        GetQueueUrlRequest urlRequest = GetQueueUrlRequest.builder()
                .queueName(queueName)
                .build();

        GetQueueUrlResponse getQueueUrlResponse;
        try {
            getQueueUrlResponse = sqsClient.getQueueUrl(urlRequest);
        } catch (QueueDoesNotExistException e) {
            LOGGER.error(e.getMessage(), e);
            throw new RuntimeException(e);
        }
        String queueUrl = getQueueUrlResponse.queueUrl();


        Map<QueueAttributeName, String> attributes = Map.of(
                QueueAttributeName.KMS_MASTER_KEY_ID, kmsMasterKeyAlias,
                QueueAttributeName.KMS_DATA_KEY_REUSE_PERIOD_SECONDS, "140" // Set the data key reuse period to 140 seconds.
        );                                                                  // This is how long SQS can reuse the data key before requesting a new one from KMS.

        SetQueueAttributesRequest attRequest = SetQueueAttributesRequest.builder()
                .queueUrl(queueUrl)
                .attributes(attributes)
                .build();
        try {
            sqsClient.setQueueAttributes(attRequest);
            LOGGER.info("The attributes have been applied to {}", queueName);
        } catch (InvalidAttributeNameException | InvalidAttributeValueException e) {
            LOGGER.error(e.getMessage(), e);
            throw new RuntimeException(e);
        } finally {
            sqsClient.close();
        }
    }
 
	 
		Disabling SSE for a queue
		To disable server-side encryption for an existing queue, set the KmsMasterKeyId
			attribute to an empty string using the SetQueueAttributes method.
		Importantnull isn't a valid value for KmsMasterKeyId.
	 
		Creating a queue with
				SSE
		To enable SSE when you create the queue, add the KmsMasterKeyId
			attribute to the CreateQueue API method.
		The following example creates a new queue with SSE enabled. The queue uses the AWS
			managed KMS key for Amazon SQS. The example also sets the AWS KMS key reuse period to 160 seconds.
		
        Before you run the example code, make sure that you have set your AWS credentials. For
		more information, see Set up AWS Credentials and Region for Development
		in the AWS SDK for Java 2.x Developer Guide.
		
		// Create an SqsClient for the specified Region.
SqsClient sqsClient = SqsClient.builder().region(Region.US_WEST_1).build();

// Create a hashmap for the attributes. Add the key alias and reuse period to the hashmap.
HashMap<QueueAttributeName, String> attributes = new HashMap<QueueAttributeName, String>();
final String kmsMasterKeyAlias = "alias/aws/sqs";  // the alias of the AWS managed KMS key for Amazon SQS.
attributes.put(QueueAttributeName.KMS_MASTER_KEY_ID, kmsMasterKeyAlias);
attributes.put(QueueAttributeName.KMS_DATA_KEY_REUSE_PERIOD_SECONDS, "140");				

// Add the attributes to the CreateQueueRequest.
CreateQueueRequest createQueueRequest =
                CreateQueueRequest.builder()
                        .queueName(queueName)
                        .attributes(attributes)
                        .build();
sqsClient.createQueue(createQueueRequest);
			
	 
		Retrieving SSE attributes
		For information about retrieving queue attributes, see Examples in the Amazon Simple Queue Service API Reference.
		To retrieve the KMS key ID or the data key reuse period for a particular queue, run
			the GetQueueAttributes method and retrieve the
				KmsMasterKeyId and KmsDataKeyReusePeriodSeconds
			values.
	Document ConventionsJava SDK examplesConfiguring tagsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring AWS KMS
						permissionsUnderstanding the data key reuse periodEstimating AWS KMS costsAWS KMS errorsAmazon SQS Key managementAmazon SQS integrates with the AWS Key Management Service (KMS) to manage KMS keys for server-side
				encryption (SSE). See Encryption at rest in Amazon SQS for SSE information and key
				management definitions. Amazon SQS uses KMS keys to validate and secure the data keys
				that encrypt and decrypt the messages. The following sections provide information
				about working with KMS keys and data keys in the Amazon SQS service.
				Configuring AWS KMS
						permissions
				Every KMS key must have a key policy. Note that you cannot modify the key
					policy of an AWS managed KMS key for Amazon SQS. The policy for this KMS key
					includes permissions for all principals in the account (that are authorized to
					use Amazon SQS) to use encrypted queues. 
				For a customer managed KMS key, you must configure the key policy to add
					permissions for each queue producer and consumer. To do this, you name the
					producer and consumer as users in the KMS key policy. For more information
					about AWS KMS permissions, see AWS KMS resources and operations or AWS KMS API permissions
						reference in the AWS Key Management Service Developer Guide.
				Alternatively, you can specify the required permissions in an IAM policy
					assigned to the principals that produce and consume encrypted messages. For more
					information, see Using IAM
						Policies with AWS KMS in the
					AWS Key Management Service Developer Guide.

				NoteWhile you can configure global permissions to send to and receive from
						Amazon SQS, AWS KMS requires explicitly naming the full ARN of KMS keys in
						specific regions in the Resource section of an IAM
						policy.
				 
					Configure KMS permissions
							for AWS services
					Several AWS services act as event sources that can send events to Amazon SQS
						queues. To allow these event sources to work with encrypted queues, you must
						create a customer managed KMS key and add permissions in the key policy
						for the service to use the required AWS KMS API methods. Perform the following
						steps to configure the permissions.
					WarningWhen changing the KMS key for encrypting your Amazon SQS messages, be aware
							that existing messages encrypted with the old KMS key will remain
							encrypted with that key. To decrypt these messages, you must retain the
							old KMS key and ensure that its key policy grants Amazon SQS the permissions
							for kms:Decrypt and
									kms:GenerateDataKey. After updating
							to a new KMS key for encrypting new messages, ensure all existing
							messages encrypted with the old KMS key are processed and removed from
							the queue before deleting or disabling the old KMS key.
					
							Create a customer managed KMS key. For more information, see
									Creating Keys
								in the AWS Key Management Service Developer Guide.
						
							To allow the AWS service event source to use the
										kms:Decrypt and
									kms:GenerateDataKey API methods, add the following
								statement to the KMS key policy.
							{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Principal": {
            "Service": "service.amazonaws.com"
         },
         "Action": [
            "kms:Decrypt",
            "kms:GenerateDataKey"
         ],
         "Resource": "*"
       }]
}
							Replace "service" in the above example with the Service
									name of the event source. Event sources include the
								following services.
							
										
											Event source
											Service name
										
									
										
											Amazon CloudWatch Events
											events.amazonaws.com
										
										
											Amazon S3 event notifications
											s3.amazonaws.com
										
										
											Amazon SNS topic subscriptions
											sns.amazonaws.com
										
									
						
							
								Configure an
									existing SSE queue using the ARN of your
								KMS key.
						
							Provide the ARN of the encrypted queue to the event source.
						
				 
				 
					Configure AWS KMS permissions for
							producers
					When the data
							key reuse period expires, the producer's next call to
							SendMessage or SendMessageBatch also triggers
						calls to kms:Decrypt and kms:GenerateDataKey. The
						call to kms:Decrypt is to verify the integrity of the new data
						key before using it. Therefore, the producer must have the
							kms:Decrypt and kms:GenerateDataKey
						permissions for the KMS key. 
					Add the following statement to the IAM policy of the producer. Remember to
						use the correct ARN values for the key resource and the queue
						resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
	     "kms:Decrypt",
         "kms:GenerateDataKey"
         ],
         "Resource":  "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:SendMessage" 
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 
				 
					Configure AWS KMS permissions
							for consumers
					When the data key reuse period expires, the consumer's next call to
							ReceiveMessage also triggers a call to
							kms:Decrypt, to verify the integrity of the new data key
						before using it. Therefore, the consumer must have the
							kms:Decrypt permission for any KMS key that is used to
						encrypt the messages in the specified queue. If the queue acts as a dead-letter queue, the consumer
						must also have the kms:Decrypt permission for any KMS key
						that is used to encrypt the messages in the source queue. Add the following
						statement to the IAM policy of the consumer. Remember to use the correct ARN
						values for the key resource and the queue resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
            "kms:Decrypt"
         ],
         "Resource": "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:ReceiveMessage"
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 

				 
					Configure AWS KMS
							permissions with confused deputy protection
					When the principal in a key policy statement is an AWS service principal, you can use the aws:SourceArn or aws:SourceAccount global condition keys to
						protect against the confused deputy
							scenario. To use these condition keys, set the value to the
						Amazon Resource Name (ARN) of the resource that is being encrypted. If you
						don't know the ARN of the resource, use aws:SourceAccount
						instead. 
					In this KMS key policy, a specific resource from service that is owned by account 111122223333
						is allowed to call KMS for Decrypt and
							GenerateDataKey actions, which occur during SSE usage of
						Amazon SQS.
					{
	"Version": "2012-10-17",
	"Statement": [{
		"Effect": "Allow",
		"Principal": {
            "Service": "<replaceable>service</replaceable>.amazonaws.com"
		},
		"Action": [
			"kms:GenerateDataKey",
			"kms:Decrypt"
		],
		"Resource": "*",
		"Condition": {
			"ArnEquals": {
				"aws:SourceArn": [
					"arn:aws:service::111122223333:resource"
				]
			}
		}
	}]
}
					When using SSE enabled Amazon SQS queues, the following services support
							aws:SourceArn:
					
						 
						 
						 
						 
						 
						 
						 
						 
					
							Amazon SNS
						
							Amazon S3
						
							CloudWatch Events
						
							AWS Lambda
						
							CodeBuild
						
							Amazon Connect Customer Profiles
						
							AWS Auto Scaling
						
							Amazon Chime
						
				 
			 
				Understanding the
						data key reuse period
				The  data key reuse period defines
					the maximum duration for Amazon SQS to reuse the same data key. When the data key
					reuse period ends, Amazon SQS generates a new data key. Note the following guidelines
					about the reuse period.
				
					 
					 
					 
					 
				
						A shorter reuse period provides better security but results in more
							calls to AWS KMS, which might incur charges beyond the Free Tier.
					
						Although the data key is cached separately for encryption and for
							decryption, the reuse period applies to both copies of the data
							key.
					
						When the data key reuse period ends, the next call to
								SendMessage or SendMessageBatch typically
							triggers a call to the AWS KMS GenerateDataKey method to get
							a new data key. Also, the next calls to SendMessage and
								ReceiveMessage will each trigger a call to AWS KMS
								Decrypt to verify the integrity of the data key before
							using it.
					
						Principals (AWS accounts or users) don't share data keys
							(messages sent by unique principals always get unique data keys).
							Therefore, the volume of calls to AWS KMS is a multiple of the number of
							unique principals in use during the data key reuse period.
					
			 
				Estimating AWS KMS costs
				To predict costs and better understand your AWS bill, you might want to know
					how often Amazon SQS uses your KMS key.
				NoteAlthough the following formula can give you a very good idea of expected
						costs, actual costs might be higher because of the distributed nature of
						Amazon SQS.
				To calculate the number of API requests (R) per
						queue, use the following formula:
				R = (B / D) * (2 * P + C)
				B is the billing period (in seconds).
				D is the data key reuse
						period (in seconds).
				P is the number of producing principals that send to the Amazon SQS queue.
				C is the number of consuming principals that receive from the
					Amazon SQS queue.
				ImportantIn general, producing principals incur double the cost of consuming
						principals. For more information, see Understanding the
						data key reuse period.If the producer and consumer have different users, the cost
						increases.
				The following are example calculations. For exact pricing information, see
						AWS Key Management Service Pricing.
				 
					Example 1: Calculating the
							number of AWS KMS API calls for 2 principals and 1 queue
					This example assumes the following:
					
						 
						 
						 
						 
					
							The billing period is January 1-31 (2,678,400 seconds).
						
							The data key reuse period is set to 5 minutes (300
								seconds).
						
							There is 1 queue.
						
							There is 1 producing principal and 1 consuming principal.
						
					(2,678,400 / 300) * (2 * 1 + 1) = 26,784
				 
				 
					Example 2:
							Calculating the number of AWS KMS API calls for multiple producers and
							consumers and 2 queues
					This example assumes the following:
					
						 
						 
						 
						 
						 
					
							The billing period is February 1-28 (2,419,200 seconds).
						
							The data key reuse period is set to 24 hours (86,400
								seconds).
						
							There are 2 queues.
						
							The first queue has 3 producing principals and 1 consuming
								principal.
						
							The second queue has 5 producing principals and 2 consuming
								principals.
						
					(2,419,200 / 86,400 * (2 * 3 + 1)) + (2,419,200 / 86,400 * (2 * 5 + 2)) = 532
				 
			 
				AWS KMS errors
				When you work with Amazon SQS and AWS KMS, you might encounter errors. The following
					references describe the errors and possible troubleshooting solutions.
				
					 
					 
					 
				
						 Common AWS KMS
								errors
					
						AWS KMS
								Decrypt errors
					
						AWS KMS GenerateDataKey errors
					
			Document ConventionsEncryption at restInternetwork traffic privacyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Identity and Access ManagementUser GuideHow AWS SigV4 worksHow AWS SigV4a worksWhen to sign requestsWhy requests are signedAdditional resourcesAWS Signature Version 4 for API requestsImportantIf you use an AWS SDK (see Sample Code and
                Libraries) or AWS Command Line Interface (AWS CLI) tool to send API requests to AWS, you can
            skip the signature process, as the SDK and CLI clients authenticate your requests by
            using the access keys that you provide. Unless you have a good reason not to, we
            recommend that you always use an SDK or the CLI.In Regions that support multiple signature versions, manually signing requests means
            you must specify which signature version to use. When you supply requests to
            Multi-Region Access Points, SDKs and the CLI automatically switch to using Signature
            Version 4A without additional configuration.Authentication information that you send in a request must include a signature. AWS
        Signature Version 4 (SigV4) is the AWS signing protocol for adding authentication
        information to AWS API requests.You don't use your secret access key to sign API requests. Instead, you use the SigV4
        signing process. Signing requests involves:
         
         
         
    
            Creating a canonical request based on the request details.
        
            Calculating a signature using your AWS credentials.
        
            Adding this signature to the request as an Authorization header.
        AWS then replicates this process and verifies the signature, granting or denying access
        accordingly.Symmetric SigV4 requires you to derive a key that is scoped to a single AWS service, in
        a single AWS region, on a particular day. This makes the key and calculated signature
        different for each region, meaning you must know the region the signature is destined
        for.Asymmetric Signature Version 4 (SigV4a) is an extension that supports signing with a new
        algorithm, and generating individual signatures that are verifiable in more than one AWS
        region. With SigV4a, you can sign a request for multiple regions, with seamless routing and
        failover between regions. When you use the AWS SDK or AWS CLI to invoke functionality that
        requires multi-region signing, the signature type is automatically changed to use SigV4a.
        For details, see How AWS SigV4a works.
        How AWS SigV4 works
        The following steps describe the general process of computing a signature with SigV4:
        
             
             
             
        
                The string to sign depends on the request
                    type. For example, when you use the HTTP Authorization header or the query
                    parameters for authentication, you use a combination of request elements to
                    create the string to sign. For an HTTP POST request, the POST
                    policy in the request is the string you sign.
            
                The signing key is a series of calculations,
                    with the result of each step fed into the next. The final step is the signing
                    key.
            
                When an AWS service receives an authenticated request, it recreates the
                        signature using the authentication
                    information contained in the request. If the signatures match, the service
                    processes the request. Otherwise, it rejects the request.
            
        For more information, see Elements of an AWS API request
            signature.
     
        How AWS SigV4a works        
        SigV4a uses asymmetric signatures based on public-private key cryptography. SigV4a
            goes through a similar scoped credentials derivation process as SigV4, except Sigv4a
            uses the same key to sign all requests without needing to derive a distinct signing key
            based on the date, service, and region. An Elliptic Curve Digital Signature
                Algorithm (ECDSA) keypair can be derived from your existing AWS secret
            access key.
        The system uses asymmetric cryptography to verify multi-region signatures, so that
            AWS only needs to store your public keys. Public keys are not secret and can't be used
            to sign requests. Asymmetric signatures are required for multi-region API requests, such
            as with Amazon S3 Multi-Region Access Points.
        The following steps describe the general process of computing a signature with SigV4a:
        
             
             
             
        
                The string to sign depends on the request
                    type. For example, when you use the HTTP Authorization header or the query
                    parameters for authentication, you use a combination of request elements to
                    create the string to sign. For an HTTP POST request, the POST
                    policy in the request is the string you sign.
            
                The signing key is derived from an AWS
                    secret access key through a series of calculations, with the result of each step
                    fed into the next. The final step produces the keypair.
            
                When an AWS service receives a request signed with Sigv4a, AWS verifies
                    the signature using only the public half of the keypair. If the signature is
                    valid, the request is authenticated and the service processes the request.
                    Requests with invalid signatures is rejected.
            

        For more information about SigV4a for multi-Region API requests, see the sigv4a-signing-examples project on GitHub.
     
        When to sign requests

        When you write custom code that sends API requests to AWS, you must include code
            that signs the requests. You might write custom code because:
        
             
             
        
                You are working with a programming language for which there is no AWS
                    SDK.
            
                You need complete control over how requests are sent to AWS.
            
        While API requests authenticate access with AWS SigV4, AWS SDKs and the AWS CLI
            authenticate your requests by using the access keys that you provide. For more
            information about authenticating with AWS SDKs and the AWS CLI, see Additional resources.
     
        Why requests are signed
        The signing process helps secure requests in the following ways:
        
             
             
             
        
                Verify the identity of the requester
                Authenticated requests require a signature that you create by using your
                    access keys (access key ID, secret access key). If you are using temporary
                    security credentials, the signature calculations also require a security token.
                    For more information, see AWS security credentials programmatic access.
            
                Protect data in transit
                To prevent tampering with a request while it's in transit, some of the request
                    elements are used to calculate a hash (digest) of the request, and the resulting
                    hash value is included as part of the request. When an AWS service receives
                    the request, it uses the same information to calculate a hash and matches it
                    against the hash value in your request. If the values don't match, AWS denies
                    the request.
            
                Protect against potential replay attacks
                In most cases, a request must reach AWS within five minutes of the time
                    stamp in the request. Otherwise, AWS denies the request.
            
        AWS SigV4 can be expressed in the HTTP Authorization header or as a query string in
            the URL. For more information, see Authentication methods.
     
        Additional resources
        
             
             
             
        
                For more information about the SigV4 signing process for different services,
                    see Request signature examples.
            
                To configure credentials for programmatic access for the AWS CLI, see Authentication and access credentials in the AWS
                        Command Line Interface User Guide.
            
                The AWS SDKs include source code on GitHub for signing AWS API requests.
                    For code samples, see Example projects in AWS samples
                    repository.
                
                     
                     
                     
                     
                     
                     
                     
                     
                
                        AWS SDK for .NET – AWS4Signer.cs
                    
                        AWS SDK for C++ – AWSAuthV4Signer.cpp
                    
                        AWS SDK for Go – sigv4.go
                    
                        AWS SDK for Java – BaseAws4Signer.java
                    
                        AWS SDK for JavaScript – signature-v4
                    
                        AWS SDK for PHP – SignatureV4.php
                    
                        AWS SDK for Python (Boto) – signers.py
                    
                        AWS SDK for Ruby – signer.rb
                    
            
    Document ConventionsServices that work with IAMSigV4 request
            elementsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Security Token ServiceAPI ReferenceRequest ParametersResponse ElementsErrorsExamplesSee AlsoAssumeRoleReturns a set of temporary security credentials that you can use to access AWS
         resources. These temporary credentials consist of an access key ID, a secret access key,
         and a security token. Typically, you use AssumeRole within your account or for
         cross-account access. For a comparison of AssumeRole with other API operations
         that produce temporary credentials, see Requesting Temporary Security
            Credentials and Compare AWS STS
            credentials in the IAM User Guide.
      Permissions
   The temporary security credentials created by AssumeRole can be used to
         make API calls to any AWS service with the following exception: You cannot call the
         AWS STS
      GetFederationToken or GetSessionToken API
         operations.(Optional) You can pass inline or managed session policies to this operation. You can
         pass a single JSON policy document to use as an inline session policy. You can also specify
         up to 10 managed policy Amazon Resource Names (ARNs) to use as managed session policies.
         The plaintext that you use for both inline and managed session policies can't exceed 2,048
         characters. Passing policies to this operation returns new 
         temporary credentials. The resulting session's permissions are the intersection of the 
         role's identity-based policy and the session policies. You can use the role's temporary 
         credentials in subsequent AWS API calls to access resources in the account that owns 
         the role. You cannot use session policies to grant more permissions than those allowed 
         by the identity-based policy of the role that is being assumed. For more information, see
            Session
            Policies in the IAM User Guide.When you create a role, you create two policies: a role trust policy that specifies
            who can assume the role, and a permissions policy that specifies
            what can be done with the role. You specify the trusted principal
         that is allowed to assume the role in the role trust policy.To assume a role from a different account, your AWS account must be trusted by the
         role. The trust relationship is defined in the role's trust policy when the role is
         created. That trust policy states which accounts are allowed to delegate that access to
         users in the account. A user who wants to access a role in a different account must also have permissions that
         are delegated from the account administrator. The administrator must attach a policy that
         allows the user to call AssumeRole for the ARN of the role in the other
         account.To allow a user to assume a role in the same account, you can do either of the
         following:
       
       
   
         Attach a policy to the user that allows the user to call AssumeRole
               (as long as the role's trust policy trusts the account).
      
         Add the user as a principal directly in the role's trust policy.
      You can do either because the role’s trust policy acts as an IAM resource-based
         policy. When a resource-based policy grants access to a principal in the same account, no
         additional identity-based policy is required. For more information about trust policies and
         resource-based policies, see IAM Policies in the
            IAM User Guide.
      Tags
   (Optional) You can pass tag key-value pairs to your session. These tags are called
         session tags. For more information about session tags, see Passing Session Tags in AWS STS in the
            IAM User Guide.An administrator must grant you the permissions necessary to pass session tags. The
         administrator can also create granular permissions to allow you to pass only specific
         session tags. For more information, see Tutorial: Using Tags
            for Attribute-Based Access Control in the
         IAM User Guide.You can set the session tags as transitive. Transitive tags persist during role
         chaining. For more information, see Chaining Roles
            with Session Tags in the IAM User Guide.
      Using MFA with AssumeRole
   (Optional) You can include multi-factor authentication (MFA) information when you call
            AssumeRole. This is useful for cross-account scenarios to ensure that the
         user that assumes the role has been authenticated with an AWS MFA device. In that
         scenario, the trust policy of the role being assumed includes a condition that tests for
         MFA authentication. If the caller does not include valid MFA information, the request to
         assume the role is denied. The condition in a trust policy that tests for MFA
         authentication might look like the following example.
      "Condition": {"Bool": {"aws:MultiFactorAuthPresent": true}}
   For more information, see Configuring MFA-Protected API Access
         in the IAM User Guide guide.To use MFA with AssumeRole, you pass values for the
            SerialNumber and TokenCode parameters. The
            SerialNumber value identifies the user's hardware or virtual MFA device.
         The TokenCode is the time-based one-time password (TOTP) that the MFA device
         produces. 
      Request Parameters
       For information about the parameters that are common to all actions, see Common Parameters.
      
          
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  DurationSeconds
               
            
            
               The duration, in seconds, of the role session. The value specified can range from 900
         seconds (15 minutes) up to the maximum session duration set for the role. The maximum
         session duration setting can have a value from 1 hour to 12 hours. If you specify a value
         higher than this setting or the administrator setting (whichever is lower), the operation
         fails. For example, if you specify a session duration of 12 hours, but your administrator
         set the maximum session duration to 6 hours, your operation fails. 
               Role chaining limits your AWS CLI or AWS API role session to a maximum of one hour.
         When you use the AssumeRole API operation to assume a role, you can specify
         the duration of your role session with the DurationSeconds parameter. You can
         specify a parameter value of up to 43200 seconds (12 hours), depending on the maximum
         session duration setting for your role. However, if you assume a role using role chaining
         and provide a DurationSeconds parameter value greater than one hour, the
         operation fails. To learn how to view the maximum value for your role, see Update the maximum session duration for a role.
               By default, the value is set to 3600 seconds. 
               NoteThe DurationSeconds parameter is separate from the duration of a console
            session that you might request using the returned credentials. The request to the
            federation endpoint for a console sign-in token takes a SessionDuration
            parameter that specifies the maximum length of the console session. For more
            information, see Creating a URL
               that Enables Federated Users to Access the AWS Management Console in the
               IAM User Guide.
               Type: Integer
               Valid Range: Minimum value of 900. Maximum value of 43200.
               Required: No
            
          
            
               
                  ExternalId
               
            
            
               A unique identifier that might be required when you assume a role in another account. If
         the administrator of the account to which the role belongs provided you with an external
         ID, then provide that value in the ExternalId parameter. This value can be any
         string, such as a passphrase or account number. A cross-account role is usually set up to
         trust everyone in an account. Therefore, the administrator of the trusting account might
         send an external ID to the administrator of the trusted account. That way, only someone
         with the ID can assume the role, rather than everyone in the account. For more information
         about the external ID, see How to Use an External ID
            When Granting Access to Your AWS Resources to a Third Party in the
            IAM User Guide.
               The regex used to validate this parameter is a string of 
    characters consisting of upper- and lower-case alphanumeric characters with no spaces. 
    You can also include underscores or any of the following characters: +=,.@:\/-
               Type: String
               Length Constraints: Minimum length of 2. Maximum length of 1224.
               Pattern: [\w+=,.@:\/-]*
               
               Required: No
            
          
            
               
                  Policy
               
            
            
               An IAM policy in JSON format that you want to use as an inline session policy.
               This parameter is optional. Passing policies to this operation returns new 
         temporary credentials. The resulting session's permissions are the intersection of the 
         role's identity-based policy and the session policies. You can use the role's temporary 
         credentials in subsequent AWS API calls to access resources in the account that owns 
         the role. You cannot use session policies to grant more permissions than those allowed 
         by the identity-based policy of the role that is being assumed. For more information, see
            Session
            Policies in the IAM User Guide.
               The plaintext that you use for both inline and managed session policies can't exceed
         2,048 characters. The JSON policy characters can be any ASCII character from the space
         character to the end of the valid character list (\u0020 through \u00FF). It can also
         include the tab (\u0009), linefeed (\u000A), and carriage return (\u000D)
         characters.
               NoteAn AWS conversion compresses the passed inline session policy, managed policy ARNs,
            and session tags into a packed binary format that has a separate limit. Your request can
            fail for this limit even if your plaintext meets the other requirements. The
               PackedPolicySize response element indicates by percentage how close the
            policies and tags for your request are to the upper size limit.
               For more information about role session permissions, see Session
            policies.
               Type: String
               Length Constraints: Minimum length of 1.
               Pattern: [\u0009\u000A\u000D\u0020-\u00FF]+
               
               Required: No
            
          
            
               PolicyArns.member.N
            
            
               The Amazon Resource Names (ARNs) of the IAM managed policies that you want to use as
         managed session policies. The policies must exist in the same account as the role.
               This parameter is optional. You can provide up to 10 managed policy ARNs. However, the
         plaintext that you use for both inline and managed session policies can't exceed 2,048
         characters. For more information about ARNs, see Amazon Resource Names (ARNs) and AWS
            Service Namespaces in the AWS General Reference.
               NoteAn AWS conversion compresses the passed inline session policy, managed policy ARNs,
            and session tags into a packed binary format that has a separate limit. Your request can
            fail for this limit even if your plaintext meets the other requirements. The
               PackedPolicySize response element indicates by percentage how close the
            policies and tags for your request are to the upper size limit.
               Passing policies to this operation returns new 
         temporary credentials. The resulting session's permissions are the intersection of the 
         role's identity-based policy and the session policies. You can use the role's temporary 
         credentials in subsequent AWS API calls to access resources in the account that owns 
         the role. You cannot use session policies to grant more permissions than those allowed 
         by the identity-based policy of the role that is being assumed. For more information, see
            Session
            Policies in the IAM User Guide.
               Type: Array of PolicyDescriptorType objects
               Required: No
            
          
            
               ProvidedContexts.member.N
            
            
               A list of previously acquired trusted context assertions in the format of a JSON array.
         The trusted context assertion is signed and encrypted by AWS STS.
               The following is an example of a ProvidedContext value that includes a
         single trusted context assertion and the ARN of the context provider from which the trusted
         context assertion was generated.
               
                  [{"ProviderArn":"arn:aws:iam::aws:contextProvider/IdentityCenter","ContextAssertion":"trusted-context-assertion"}]
               
               Type: Array of ProvidedContext objects
               Array Members: Maximum number of 5 items.
               Required: No
            
          
            
               
                  RoleArn
               
            
            
               The Amazon Resource Name (ARN) of the role to assume.
               Type: String
               Length Constraints: Minimum length of 20. Maximum length of 2048.
               Pattern: [\u0009\u000A\u000D\u0020-\u007E\u0085\u00A0-\uD7FF\uE000-\uFFFD\u10000-\u10FFFF]+
               
               Required: Yes
            
          
            
               
                  RoleSessionName
               
            
            
               An identifier for the assumed role session.
               Use the role session name to uniquely identify a session when the same role is assumed
         by different principals or for different reasons. In cross-account scenarios, the role
         session name is visible to, and can be logged by the account that owns the role. The role
         session name is also used in the ARN of the assumed role principal. This means that
         subsequent cross-account API requests that use the temporary security credentials will
         expose the role session name to the external account in their AWS CloudTrail logs.
               For security purposes, administrators can view this field in AWS CloudTrail logs to help identify who performed an action in AWS. Your
         administrator might require that you specify your user name as the session name when you
         assume the role. For more information, see sts:RoleSessionName.
               The regex used to validate this parameter is a string of 
    characters consisting of upper- and lower-case alphanumeric characters with no spaces. 
    You can also include underscores or any of the following characters: +=,.@-
               Type: String
               Length Constraints: Minimum length of 2. Maximum length of 64.
               Pattern: [\w+=,.@-]*
               
               Required: Yes
            
          
            
               
                  SerialNumber
               
            
            
               The identification number of the MFA device that is associated with the user who is
         making the AssumeRole call. Specify this value if the trust policy of the role
         being assumed includes a condition that requires MFA authentication. The value is either
         the serial number for a hardware device (such as GAHT12345678) or an Amazon
         Resource Name (ARN) for a virtual device (such as
            arn:aws:iam::123456789012:mfa/user).
               The regex used to validate this parameter is a string of 
    characters consisting of upper- and lower-case alphanumeric characters with no spaces. 
    You can also include underscores or any of the following characters: +=/:,.@-
               Type: String
               Length Constraints: Minimum length of 9. Maximum length of 256.
               Pattern: [\w+=/:,.@-]*
               
               Required: No
            
          
            
               
                  SourceIdentity
               
            
            
               The source identity specified by the principal that is calling the
            AssumeRole operation. The source identity value persists across chained role sessions.
               You can require users to specify a source identity when they assume a role. You do this
         by using the sts:SourceIdentity condition key in a role trust policy. You
         can use source identity information in AWS CloudTrail logs to determine who took actions with a
         role. You can use the aws:SourceIdentity condition key to further control
         access to AWS resources based on the value of source identity. For more information about
         using source identity, see Monitor and control
            actions taken with assumed roles in the
         IAM User Guide.
               The regex used to validate this parameter is a string of characters consisting of upper-
         and lower-case alphanumeric characters with no spaces. You can also include underscores or
         any of the following characters: +=,.@-. You cannot use a value that begins with the text
            aws:. This prefix is reserved for AWS internal use.
               Type: String
               Length Constraints: Minimum length of 2. Maximum length of 64.
               Pattern: [\w+=,.@-]*
               
               Required: No
            
          
            
               Tags.member.N
            
            
               A list of session tags that you want to pass. Each session tag consists of a key name
         and an associated value. For more information about session tags, see Tagging AWS STS
            Sessions in the IAM User Guide.
               This parameter is optional. You can pass up to 50 session tags. The plaintext session
         tag keys can’t exceed 128 characters, and the values can’t exceed 256 characters. For these
         and additional limits, see IAM
            and AWS STS Character Limits in the IAM User Guide.
               NoteAn AWS conversion compresses the passed inline session policy, managed policy ARNs,
            and session tags into a packed binary format that has a separate limit. Your request can
            fail for this limit even if your plaintext meets the other requirements. The
               PackedPolicySize response element indicates by percentage how close the
            policies and tags for your request are to the upper size limit.
               You can pass a session tag with the same key as a tag that is already attached to the
         role. When you do, session tags override a role tag with the same key. 
               Tag key–value pairs are not case sensitive, but case is preserved. This means that you
         cannot have separate Department and department tag keys. Assume
         that the role has the Department=Marketing tag and you pass the
            department=engineering session tag. Department
         and department are not saved as separate tags, and the session tag passed in
         the request takes precedence over the role tag.
               Additionally, if you used temporary credentials to perform this operation, the new
         session inherits any transitive session tags from the calling session. If you pass a
         session tag with the same key as an inherited tag, the operation fails. To view the
         inherited tags for a session, see the AWS CloudTrail logs. For more information, see Viewing Session Tags in CloudTrail in the
         IAM User Guide.
               Type: Array of Tag objects
               Array Members: Maximum number of 50 items.
               Required: No
            
          
            
               
                  TokenCode
               
            
            
               The value provided by the MFA device, if the trust policy of the role being assumed
         requires MFA. (In other words, if the policy includes a condition that tests for MFA). If
         the role being assumed requires MFA and if the TokenCode value is missing or
         expired, the AssumeRole call returns an "access denied" error.
               The format for this parameter, as described by its regex pattern, is a sequence of six
         numeric digits.
               Type: String
               Length Constraints: Fixed length of 6.
               Pattern: [\d]*
               
               Required: No
            
          
            
               TransitiveTagKeys.member.N
            
            
               A list of keys for session tags that you want to set as transitive. If you set a tag key
         as transitive, the corresponding key and value passes to subsequent sessions in a role
         chain. For more information, see Chaining Roles
            with Session Tags in the IAM User Guide.
               This parameter is optional. The transitive status of a session tag does not impact its
         packed binary size.
               If you choose not to specify a transitive tag key, then no tags are passed from this
         session to any subsequent sessions.
               Type: Array of strings
               Array Members: Maximum number of 50 items.
               Length Constraints: Minimum length of 1. Maximum length of 128.
               Pattern: [\p{L}\p{Z}\p{N}_.:/=+\-@]+
               
               Required: No
            
         
    
      Response Elements
      The following elements are returned by the service.
      
          
          
          
          
      
            
               
                  AssumedRoleUser
               
            
            
               The Amazon Resource Name (ARN) and the assumed role ID, which are identifiers that you
         can use to refer to the resulting temporary security credentials. For example, you can
         reference these credentials as a principal in a resource-based policy by using the ARN or
         assumed role ID. The ARN and ID include the RoleSessionName that you specified
         when you called AssumeRole. 
               Type: AssumedRoleUser object
            
          
            
               
                  Credentials
               
            
            
               The temporary security credentials, which include an access key ID, a secret access key,
         and a security (or session) token.
               NoteThe size of the security token that AWS STS API operations return is not fixed. We
        strongly recommend that you make no assumptions about the maximum size.
               Type: Credentials object
            
          
            
               
                  PackedPolicySize
               
            
            
               A percentage value that indicates the packed size of the session policies and session 
      tags combined passed in the request. The request fails if the packed size is greater than 100 percent, 
      which means the policies and tags exceeded the allowed space.
               Type: Integer
               Valid Range: Minimum value of 0.
            
          
            
               
                  SourceIdentity
               
            
            
               The source identity specified by the principal that is calling the
            AssumeRole operation.
               You can require users to specify a source identity when they assume a role. You do this
         by using the sts:SourceIdentity condition key in a role trust policy. You can
         use source identity information in AWS CloudTrail logs to determine who took actions with a role.
         You can use the aws:SourceIdentity condition key to further control access to
         AWS resources based on the value of source identity. For more information about using
         source identity, see Monitor and control
            actions taken with assumed roles in the
         IAM User Guide.
               The regex used to validate this parameter is a string of characters consisting of upper-
         and lower-case alphanumeric characters with no spaces. You can also include underscores or
         any of the following characters: =,.@-
               Type: String
               Length Constraints: Minimum length of 2. Maximum length of 64.
               Pattern: [\w+=,.@-]*
               
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
      
            
               
                  ExpiredToken
               
            
            
               The web identity token that was passed is expired or is not valid. Get a new identity
            token from the identity provider and then retry the request.
               HTTP Status Code: 400
            
          
            
               
                  MalformedPolicyDocument
               
            
            
               The request was rejected because the policy document was malformed. The error message
            describes the specific error.
               HTTP Status Code: 400
            
          
            
               
                  PackedPolicyTooLarge
               
            
            
               The request was rejected because the total packed size of the session policies and
            session tags combined was too large. An AWS conversion compresses the session policy
            document, session policy ARNs, and session tags into a packed binary format that has a
            separate limit. The error message indicates by percentage how close the policies and
            tags are to the upper size limit. For more information, see Passing Session Tags in AWS STS in
            the IAM User Guide.
               You could receive this error even though you meet other defined session policy and
            session tag limits. For more information, see IAM and AWS STS Entity Character Limits in the IAM User
                Guide.
               HTTP Status Code: 400
            
          
            
               
                  RegionDisabled
               
            
            
               
                  AWS STS is not activated in the requested region for the account that is being asked to
            generate credentials. The account administrator must use the IAM console to activate
            AWS STS in that region. For more information, see Activating and
                Deactivating AWS STS in an AWS Region in the IAM User
                Guide.
               HTTP Status Code: 403
            
         
    
      Examples
       
         Example
         This example illustrates one usage of AssumeRole.
          
            Sample Request
            https://sts.amazonaws.com/
?Version=2011-06-15
&Action=AssumeRole
&RoleSessionName=testAR
&RoleArn=arn:aws:iam::123456789012:role/demo
&PolicyArns.member.1.arn=arn:aws:iam::123456789012:policy/demopolicy1
&PolicyArns.member.2.arn=arn:aws:iam::123456789012:policy/demopolicy2
&Policy={"Version":"2012-10-17","Statement":[{"Sid":"Stmt1",
"Effect":"Allow","Action":"s3:*","Resource":"*"}]}
&DurationSeconds=3600
&Tags.member.1.Key=Project
&Tags.member.1.Value=Pegasus
&Tags.member.2.Key=Team
&Tags.member.2.Value=Engineering
&Tags.member.3.Key=Cost-Center
&Tags.member.3.Value=12345
&TransitiveTagKeys.member.1=Project
&TransitiveTagKeys.member.2=Cost-Center
&ExternalId=123ABC
&SourceIdentity=Alice
&AUTHPARAMS
          
          
            Sample Response
            <AssumeRoleResponse xmlns="https://sts.amazonaws.com/doc/2011-06-15/">
  <AssumeRoleResult>
  <SourceIdentity>Alice</SourceIdentity>
    <AssumedRoleUser>
      <Arn>arn:aws:sts::123456789012:assumed-role/demo/TestAR</Arn>
      <AssumedRoleId>ARO123EXAMPLE123:TestAR</AssumedRoleId>
    </AssumedRoleUser>
    <Credentials>
      <AccessKeyId>ASIAIOSFODNN7EXAMPLE</AccessKeyId>
      <SecretAccessKey>wJalrXUtnFEMI/K7MDENG/bPxRfiCYzEXAMPLEKEY</SecretAccessKey>
      <SessionToken>
       AQoDYXdzEPT//////////wEXAMPLEtc764bNrC9SAPBSM22wDOk4x4HIZ8j4FZTwdQW
       LWsKWHGBuFqwAeMicRXmxfpSPfIeoIYRqTflfKD8YUuwthAx7mSEI/qkPpKPi/kMcGd
       QrmGdeehM4IC1NtBmUpp2wUE8phUZampKsburEDy0KPkyQDYwT7WZ0wq5VSXDvp75YU
       9HFvlRd8Tx6q6fE8YQcHNVXAkiY9q6d+xo0rKwT38xVqr7ZD0u0iPPkUL64lIZbqBAz
       +scqKmlzm8FDrypNC9Yjc8fPOLn9FX9KSYvKTr4rvx3iSIlTJabIQwj2ICCR/oLxBA==
      </SessionToken>
      <Expiration>2019-11-09T13:34:41Z</Expiration>
    </Credentials>
    <PackedPolicySize>6</PackedPolicySize>
  </AssumeRoleResult>
  <ResponseMetadata>
    <RequestId>c6104cbe-af31-11e0-8154-cbc7ccf896c7</RequestId>
  </ResponseMetadata>
</AssumeRoleResponse>
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsActionsAssumeRoleWithSAMLDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAuto ScalingUser GuideLifecycle hook availabilityConsiderations and
                limitationsRelated resourcesAmazon EC2 Auto Scaling lifecycle hooksAmazon EC2 Auto Scaling offers the ability to add lifecycle hooks to your Auto Scaling groups. These hooks let
        you create solutions that are aware of events in the Auto Scaling instance lifecycle, and then
        perform a custom action on instances when the corresponding lifecycle event occurs. A
        lifecycle hook provides a specified amount of time (one hour by default) to wait for the
        action to complete before the instance transitions to the next state.As an example of using lifecycle hooks with Auto Scaling instances: 
         
         
    
            When a scale-out event occurs, your newly launched instance completes its startup
                sequence and transitions to a wait state. While the instance is in a wait state, it
                runs a script to download and install the needed software packages for your
                application, making sure that your instance is fully ready before it starts
                receiving traffic. When the script is finished installing software, it sends the
                    complete-lifecycle-action command to continue.
        
            When a scale-in event occurs, a lifecycle hook pauses the instance before it is
                terminated and sends you a notification using Amazon EventBridge. While the instance is in the
                wait state, you can invoke an AWS Lambda function or connect to the instance to
                download logs or other data before the instance is fully terminated. 
        A popular use of lifecycle hooks is to control when instances are registered with Elastic Load Balancing.
        By adding a launch lifecycle hook to your Auto Scaling group, you can ensure that your bootstrap
        scripts have completed successfully and the applications on the instances are ready to
        accept traffic before they are registered to the load balancer at the end of the lifecycle
        hook.ContentsLifecycle hook availabilityConsiderations and
                limitationsRelated resourcesHow lifecycle hooks work in Auto Scaling groupsPrepare to add a
                lifecycle hookRetrieve
                the target lifecycle stateAdd lifecycle hooks to your Auto Scaling groupComplete a lifecycle action in an Auto Scaling groupTutorial: Use instance metadata to retrieve lifecycle state Tutorial: Configure a lifecycle hook
                that invokes a Lambda function
        Lifecycle hook availability
        The following table lists the lifecycle hooks available for various scenarios.
        
                    
                        Event
                        Instance launch or termination¹
                        Maximum Instance
                                Lifetime: Replacement instances
                        Instance Refresh:
                            Replacement instances
                        Capacity
                                Rebalancing: Replacement instances
                        Warm Pools:
                            Instances entering and leaving the warm pool
                    
                
                    
                        Instance launching
                        ✓
                        ✓
                        ✓
                        ✓
                        ✓
                    
                    
                        Instance terminating
                        ✓
                        ✓
                        ✓
                        ✓
                        ✓
                    
                
        ¹ Applies to all launches and terminations, whether they are initiated
            automatically or manually such as when you call the SetDesiredCapacity or
                TerminateInstanceInAutoScalingGroup operations. Does not apply when you
            attach or detach instances, move instances in and out of standby mode, or delete the
            group with the force delete option.
     
        Considerations and limitations for
                lifecycle hooks
        When working with lifecycle hooks, keep in mind the following notes and
            limitations:
        
             
             
             
             
             
             
             
             
        
                Amazon EC2 Auto Scaling provides its own lifecycle to help with the management of Auto Scaling
                    groups. This lifecycle differs from that of other EC2 instances. For more
                    information, see Amazon EC2 Auto Scaling instance lifecycle. Instances in a warm pool also
                    have their own lifecycle, as described in Lifecycle state transitions for
                    instances in a warm pool.
            
                You can use lifecycle hooks with Spot Instances, but a lifecycle hook does not
                    prevent an instance from terminating in the event that capacity is no longer
                    available, which can happen at any time with a two-minute interruption notice.
                    For more information, see Spot Instance interruptions in the
                        Amazon EC2 User Guide. However, you can enable Capacity
                    Rebalancing to proactively replace Spot Instances that have received a rebalance
                    recommendation from the Amazon EC2 Spot service, a signal that is sent when a Spot
                    Instance is at elevated risk of interruption. For more information, see Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances.
            
                Instances can remain in a wait state for a finite period of time. The default
                    timeout for a lifecycle hook is one hour (heartbeat timeout). There is also a
                    global timeout that specifies the maximum amount of time that you can keep an
                    instance in a wait state. The global timeout is 48 hours or 100 times the
                    heartbeat timeout, whichever is smaller.
            
                The result of the lifecycle hook can be either abandon or continue. If an
                    instance is launching, continue indicates that your actions were successful, and
                    that Amazon EC2 Auto Scaling can put the instance into service. Otherwise, abandon indicates
                    that your custom actions were unsuccessful, and that we can terminate and
                    replace the instance. If an instance is terminating, both abandon and continue
                    allow the instance to terminate. However, abandon stops any remaining actions,
                    such as other lifecycle hooks, and continue allows any other lifecycle hooks to
                    complete.
            
                Amazon EC2 Auto Scaling limits the rate at which it allows instances to launch if the
                    lifecycle hooks are failing consistently, so make sure to test and fix any
                    permanent errors in your lifecycle actions. 
            
                Creating and updating lifecycle hooks using the AWS CLI, AWS CloudFormation, or an SDK
                    provides options not available when creating a lifecycle hook from the
                    AWS Management Console. For example, the field to specify the ARN of an SNS topic or SQS
                    queue doesn't appear in the console, because Amazon EC2 Auto Scaling already sends events to
                    Amazon EventBridge. These events can be filtered and redirected to AWS services such as
                    Lambda, Amazon SNS, and Amazon SQS as needed.
            
                You can add multiple lifecycle hooks to an Auto Scaling group while you are creating
                    it, by calling the CreateAutoScalingGroup API using the AWS CLI, AWS CloudFormation, or an SDK.
                    However, each hook must have the same notification target and IAM role, if
                    specified. To create lifecycle hooks with different notification targets and
                    different roles, create the lifecycle hooks one at a time in separate calls to
                    the PutLifecycleHook API. 
            
                If you add a lifecycle hook for instance launch, the health check grace period
                    starts as soon as the instance reaches the InService state. For
                    more information, see Set the health check grace period for an
                Auto Scaling group.
            
        
            Scaling considerations
             
             
             
        
                Dynamic scaling policies scale in and out in response to CloudWatch metric data,
                    such as CPU and network I/O, that's aggregated across multiple instances. When
                    scaling out, Amazon EC2 Auto Scaling doesn't immediately count a new instance towards the
                    aggregated instance metrics of the Auto Scaling group. It waits until the instance
                    reaches the InService state and the instance warmup has finished.
                    For more information, see Scaling performance
                    considerations in the default instance
                    warmup topic. 
            
                On scale in, the aggregated instance metrics might not instantly reflect the
                    removal of a terminating instance. The terminating instance stops counting
                    toward the group's aggregated instance metrics shortly after the Amazon EC2 Auto Scaling
                    termination workflow begins. 
                
            
                In most cases when lifecycle hooks are invoked, scaling activities due to
                    simple scaling policies are paused until the lifecycle actions have completed
                    and the cooldown period has expired. Setting a long interval for the cooldown
                    period means that it will take longer for scaling to resume. For more
                    information, see Lifecycle hooks can cause additional
                        delays in the cooldown topic. In
                    general, we recommend against using simple scaling policies if you can use
                    either step scaling or target tracking scaling policies instead.
            
     
        Related resources
        For an introduction video, see AWS re:Invent 2018: Capacity Management
                Made Easy with Amazon EC2 Auto Scaling on YouTube.
        We provide a few JSON and YAML template snippets that you can use to understand how to
            declare lifecycle hooks in your AWS CloudFormation stack templates. For more information, see the
                AWS::AutoScaling::LifecycleHook reference in the
                AWS CloudFormation User Guide.
        You can also visit our GitHub
                repository to download example templates and user data scripts for lifecycle
            hooks.
        For examples of the use of lifecycle hooks, see the following blog posts. 
        
             
             
        
                Building a Backup System for Scaled Instances using Lambda and Amazon EC2 Run
                        Command
            
                Run code before terminating an EC2 Auto Scaling instance.
            
    Document ConventionsRemove an instance maintenance
                    policyHow lifecycle hooks work in Auto Scaling groupsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS KMSDeveloper GuideWhy use AWS KMS?AWS KMS in AWS RegionsAWS KMS pricingAWS KMS service level agreementAWS Key Management ServiceAWS Key Management Service (AWS KMS) is an AWS managed service that makes it easy for you to create and
    control the encryption keys that are used to encrypt your data. The AWS KMS keys that you
    create in AWS KMS are protected by FIPS 140-3 Security Level 3 validated hardware
      security modules (HSM). They never leave AWS KMS unencrypted. To use or manage your
    KMS keys, you interact with AWS KMS.
    Why use AWS KMS?
    When you encrypt data, you need to protect your encryption key. If you encrypt your key,
      you need to protect its encryption key. Eventually, you must protect the highest level
      encryption key (known as a root key) in the hierarchy
      that protects your data. That's where AWS KMS comes in.
    
    
       
        
       
       
    
    AWS KMS protects your root keys. KMS keys are created, managed, used, and deleted entirely
      within AWS KMS. They never leave the service unencrypted. To use or manage your KMS keys, you
      call AWS KMS.
    
       
        
       
       
    
    
    Additionally, you can create and manage key
      policies in AWS KMS, ensuring that only trusted users have access to
      KMS keys.
    
   
    AWS KMS in AWS Regions
    The AWS Regions in which AWS KMS is supported are listed in AWS Key Management Service Endpoints and Quotas. If an
      AWS KMS feature is not supported in an AWS Region that AWS KMS supports, the regional difference
      is described in the topic about the feature. 
   
    AWS KMS pricing
    As with other AWS products, using AWS KMS does not require contracts or minimum purchases.
      For more information about AWS KMS pricing, see AWS Key Management Service
        Pricing.
   
    AWS KMS service level agreement
    AWS Key Management Service is backed by a service level
      agreement that defines our service availability policy.
  Document ConventionsAccessing AWS Key Management ServiceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS KMSDeveloper GuideCustomer managed keysAWS managed keysAWS owned keysAWS KMS key hierarchyKey identifiers (KeyId)AWS KMS keysThe KMS keys that you create and manage for use in your own cryptographic applications
      are of a type known as customer managed keys. Customer managed keys can also be used in
      conjunction with AWS services that use KMS keys to encrypt the data the service stores on
      your behalf. Customer managed keys are recommended for customers who want full control over the
      lifecycle and usage of their keys. There is a monthly cost to have a customer managed key in your
      account. In addition, requests use and/or manage the key incur a usage cost. See AWS Key Management Service Pricing for more details.There are cases where a customer might want an AWS service to encrypt their data, but
      they don’t want the overhead of managing keys and don’t want to pay for a key. An
        AWS managed key is a KMS key that exists in your account, but can
      only be used under certain circumstances. Specifically, it can only be used in the context of
      the AWS service you’re operating in and it can only be used by principals within the account
      that the key exists. You cannot manage anything about the lifecycle or permissions of these
      keys. As you use encryption features in AWS services, you may see AWS managed keys; they
      use an alias of the form “aws<service code>”. For example, an aws/ebs key
      can only be used to encrypt EBS volumes and only for volumes used by IAM principals in the
      same account as the key. Think of an AWS managed key that is scoped down for use only by
      users in your account for resources in your account. You cannot share resources encrypted
      under an AWS managed key with other accounts. While an AWS managed key is free to exist in
      your account, you are charged for any use of this key type by the AWS service that is
      assigned to the key.AWS managed keys are a legacy key type that is no longer being created for new AWS
      services as of 2021. Instead, new (and legacy) AWS services are using what’s known as an
        AWS owned key to encrypt customer data by default. An AWS owned key
      is a KMS key that is in an account managed by the AWS service, so the service operators
      have the ability to manage its lifecycle and usage permissions. By using AWS owned keys,
      AWS services can transparently encrypt your data and allow for easy cross-account or
      cross-region sharing of data without you needing to worry about key permissions. Use
      AWS owned keys for encryption-by-default workloads that provide easier, more automated data
      protection. Because these keys are owned and managed by AWS, you are not charged for their
      existence or their usage, you cannot change their policies, you cannot audit activities on
      these keys, and you cannot delete them. Use customer managed keys when control is important, but use
      AWS owned keys when convenience is most important.
          
            
            
              Customer managed keys
            
            
              AWS managed keys
            
            
              AWS owned keys
            
          
          
            
              Key policy
            
            Exclusively controlled by the customer
            Controlled by service; viewable by customer
            Exclusively controlled and only viewable by the AWS service that encrypts your
              data
          
          
            
              Logging
            
            CloudTrail customer trail or event data store
            CloudTrail customer trail or event data store
            Not viewable by the customer
          
          
            
              Lifecycle management
            
            Customer manages rotation, deletion and Regional location
            AWS KMS manages rotation (annual), deletion, and Regional location
            AWS service manages rotation, deletion, and Regional location
          
          
            
              Pricing
            
            
              Monthly fee for existence of keys (pro-rated
              hourly). Also charged for key usage
            
            No monthly fee; but the caller is charged for API usage on these
              keys
            No charges to customer
          
        The KMS keys that you create are customer managed keys.
      AWS services that use KMS keys to encrypt your service resources often create keys for
      you. KMS keys that AWS services create in your AWS account are AWS managed keys. KMS keys that AWS services create
      in a service account are AWS owned keys.
          
            Type of KMS key
            Can view KMS key metadata
            Can manage KMS key
            Used only for my AWS account
            Automatic rotation
            Pricing
          
        
          
            Customer managed key
            Yes
            Yes
            Yes
            Optional.
            Monthly fee (pro-rated hourly)Per-use fee
          
          
            AWS managed key
            Yes
            No
            Yes
            Required. Every year (approximately 365 days).
            No monthly feePer-use fee (some AWS services pay this fee
                for you)
          
          
            AWS owned key
            No
            No
            No
            The AWS service manages the rotation strategy.
            No fees
          
        AWS services that integrate with AWS KMS differ
      in their support for KMS keys. Some AWS services encrypt your data by default with an
      AWS owned key or an AWS managed key. Some AWS services support customer managed keys. Other AWS
      services support all types of KMS keys to allow you the ease of an AWS owned key, the
      visibility of an AWS managed key, or the control of a customer managed key. For detailed information
      about the encryption options that an AWS service offers, see the Encryption at Rest topic in the user guide or the developer guide for the
      service.
      Customer managed keys
      The KMS keys that you create are customer managed
          keys. Customer managed keys are KMS keys in your AWS account that you create,
        own, and manage. You have full control over these KMS keys, including establishing and
        maintaining their key policies, IAM policies, and
          grants, enabling and disabling them, rotating their cryptographic material, adding tags, creating
          aliases that refer to the KMS keys, and scheduling
          the KMS keys for deletion. 
      Customer managed keys appear on the Customer managed keys page of the AWS Management Console
        for AWS KMS. To definitively identify a customer managed key, use the DescribeKey operation. For customer managed keys,
        the value of the KeyManager field of the DescribeKey response is
          CUSTOMER.
      You can use your customer managed key in cryptographic operations and audit usage in AWS CloudTrail
        logs. In addition, many AWS services that integrate
          with AWS KMS let you specify a customer managed key to protect the data stored and managed for
        you. 
      Customer managed keys incur a monthly fee and a fee for use in excess of the free tier. They
        are counted against the AWS KMS quotas for your account. For
        details, see AWS Key Management Service Pricing and Quotas.
     
      AWS managed keys
      AWS managed keys are KMS keys in your account
        that are created, managed, and used on your behalf by an AWS service integrated with AWS KMS.
      Some AWS services let you choose an AWS managed key or a customer managed key to protect your
        resources in that service. In general, unless you are required to control the encryption key
        that protects your resources, an AWS managed key is a good choice. You don't have to
        create or maintain the key or its key policy, and there's never a monthly fee for an
        AWS managed key.
      You have permission to view the AWS managed keys
        in your account, view their key policies, and
          audit their use in AWS CloudTrail logs. However,
        you cannot change any properties of AWS managed keys, rotate them, change their key
        policies, or schedule them for deletion. And, you cannot use AWS managed keys in
        cryptographic operations directly; the service that creates them uses them on your behalf. 
      Resource control policies in your organization 
        do not apply to AWS managed keys.
      AWS managed keys appear on the AWS managed keys page of the
        AWS Management Console for AWS KMS. You can also identify AWS managed keys by their aliases, which have
        the format aws/service-name, such as
          aws/redshift. To definitively identify an AWS managed keys, use the DescribeKey operation. For
        AWS managed keys, the value of the KeyManager field of the
          DescribeKey response is AWS.
      All AWS managed keys are automatically rotated every year. You cannot change this
        rotation schedule.
      NoteIn May 2022, AWS KMS changed the rotation schedule for
 AWS managed keys from every three years (approximately 1,095 days) to
 every year (approximately 365 days).New AWS managed keys are automatically rotated one year after they
are created, and approximately every year thereafter. Existing AWS managed keys are automatically rotated one year after
their most recent rotation, and every year thereafter.
      There is no monthly fee for AWS managed keys. They can be subject to fees for use in
        excess of the free tier, but some AWS services cover these costs for you. For details, see
        the Encryption at Rest topic in the user guide or
        developer guide for the service. For details, see AWS Key Management Service
          Pricing.
      AWS managed keys do not count against resource quotas on the number of KMS keys in
        each Region of your account. But when used on behalf of a principal in your account, the
        KMS keys count against request quotas. For details, see Quotas.
     
      AWS owned keys
      AWS owned keys are a collection of KMS keys that
        an AWS service owns and manages for use in multiple AWS accounts. Although
        AWS owned keys are not in your AWS account, an AWS service can use an AWS owned key
        to protect the resources in your account.
      Some AWS services let you choose an AWS owned key or a customer managed key. In general,
        unless you are required to audit or control the encryption key that protects your resources,
        an AWS owned key is a good choice. AWS owned keys are completely free of charge (no
        monthly fees or usage fees), they do not count against the AWS KMS
          quotas for your account, and they're easy to use. You don't need to create or
        maintain the key or its key policy.
      The rotation of AWS owned keys varies across services. For information about the
        rotation of a particular AWS owned key, see the Encryption at
          Rest topic in the user guide or developer guide for the service.
     
      AWS KMS key hierarchy
      Your key hierarchy starts with a top-level logical key, an AWS KMS key. A KMS key
        represents a container for top-level key material and is uniquely defined within the AWS
        service namespace with an Amazon Resource Name (ARN). The ARN includes a uniquely generated
        key identifier, a key ID. A KMS key is created based on
        a user-initiated request through AWS KMS. Upon reception, AWS KMS requests the creation of an
        initial HSM backing key (HBK) to be placed into the KMS key container. The HBK is
        generated on an HSM in the domain and is designed never to be exported from the HSM in
        plaintext. Instead, the HBK is exported encrypted under HSM-managed domain keys. These
        exported HBKs are referred to as exported key tokens (EKTs).
      The EKT is exported to a highly durable, low-latency storage. For example, suppose you
        receive an ARN to the logical KMS key. This represents the top of a key hierarchy, or
        cryptographic context, for you. You can create multiple KMS keys within your account and
        set policies on your KMS keys like any other AWS named resource.
      Within the hierarchy of a specific KMS key, the HBK can be thought of as a version of
        the KMS key. When you want to rotate the KMS key through AWS KMS, a new HBK is created and
        associated with the KMS key as the active HBK for the KMS key. The older HBKs are
        preserved and can be used to decrypt and verify previously protected data. But only the
        active cryptographic key can be used to protect new information. 
      
         
          
         
         
      
      You can make requests through AWS KMS to use your KMS keys to directly protect
        information or request additional HSM-generated keys that are protected under your
        KMS key. These keys are called customer data keys, or CDKs. CDKs can be returned encrypted
        as ciphertext (CT), in plaintext, or both. All objects encrypted under a KMS key (either
        customer-supplied data or HSM-generated keys) can be decrypted only on an HSM via a call
        through AWS KMS.
      The returned ciphertext, or the decrypted payload, is never stored within AWS KMS. The
        information is returned to you over your TLS connection to AWS KMS. This also applies to calls
        made by AWS services on your behalf. 
      The key hierarchy and the specific key properties appear in the following table.
      
            
              Key
              Description
              Lifecycle
            
          
            
              
                Domain key
              
              
                A 256-bit AES-GCM key only in memory of an HSM used to wrap versions of the
                  KMS keys, the HSM backing keys.
              
              
                Rotated daily1
              
            

            
              
                HSM backing key
              
              
                A 256-bit symmetric key or RSA or elliptic curve private key, used to protect
                  customer data and keys and stored encrypted under domain keys. One or more HSM
                  backing keys comprise the KMS key, represented by the keyId.
              
              
                Rotated yearly2 (optional config.)
              
            

            
              
                Derived encryption key
              
              
                A 256-bit AES-GCM key only in memory of an HSM used to encrypt customer data
                  and keys. Derived from an HBK for each encryption.
              

              
                Used once per encrypt and regenerated on decrypt 
              
            

            
              
                Customer data key
              
              
                User-deﬁned symmetric or asymmetric key exported from HSM in plaintext and
                  ciphertext.
                Encrypted under an HSM backing key and returned to authorized users over TLS
                  channel.
              
              
                Rotation and use controlled by application
              
            
          
      1 AWS KMS might from time to time relax domain key rotation to
        at most weekly to account for domain administration and configuration tasks.
      2 Default AWS managed keys created and managed by AWS KMS on
        your behalf are automatically rotated annually.

     
      Key identifiers (KeyId)
      Key identifiers act like names for your KMS keys. They help you to recognize your
        KMS keys in the console. You use them to indicate which KMS keys you want to use in
        AWS KMS API operations, key policies, IAM policies, and grants. The key identifier values
        are completely unrelated to the key material associated with the KMS key.
      AWS KMS defines several key identifiers. When you create a KMS key, AWS KMS generates a
        key ARN and key ID, which are properties of the KMS key. When you create an alias, AWS KMS generates an alias ARN based on the alias name
        that you define. You can view the key and alias identifiers in the AWS Management Console and in the
        AWS KMS API. 
      In the AWS KMS console, you can view and filter KMS keys by their key ARN, key ID, or
        alias name, and sort by key ID and alias name. For help finding the key identifiers in the
        console, see Find the key ID and key ARN.
      In the AWS KMS API, the parameters you use to identify a KMS key are named
          KeyId or a variation, such as TargetKeyId or
          DestinationKeyId. However, the values of those parameters are not limited to
        key IDs. Some can take any valid key identifier. For information about the values for each
        parameter, see the parameter description in the AWS Key Management Service API Reference.
      NoteWhen using the AWS KMS API, be careful about the key identifier that you use. Different
          APIs require different key identifiers. In general, use the most complete and practical
          key identifier for your task.
      AWS KMS supports the following key identifiers.
      
         
      
          Key ARN
          
            The key ARN is the Amazon Resource Name (ARN) of a KMS key. It is a unique,
              fully qualified identifier for the KMS key. A key ARN includes the AWS account,
              Region, and the key ID. For help finding the key ARN of a KMS key, see Find the key ID and key ARN.
            The format of a key ARN is as follows:
            arn:<partition>:kms:<region>:<account-id>:key/<key-id>
            The following is an example key ARN for a single-Region KMS key.
            arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab
            The key-id element of the key ARNs of multi-Region keys begin with the
                mrk- prefix. The following is an example key ARN for a multi-Region
              key.
            arn:aws:kms:us-west-2:111122223333:key/mrk-1234abcd12ab34cd56ef1234567890ab
          
        
      
         
         
         
      
          Key ID
          
            The key ID uniquely identifies a KMS key within an account and Region. For help
              finding the key ID of a KMS key, see Find the key ID and key ARN.
            The following is an example key ID for a single-Region KMS key.
            1234abcd-12ab-34cd-56ef-1234567890ab
            The key IDs of multi-Region keys
              begin with the mrk- prefix. The following is an example key ID for a
              multi-Region key.
            mrk-1234abcd12ab34cd56ef1234567890ab
          
        
          Alias ARN
          
            The alias ARN is the Amazon Resource Name (ARN) of an AWS KMS alias. It is a unique,
              fully qualified identifier for the alias, and for the KMS key it represents. An
              alias ARN includes the AWS account, Region, and the alias name.
            At any given time, an alias ARN identifies one particular KMS key. However,
              because you can change the KMS key associated with the alias, the alias ARN can
              identify different KMS keys at different times. For help finding the alias ARN of a
              KMS key, see Find the alias name and alias ARN for a KMS key.
            The format of an alias ARN is as follows:
            arn:<partition>:kms:<region>:<account-id>:alias/<alias-name>
            The following is the alias ARN for a fictitious ExampleAlias.
            arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias
          
        
          Alias name
          
            The alias name is a string of up to 256 characters. It uniquely identifies an
              associated KMS key within an account and Region. In the AWS KMS API, alias names
              always begin with alias/. For help finding the alias name of a KMS key,
              see Find the alias name and alias ARN for a KMS key.
            The format of an alias name is as follows:
            alias/<alias-name>
            For example:
            alias/ExampleAlias
            The aws/ prefix for an alias name is reserved for AWS managed keys. You cannot create an alias with
              this prefix. For example, the alias name of the AWS managed key for Amazon Simple Storage Service (Amazon S3)
              is the following.
            alias/aws/s3
          
        
    Document ConventionsConceptsAsymmetric keysDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring AWS KMS
						permissionsUnderstanding the data key reuse periodEstimating AWS KMS costsAWS KMS errorsAmazon SQS Key managementAmazon SQS integrates with the AWS Key Management Service (KMS) to manage KMS keys for server-side
				encryption (SSE). See Encryption at rest in Amazon SQS for SSE information and key
				management definitions. Amazon SQS uses KMS keys to validate and secure the data keys
				that encrypt and decrypt the messages. The following sections provide information
				about working with KMS keys and data keys in the Amazon SQS service.
				Configuring AWS KMS
						permissions
				Every KMS key must have a key policy. Note that you cannot modify the key
					policy of an AWS managed KMS key for Amazon SQS. The policy for this KMS key
					includes permissions for all principals in the account (that are authorized to
					use Amazon SQS) to use encrypted queues. 
				For a customer managed KMS key, you must configure the key policy to add
					permissions for each queue producer and consumer. To do this, you name the
					producer and consumer as users in the KMS key policy. For more information
					about AWS KMS permissions, see AWS KMS resources and operations or AWS KMS API permissions
						reference in the AWS Key Management Service Developer Guide.
				Alternatively, you can specify the required permissions in an IAM policy
					assigned to the principals that produce and consume encrypted messages. For more
					information, see Using IAM
						Policies with AWS KMS in the
					AWS Key Management Service Developer Guide.

				NoteWhile you can configure global permissions to send to and receive from
						Amazon SQS, AWS KMS requires explicitly naming the full ARN of KMS keys in
						specific regions in the Resource section of an IAM
						policy.
				 
					Configure KMS permissions
							for AWS services
					Several AWS services act as event sources that can send events to Amazon SQS
						queues. To allow these event sources to work with encrypted queues, you must
						create a customer managed KMS key and add permissions in the key policy
						for the service to use the required AWS KMS API methods. Perform the following
						steps to configure the permissions.
					WarningWhen changing the KMS key for encrypting your Amazon SQS messages, be aware
							that existing messages encrypted with the old KMS key will remain
							encrypted with that key. To decrypt these messages, you must retain the
							old KMS key and ensure that its key policy grants Amazon SQS the permissions
							for kms:Decrypt and
									kms:GenerateDataKey. After updating
							to a new KMS key for encrypting new messages, ensure all existing
							messages encrypted with the old KMS key are processed and removed from
							the queue before deleting or disabling the old KMS key.
					
							Create a customer managed KMS key. For more information, see
									Creating Keys
								in the AWS Key Management Service Developer Guide.
						
							To allow the AWS service event source to use the
										kms:Decrypt and
									kms:GenerateDataKey API methods, add the following
								statement to the KMS key policy.
							{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Principal": {
            "Service": "service.amazonaws.com"
         },
         "Action": [
            "kms:Decrypt",
            "kms:GenerateDataKey"
         ],
         "Resource": "*"
       }]
}
							Replace "service" in the above example with the Service
									name of the event source. Event sources include the
								following services.
							
										
											Event source
											Service name
										
									
										
											Amazon CloudWatch Events
											events.amazonaws.com
										
										
											Amazon S3 event notifications
											s3.amazonaws.com
										
										
											Amazon SNS topic subscriptions
											sns.amazonaws.com
										
									
						
							
								Configure an
									existing SSE queue using the ARN of your
								KMS key.
						
							Provide the ARN of the encrypted queue to the event source.
						
				 
				 
					Configure AWS KMS permissions for
							producers
					When the data
							key reuse period expires, the producer's next call to
							SendMessage or SendMessageBatch also triggers
						calls to kms:Decrypt and kms:GenerateDataKey. The
						call to kms:Decrypt is to verify the integrity of the new data
						key before using it. Therefore, the producer must have the
							kms:Decrypt and kms:GenerateDataKey
						permissions for the KMS key. 
					Add the following statement to the IAM policy of the producer. Remember to
						use the correct ARN values for the key resource and the queue
						resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
	     "kms:Decrypt",
         "kms:GenerateDataKey"
         ],
         "Resource":  "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:SendMessage" 
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 
				 
					Configure AWS KMS permissions
							for consumers
					When the data key reuse period expires, the consumer's next call to
							ReceiveMessage also triggers a call to
							kms:Decrypt, to verify the integrity of the new data key
						before using it. Therefore, the consumer must have the
							kms:Decrypt permission for any KMS key that is used to
						encrypt the messages in the specified queue. If the queue acts as a dead-letter queue, the consumer
						must also have the kms:Decrypt permission for any KMS key
						that is used to encrypt the messages in the source queue. Add the following
						statement to the IAM policy of the consumer. Remember to use the correct ARN
						values for the key resource and the queue resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
            "kms:Decrypt"
         ],
         "Resource": "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:ReceiveMessage"
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 

				 
					Configure AWS KMS
							permissions with confused deputy protection
					When the principal in a key policy statement is an AWS service principal, you can use the aws:SourceArn or aws:SourceAccount global condition keys to
						protect against the confused deputy
							scenario. To use these condition keys, set the value to the
						Amazon Resource Name (ARN) of the resource that is being encrypted. If you
						don't know the ARN of the resource, use aws:SourceAccount
						instead. 
					In this KMS key policy, a specific resource from service that is owned by account 111122223333
						is allowed to call KMS for Decrypt and
							GenerateDataKey actions, which occur during SSE usage of
						Amazon SQS.
					{
	"Version": "2012-10-17",
	"Statement": [{
		"Effect": "Allow",
		"Principal": {
            "Service": "<replaceable>service</replaceable>.amazonaws.com"
		},
		"Action": [
			"kms:GenerateDataKey",
			"kms:Decrypt"
		],
		"Resource": "*",
		"Condition": {
			"ArnEquals": {
				"aws:SourceArn": [
					"arn:aws:service::111122223333:resource"
				]
			}
		}
	}]
}
					When using SSE enabled Amazon SQS queues, the following services support
							aws:SourceArn:
					
						 
						 
						 
						 
						 
						 
						 
						 
					
							Amazon SNS
						
							Amazon S3
						
							CloudWatch Events
						
							AWS Lambda
						
							CodeBuild
						
							Amazon Connect Customer Profiles
						
							AWS Auto Scaling
						
							Amazon Chime
						
				 
			 
				Understanding the
						data key reuse period
				The  data key reuse period defines
					the maximum duration for Amazon SQS to reuse the same data key. When the data key
					reuse period ends, Amazon SQS generates a new data key. Note the following guidelines
					about the reuse period.
				
					 
					 
					 
					 
				
						A shorter reuse period provides better security but results in more
							calls to AWS KMS, which might incur charges beyond the Free Tier.
					
						Although the data key is cached separately for encryption and for
							decryption, the reuse period applies to both copies of the data
							key.
					
						When the data key reuse period ends, the next call to
								SendMessage or SendMessageBatch typically
							triggers a call to the AWS KMS GenerateDataKey method to get
							a new data key. Also, the next calls to SendMessage and
								ReceiveMessage will each trigger a call to AWS KMS
								Decrypt to verify the integrity of the data key before
							using it.
					
						Principals (AWS accounts or users) don't share data keys
							(messages sent by unique principals always get unique data keys).
							Therefore, the volume of calls to AWS KMS is a multiple of the number of
							unique principals in use during the data key reuse period.
					
			 
				Estimating AWS KMS costs
				To predict costs and better understand your AWS bill, you might want to know
					how often Amazon SQS uses your KMS key.
				NoteAlthough the following formula can give you a very good idea of expected
						costs, actual costs might be higher because of the distributed nature of
						Amazon SQS.
				To calculate the number of API requests (R) per
						queue, use the following formula:
				R = (B / D) * (2 * P + C)
				B is the billing period (in seconds).
				D is the data key reuse
						period (in seconds).
				P is the number of producing principals that send to the Amazon SQS queue.
				C is the number of consuming principals that receive from the
					Amazon SQS queue.
				ImportantIn general, producing principals incur double the cost of consuming
						principals. For more information, see Understanding the
						data key reuse period.If the producer and consumer have different users, the cost
						increases.
				The following are example calculations. For exact pricing information, see
						AWS Key Management Service Pricing.
				 
					Example 1: Calculating the
							number of AWS KMS API calls for 2 principals and 1 queue
					This example assumes the following:
					
						 
						 
						 
						 
					
							The billing period is January 1-31 (2,678,400 seconds).
						
							The data key reuse period is set to 5 minutes (300
								seconds).
						
							There is 1 queue.
						
							There is 1 producing principal and 1 consuming principal.
						
					(2,678,400 / 300) * (2 * 1 + 1) = 26,784
				 
				 
					Example 2:
							Calculating the number of AWS KMS API calls for multiple producers and
							consumers and 2 queues
					This example assumes the following:
					
						 
						 
						 
						 
						 
					
							The billing period is February 1-28 (2,419,200 seconds).
						
							The data key reuse period is set to 24 hours (86,400
								seconds).
						
							There are 2 queues.
						
							The first queue has 3 producing principals and 1 consuming
								principal.
						
							The second queue has 5 producing principals and 2 consuming
								principals.
						
					(2,419,200 / 86,400 * (2 * 3 + 1)) + (2,419,200 / 86,400 * (2 * 5 + 2)) = 532
				 
			 
				AWS KMS errors
				When you work with Amazon SQS and AWS KMS, you might encounter errors. The following
					references describe the errors and possible troubleshooting solutions.
				
					 
					 
					 
				
						 Common AWS KMS
								errors
					
						AWS KMS
								Decrypt errors
					
						AWS KMS GenerateDataKey errors
					
			Document ConventionsEncryption at restInternetwork traffic privacyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationKMSAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoCreateKeyCreates a unique customer managed KMS key in your AWS account and Region.
      You can use a KMS key in cryptographic operations, such as encryption and signing. Some AWS
      services let you use KMS keys that you create and manage to protect your service
      resources.A KMS key is a logical representation of a cryptographic key. In addition to the key
      material used in cryptographic operations, a KMS key includes metadata, such as the key ID,
      key policy, creation date, description, and key state. Use the parameters of CreateKey to specify the type of KMS key, the source of
      its key material, its key policy, description, tags, and other properties.Note
         AWS KMS has replaced the term customer master key (CMK) with 
            AWS KMS key and KMS key. The concept has not changed. To prevent breaking changes, AWS KMS is keeping some variations of this term.To create different types of KMS keys, use the following guidance:
       
       
       
       
       
   
         Symmetric encryption KMS key
         
            By default, CreateKey creates a symmetric encryption KMS key with key
            material that KMS generates. This is the basic and most widely used type of KMS key, and
            provides the best performance.
            To create a symmetric encryption KMS key, you don't need to specify any parameters.
            The default value for KeySpec, SYMMETRIC_DEFAULT, the default
            value for KeyUsage, ENCRYPT_DECRYPT, and the default value for
              Origin, AWS_KMS, create a symmetric encryption KMS key with
            KMS key material.
            If you need a key for basic encryption and decryption or you are creating a KMS key
            to protect your resources in an AWS service, create a symmetric encryption KMS key.
            The key material in a symmetric encryption key never leaves AWS KMS unencrypted. You can
            use a symmetric encryption KMS key to encrypt and decrypt data up to 4,096 bytes, but
            they are typically used to generate data keys and data keys pairs. For details, see
              GenerateDataKey and GenerateDataKeyPair.
             
         
       
         Asymmetric KMS keys
         
            To create an asymmetric KMS key, use the KeySpec parameter to specify
            the type of key material in the KMS key. Then, use the KeyUsage parameter
            to determine whether the KMS key will be used to encrypt and decrypt or sign and verify.
            You can't change these properties after the KMS key is created.
            Asymmetric KMS keys contain an RSA key pair, Elliptic Curve (ECC) key pair, or an
            SM2 key pair (China Regions only). The private key in an asymmetric KMS key never leaves
            AWS KMS unencrypted. However, you can use the GetPublicKey operation to
            download the public key so it can be used outside of AWS KMS. Each KMS key can have only
            one key usage. KMS keys with RSA key pairs can be used to encrypt and decrypt data or
            sign and verify messages (but not both). KMS keys with NIST-recommended ECC key pairs
            can be used to sign and verify messages or derive shared secrets (but not both). KMS
            keys with ECC_SECG_P256K1 can be used only to sign and verify messages. KMS
            keys with SM2 key pairs (China Regions only) can be used to either encrypt and decrypt
            data, sign and verify messages, or derive shared secrets (you must choose one key usage
            type). For information about asymmetric KMS keys, see Asymmetric KMS keys in the
            
                  AWS Key Management Service Developer Guide.
             
         
       
         HMAC KMS key
         
            To create an HMAC KMS key, set the KeySpec parameter to a key spec
            value for HMAC KMS keys. Then set the KeyUsage parameter to
              GENERATE_VERIFY_MAC. You must set the key usage even though
              GENERATE_VERIFY_MAC is the only valid key usage value for HMAC KMS keys.
            You can't change these properties after the KMS key is created.
            HMAC KMS keys are symmetric keys that never leave AWS KMS unencrypted. You can use
            HMAC keys to generate (GenerateMac) and verify (VerifyMac) HMAC codes for messages up to 4096 bytes.
             
         
       
         Multi-Region primary keys
         
            To create a multi-Region primary key in the local AWS Region,
            use the MultiRegion parameter with a value of True. To create
            a multi-Region replica key, that is, a KMS key with the same key ID
            and key material as a primary key, but in a different AWS Region, use the ReplicateKey operation. To change a replica key to a primary key, and its
            primary key to a replica key, use the UpdatePrimaryRegion
            operation.
            You can create multi-Region KMS keys for all supported KMS key types: symmetric
            encryption KMS keys, HMAC KMS keys, asymmetric encryption KMS keys, and asymmetric
            signing KMS keys. You can also create multi-Region keys with imported key material.
            However, you can't create multi-Region keys in a custom key store.
            This operation supports multi-Region keys, an AWS KMS feature that lets you create multiple
      interoperable KMS keys in different AWS Regions. Because these KMS keys have the same key ID, key
      material, and other metadata, you can use them interchangeably to encrypt data in one AWS Region and decrypt
      it in a different AWS Region without re-encrypting the data or making a cross-Region call. For more information about multi-Region keys, see Multi-Region keys in AWS KMS in the 
                  AWS Key Management Service Developer Guide.
             
         
         Imported key material
         
            To import your own key material into a KMS key, begin by creating a KMS key with no
            key material. To do this, use the Origin parameter of
              CreateKey with a value of EXTERNAL. Next, use GetParametersForImport operation to get a public key and import token. Use
            the wrapping public key to encrypt your key material. Then, use ImportKeyMaterial with your import token to import the key material. For
            step-by-step instructions, see Importing Key Material in the 
                  
                     AWS Key Management Service Developer Guide
               .
            You can import key material into KMS keys of all supported KMS key types: symmetric
            encryption KMS keys, HMAC KMS keys, asymmetric encryption KMS keys, and asymmetric
            signing KMS keys. You can also create multi-Region keys with imported key material.
            However, you can't import key material into a KMS key in a custom key store.
            To create a multi-Region primary key with imported key material, use the
              Origin parameter of CreateKey with a value of
              EXTERNAL and the MultiRegion parameter with a value of
              True. To create replicas of the multi-Region primary key, use the ReplicateKey operation. For instructions, see Importing key material step
              1. For more information about multi-Region keys, see Multi-Region keys in AWS KMS in the 
                  AWS Key Management Service Developer Guide.
             
         
       
         Custom key store
         
            A custom key store lets you protect your AWS resources using keys in a backing key
            store that you own and manage. When you request a cryptographic operation with a KMS key
            in a custom key store, the operation is performed in the backing key store using its
            cryptographic keys.
            
               AWS KMS supports AWS CloudHSM key stores backed by an AWS CloudHSM cluster and external key stores backed by an
            external key manager outside of AWS. When you create a KMS key in an AWS CloudHSM key store,
            AWS KMS generates an encryption key in the AWS CloudHSM cluster and associates it with the KMS
            key. When you create a KMS key in an external key store, you specify an existing
            encryption key in the external key manager.
            NoteSome external key managers provide a simpler method for creating a KMS key in an
              external key store. For details, see your external key manager documentation.
            Before you create a KMS key in a custom key store, the ConnectionState
            of the key store must be CONNECTED. To connect the custom key store, use
            the ConnectCustomKeyStore operation. To find the
              ConnectionState, use the DescribeCustomKeyStores
            operation.
            To create a KMS key in a custom key store, use the CustomKeyStoreId.
            Use the default KeySpec value, SYMMETRIC_DEFAULT, and the
            default KeyUsage value, ENCRYPT_DECRYPT to create a symmetric
            encryption key. No other key type is supported in a custom key store.
            To create a KMS key in an AWS CloudHSM key store, use the
              Origin parameter with a value of AWS_CLOUDHSM. The AWS CloudHSM
            cluster that is associated with the custom key store must have at least two active HSMs
            in different Availability Zones in the AWS Region.
            To create a KMS key in an external key store, use the
              Origin parameter with a value of EXTERNAL_KEY_STORE and an
              XksKeyId parameter that identifies an existing external key.
            NoteSome external key managers provide a simpler method for creating a KMS key in an
              external key store. For details, see your external key manager documentation.
         
      
      Cross-account use: No. You cannot use this operation to
      create a KMS key in a different AWS account.
      Required permissions: kms:CreateKey (IAM policy). To use the
        Tags parameter, kms:TagResource (IAM policy). For examples and information about related
      permissions, see Allow a user
        to create KMS keys in the 
         AWS Key Management Service Developer Guide.
      Related operations:
   
       
       
       
   
         
            DescribeKey
         
      
         
            ListKeys
         
      
         
            ScheduleKeyDeletion
         
      
      Eventual consistency: The AWS KMS API follows an eventual consistency model. 
  For more information, see AWS KMS eventual consistency.
      Request Syntax
      {
   "BypassPolicyLockoutSafetyCheck": boolean,
   "CustomerMasterKeySpec": "string",
   "CustomKeyStoreId": "string",
   "Description": "string",
   "KeySpec": "string",
   "KeyUsage": "string",
   "MultiRegion": boolean,
   "Origin": "string",
   "Policy": "string",
   "Tags": [ 
      { 
         "TagKey": "string",
         "TagValue": "string"
      }
   ],
   "XksKeyId": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      NoteIn the following list, the required parameters are described first.
      
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  BypassPolicyLockoutSafetyCheck
               
            
            
               Skips ("bypasses") the key policy lockout safety check. The default value is false.
               ImportantSetting this value to true increases the risk that the KMS key becomes unmanageable. Do
        not set this value to true indiscriminately.For more information, see Default key policy in the 
                        AWS Key Management Service Developer Guide.
               Use this parameter only when you intend to prevent the principal that is making the
      request from making a subsequent PutKeyPolicy
      request on the KMS key.
               Type: Boolean
               Required: No
            
          
            
               
                  CustomerMasterKeySpec
               
            
            
               
                  This parameter has been deprecated.
               
               Instead, use the KeySpec parameter.
               The KeySpec and CustomerMasterKeySpec parameters work the same
      way. Only the names differ. We recommend that you use KeySpec parameter in your
      code. However, to avoid breaking changes, AWS KMS supports both parameters.
               Type: String
               Valid Values: RSA_2048 | RSA_3072 | RSA_4096 | ECC_NIST_P256 | ECC_NIST_P384 | ECC_NIST_P521 | ECC_SECG_P256K1 | SYMMETRIC_DEFAULT | HMAC_224 | HMAC_256 | HMAC_384 | HMAC_512 | SM2
               
               Required: No
            
          
            
               
                  CustomKeyStoreId
               
            
            
               Creates the KMS key in the specified custom key store. The ConnectionState of
      the custom key store must be CONNECTED. To find the CustomKeyStoreID and
      ConnectionState use the DescribeCustomKeyStores operation.
               This parameter is valid only for symmetric encryption KMS keys in a single Region. You
      cannot create any other type of KMS key in a custom key store.
               When you create a KMS key in an AWS CloudHSM key store, AWS KMS generates a non-exportable 256-bit
      symmetric key in its associated AWS CloudHSM cluster and associates it with the KMS key. When you
      create a KMS key in an external key store, you must use the XksKeyId parameter to
      specify an external key that serves as key material for the KMS key.
               Type: String
               Length Constraints: Minimum length of 1. Maximum length of 64.
               Required: No
            
          
            
               
                  Description
               
            
            
               A description of the KMS key. Use a description that helps you decide whether the KMS key
      is appropriate for a task. The default value is an empty string (no description).
               ImportantDo not include confidential or sensitive information in this field. This field may be displayed in plaintext in CloudTrail logs and other output.
               To set or change the description after the key is created, use UpdateKeyDescription.
               Type: String
               Length Constraints: Minimum length of 0. Maximum length of 8192.
               Required: No
            
          
            
               
                  KeySpec
               
            
            
               Specifies the type of KMS key to create. The default value,
      SYMMETRIC_DEFAULT, creates a KMS key with a 256-bit AES-GCM key that is used for
      encryption and decryption, except in China Regions, where it creates a 128-bit symmetric key
      that uses SM4 encryption. For a detailed description of all supported key specs, see Key spec
        reference in the 
                     
                        AWS Key Management Service Developer Guide
                  .
               The KeySpec determines whether the KMS key contains a symmetric key or an
      asymmetric key pair. It also determines the algorithms that the KMS key supports. You can't
      change the KeySpec after the KMS key is created. To further restrict the
      algorithms that can be used with the KMS key, use a condition key in its key policy or IAM
      policy. For more information, see kms:EncryptionAlgorithm, kms:MacAlgorithm, kms:KeyAgreementAlgorithm, or kms:SigningAlgorithm in the 
                     
                        AWS Key Management Service Developer Guide
                  .
               Important
                     AWS services that
          are integrated with AWS KMS use symmetric encryption KMS keys to protect your data.
        These services do not support asymmetric KMS keys or HMAC KMS keys.
               
                  AWS KMS supports the following key specs for KMS keys:
               
                   
                   
                   
                   
                   
                   
               
                     Symmetric encryption key (default)
                     
                         
                     
                           
                              SYMMETRIC_DEFAULT
                           
                        
                  
                     HMAC keys (symmetric)
                     
                         
                         
                         
                         
                     
                           
                              HMAC_224
                           
                        
                           
                              HMAC_256
                           
                        
                           
                              HMAC_384
                           
                        
                           
                              HMAC_512
                           
                        
                  
                     Asymmetric RSA key pairs (encryption and decryption -or- signing and
          verification)
                     
                         
                         
                         
                     
                           
                              RSA_2048
                           
                        
                           
                              RSA_3072
                           
                        
                           
                              RSA_4096
                           
                        
                  
                     Asymmetric NIST-recommended elliptic curve key pairs (signing and verification -or-
          deriving shared secrets)
                     
                         
                         
                         
                     
                           
                              ECC_NIST_P256 (secp256r1)
                        
                           
                              ECC_NIST_P384 (secp384r1)
                        
                           
                              ECC_NIST_P521 (secp521r1)
                        
                  
                     Other asymmetric elliptic curve key pairs (signing and verification)
                     
                         
                     
                           
                              ECC_SECG_P256K1 (secp256k1), commonly used for
              cryptocurrencies.
                        
                  
                     SM2 key pairs (encryption and decryption -or- signing and verification -or- deriving
          shared secrets)
                     
                         
                     
                           
                              SM2 (China Regions only)
                        
                  
               Type: String
               Valid Values: RSA_2048 | RSA_3072 | RSA_4096 | ECC_NIST_P256 | ECC_NIST_P384 | ECC_NIST_P521 | ECC_SECG_P256K1 | SYMMETRIC_DEFAULT | HMAC_224 | HMAC_256 | HMAC_384 | HMAC_512 | SM2
               
               Required: No
            
          
            
               
                  KeyUsage
               
            
            
               Determines the cryptographic operations for which you can use the KMS key. The default value is
        ENCRYPT_DECRYPT. This parameter is optional when you are creating a symmetric
      encryption KMS key; otherwise, it is required. You can't change the KeyUsage
      value after the KMS key is created.
               Select only one valid value.
               
                   
                   
                   
                   
                   
                   
               
                     For symmetric encryption KMS keys, omit the parameter or specify
            ENCRYPT_DECRYPT.
                  
                     For HMAC KMS keys (symmetric), specify GENERATE_VERIFY_MAC.
                  
                     For asymmetric KMS keys with RSA key pairs, specify ENCRYPT_DECRYPT or
            SIGN_VERIFY.
                  
                     For asymmetric KMS keys with NIST-recommended elliptic curve key pairs, specify
            SIGN_VERIFY or KEY_AGREEMENT.
                  
                     For asymmetric KMS keys with ECC_SECG_P256K1 key pairs specify
            SIGN_VERIFY.
                  
                     For asymmetric KMS keys with SM2 key pairs (China Regions only), specify
            ENCRYPT_DECRYPT, SIGN_VERIFY, or
          KEY_AGREEMENT.
                  
               Type: String
               Valid Values: SIGN_VERIFY | ENCRYPT_DECRYPT | GENERATE_VERIFY_MAC | KEY_AGREEMENT
               
               Required: No
            
          
            
               
                  MultiRegion
               
            
            
               Creates a multi-Region primary key that you can replicate into other AWS Regions. You
      cannot change this value after you create the KMS key. 
               For a multi-Region key, set this parameter to True. For a single-Region KMS
      key, omit this parameter or set it to False. The default value is
        False.
               This operation supports multi-Region keys, an AWS KMS feature that lets you create multiple
      interoperable KMS keys in different AWS Regions. Because these KMS keys have the same key ID, key
      material, and other metadata, you can use them interchangeably to encrypt data in one AWS Region and decrypt
      it in a different AWS Region without re-encrypting the data or making a cross-Region call. For more information about multi-Region keys, see Multi-Region keys in AWS KMS in the 
                     AWS Key Management Service Developer Guide.
               This value creates a primary key, not a replica. To create a
        replica key, use the ReplicateKey operation. 
               You can create a symmetric or asymmetric multi-Region key, and you can create a
      multi-Region key with imported key material. However, you cannot create a multi-Region key in
      a custom key store.
               Type: Boolean
               Required: No
            
          
            
               
                  Origin
               
            
            
               The source of the key material for the KMS key. You cannot change the origin after you
      create the KMS key. The default is AWS_KMS, which means that AWS KMS creates the
      key material.
               To create a
        KMS key with no key material (for imported key material), set this value to
        EXTERNAL. For more information about importing key material into AWS KMS, see
        Importing Key
        Material in the 
                     AWS Key Management Service Developer Guide. The EXTERNAL origin value is valid
      only for symmetric KMS keys.
               To create a KMS
        key in an AWS CloudHSM key store and create its key material in the associated AWS CloudHSM
      cluster, set this value to AWS_CLOUDHSM. You must also use the
        CustomKeyStoreId parameter to identify the AWS CloudHSM key store. The
        KeySpec value must be SYMMETRIC_DEFAULT.
               To create a KMS key in
        an external key store, set this value to EXTERNAL_KEY_STORE. You must
      also use the CustomKeyStoreId parameter to identify the external key store and
      the XksKeyId parameter to identify the associated external key. The
        KeySpec value must be SYMMETRIC_DEFAULT.
               Type: String
               Valid Values: AWS_KMS | EXTERNAL | AWS_CLOUDHSM | EXTERNAL_KEY_STORE
               
               Required: No
            
          
            
               
                  Policy
               
            
            
               The key policy to attach to the KMS key.
               If you provide a key policy, it must meet the following criteria:
               
                   
                   
               
                     The key policy must allow the calling principal to make a
          subsequent PutKeyPolicy request on the KMS key.  This reduces the risk that
          the KMS key becomes unmanageable. For more information, see Default key policy in the 
                           AWS Key Management Service Developer Guide. (To omit
          this condition, set BypassPolicyLockoutSafetyCheck to true.)
                  
                     Each statement in the key policy must contain one or more principals. The principals
          in the key policy must exist and be visible to AWS KMS. When you create a new AWS
          principal, you might need to enforce a delay before including the new principal in a key
          policy because the new principal might not be immediately visible to AWS KMS. For more
          information, see Changes that I make are not always immediately visible in the 
                           AWS
            Identity and Access Management User Guide.
                  
               NoteIf either of the required Resource or Action 
        elements are missing from a key policy statement, the policy statement has 
        no effect. When a key policy statement is missing one of these elements,
        the AWS KMS console correctly reports an error, but the 
        CreateKey and PutKeyPolicy API requests succeed, even though the policy 
        statement is ineffective.For more information on required key policy elements, see Elements in a key policy in the 
                        AWS Key Management Service Developer Guide.
               If you do not provide a key policy, AWS KMS attaches a default key policy to the KMS key.
      For more information, see Default key policy in the
      
                     AWS Key Management Service Developer Guide. 
               NoteIf the key policy exceeds the length constraint, AWS KMS returns a
          LimitExceededException.
               For help writing and formatting a JSON policy document, see the IAM JSON Policy Reference in the 
                     
                        AWS Identity and Access Management User Guide
                  .
               Type: String
               Length Constraints: Minimum length of 1. Maximum length of 32768.
               Pattern: [\u0009\u000A\u000D\u0020-\u00FF]+
               
               Required: No
            
          
            
               
                  Tags
               
            
            
               Assigns one or more tags to the KMS key. Use this parameter to tag the KMS key when it is
      created. To tag an existing KMS key, use the TagResource operation.
               ImportantDo not include confidential or sensitive information in this field. This field may be displayed in plaintext in CloudTrail logs and other output.
               NoteTagging or untagging a KMS key can allow or deny permission to the KMS key. For details, see ABAC for AWS KMS in the 
                        AWS Key Management Service Developer Guide.
               To use this parameter, you must have kms:TagResource permission in an IAM policy.
               Each tag consists of a tag key and a tag value. Both the tag key and the tag value are
      required, but the tag value can be an empty (null) string. You cannot have more than one tag
      on a KMS key with the same tag key. If you specify an existing tag key with a different tag
      value, AWS KMS replaces the current tag value with the specified one.
               When you add tags to an AWS resource, AWS generates a cost allocation
              report with usage and costs aggregated by tags. Tags can also be used to control access to a KMS key. For details,
              see Tags in AWS KMS.
               Type: Array of Tag objects
               Required: No
            
          
            
               
                  XksKeyId
               
            
            
               Identifies the external key that
      serves as key material for the KMS key in an external key store. Specify the ID that
      the external key store proxy uses to refer to the external key. For help, see the
      documentation for your external key store proxy.
               This parameter is required for a KMS key with an Origin value of
        EXTERNAL_KEY_STORE. It is not valid for KMS keys with any other
        Origin value.
               The external key must be an existing 256-bit AES symmetric encryption key hosted outside
      of AWS in an external key manager associated with the external key store specified by the
        CustomKeyStoreId parameter. This key must be enabled and configured to perform
      encryption and decryption. Each KMS key in an external key store must use a different external
      key. For details, see Requirements for a KMS key in
        an external key store in the 
                     AWS Key Management Service Developer Guide.
               Each KMS key in an external key store is associated two backing keys. One is key material
      that AWS KMS generates. The other is the external key specified by this parameter. When you use
      the KMS key in an external key store to encrypt data, the encryption operation is performed
      first by AWS KMS using the AWS KMS key material, and then by the external key manager using the
      specified external key, a process known as double encryption. For
      details, see Double
        encryption in the 
                     AWS Key Management Service Developer Guide.
               Type: String
               Length Constraints: Minimum length of 1. Maximum length of 128.
               Pattern: ^[a-zA-Z0-9-_.]+$
               
               Required: No
            
         
    
      Response Syntax
      {
   "KeyMetadata": { 
      "Arn": "string",
      "AWSAccountId": "string",
      "CloudHsmClusterId": "string",
      "CreationDate": number,
      "CustomerMasterKeySpec": "string",
      "CustomKeyStoreId": "string",
      "DeletionDate": number,
      "Description": "string",
      "Enabled": boolean,
      "EncryptionAlgorithms": [ "string" ],
      "ExpirationModel": "string",
      "KeyAgreementAlgorithms": [ "string" ],
      "KeyId": "string",
      "KeyManager": "string",
      "KeySpec": "string",
      "KeyState": "string",
      "KeyUsage": "string",
      "MacAlgorithms": [ "string" ],
      "MultiRegion": boolean,
      "MultiRegionConfiguration": { 
         "MultiRegionKeyType": "string",
         "PrimaryKey": { 
            "Arn": "string",
            "Region": "string"
         },
         "ReplicaKeys": [ 
            { 
               "Arn": "string",
               "Region": "string"
            }
         ]
      },
      "Origin": "string",
      "PendingDeletionWindowInDays": number,
      "SigningAlgorithms": [ "string" ],
      "ValidTo": number,
      "XksKeyConfiguration": { 
         "Id": "string"
      }
   }
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
      
            
               
                  KeyMetadata
               
            
            
               Metadata associated with the KMS key.
               Type: KeyMetadata object
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  CloudHsmClusterInvalidConfigurationException
               
            
            
               The request was rejected because the associated AWS CloudHSM cluster did not meet the
      configuration requirements for an AWS CloudHSM key store.
               
                   
                   
                   
               
                     The AWS CloudHSM cluster must be configured with private subnets in at least two different
          Availability Zones in the Region.
                  
                     The security group for
            the cluster (cloudhsm-cluster-<cluster-id>-sg) must
          include inbound rules and outbound rules that allow TCP traffic on ports 2223-2225. The
            Source in the inbound rules and the Destination in the outbound rules must match the security group
          ID. These rules are set by default when you create the AWS CloudHSM cluster. Do not delete or
          change them. To get information about a particular security group, use the DescribeSecurityGroups operation.
                  
                     The AWS CloudHSM cluster must contain at least as many HSMs as the operation requires. To add
          HSMs, use the AWS CloudHSM
                        CreateHsm operation.
                     For the CreateCustomKeyStore, UpdateCustomKeyStore, and CreateKey operations, the AWS CloudHSM cluster must have at least two
          active HSMs, each in a different Availability Zone. For the ConnectCustomKeyStore operation, the AWS CloudHSM must contain at least one active
          HSM.
                  
               For information about the requirements for an AWS CloudHSM cluster that is associated with an
      AWS CloudHSM key store, see Assemble the Prerequisites
      in the 
                     AWS Key Management Service Developer Guide. For information about creating a private subnet for an AWS CloudHSM cluster,
      see Create a Private
        Subnet in the 
                     AWS CloudHSM User Guide. For information about cluster security groups, see
        Configure a Default Security
        Group in the 
                     
                        AWS CloudHSM User Guide
                  . 
               HTTP Status Code: 400
            
          
            
               
                  CustomKeyStoreInvalidStateException
               
            
            
               The request was rejected because of the ConnectionState of the custom key
      store. To get the ConnectionState of a custom key store, use the DescribeCustomKeyStores operation.
               This exception is thrown under the following conditions:
               
                   
                   
                   
                   
                   
               
                     You requested the ConnectCustomKeyStore operation on a custom key
          store with a ConnectionState of DISCONNECTING or
            FAILED. This operation is valid for all other ConnectionState
          values. To reconnect a custom key store in a FAILED state, disconnect it
            (DisconnectCustomKeyStore), then connect it
            (ConnectCustomKeyStore).
                  
                     You requested the CreateKey operation in a custom key store that is
          not connected. This operations is valid only when the custom key store
            ConnectionState is CONNECTED.
                  
                     You requested the DisconnectCustomKeyStore operation on a custom key
          store with a ConnectionState of DISCONNECTING or
            DISCONNECTED. This operation is valid for all other
            ConnectionState values.
                  
                     You requested the UpdateCustomKeyStore or DeleteCustomKeyStore operation on a custom key store that is not
          disconnected. This operation is valid only when the custom key store
            ConnectionState is DISCONNECTED.
                  
                     You requested the GenerateRandom operation in an AWS CloudHSM key store
          that is not connected. This operation is valid only when the AWS CloudHSM key store
            ConnectionState is CONNECTED. 
                  
               HTTP Status Code: 400
            
          
            
               
                  CustomKeyStoreNotFoundException
               
            
            
               The request was rejected because AWS KMS cannot find a custom key store with the specified
      key store name or ID.
               HTTP Status Code: 400
            
          
            
               
                  DependencyTimeoutException
               
            
            
               The system timed out while trying to fulfill the request. You can retry the
      request.
               HTTP Status Code: 500
            
          
            
               
                  InvalidArnException
               
            
            
               The request was rejected because a specified ARN, or an ARN in a key policy, is not
      valid.
               HTTP Status Code: 400
            
          
            
               
                  KMSInternalException
               
            
            
               The request was rejected because an internal exception occurred. The request can be
      retried.
               HTTP Status Code: 500
            
          
            
               
                  LimitExceededException
               
            
            
               The request was rejected because a length constraint or quota was exceeded. For more
      information, see Quotas in
      the 
                     AWS Key Management Service Developer Guide.
               HTTP Status Code: 400
            
          
            
               
                  MalformedPolicyDocumentException
               
            
            
               The request was rejected because the specified policy is not syntactically or semantically
      correct.
               HTTP Status Code: 400
            
          
            
               
                  TagException
               
            
            
               The request was rejected because one or more tags are not valid.
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperationException
               
            
            
               The request was rejected because a specified parameter is not supported or a specified
      resource is not valid for this operation.
               HTTP Status Code: 400
            
          
            
               
                  XksKeyAlreadyInUseException
               
            
            
               The request was rejected because the (XksKeyId) is already associated with
      another KMS key in this external key store. Each KMS key in an external key store must be
      associated with a different external key.
               HTTP Status Code: 400
            
          
            
               
                  XksKeyInvalidConfigurationException
               
            
            
               The request was rejected because the external key specified by the XksKeyId
      parameter did not meet the configuration requirements for an external key store.
               The external key must be an AES-256 symmetric key that is enabled and performs encryption
      and decryption.
               HTTP Status Code: 400
            
          
            
               
                  XksKeyNotFoundException
               
            
            
               The request was rejected because the external key store proxy could not find the external
      key. This exception is thrown when the value of the XksKeyId parameter doesn't
      identify a key in the external key manager associated with the external key proxy.
               Verify that the XksKeyId represents an existing key in the external key
      manager. Use the key identifier that the external key store proxy uses to identify the key.
      For details, see the documentation provided with your external key store proxy or key
      manager.
               HTTP Status Code: 400
            
         
    
      Examples
      The following examples are formatted for
    legibility.
       
         Example Request
         This example illustrates one usage of CreateKey.
          
            POST / HTTP/1.1
Host: kms.us-east-2.amazonaws.com
Content-Type: application/x-amz-json-1.1
Authorization: AWS4-HMAC-SHA256\
 Credential=AKIAI44QH8DHBEXAMPLE/20170705/us-east-2/kms/aws4_request,\
 SignedHeaders=content-type;host;x-amz-date;x-amz-target,\
 Signature=8fb59aa17854a97df47aae69f560b66178ed0b5e1ebe334be516c4f3f59acedc
X-Amz-Target: TrentService.CreateKey
X-Amz-Date: 20170705T210455Z
Content-Length: 62

{
  "Tags": [{
    "TagValue": "ExampleUser",
    "TagKey": "CreatedBy"
  }]
}
          
       
       
         Example Response
         This example illustrates one usage of CreateKey.
          
            HTTP/1.1 200 OK
Server: Server
Date: Wed, 05 Jul 2017 21:04:55 GMT
Content-Type: application/x-amz-json-1.1
Content-Length: 335
Connection: keep-alive
x-amzn-RequestId: 98b2de61-61c5-11e7-bd87-9fc4a74e147b

{
  "KeyMetadata": {
    "AWSAccountId": "111122223333",
    "Arn": "arn:aws:kms:us-east-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab",
    "CreationDate": 1.499288695918E9,
    "CustomerMasterKeySpec": "SYMMETRIC_DEFAULT",
    "Description": "",
    "Enabled": true,
    "EncryptionAlgorithms": [
        "SYMMETRIC_DEFAULT"
    ],
    "KeyId": "1234abcd-12ab-34cd-56ef-1234567890ab",
    "KeyManager": "CUSTOMER",
    "KeySpec": "SYMMETRIC_DEFAULT",
    "KeyState": "Enabled",
    "KeyUsage": "ENCRYPT_DECRYPT",
    "MultiRegion": false,
    "Origin": "AWS_KMS"
  }
}
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsCreateGrantDecryptDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS KMSDeveloper GuideCustomer managed keysAWS managed keysAWS owned keysAWS KMS key hierarchyKey identifiers (KeyId)AWS KMS keysThe KMS keys that you create and manage for use in your own cryptographic applications
      are of a type known as customer managed keys. Customer managed keys can also be used in
      conjunction with AWS services that use KMS keys to encrypt the data the service stores on
      your behalf. Customer managed keys are recommended for customers who want full control over the
      lifecycle and usage of their keys. There is a monthly cost to have a customer managed key in your
      account. In addition, requests use and/or manage the key incur a usage cost. See AWS Key Management Service Pricing for more details.There are cases where a customer might want an AWS service to encrypt their data, but
      they don’t want the overhead of managing keys and don’t want to pay for a key. An
        AWS managed key is a KMS key that exists in your account, but can
      only be used under certain circumstances. Specifically, it can only be used in the context of
      the AWS service you’re operating in and it can only be used by principals within the account
      that the key exists. You cannot manage anything about the lifecycle or permissions of these
      keys. As you use encryption features in AWS services, you may see AWS managed keys; they
      use an alias of the form “aws<service code>”. For example, an aws/ebs key
      can only be used to encrypt EBS volumes and only for volumes used by IAM principals in the
      same account as the key. Think of an AWS managed key that is scoped down for use only by
      users in your account for resources in your account. You cannot share resources encrypted
      under an AWS managed key with other accounts. While an AWS managed key is free to exist in
      your account, you are charged for any use of this key type by the AWS service that is
      assigned to the key.AWS managed keys are a legacy key type that is no longer being created for new AWS
      services as of 2021. Instead, new (and legacy) AWS services are using what’s known as an
        AWS owned key to encrypt customer data by default. An AWS owned key
      is a KMS key that is in an account managed by the AWS service, so the service operators
      have the ability to manage its lifecycle and usage permissions. By using AWS owned keys,
      AWS services can transparently encrypt your data and allow for easy cross-account or
      cross-region sharing of data without you needing to worry about key permissions. Use
      AWS owned keys for encryption-by-default workloads that provide easier, more automated data
      protection. Because these keys are owned and managed by AWS, you are not charged for their
      existence or their usage, you cannot change their policies, you cannot audit activities on
      these keys, and you cannot delete them. Use customer managed keys when control is important, but use
      AWS owned keys when convenience is most important.
          
            
            
              Customer managed keys
            
            
              AWS managed keys
            
            
              AWS owned keys
            
          
          
            
              Key policy
            
            Exclusively controlled by the customer
            Controlled by service; viewable by customer
            Exclusively controlled and only viewable by the AWS service that encrypts your
              data
          
          
            
              Logging
            
            CloudTrail customer trail or event data store
            CloudTrail customer trail or event data store
            Not viewable by the customer
          
          
            
              Lifecycle management
            
            Customer manages rotation, deletion and Regional location
            AWS KMS manages rotation (annual), deletion, and Regional location
            AWS service manages rotation, deletion, and Regional location
          
          
            
              Pricing
            
            
              Monthly fee for existence of keys (pro-rated
              hourly). Also charged for key usage
            
            No monthly fee; but the caller is charged for API usage on these
              keys
            No charges to customer
          
        The KMS keys that you create are customer managed keys.
      AWS services that use KMS keys to encrypt your service resources often create keys for
      you. KMS keys that AWS services create in your AWS account are AWS managed keys. KMS keys that AWS services create
      in a service account are AWS owned keys.
          
            Type of KMS key
            Can view KMS key metadata
            Can manage KMS key
            Used only for my AWS account
            Automatic rotation
            Pricing
          
        
          
            Customer managed key
            Yes
            Yes
            Yes
            Optional.
            Monthly fee (pro-rated hourly)Per-use fee
          
          
            AWS managed key
            Yes
            No
            Yes
            Required. Every year (approximately 365 days).
            No monthly feePer-use fee (some AWS services pay this fee
                for you)
          
          
            AWS owned key
            No
            No
            No
            The AWS service manages the rotation strategy.
            No fees
          
        AWS services that integrate with AWS KMS differ
      in their support for KMS keys. Some AWS services encrypt your data by default with an
      AWS owned key or an AWS managed key. Some AWS services support customer managed keys. Other AWS
      services support all types of KMS keys to allow you the ease of an AWS owned key, the
      visibility of an AWS managed key, or the control of a customer managed key. For detailed information
      about the encryption options that an AWS service offers, see the Encryption at Rest topic in the user guide or the developer guide for the
      service.
      Customer managed keys
      The KMS keys that you create are customer managed
          keys. Customer managed keys are KMS keys in your AWS account that you create,
        own, and manage. You have full control over these KMS keys, including establishing and
        maintaining their key policies, IAM policies, and
          grants, enabling and disabling them, rotating their cryptographic material, adding tags, creating
          aliases that refer to the KMS keys, and scheduling
          the KMS keys for deletion. 
      Customer managed keys appear on the Customer managed keys page of the AWS Management Console
        for AWS KMS. To definitively identify a customer managed key, use the DescribeKey operation. For customer managed keys,
        the value of the KeyManager field of the DescribeKey response is
          CUSTOMER.
      You can use your customer managed key in cryptographic operations and audit usage in AWS CloudTrail
        logs. In addition, many AWS services that integrate
          with AWS KMS let you specify a customer managed key to protect the data stored and managed for
        you. 
      Customer managed keys incur a monthly fee and a fee for use in excess of the free tier. They
        are counted against the AWS KMS quotas for your account. For
        details, see AWS Key Management Service Pricing and Quotas.
     
      AWS managed keys
      AWS managed keys are KMS keys in your account
        that are created, managed, and used on your behalf by an AWS service integrated with AWS KMS.
      Some AWS services let you choose an AWS managed key or a customer managed key to protect your
        resources in that service. In general, unless you are required to control the encryption key
        that protects your resources, an AWS managed key is a good choice. You don't have to
        create or maintain the key or its key policy, and there's never a monthly fee for an
        AWS managed key.
      You have permission to view the AWS managed keys
        in your account, view their key policies, and
          audit their use in AWS CloudTrail logs. However,
        you cannot change any properties of AWS managed keys, rotate them, change their key
        policies, or schedule them for deletion. And, you cannot use AWS managed keys in
        cryptographic operations directly; the service that creates them uses them on your behalf. 
      Resource control policies in your organization 
        do not apply to AWS managed keys.
      AWS managed keys appear on the AWS managed keys page of the
        AWS Management Console for AWS KMS. You can also identify AWS managed keys by their aliases, which have
        the format aws/service-name, such as
          aws/redshift. To definitively identify an AWS managed keys, use the DescribeKey operation. For
        AWS managed keys, the value of the KeyManager field of the
          DescribeKey response is AWS.
      All AWS managed keys are automatically rotated every year. You cannot change this
        rotation schedule.
      NoteIn May 2022, AWS KMS changed the rotation schedule for
 AWS managed keys from every three years (approximately 1,095 days) to
 every year (approximately 365 days).New AWS managed keys are automatically rotated one year after they
are created, and approximately every year thereafter. Existing AWS managed keys are automatically rotated one year after
their most recent rotation, and every year thereafter.
      There is no monthly fee for AWS managed keys. They can be subject to fees for use in
        excess of the free tier, but some AWS services cover these costs for you. For details, see
        the Encryption at Rest topic in the user guide or
        developer guide for the service. For details, see AWS Key Management Service
          Pricing.
      AWS managed keys do not count against resource quotas on the number of KMS keys in
        each Region of your account. But when used on behalf of a principal in your account, the
        KMS keys count against request quotas. For details, see Quotas.
     
      AWS owned keys
      AWS owned keys are a collection of KMS keys that
        an AWS service owns and manages for use in multiple AWS accounts. Although
        AWS owned keys are not in your AWS account, an AWS service can use an AWS owned key
        to protect the resources in your account.
      Some AWS services let you choose an AWS owned key or a customer managed key. In general,
        unless you are required to audit or control the encryption key that protects your resources,
        an AWS owned key is a good choice. AWS owned keys are completely free of charge (no
        monthly fees or usage fees), they do not count against the AWS KMS
          quotas for your account, and they're easy to use. You don't need to create or
        maintain the key or its key policy.
      The rotation of AWS owned keys varies across services. For information about the
        rotation of a particular AWS owned key, see the Encryption at
          Rest topic in the user guide or developer guide for the service.
     
      AWS KMS key hierarchy
      Your key hierarchy starts with a top-level logical key, an AWS KMS key. A KMS key
        represents a container for top-level key material and is uniquely defined within the AWS
        service namespace with an Amazon Resource Name (ARN). The ARN includes a uniquely generated
        key identifier, a key ID. A KMS key is created based on
        a user-initiated request through AWS KMS. Upon reception, AWS KMS requests the creation of an
        initial HSM backing key (HBK) to be placed into the KMS key container. The HBK is
        generated on an HSM in the domain and is designed never to be exported from the HSM in
        plaintext. Instead, the HBK is exported encrypted under HSM-managed domain keys. These
        exported HBKs are referred to as exported key tokens (EKTs).
      The EKT is exported to a highly durable, low-latency storage. For example, suppose you
        receive an ARN to the logical KMS key. This represents the top of a key hierarchy, or
        cryptographic context, for you. You can create multiple KMS keys within your account and
        set policies on your KMS keys like any other AWS named resource.
      Within the hierarchy of a specific KMS key, the HBK can be thought of as a version of
        the KMS key. When you want to rotate the KMS key through AWS KMS, a new HBK is created and
        associated with the KMS key as the active HBK for the KMS key. The older HBKs are
        preserved and can be used to decrypt and verify previously protected data. But only the
        active cryptographic key can be used to protect new information. 
      
         
          
         
         
      
      You can make requests through AWS KMS to use your KMS keys to directly protect
        information or request additional HSM-generated keys that are protected under your
        KMS key. These keys are called customer data keys, or CDKs. CDKs can be returned encrypted
        as ciphertext (CT), in plaintext, or both. All objects encrypted under a KMS key (either
        customer-supplied data or HSM-generated keys) can be decrypted only on an HSM via a call
        through AWS KMS.
      The returned ciphertext, or the decrypted payload, is never stored within AWS KMS. The
        information is returned to you over your TLS connection to AWS KMS. This also applies to calls
        made by AWS services on your behalf. 
      The key hierarchy and the specific key properties appear in the following table.
      
            
              Key
              Description
              Lifecycle
            
          
            
              
                Domain key
              
              
                A 256-bit AES-GCM key only in memory of an HSM used to wrap versions of the
                  KMS keys, the HSM backing keys.
              
              
                Rotated daily1
              
            

            
              
                HSM backing key
              
              
                A 256-bit symmetric key or RSA or elliptic curve private key, used to protect
                  customer data and keys and stored encrypted under domain keys. One or more HSM
                  backing keys comprise the KMS key, represented by the keyId.
              
              
                Rotated yearly2 (optional config.)
              
            

            
              
                Derived encryption key
              
              
                A 256-bit AES-GCM key only in memory of an HSM used to encrypt customer data
                  and keys. Derived from an HBK for each encryption.
              

              
                Used once per encrypt and regenerated on decrypt 
              
            

            
              
                Customer data key
              
              
                User-deﬁned symmetric or asymmetric key exported from HSM in plaintext and
                  ciphertext.
                Encrypted under an HSM backing key and returned to authorized users over TLS
                  channel.
              
              
                Rotation and use controlled by application
              
            
          
      1 AWS KMS might from time to time relax domain key rotation to
        at most weekly to account for domain administration and configuration tasks.
      2 Default AWS managed keys created and managed by AWS KMS on
        your behalf are automatically rotated annually.

     
      Key identifiers (KeyId)
      Key identifiers act like names for your KMS keys. They help you to recognize your
        KMS keys in the console. You use them to indicate which KMS keys you want to use in
        AWS KMS API operations, key policies, IAM policies, and grants. The key identifier values
        are completely unrelated to the key material associated with the KMS key.
      AWS KMS defines several key identifiers. When you create a KMS key, AWS KMS generates a
        key ARN and key ID, which are properties of the KMS key. When you create an alias, AWS KMS generates an alias ARN based on the alias name
        that you define. You can view the key and alias identifiers in the AWS Management Console and in the
        AWS KMS API. 
      In the AWS KMS console, you can view and filter KMS keys by their key ARN, key ID, or
        alias name, and sort by key ID and alias name. For help finding the key identifiers in the
        console, see Find the key ID and key ARN.
      In the AWS KMS API, the parameters you use to identify a KMS key are named
          KeyId or a variation, such as TargetKeyId or
          DestinationKeyId. However, the values of those parameters are not limited to
        key IDs. Some can take any valid key identifier. For information about the values for each
        parameter, see the parameter description in the AWS Key Management Service API Reference.
      NoteWhen using the AWS KMS API, be careful about the key identifier that you use. Different
          APIs require different key identifiers. In general, use the most complete and practical
          key identifier for your task.
      AWS KMS supports the following key identifiers.
      
         
      
          Key ARN
          
            The key ARN is the Amazon Resource Name (ARN) of a KMS key. It is a unique,
              fully qualified identifier for the KMS key. A key ARN includes the AWS account,
              Region, and the key ID. For help finding the key ARN of a KMS key, see Find the key ID and key ARN.
            The format of a key ARN is as follows:
            arn:<partition>:kms:<region>:<account-id>:key/<key-id>
            The following is an example key ARN for a single-Region KMS key.
            arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab
            The key-id element of the key ARNs of multi-Region keys begin with the
                mrk- prefix. The following is an example key ARN for a multi-Region
              key.
            arn:aws:kms:us-west-2:111122223333:key/mrk-1234abcd12ab34cd56ef1234567890ab
          
        
      
         
         
         
      
          Key ID
          
            The key ID uniquely identifies a KMS key within an account and Region. For help
              finding the key ID of a KMS key, see Find the key ID and key ARN.
            The following is an example key ID for a single-Region KMS key.
            1234abcd-12ab-34cd-56ef-1234567890ab
            The key IDs of multi-Region keys
              begin with the mrk- prefix. The following is an example key ID for a
              multi-Region key.
            mrk-1234abcd12ab34cd56ef1234567890ab
          
        
          Alias ARN
          
            The alias ARN is the Amazon Resource Name (ARN) of an AWS KMS alias. It is a unique,
              fully qualified identifier for the alias, and for the KMS key it represents. An
              alias ARN includes the AWS account, Region, and the alias name.
            At any given time, an alias ARN identifies one particular KMS key. However,
              because you can change the KMS key associated with the alias, the alias ARN can
              identify different KMS keys at different times. For help finding the alias ARN of a
              KMS key, see Find the alias name and alias ARN for a KMS key.
            The format of an alias ARN is as follows:
            arn:<partition>:kms:<region>:<account-id>:alias/<alias-name>
            The following is the alias ARN for a fictitious ExampleAlias.
            arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias
          
        
          Alias name
          
            The alias name is a string of up to 256 characters. It uniquely identifies an
              associated KMS key within an account and Region. In the AWS KMS API, alias names
              always begin with alias/. For help finding the alias name of a KMS key,
              see Find the alias name and alias ARN for a KMS key.
            The format of an alias name is as follows:
            alias/<alias-name>
            For example:
            alias/ExampleAlias
            The aws/ prefix for an alias name is reserved for AWS managed keys. You cannot create an alias with
              this prefix. For example, the alias name of the AWS managed key for Amazon Simple Storage Service (Amazon S3)
              is the following.
            alias/aws/s3
          
        
    Document ConventionsConceptsAsymmetric keysDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS KMSDeveloper GuidePermissions for creating KMS keysChoosing what type of KMS key to createCreate a KMS keyYou can create AWS KMS keys in the AWS Management Console, or by using the CreateKey operation or the AWS::KMS::Key AWS CloudFormation resource. During
    this process, you set the key policy for the KMS key, which you can change at any time. You
    also select the following values that define the type of KMS key that you create. You cannot
    change these properties after the KMS key is created. 
     
     
     
     
  
      KMS key type
      
        Key type is a property that determines what type of cryptographic
          key is created. AWS KMS offers three key types to protect data:
        
           
           
           
        
            Advanced Encryption Standard (AES) symmetric keys
            256-bit keys that are used under the Galois Counter Mode (GCM) mode of AES to
              provide authenticated encryption/decryption of data under 4KB in size. This is the
              most common type of key and is used to protect other data encryption keys used in your
              applications and by AWS services that encrypt your data on your behalf.
          
            RSA, elliptic curve, or SM2 (China Regions only) asymmetric keys
            These keys are available in various sizes and support many algorithms. They can be
              used for encryption and decryption, sign and verify, or derive shared secrets
              operations depending on the algorithm choice.
          
            Symmetric keys for performing hash-based message authentication codes (HMAC)
              operations
            These keys are 256-bit keys used for sign and verify operations.
            KMS keys cannot be exported from the service in plaintext. They are generated by
              and can only be used within the hardware security modules (HSMs) used by the service.
              This is the foundational security property of AWS KMS to ensure that keys are not
              compromised.
          

      
    
      Key usage
      
        Key usage is a property that determines the
          cryptographic operations the key supports. KMS keys can have a key usage of
            ENCRYPT_DECRYPT, SIGN_VERIFY,
          GENERATE_VERIFY_MAC, or KEY_AGREEMENT. Each KMS key can have
          only one key usage. Using a KMS key for more than one type of operation makes the
          product of both operations more vulnerable to attack.
      
    
      Key spec
      
        Key spec is a property that represents the
          cryptographic configuration of a key. The meaning of the key spec differs with the key
          type.
        For KMS keys, the key spec determines whether the
          KMS key is symmetric or asymmetric. It also determines the type of its key material, and
          the algorithms it supports.
        The default key spec, SYMMETRIC_DEFAULT,
          represents a 256-bit symmetric encryption key. For a detailed description of all supported
          key specs, see Key spec reference.
      
    
      
      Key material origin
      
        Key material origin is a KMS key property that
          identifies the source of the key material in the KMS key. You choose the key material
          origin when you create the KMS key, and you cannot change it. The source of the key
          material affects the security, durability, availability, latency, and throughput
          characteristics of the KMS key. 
        Each KMS key includes a reference to its key material in its metadata. The key
          material origin of symmetric encryption KMS keys can vary. You can use key material that
          AWS KMS generates, key material that is generated in a custom key store, or import your own key material. 
        By default, each KMS key has unique key material. However, you can create a set of
            multi-Region keys with the same key
          material.
        KMS keys can have one of the following key material origin values:
            AWS_KMS, EXTERNAL (imported key
            material), AWS_CLOUDHSM (KMS key
            in a AWS CloudHSM key store), or EXTERNAL_KEY_STORE (KMS key in an external key store).
      
    TopicsPermissions for creating KMS keysChoosing what type of KMS key to createCreate a symmetric encryption KMS keyCreate an asymmetric KMS keyCreate an HMAC KMS keyCreate multi-Region primary keysCreate multi-Region replica keysCreate a KMS key with imported key
            materialCreate a KMS key in an AWS CloudHSM key storeCreate a KMS key in external key stores
    Permissions for creating KMS keys
    To create a KMS key in the console or by using the APIs, you must have the following
      permission in an IAM policy. Whenever possible, use condition keys to limit the permissions. For example, you can use the kms:KeySpec condition key in an IAM policy to
      allow principals to create only symmetric encryption keys.
    For an example of an IAM policy for principals who create keys, see Allow a user to create KMS keys.
    NoteBe cautious when giving principals permission to manage tags and aliases. Changing a tag or alias can allow or deny permission to the
                customer managed key. For details, see ABAC for AWS KMS.
    
       
       
       
       
    
        kms:CreateKey is required.
        
      
        kms:CreateAlias is required to
          create a KMS key in the console where an alias is required for every new
          KMS key.
      
        kms:TagResource is required to
          add tags while creating the KMS key.
      
        iam:CreateServiceLinkedRole is required to create multi-Region primary keys.
          For details, see Control access to multi-Region keys.
      
    The kms:PutKeyPolicy permission is
      not required to create the KMS key. The kms:CreateKey permission includes
      permission to set the initial key policy. But you must add this permission to the key policy
      while creating the KMS key to ensure that you can control access to the KMS key. The
      alternative is using the BypassLockoutSafetyCheck parameter, which is not recommended.
    KMS keys belong to the AWS account in which they were created. The IAM user who
      creates a KMS key is not considered to be the key owner and they don't automatically have
      permission to use or manage the KMS key that they created. Like any other principal, the key
      creator needs to get permission through a key policy, IAM policy, or grant. However,
      principals who have the kms:CreateKey permission can set the initial key policy
      and give themselves permission to use or manage the key.
   
    Choosing what type of KMS key to create
    The type of KMS key that you create depends largely on how you plan to
        use the KMS key, your security requirements, and your authorization
      requirements. The key type and key usage of a KMS key determine what cryptographic
      operations the key can perform. Each KMS key has only one key usage. Using a KMS key for
      more than one type of operation makes the product of all operations more vulnerable to
      attack.

    To allow principals to create KMS keys only for a particular key usage, use the kms:KeyUsage condition key. You can also use the
        kms:KeyUsage condition key to allow principals to call API operations for a
      KMS key based on its key usage. For example, you can allow permission to disable a KMS key
      only if its key usage is SIGN_VERIFY. 

    Use the following guidance to determine which type of KMS key you need based on your use
      case.

    
       
       
       
       
       
       
    
        Encrypt and decrypt data
        
          Use a symmetric KMS key for most use cases
            that require encrypting and decrypting data. The symmetric encryption algorithm that
            AWS KMS uses is fast, efficient, and assures the confidentiality and authenticity of data.
            It supports authenticated encryption with additional authenticated data (AAD), defined
            as an encryption context. This type of KMS key
            requires both the sender and recipient of encrypted data to have valid AWS credentials
            to call AWS KMS.
          If your use case requires encryption outside of AWS by users who cannot call
            AWS KMS, asymmetric KMS keys are a good
            choice. You can distribute the public key of the asymmetric KMS key to allow these
            users to encrypt data. And your applications that need to decrypt that data can use the
            private key of the asymmetric KMS key within AWS KMS.
        
      
        Sign messages and verify signatures
        
          To sign messages and verify signatures, you must use an asymmetric KMS key. You can use a KMS key
            with a key spec that represents an RSA
            key pair, an elliptic curve (ECC) key pair, or an SM2 key pair (China Regions only).
            The key spec you choose is determined by the signing algorithm that you want to use. The
            ECDSA signing algorithms that ECC key pairs support are recommended over the RSA signing
            algorithms. However, you might need to use a particular key spec and signing algorithm
            to support users who verify signatures outside of AWS.
        
      
        Encrypt with asymmetric key pairs
        
          To encrypt data with an asymmetric key pair, you must use an asymmetric KMS key with an RSA key spec or an SM2 key spec (China Regions only). To encrypt data in
            AWS KMS with the public key of a KMS key pair, use the Encrypt operation. You can also download the public key and share it with the
            parties that need to encrypt data outside of AWS KMS.
          When you download the public key of an asymmetric KMS key, you can use it outside
            of AWS KMS. But it is no longer subject to the security controls that protect the
            KMS key in AWS KMS. For example, you cannot use AWS KMS key policies or grants to control
            use of the public key. Nor can you control whether the key is used only for encryption
            and decryption using the encryption algorithms that AWS KMS supports. For more details,
            see Special Considerations for
              Downloading Public Keys.
          To decrypt data that was encrypted with the public key outside of AWS KMS, call the
              Decrypt operation. The
              Decrypt operation fails if the data was encrypted under a public key from
            a KMS key with a key usage of SIGN_VERIFY. It will also fail if it was
            encrypted by using an algorithm that AWS KMS does not support for the key spec you
            selected. For more information on key specs and supported algorithms, see Key spec reference.
          To avoid these errors, anyone using a public key outside of AWS KMS must store the key
            configuration. The AWS KMS console and the GetPublicKey response provide the information that you must include when you
            share the public key.
        
      
        Derive shared secrets
        
          To derive shared secrets, use a KMS key with NIST-recommended elliptic curve or SM2
            (China Regions only) key material. AWS KMS uses the Elliptic Curve Cryptography Cofactor Diffie-Hellman Primitive (ECDH) to
            establish a key agreement between two peers by deriving a shared secret from their
            elliptic curve public-private key pairs. You can use the raw shared secret that the
               DeriveSharedSecret
            operation returns to derive a symmetric key that can encrypt and decrypt data that is
            sent between two parties, or generate and verify HMACs. AWS KMS recommends that you follow
              NIST
              recommendations for key derivation when using the raw shared secret to derive
            a symmetric key.
        
      
        Generate and verify HMAC codes
        
          To generate and verify hash-based message authentication codes, use an HMAC
            KMS key. When you create an HMAC key in AWS KMS, AWS KMS creates and protects your key
            material and ensures that you use the correct MAC algorithms for your key. HMAC codes
            can also be used as pseudo-random numbers, and in certain scenarios for symmetric
            signing and tokenizing.
          HMAC KMS keys are symmetric keys. When creating an HMAC KMS key in the AWS KMS
            console, choose the Symmetric key type.
        
      
        Use with AWS services
        
          To create a KMS key for use with an AWS
              service that is integrated with AWS KMS, consult the documentation for the
            service. AWS services that encrypt your data require a symmetric encryption KMS key.
        
      
    In addition to these considerations, cryptographic operations on KMS keys with different
      key specs have different prices and different request quotas. For information about AWS KMS
      pricing, see AWS Key Management Service Pricing. For
      information about request quotas, see Request quotas.

  Document ConventionsGlossaryCreate a symmetric encryption KMS keyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationKMSAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoDescribeKeyProvides detailed information about a KMS key. You can run DescribeKey on a
        customer managed
        key or an AWS managed key.This detailed information includes the key ARN, creation date (and deletion date, if
      applicable), the key state, and the origin and expiration date (if any) of the key material.
      It includes fields, like KeySpec, that help you distinguish different types of
      KMS keys. It also displays the key usage (encryption, signing, or generating and verifying
      MACs) and the algorithms that the KMS key supports. For multi-Region keys, DescribeKey displays the primary key and all
      related replica keys. For KMS keys in AWS CloudHSM key stores, it includes information
      about the key store, such as the key store ID and the AWS CloudHSM cluster ID. For KMS keys in external key stores,
      it includes the custom key store ID and the ID of the external key.
      DescribeKey does not return the following information:
       
       
       
       
   
         Aliases associated with the KMS key. To get this information, use ListAliases.
      
         Whether automatic key rotation is enabled on the KMS key. To get this information, use
            GetKeyRotationStatus. Also, some key states prevent a KMS key from
          being automatically rotated. For details, see How key rotation
            works in the 
               AWS Key Management Service Developer Guide.
      
         Tags on the KMS key. To get this information, use ListResourceTags.
      
         Key policies and grants on the KMS key. To get this information, use GetKeyPolicy and ListGrants.
      In general, DescribeKey is a non-mutating operation. It returns data about
      KMS keys, but doesn't change them. However, AWS services use DescribeKey to
      create AWS
        managed keys from a predefined AWS alias with no key
      ID.
      Cross-account use: Yes. To perform this operation with a KMS key in a different AWS account, specify
  the key ARN or alias ARN in the value of the KeyId parameter.
      Required permissions: kms:DescribeKey (key policy)
      Related operations:
   
       
       
       
       
       
       
       
   
         
            GetKeyPolicy
         
      
         
            GetKeyRotationStatus
         
      
         
            ListAliases
         
      
         
            ListGrants
         
      
         
            ListKeys
         
      
         
            ListResourceTags
         
      
         
            ListRetirableGrants
         
      
      Eventual consistency: The AWS KMS API follows an eventual consistency model. 
  For more information, see AWS KMS eventual consistency.
      Request Syntax
      {
   "GrantTokens": [ "string" ],
   "KeyId": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      NoteIn the following list, the required parameters are described first.
      
          
          
      
            
               
                  KeyId
               
            
            
               Describes the specified KMS key. 
               If you specify a predefined AWS alias (an AWS alias with no key ID), AWS KMS associates
      the alias with an AWS managed key and returns its
        KeyId and Arn in the response.
               To specify a KMS key, use its key ID, key ARN, alias name, or alias ARN. When using an alias name, prefix it with "alias/". To specify a KMS key in a different AWS account, you must use the key ARN or alias ARN.
               For example:
               
                   
                   
                   
                   
               
                     Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab
                     
                  
                     Key ARN: arn:aws:kms:us-east-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab
                     
                  
                     Alias name: alias/ExampleAlias
                     
                  
                     Alias ARN: arn:aws:kms:us-east-2:111122223333:alias/ExampleAlias
                     
                  
               To get the key ID and key ARN for a KMS key, use ListKeys or DescribeKey. To get the alias name and alias ARN, use ListAliases.
               Type: String
               Length Constraints: Minimum length of 1. Maximum length of 2048.
               Required: Yes
            
          
            
               
                  GrantTokens
               
            
            
               A list of grant tokens.
               Use a grant token when your permission to call this operation comes from a new grant that has not yet achieved eventual consistency. For more information, see Grant token and Using a grant token in the
    
                     AWS Key Management Service Developer Guide.
               Type: Array of strings
               Array Members: Minimum number of 0 items. Maximum number of 10 items.
               Length Constraints: Minimum length of 1. Maximum length of 8192.
               Required: No
            
         
    
      Response Syntax
      {
   "KeyMetadata": { 
      "Arn": "string",
      "AWSAccountId": "string",
      "CloudHsmClusterId": "string",
      "CreationDate": number,
      "CustomerMasterKeySpec": "string",
      "CustomKeyStoreId": "string",
      "DeletionDate": number,
      "Description": "string",
      "Enabled": boolean,
      "EncryptionAlgorithms": [ "string" ],
      "ExpirationModel": "string",
      "KeyAgreementAlgorithms": [ "string" ],
      "KeyId": "string",
      "KeyManager": "string",
      "KeySpec": "string",
      "KeyState": "string",
      "KeyUsage": "string",
      "MacAlgorithms": [ "string" ],
      "MultiRegion": boolean,
      "MultiRegionConfiguration": { 
         "MultiRegionKeyType": "string",
         "PrimaryKey": { 
            "Arn": "string",
            "Region": "string"
         },
         "ReplicaKeys": [ 
            { 
               "Arn": "string",
               "Region": "string"
            }
         ]
      },
      "Origin": "string",
      "PendingDeletionWindowInDays": number,
      "SigningAlgorithms": [ "string" ],
      "ValidTo": number,
      "XksKeyConfiguration": { 
         "Id": "string"
      }
   }
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
      
            
               
                  KeyMetadata
               
            
            
               Metadata associated with the key.
               Type: KeyMetadata object
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
      
            
               
                  DependencyTimeoutException
               
            
            
               The system timed out while trying to fulfill the request. You can retry the
      request.
               HTTP Status Code: 500
            
          
            
               
                  InvalidArnException
               
            
            
               The request was rejected because a specified ARN, or an ARN in a key policy, is not
      valid.
               HTTP Status Code: 400
            
          
            
               
                  KMSInternalException
               
            
            
               The request was rejected because an internal exception occurred. The request can be
      retried.
               HTTP Status Code: 500
            
          
            
               
                  NotFoundException
               
            
            
               The request was rejected because the specified entity or resource could not be
      found.
               HTTP Status Code: 400
            
         
    
      Examples
      The following examples are formatted for
    legibility.
       
         Example Request
         This example illustrates one usage of DescribeKey.
          
            POST / HTTP/1.1
Host: kms.us-east-2.amazonaws.com
Content-Length: 49
X-Amz-Target: TrentService.DescribeKey
X-Amz-Date: 20170705T211529Z
Authorization: AWS4-HMAC-SHA256\
 Credential=AKIAI44QH8DHBEXAMPLE/20170705/us-east-2/kms/aws4_request,\
 SignedHeaders=content-type;host;x-amz-date;x-amz-target,\
 Signature=6bcb6a5ef9ee7585d83955e8a5c3f6d47cf581596208fc0e436fa1de26ef3f6a
Content-Type: application/x-amz-json-1.1

{"KeyId": "1234abcd-12ab-34cd-56ef-1234567890ab"}
          
       
       
         Example Response
         This example illustrates one usage of DescribeKey.
          
            HTTP/1.1 200 OK
Server: Server
Date: Wed, 05 Jul 2017 21:15:30 GMT
Content-Type: application/x-amz-json-1.1
Content-Length: 335
Connection: keep-alive
x-amzn-RequestId: 13230ddb-61c7-11e7-af6f-c5b105d7a982

{
  "KeyMetadata": {
    "AWSAccountId": "111122223333",
    "Arn": "arn:aws:kms:us-east-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab",
    "CreationDate": 1.499288695918E9,
    "CustomerMasterKeySpec": "SYMMETRIC_DEFAULT",
    "Description": "",
    "Enabled": true,
    "KeyId": "1234abcd-12ab-34cd-56ef-1234567890ab",
    "KeyManager": "CUSTOMER",
    "KeySpec": "SYMMETRIC_DEFAULT",
    "KeyState": "Enabled",
    "KeyUsage": "ENCRYPT_DECRYPT",
    "MultiRegion": false,
    "Origin": "AWS_KMS",
    "EncryptionAlgorithms": [
        "SYMMETRIC_DEFAULT"
    ]
  }
}
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsDescribeCustomKeyStoresDisableKeyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS KMSDeveloper GuideIdentify and view keysYou can use AWS Management Console or the AWS Key Management Service (AWS KMS) API to view AWS KMS keys in each account and
    Region, including KMS keys that you manage and KMS keys that are managed by AWS.TopicsFind the key ID and key ARNAccess and list KMS key detailsIdentify different key typesCustomize your console viewFind KMS keys and key material in an AWS CloudHSM key
      storeDocument ConventionsCreate a KMS key in external key storesFind the key ID and key ARNDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring AWS KMS
						permissionsUnderstanding the data key reuse periodEstimating AWS KMS costsAWS KMS errorsAmazon SQS Key managementAmazon SQS integrates with the AWS Key Management Service (KMS) to manage KMS keys for server-side
				encryption (SSE). See Encryption at rest in Amazon SQS for SSE information and key
				management definitions. Amazon SQS uses KMS keys to validate and secure the data keys
				that encrypt and decrypt the messages. The following sections provide information
				about working with KMS keys and data keys in the Amazon SQS service.
				Configuring AWS KMS
						permissions
				Every KMS key must have a key policy. Note that you cannot modify the key
					policy of an AWS managed KMS key for Amazon SQS. The policy for this KMS key
					includes permissions for all principals in the account (that are authorized to
					use Amazon SQS) to use encrypted queues. 
				For a customer managed KMS key, you must configure the key policy to add
					permissions for each queue producer and consumer. To do this, you name the
					producer and consumer as users in the KMS key policy. For more information
					about AWS KMS permissions, see AWS KMS resources and operations or AWS KMS API permissions
						reference in the AWS Key Management Service Developer Guide.
				Alternatively, you can specify the required permissions in an IAM policy
					assigned to the principals that produce and consume encrypted messages. For more
					information, see Using IAM
						Policies with AWS KMS in the
					AWS Key Management Service Developer Guide.

				NoteWhile you can configure global permissions to send to and receive from
						Amazon SQS, AWS KMS requires explicitly naming the full ARN of KMS keys in
						specific regions in the Resource section of an IAM
						policy.
				 
					Configure KMS permissions
							for AWS services
					Several AWS services act as event sources that can send events to Amazon SQS
						queues. To allow these event sources to work with encrypted queues, you must
						create a customer managed KMS key and add permissions in the key policy
						for the service to use the required AWS KMS API methods. Perform the following
						steps to configure the permissions.
					WarningWhen changing the KMS key for encrypting your Amazon SQS messages, be aware
							that existing messages encrypted with the old KMS key will remain
							encrypted with that key. To decrypt these messages, you must retain the
							old KMS key and ensure that its key policy grants Amazon SQS the permissions
							for kms:Decrypt and
									kms:GenerateDataKey. After updating
							to a new KMS key for encrypting new messages, ensure all existing
							messages encrypted with the old KMS key are processed and removed from
							the queue before deleting or disabling the old KMS key.
					
							Create a customer managed KMS key. For more information, see
									Creating Keys
								in the AWS Key Management Service Developer Guide.
						
							To allow the AWS service event source to use the
										kms:Decrypt and
									kms:GenerateDataKey API methods, add the following
								statement to the KMS key policy.
							{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Principal": {
            "Service": "service.amazonaws.com"
         },
         "Action": [
            "kms:Decrypt",
            "kms:GenerateDataKey"
         ],
         "Resource": "*"
       }]
}
							Replace "service" in the above example with the Service
									name of the event source. Event sources include the
								following services.
							
										
											Event source
											Service name
										
									
										
											Amazon CloudWatch Events
											events.amazonaws.com
										
										
											Amazon S3 event notifications
											s3.amazonaws.com
										
										
											Amazon SNS topic subscriptions
											sns.amazonaws.com
										
									
						
							
								Configure an
									existing SSE queue using the ARN of your
								KMS key.
						
							Provide the ARN of the encrypted queue to the event source.
						
				 
				 
					Configure AWS KMS permissions for
							producers
					When the data
							key reuse period expires, the producer's next call to
							SendMessage or SendMessageBatch also triggers
						calls to kms:Decrypt and kms:GenerateDataKey. The
						call to kms:Decrypt is to verify the integrity of the new data
						key before using it. Therefore, the producer must have the
							kms:Decrypt and kms:GenerateDataKey
						permissions for the KMS key. 
					Add the following statement to the IAM policy of the producer. Remember to
						use the correct ARN values for the key resource and the queue
						resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
	     "kms:Decrypt",
         "kms:GenerateDataKey"
         ],
         "Resource":  "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:SendMessage" 
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 
				 
					Configure AWS KMS permissions
							for consumers
					When the data key reuse period expires, the consumer's next call to
							ReceiveMessage also triggers a call to
							kms:Decrypt, to verify the integrity of the new data key
						before using it. Therefore, the consumer must have the
							kms:Decrypt permission for any KMS key that is used to
						encrypt the messages in the specified queue. If the queue acts as a dead-letter queue, the consumer
						must also have the kms:Decrypt permission for any KMS key
						that is used to encrypt the messages in the source queue. Add the following
						statement to the IAM policy of the consumer. Remember to use the correct ARN
						values for the key resource and the queue resource.
					{
   "Version": "2012-10-17",
      "Statement": [{
         "Effect": "Allow",
         "Action": [
            "kms:Decrypt"
         ],
         "Resource": "arn:aws:kms:us-east-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
         }, {
         "Effect": "Allow",
         "Action": [
            "sqs:ReceiveMessage"
         ],
         "Resource": "arn:aws:sqs:*:123456789012:MyQueue"
      }]
}
				 

				 
					Configure AWS KMS
							permissions with confused deputy protection
					When the principal in a key policy statement is an AWS service principal, you can use the aws:SourceArn or aws:SourceAccount global condition keys to
						protect against the confused deputy
							scenario. To use these condition keys, set the value to the
						Amazon Resource Name (ARN) of the resource that is being encrypted. If you
						don't know the ARN of the resource, use aws:SourceAccount
						instead. 
					In this KMS key policy, a specific resource from service that is owned by account 111122223333
						is allowed to call KMS for Decrypt and
							GenerateDataKey actions, which occur during SSE usage of
						Amazon SQS.
					{
	"Version": "2012-10-17",
	"Statement": [{
		"Effect": "Allow",
		"Principal": {
            "Service": "<replaceable>service</replaceable>.amazonaws.com"
		},
		"Action": [
			"kms:GenerateDataKey",
			"kms:Decrypt"
		],
		"Resource": "*",
		"Condition": {
			"ArnEquals": {
				"aws:SourceArn": [
					"arn:aws:service::111122223333:resource"
				]
			}
		}
	}]
}
					When using SSE enabled Amazon SQS queues, the following services support
							aws:SourceArn:
					
						 
						 
						 
						 
						 
						 
						 
						 
					
							Amazon SNS
						
							Amazon S3
						
							CloudWatch Events
						
							AWS Lambda
						
							CodeBuild
						
							Amazon Connect Customer Profiles
						
							AWS Auto Scaling
						
							Amazon Chime
						
				 
			 
				Understanding the
						data key reuse period
				The  data key reuse period defines
					the maximum duration for Amazon SQS to reuse the same data key. When the data key
					reuse period ends, Amazon SQS generates a new data key. Note the following guidelines
					about the reuse period.
				
					 
					 
					 
					 
				
						A shorter reuse period provides better security but results in more
							calls to AWS KMS, which might incur charges beyond the Free Tier.
					
						Although the data key is cached separately for encryption and for
							decryption, the reuse period applies to both copies of the data
							key.
					
						When the data key reuse period ends, the next call to
								SendMessage or SendMessageBatch typically
							triggers a call to the AWS KMS GenerateDataKey method to get
							a new data key. Also, the next calls to SendMessage and
								ReceiveMessage will each trigger a call to AWS KMS
								Decrypt to verify the integrity of the data key before
							using it.
					
						Principals (AWS accounts or users) don't share data keys
							(messages sent by unique principals always get unique data keys).
							Therefore, the volume of calls to AWS KMS is a multiple of the number of
							unique principals in use during the data key reuse period.
					
			 
				Estimating AWS KMS costs
				To predict costs and better understand your AWS bill, you might want to know
					how often Amazon SQS uses your KMS key.
				NoteAlthough the following formula can give you a very good idea of expected
						costs, actual costs might be higher because of the distributed nature of
						Amazon SQS.
				To calculate the number of API requests (R) per
						queue, use the following formula:
				R = (B / D) * (2 * P + C)
				B is the billing period (in seconds).
				D is the data key reuse
						period (in seconds).
				P is the number of producing principals that send to the Amazon SQS queue.
				C is the number of consuming principals that receive from the
					Amazon SQS queue.
				ImportantIn general, producing principals incur double the cost of consuming
						principals. For more information, see Understanding the
						data key reuse period.If the producer and consumer have different users, the cost
						increases.
				The following are example calculations. For exact pricing information, see
						AWS Key Management Service Pricing.
				 
					Example 1: Calculating the
							number of AWS KMS API calls for 2 principals and 1 queue
					This example assumes the following:
					
						 
						 
						 
						 
					
							The billing period is January 1-31 (2,678,400 seconds).
						
							The data key reuse period is set to 5 minutes (300
								seconds).
						
							There is 1 queue.
						
							There is 1 producing principal and 1 consuming principal.
						
					(2,678,400 / 300) * (2 * 1 + 1) = 26,784
				 
				 
					Example 2:
							Calculating the number of AWS KMS API calls for multiple producers and
							consumers and 2 queues
					This example assumes the following:
					
						 
						 
						 
						 
						 
					
							The billing period is February 1-28 (2,419,200 seconds).
						
							The data key reuse period is set to 24 hours (86,400
								seconds).
						
							There are 2 queues.
						
							The first queue has 3 producing principals and 1 consuming
								principal.
						
							The second queue has 5 producing principals and 2 consuming
								principals.
						
					(2,419,200 / 86,400 * (2 * 3 + 1)) + (2,419,200 / 86,400 * (2 * 5 + 2)) = 532
				 
			 
				AWS KMS errors
				When you work with Amazon SQS and AWS KMS, you might encounter errors. The following
					references describe the errors and possible troubleshooting solutions.
				
					 
					 
					 
				
						 Common AWS KMS
								errors
					
						AWS KMS
								Decrypt errors
					
						AWS KMS GenerateDataKey errors
					
			Document ConventionsEncryption at restInternetwork traffic privacyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Encryption SDKDeveloper GuideHow the AWS Encryption SDK encrypts dataHow the AWS Encryption SDK decrypts an encrypted messageHow the AWS Encryption SDK worksThe workflows in this section explain how the AWS Encryption SDK encrypts data and decrypts
      encrypted messages. These workflows describes the basic process
    using the default features. For details about defining and using custom components, see the
    GitHub repository for each supported language
      implementation.The AWS Encryption SDK uses envelope encryption to protect your data. Each message is encrypted
    under a unique data key. Then the data key is encrypted by the wrapping keys you specify. To
    decrypt the encrypted message, the AWS Encryption SDK uses the wrapping keys you specify to decrypt at
    least one encrypted data key. Then it can decrypt the ciphertext and return a plaintext
    message.Need help with the terminology we use in the AWS Encryption SDK? See Concepts in the AWS Encryption SDK.
      How the AWS Encryption SDK encrypts data
      The AWS Encryption SDK provides methods that encrypt strings, byte arrays, and byte streams.
      For code examples, see the Examples topic in each Programming languages section.
      
         
         
         
         
         
      
          Create a keyring (or master key provider) that specifies the wrapping
          keys that protect your data.
        
          Pass the keyring and plaintext data to an encryption method. We recommend that you
          pass in an optional, non-secret encryption
            context.
        
          The encryption method asks the keyring for encryption materials. The keyring returns
          unique data encryption keys for the message: one plaintext data key and one copy of that
          data key encrypted by each of the specified wrapping keys.
        
          The encryption method uses the plaintext data key to encrypt the data, and then
          discards the plaintext data key. If you provide an encryption context (an AWS Encryption SDK
            best practice), the encryption method
          cryptographically binds the encryption context to the encrypted data.
        
          The encryption method returns an encrypted message that
          contains the encrypted data, the encrypted data keys, and other metadata, including the
          encryption context, if you used one.
        
     
      How the AWS Encryption SDK decrypts an encrypted message
      The AWS Encryption SDK provides methods that decrypt the encrypted message and return plaintext. For code examples, see the Examples topic in
      each Programming languages
      section.
      The keyring (or master key provider) that decrypts the encrypted
      message must be compatible with the one used to encrypt the message. One of its wrapping keys
      must be able to decrypt an encrypted data key in the encrypted message. For information about
      compatibility with keyrings and master key providers, see Keyring compatibility.
      
         
         
         
         
         
      
          Create a keyring or master key provider with wrapping keys that can decrypt your data. You can use
          the same keyring that you provided to the encryption method or a different one.
        
          Pass the encrypted message and the keyring to a
          decryption method.
        
          The decryption method asks the keyring or master key provider to decrypt one of the
            encrypted data keys in the encrypted message. It passes in information from the
            encrypted message, including the encrypted data keys.
        
          The keyring uses its wrapping keys to decrypt one of the encrypted data keys. If
          it's successful, the response includes the plaintext data key. If none of the wrapping
          keys specified by the keyring or master key provider can decrypt an encrypted data key,
          the decrypt call fails.
        
          The decryption method uses the plaintext data key to decrypt the data, discards the
            plaintext data key, and returns the plaintext data.
        
    Document ConventionsConceptsSupported algorithm suitesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoSendMessageDelivers a message to the specified queue.ImportantA message can include only XML, JSON, and unformatted text. The following Unicode characters are allowed. For more information, see the W3C specification for characters.
         #x9 | #xA | #xD | #x20 to #xD7FF | #xE000 to #xFFFD | #x10000 to #x10FFFF
      Amazon SQS does not throw an exception or completely reject the message if it contains invalid characters. Instead, it replaces those invalid characters with U+FFFD before storing the message in the queue, as long as the message body contains at least one valid character.
      Request Syntax
      {
   "DelaySeconds": number,
   "MessageAttributes": { 
      "string" : { 
         "BinaryListValues": [ blob ],
         "BinaryValue": blob,
         "DataType": "string",
         "StringListValues": [ "string" ],
         "StringValue": "string"
      }
   },
   "MessageBody": "string",
   "MessageDeduplicationId": "string",
   "MessageGroupId": "string",
   "MessageSystemAttributes": { 
      "string" : { 
         "BinaryListValues": [ blob ],
         "BinaryValue": blob,
         "DataType": "string",
         "StringListValues": [ "string" ],
         "StringValue": "string"
      }
   },
   "QueueUrl": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
          
          
          
          
          
      
            
               
                  DelaySeconds
               
            
            
                The length of time, in seconds, for which to delay a specific message. Valid values:
            0 to 900. Maximum: 15 minutes. Messages with a positive DelaySeconds value
            become available for processing after the delay period is finished. If you don't specify
            a value, the default value for the queue applies. 
               NoteWhen you set FifoQueue, you can't set DelaySeconds per message. You can set this parameter only on a queue level.
               Type: Integer
               Required: No
            
          
            
               
                  MessageAttributes
               
            
            
               Each message attribute consists of a Name, Type, 
and Value. For more information, see 
Amazon SQS 
message attributes in the Amazon SQS Developer Guide.
               Type: String to MessageAttributeValue object map
               Required: No
            
          
            
               
                  MessageBody
               
            
            
               The message to send. The minimum size is one character. The maximum size is 256
            KiB.
               ImportantA message can include only XML, JSON, and unformatted text. The following Unicode characters are allowed. For more information, see the W3C specification for characters.
                     #x9 | #xA | #xD | #x20 to #xD7FF | #xE000 to #xFFFD | #x10000 to #x10FFFF
                  Amazon SQS does not throw an exception or completely reject the message if it contains invalid characters. Instead, it replaces those invalid characters with U+FFFD before storing the message in the queue, as long as the message body contains at least one valid character.
               Type: String
               Required: Yes
            
          
            
               
                  MessageDeduplicationId
               
            
            
               This parameter applies only to FIFO (first-in-first-out) queues.
               The token used for deduplication of sent messages. If a message with a particular
                MessageDeduplicationId is sent successfully, any messages sent with the
            same MessageDeduplicationId are accepted successfully but aren't delivered
            during the 5-minute deduplication interval. For more information, see  Exactly-once processing in the Amazon SQS Developer
            Guide.
               
                   
                   
                   
               
                     Every message must have a unique MessageDeduplicationId,
                     
                         
                         
                         
                         
                     
                           You may provide a MessageDeduplicationId
                            explicitly.
                        
                           If you aren't able to provide a MessageDeduplicationId
                            and you enable ContentBasedDeduplication for your queue,
                            Amazon SQS uses a SHA-256 hash to generate the
                                MessageDeduplicationId using the body of the message
                            (but not the attributes of the message). 
                        
                           If you don't provide a MessageDeduplicationId and the
                            queue doesn't have ContentBasedDeduplication set, the
                            action fails with an error.
                        
                           If the queue has ContentBasedDeduplication set, your
                                MessageDeduplicationId overrides the generated
                            one.
                        
                  
                     When ContentBasedDeduplication is in effect, messages with
                    identical content sent within the deduplication interval are treated as
                    duplicates and only one copy of the message is delivered.
                  
                     If you send one message with ContentBasedDeduplication enabled
                    and then another message with a MessageDeduplicationId that is the
                    same as the one generated for the first MessageDeduplicationId, the
                    two messages are treated as duplicates and only one copy of the message is
                    delivered. 
                  
               NoteThe MessageDeduplicationId is available to the consumer of the
                message (this can be useful for troubleshooting delivery issues).If a message is sent successfully but the acknowledgement is lost and the message
                is resent with the same MessageDeduplicationId after the deduplication
                interval, Amazon SQS can't detect duplicate messages.Amazon SQS continues to keep track of the message deduplication ID even after the message is received and deleted.
               The maximum length of MessageDeduplicationId is 128 characters.
                MessageDeduplicationId can contain alphanumeric characters
                (a-z, A-Z, 0-9) and punctuation
                (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~).
               For best practices of using MessageDeduplicationId, see Using the MessageDeduplicationId Property in the Amazon SQS Developer
                Guide.
               Type: String
               Required: No
            
          
            
               
                  MessageGroupId
               
            
            
               This parameter applies only to FIFO (first-in-first-out) queues.
               The tag that specifies that a message belongs to a specific message group. Messages
            that belong to the same message group are processed in a FIFO manner (however,
            messages in different message groups might be processed out of order). To interleave
            multiple ordered streams within a single queue, use MessageGroupId values
            (for example, session data for multiple users). In this scenario, multiple consumers can
            process the queue, but the session data of each user is processed in a FIFO
            fashion.
               
                   
                   
               
                     You must associate a non-empty MessageGroupId with a message. If
                    you don't provide a MessageGroupId, the action fails.
                  
                     
                        ReceiveMessage might return messages with multiple
                        MessageGroupId values. For each MessageGroupId,
                    the messages are sorted by time sent. The caller can't specify a
                        MessageGroupId.
                  
               The maximum length of MessageGroupId is 128 characters. Valid values:
            alphanumeric characters and punctuation
                (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~).
               For best practices of using MessageGroupId, see Using the MessageGroupId Property in the Amazon SQS Developer
                Guide.
               Important
                     MessageGroupId is required for FIFO queues. You can't use it for
                Standard queues.
               Type: String
               Required: No
            
          
            
               
                  MessageSystemAttributes
               
            
            
               The message system attribute to send. Each message system attribute consists of a Name, Type, and Value.
               Important
                      
                      
                  
                        Currently, the only supported message system attribute is AWSTraceHeader.
                    Its type must be String and its value must be a correctly formatted
                    AWS X-Ray trace header string.
                     
                        The size of a message system attribute doesn't count towards the total size of a message.
                     
               Type: String to MessageSystemAttributeValue object map
               Valid Keys: AWSTraceHeader
               
               Required: No
            
          
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue to which a message is sent.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
         
    
      Response Syntax
      {
   "MD5OfMessageAttributes": "string",
   "MD5OfMessageBody": "string",
   "MD5OfMessageSystemAttributes": "string",
   "MessageId": "string",
   "SequenceNumber": "string"
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
          
          
          
          
      
            
               
                  MD5OfMessageAttributes
               
            
            
               An MD5 digest of the non-URL-encoded message attribute string. You can use this attribute to verify that Amazon SQS received the message correctly. Amazon SQS URL-decodes the message before creating the MD5 digest. For information about MD5, see RFC1321.
               Type: String
            
          
            
               
                  MD5OfMessageBody
               
            
            
               An MD5 digest of the non-URL-encoded message body string. You can use this attribute to verify that Amazon SQS received the message correctly. Amazon SQS URL-decodes the message before creating the MD5 digest. For information about MD5, see RFC1321.
               Type: String
            
          
            
               
                  MD5OfMessageSystemAttributes
               
            
            
               An MD5 digest of the non-URL-encoded message system attribute string. You can use this 
attribute to verify that Amazon SQS received the message correctly. Amazon SQS URL-decodes the message before creating the MD5 digest.
               Type: String
            
          
            
               
                  MessageId
               
            
            
               An attribute containing the MessageId of the message sent to the queue.
            For more information, see Queue and Message Identifiers in the Amazon SQS Developer
                Guide. 
               Type: String
            
          
            
               
                  SequenceNumber
               
            
            
               This parameter applies only to FIFO (first-in-first-out) queues.
               The large, non-consecutive number that Amazon SQS assigns to each message.
               The length of SequenceNumber is 128 bits. SequenceNumber
            continues to increase for a particular MessageGroupId.
               Type: String
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidMessageContents
               
            
            
               The message contains characters outside the allowed set.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  KmsAccessDenied
               
            
            
               The caller doesn't have the required KMS access.
               HTTP Status Code: 400
            
          
            
               
                  KmsDisabled
               
            
            
               The request was denied due to request throttling.
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidKeyUsage
               
            
            
               The request was rejected for one of the following reasons:
               
                   
                   
               
                     The KeyUsage value of the KMS key is incompatible with the API
                    operation.
                  
                     The encryption algorithm or signing algorithm specified for the operation is
                    incompatible with the type of key material in the KMS key (KeySpec).
                  
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidState
               
            
            
               The request was rejected because the state of the specified resource is not valid for
            this request.
               HTTP Status Code: 400
            
          
            
               
                  KmsNotFound
               
            
            
               The request was rejected because the specified entity or resource could not be found.
        
               HTTP Status Code: 400
            
          
            
               
                  KmsOptInRequired
               
            
            
               The request was rejected because the specified key policy isn't syntactically or
            semantically correct.
               HTTP Status Code: 400
            
          
            
               
                  KmsThrottled
               
            
            
               
                  AWS KMS throttles requests for the following conditions.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example SendMessage request sends a message containing
                    This is a test message to the queue. You must URL-encode the entire URL. However, in this example only the message body is URL-encoded to make the example easier to read.
                The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SendMessage
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "MessageBody": "This is a test message",
    "MessageAttributes": {
        "my_attribute_name_1": {
            "DataType": "String",
            "StringValue": "my_attribute_value_1"
        },
        "my_attribute_name_2": {
            "DataType": "String",
            "StringValue": "my_attribute_value_2"
        }
    }
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
    "MD5OfMessageAttributes": "c48838208d2b4e14e3ca0093a8443f09",
    "MD5OfMessageBody": "fafb00f5732ab283681e124bf8747ed1",
    "MessageId": "219f8380-5770-4cc2-8c3e-5c715e145f5e"
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SendMessage
&MessageBody=This+is+a+test+message
&MessageAttribute.1.Name=my_attribute_name_1
&MessageAttribute.1.Value.StringValue=my_attribute_value_1
&MessageAttribute.1.Value.DataType=String
&MessageAttribute.2.Name=my_attribute_name_2
&MessageAttribute.2.Value.StringValue=my_attribute_value_2
&MessageAttribute.2.Value.DataType=String
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SendMessageResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <SendMessageResult>
        <MessageId>374cec7b-d0c8-4a2e-ad0b-67be763cf97e</MessageId>
        <MD5OfMessageBody>fafb00f5732ab283681e124bf8747ed1</MD5OfMessageBody>
        <MD5OfMessageAttributes>c48838208d2b4e14e3ca0093a8443f09</MD5OfMessageAttributes>
    </SendMessageResult>
    <ResponseMetadata>
        <RequestId>7fe4446e-b452-53f7-8f85-181e06f2dd99</RequestId>
    </ResponseMetadata>
</SendMessageResponse>
          
       
       
         Example
         The following example creates a message
                    timer—applying a 45-second initial visibility delay to a
                    single message— by calling the SendMessage action with the
                        DelaySeconds parameter set to 45 seconds.
         NoteQueue URLs and names are case-sensitive.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SendMessage
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "MessageBody": "This is a test message",
    "DelaySeconds": 45
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SendMessage
&MessageBody=This+is+a+test+message
&DelaySeconds=45
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsRemovePermissionSendMessageBatchDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoSendMessageBatchYou can use SendMessageBatch to send up to 10 messages to the specified
            queue by assigning either identical or different values to each message (or by not
            assigning values at all). This is a batch version of 
         SendMessage. For a FIFO queue, multiple messages within a single batch are enqueued
            in the order they are sent.The result of sending each message is reported individually in the response.
            Because the batch request can result in a combination of successful and unsuccessful actions, you should check for batch errors even when the call returns an HTTP status code of 200.The maximum allowed individual message size and the maximum total payload size (the
            sum of the individual lengths of all of the batched messages) are both 256 KiB (262,144
            bytes).ImportantA message can include only XML, JSON, and unformatted text. The following Unicode characters are allowed. For more information, see the W3C specification for characters.
         #x9 | #xA | #xD | #x20 to #xD7FF | #xE000 to #xFFFD | #x10000 to #x10FFFF
      Amazon SQS does not throw an exception or completely reject the message if it contains invalid characters. Instead, it replaces those invalid characters with U+FFFD before storing the message in the queue, as long as the message body contains at least one valid character.If you don't specify the DelaySeconds parameter for an entry, Amazon SQS uses
            the default value for the queue.
      Request Syntax
      {
   "Entries": [ 
      { 
         "DelaySeconds": number,
         "Id": "string",
         "MessageAttributes": { 
            "string" : { 
               "BinaryListValues": [ blob ],
               "BinaryValue": blob,
               "DataType": "string",
               "StringListValues": [ "string" ],
               "StringValue": "string"
            }
         },
         "MessageBody": "string",
         "MessageDeduplicationId": "string",
         "MessageGroupId": "string",
         "MessageSystemAttributes": { 
            "string" : { 
               "BinaryListValues": [ blob ],
               "BinaryValue": blob,
               "DataType": "string",
               "StringListValues": [ "string" ],
               "StringValue": "string"
            }
         }
      }
   ],
   "QueueUrl": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
      
            
               
                  Entries
               
            
            
               A list of 
                     SendMessageBatchRequestEntry
                   items.
               Type: Array of SendMessageBatchRequestEntry objects
               Required: Yes
            
          
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue to which batched messages are sent.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
         
    
      Response Syntax
      {
   "Failed": [ 
      { 
         "Code": "string",
         "Id": "string",
         "Message": "string",
         "SenderFault": boolean
      }
   ],
   "Successful": [ 
      { 
         "Id": "string",
         "MD5OfMessageAttributes": "string",
         "MD5OfMessageBody": "string",
         "MD5OfMessageSystemAttributes": "string",
         "MessageId": "string",
         "SequenceNumber": "string"
      }
   ]
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
          
      
            
               
                  Failed
               
            
            
               A list of 
                     BatchResultErrorEntry
                   items with error
            details about each message that can't be enqueued.
               Type: Array of BatchResultErrorEntry objects
            
          
            
               
                  Successful
               
            
            
               A list of 
                     SendMessageBatchResultEntry
                   items.
               Type: Array of SendMessageBatchResultEntry objects
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  BatchEntryIdsNotDistinct
               
            
            
               Two or more batch entries in the request have the same Id.
               HTTP Status Code: 400
            
          
            
               
                  BatchRequestTooLong
               
            
            
               The length of all the messages put together is more than the limit.
               HTTP Status Code: 400
            
          
            
               
                  EmptyBatchRequest
               
            
            
               The batch request doesn't contain any entries.
               HTTP Status Code: 400
            
          
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidBatchEntryId
               
            
            
               The Id of a batch entry in a batch request doesn't abide by the
            specification.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  KmsAccessDenied
               
            
            
               The caller doesn't have the required KMS access.
               HTTP Status Code: 400
            
          
            
               
                  KmsDisabled
               
            
            
               The request was denied due to request throttling.
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidKeyUsage
               
            
            
               The request was rejected for one of the following reasons:
               
                   
                   
               
                     The KeyUsage value of the KMS key is incompatible with the API
                    operation.
                  
                     The encryption algorithm or signing algorithm specified for the operation is
                    incompatible with the type of key material in the KMS key (KeySpec).
                  
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidState
               
            
            
               The request was rejected because the state of the specified resource is not valid for
            this request.
               HTTP Status Code: 400
            
          
            
               
                  KmsNotFound
               
            
            
               The request was rejected because the specified entity or resource could not be found.
        
               HTTP Status Code: 400
            
          
            
               
                  KmsOptInRequired
               
            
            
               The request was rejected because the specified key policy isn't syntactically or
            semantically correct.
               HTTP Status Code: 400
            
          
            
               
                  KmsThrottled
               
            
            
               
                  AWS KMS throttles requests for the following conditions.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  TooManyEntriesInBatchRequest
               
            
            
               The batch request contains more entries than permissible. For Amazon SQS, the
            maximum number of entries you can include in a single SendMessageBatch, DeleteMessageBatch, or ChangeMessageVisibilityBatch request is 10.
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example SendMessageBatch request sends two messages to
                the queue. You must URL-encode the entire URL. However, in this example only the message body is URL-encoded to make the example easier to read. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SendMessageBatch
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Entries": [
        {
            "Id": "test_msg_001",
            "MessageBody": "test message body 1"
        },
        {
            "Id": "test_msg_002",
            "MessageBody": "test message body 2",
            "DelaySeconds": 60,
            "MessageAttributes": {
                "my_attribute_name_1": {
                    "DataType": "String",
                    "StringValue": "my_attribute_value_1"
                }
            }
        }
    ]
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
   "Failed": [],
    "Successful": [
        {
            "Id": "test_msg_001",
            "MD5OfMessageBody": "0e024d309850c78cba5eabbeff7cae71",
            "MessageId": "f4eb349f-cd33-4bc4-bdc2-e557c900d41d"
        },
        {
            "Id": "test_msg_002",
            "MD5OfMessageAttributes": "8ef4d60dbc8efda9f260e1dfd09d29f3",
            "MD5OfMessageBody": "27118326006d3829667a400ad23d5d98",
            "MessageId": "1dcfcd50-5a67-45ae-ae4c-1c152b5effb9"
        }
    ]
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SendMessageBatch
&SendMessageBatchRequestEntry.1.Id=test_msg_001
&SendMessageBatchRequestEntry.1.MessageBody=test%20message%20body%201
&SendMessageBatchRequestEntry.2.Id=test_msg_002
&SendMessageBatchRequestEntry.2.MessageBody=test%20message%20body%202
&SendMessageBatchRequestEntry.2.DelaySeconds=60
&SendMessageBatchRequestEntry.2.MessageAttribute.1.Name=test_attribute_name_1
&SendMessageBatchRequestEntry.2.MessageAttribute.1.Value.StringValue=test_attribute_value_1
&SendMessageBatchRequestEntry.2.MessageAttribute.1.Value.DataType=String
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<SendMessageBatchResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <SendMessageBatchResult>
        <SendMessageBatchResultEntry>
            <Id>test_msg_001</Id>
            <MessageId>60e827c3-c8a5-410a-af0e-fb43746e70b1</MessageId>
            <MD5OfMessageBody>0e024d309850c78cba5eabbeff7cae71</MD5OfMessageBody>
        </SendMessageBatchResultEntry>
        <SendMessageBatchResultEntry>
            <Id>test_msg_00</Id>
            <MessageId>c6e7fc6a-b802-4724-be06-59833004578b</MessageId>
            <MD5OfMessageBody>7fb8146a82f95e0af155278f406862c2</MD5OfMessageBody>
            <MD5OfMessageAttributes>ba056227cfd9533dba1f72ad9816d233</MD5OfMessageAttributes>
        </SendMessageBatchResultEntry>
    </SendMessageBatchResult>
    <ResponseMetadata>
        <RequestId>5150a701-14f7-5609-b136-fb71a0ca744a</RequestId>
    </ResponseMetadata>
</SendMessageBatchResponse>
          
       
       
         Example
         The following example sends multiple messages with message
                        timers—applying a visibility delay of variable length to
                    the messages in the batch—by calling the SendMessageBatch
                    action without a value for DelaySeconds for
                    the first message and with the values of 45 seconds and 2 minutes for the second
                    and third messages.
         NoteIf you don't set a value for the DelaySeconds parameter, the
                        message might still be subject to a delay if you add the message to a
                            delay queue. For more information about using delay
                        queues, see Amazon SQS Delay Queues in the Amazon SQS Developer
                            Guide.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.SendMessageBatch
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "Entries": [
        {
            "Id": "test_msg_no_message_timer",
            "MessageBody": "test message body 1"
        },
        {
            "Id": "test_msg_delay_45_seconds",
            "MessageBody": "test message body 2",
            "DelaySeconds": 45
        },
        {
            "Id": "test_msg_delay_2_minutes",
            "MessageBody": "test message body 3",
            "DelaySeconds": 120
        }
    ]
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=SendMessageBatch
&SendMessageBatchRequestEntry.1.Id=test_msg_no_message_timer
&SendMessageBatchRequestEntry.1.MessageBody=test%20message%20body%201
&SendMessageBatchRequestEntry.2.Id=test_msg_delay_45_seconds
&SendMessageBatchRequestEntry.2.MessageBody=test%20message%20body%202
&SendMessageBatchRequestEntry.2.DelaySeconds=45
&SendMessageBatchRequestEntry.3.Id=test_msg_delay_2_minutes
&SendMessageBatchRequestEntry.3.MessageBody=test%20message%20body%203
&SendMessageBatchRequestEntry.3.DelaySeconds=120
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsSendMessageSetQueueAttributesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse SyntaxResponse ElementsErrorsExamplesSee AlsoReceiveMessageRetrieves one or more messages (up to 10), from the specified queue. Using the
                WaitTimeSeconds parameter enables long-poll support. For more
            information, see Amazon SQS
                Long Polling in the Amazon SQS Developer Guide. Short poll is the default behavior where a weighted random set of machines is sampled
            on a ReceiveMessage call. Therefore, only the messages on the sampled
            machines are returned. If the number of messages in the queue is small (fewer than
            1,000), you most likely get fewer messages than you requested per
                ReceiveMessage call. If the number of messages in the queue is
            extremely small, you might not receive any messages in a particular
                ReceiveMessage response. If this happens, repeat the request.For each message returned, the response includes the following:
       
       
       
       
       
       
   
         The message body.
      
         An MD5 digest of the message body. For information about MD5, see RFC1321.
      
         The MessageId you received when you sent the message to the
                    queue.
      
         The receipt handle.
      
         The message attributes.
      
         An MD5 digest of the message attributes.
      The receipt handle is the identifier you must provide when deleting the message. For
            more information, see Queue and Message Identifiers in the Amazon SQS Developer
                Guide.You can provide the VisibilityTimeout parameter in your request. The
            parameter is applied to the messages that Amazon SQS returns in the response. If you don't
            include the parameter, the overall visibility timeout for the queue is used for the
            returned messages. The default visibility timeout for a queue is 30 seconds. NoteIn the future, new attributes might be added. If you write code that calls this action, we recommend that you structure your code so that it can handle new attributes gracefully.
      Request Syntax
      {
   "AttributeNames": [ "string" ],
   "MaxNumberOfMessages": number,
   "MessageAttributeNames": [ "string" ],
   "MessageSystemAttributeNames": [ "string" ],
   "QueueUrl": "string",
   "ReceiveRequestAttemptId": "string",
   "VisibilityTimeout": number,
   "WaitTimeSeconds": number
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
          
          
          
          
          
          
      
            
               
                  AttributeNames
               
            
            
               
                  This parameter has been deprecated.
               
               ImportantThis parameter has been discontinued but will be supported for backward
                compatibility. To provide attribute names, you are encouraged to use
                    MessageSystemAttributeNames. 
               A list of attributes that need to be returned along with each message. These
            attributes include:
               
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
               
                     
                        All – Returns all values.
                  
                     
                        ApproximateFirstReceiveTimestamp – Returns the time the
                    message was first received from the queue (epoch time in
                    milliseconds).
                  
                     
                        ApproximateReceiveCount – Returns the number of times a
                    message has been received across all queues but not deleted.
                  
                     
                        AWSTraceHeader – Returns the AWS X-Ray trace
                    header string. 
                  
                     
                        SenderId
                     
                     
                         
                         
                     
                           For a user, returns the user ID, for example
                                ABCDEFGHI1JKLMNOPQ23R.
                        
                           For an IAM role, returns the IAM role ID, for example
                                ABCDE1F2GH3I4JK5LMNOP:i-a123b456.
                        
                  
                     
                        SentTimestamp – Returns the time the message was sent to the
                    queue (epoch time in
                    milliseconds).
                  
                     
                        SqsManagedSseEnabled – Enables server-side queue encryption
                    using SQS owned encryption keys. Only one server-side encryption option is
                    supported per queue (for example, SSE-KMS or SSE-SQS).
                  
                     
                        MessageDeduplicationId – Returns the value provided by the
                    producer that calls the 
                           SendMessage
                        
                    action.
                  
                     
                        MessageGroupId – Returns the value provided by the
                    producer that calls the 
                           SendMessage
                         action.
                    Messages with the same MessageGroupId are returned in
                    sequence.
                  
                     
                        SequenceNumber – Returns the value provided by
                    Amazon SQS.
                  
               Type: Array of strings
               Valid Values: All | Policy | VisibilityTimeout | MaximumMessageSize | MessageRetentionPeriod | ApproximateNumberOfMessages | ApproximateNumberOfMessagesNotVisible | CreatedTimestamp | LastModifiedTimestamp | QueueArn | ApproximateNumberOfMessagesDelayed | DelaySeconds | ReceiveMessageWaitTimeSeconds | RedrivePolicy | FifoQueue | ContentBasedDeduplication | KmsMasterKeyId | KmsDataKeyReusePeriodSeconds | DeduplicationScope | FifoThroughputLimit | RedriveAllowPolicy | SqsManagedSseEnabled
               
               Required: No
            
          
            
               
                  MaxNumberOfMessages
               
            
            
               The maximum number of messages to return. Amazon SQS never returns more messages than this
            value (however, fewer messages might be returned). Valid values: 1 to 10. Default:
            1.
               Type: Integer
               Required: No
            
          
            
               
                  MessageAttributeNames
               
            
            
               The name of the message attribute, where N is the index.
               
                   
                   
                   
                   
                   
               
                     The name can contain alphanumeric characters and the underscore
                        (_), hyphen (-), and period
                    (.).
                  
                     The name is case-sensitive and must be unique among all attribute names for
                    the message.
                  
                     The name must not start with AWS-reserved prefixes such as AWS.
                    or Amazon. (or any casing variants).
                  
                     The name must not start or end with a period (.), and it should
                    not have periods in succession (..).
                  
                     The name can be up to 256 characters long.
                  
               When using ReceiveMessage, you can send a list of attribute names to
            receive, or you can return all of the attributes by specifying All or
                .* in your request. You can also use all message attributes starting
            with a prefix, for example bar.*.
               Type: Array of strings
               Required: No
            
          
            
               
                  MessageSystemAttributeNames
               
            
            
               A list of attributes that need to be returned along with each message. These
            attributes include:
               
                   
                   
                   
                   
                   
                   
                   
                   
                   
                   
               
                     
                        All – Returns all values.
                  
                     
                        ApproximateFirstReceiveTimestamp – Returns the time the
                    message was first received from the queue (epoch time in
                    milliseconds).
                  
                     
                        ApproximateReceiveCount – Returns the number of times a
                    message has been received across all queues but not deleted.
                  
                     
                        AWSTraceHeader – Returns the AWS X-Ray trace
                    header string. 
                  
                     
                        SenderId
                     
                     
                         
                         
                     
                           For a user, returns the user ID, for example
                                ABCDEFGHI1JKLMNOPQ23R.
                        
                           For an IAM role, returns the IAM role ID, for example
                                ABCDE1F2GH3I4JK5LMNOP:i-a123b456.
                        
                  
                     
                        SentTimestamp – Returns the time the message was sent to the
                    queue (epoch time in
                    milliseconds).
                  
                     
                        SqsManagedSseEnabled – Enables server-side queue encryption
                    using SQS owned encryption keys. Only one server-side encryption option is
                    supported per queue (for example, SSE-KMS or SSE-SQS).
                  
                     
                        MessageDeduplicationId – Returns the value provided by the
                    producer that calls the 
                           SendMessage
                        
                    action.
                  
                     
                        MessageGroupId – Returns the value provided by the
                    producer that calls the 
                           SendMessage
                         action.
                    Messages with the same MessageGroupId are returned in
                    sequence.
                  
                     
                        SequenceNumber – Returns the value provided by
                    Amazon SQS.
                  
               Type: Array of strings
               Valid Values: All | SenderId | SentTimestamp | ApproximateReceiveCount | ApproximateFirstReceiveTimestamp | SequenceNumber | MessageDeduplicationId | MessageGroupId | AWSTraceHeader | DeadLetterQueueSourceArn
               
               Required: No
            
          
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue from which messages are received.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
          
            
               
                  ReceiveRequestAttemptId
               
            
            
               This parameter applies only to FIFO (first-in-first-out) queues.
               The token used for deduplication of ReceiveMessage calls. If a networking
            issue occurs after a ReceiveMessage action, and instead of a response you
            receive a generic error, it is possible to retry the same action with an identical
                ReceiveRequestAttemptId to retrieve the same set of messages, even if
            their visibility timeout has not yet expired.
               
                   
                   
                   
                   
                   
                   
               
                     You can use ReceiveRequestAttemptId only for 5 minutes after a
                        ReceiveMessage action.
                  
                     When you set FifoQueue, a caller of the
                        ReceiveMessage action can provide a
                        ReceiveRequestAttemptId explicitly.
                  
                     It is possible to retry the ReceiveMessage action with the same
                        ReceiveRequestAttemptId if none of the messages have been
                    modified (deleted or had their visibility changes).
                  
                     During a visibility timeout, subsequent calls with the same
                        ReceiveRequestAttemptId return the same messages and receipt
                    handles. If a retry occurs within the deduplication interval, it resets the
                    visibility timeout. For more information, see Visibility Timeout in the Amazon SQS Developer
                        Guide.
                     ImportantIf a caller of the ReceiveMessage action still processes
                        messages when the visibility timeout expires and messages become visible,
                        another worker consuming from the same queue can receive the same messages
                        and therefore process duplicates. Also, if a consumer whose message
                        processing time is longer than the visibility timeout tries to delete the
                        processed messages, the action fails with an error.To mitigate this effect, ensure that your application observes a safe
                        threshold before the visibility timeout expires and extend the visibility
                        timeout as necessary.
                  
                     While messages with a particular MessageGroupId are invisible, no
                    more messages belonging to the same MessageGroupId are returned
                    until the visibility timeout expires. You can still receive messages with
                    another MessageGroupId as long as it is also visible.
                  
                     If a caller of ReceiveMessage can't track the
                        ReceiveRequestAttemptId, no retries work until the original
                    visibility timeout expires. As a result, delays might occur but the messages in
                    the queue remain in a strict order.
                  
               The maximum length of ReceiveRequestAttemptId is 128 characters.
                ReceiveRequestAttemptId can contain alphanumeric characters
                (a-z, A-Z, 0-9) and punctuation
                (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~).
               For best practices of using ReceiveRequestAttemptId, see Using the ReceiveRequestAttemptId Request Parameter in the Amazon SQS
                Developer Guide.
               Type: String
               Required: No
            
          
            
               
                  VisibilityTimeout
               
            
            
               The duration (in seconds) that the received messages are hidden from subsequent
            retrieve requests after being retrieved by a ReceiveMessage request. If not
            specified, the default visibility timeout for the queue is used, which is 30
            seconds.
               Understanding VisibilityTimeout:
               
                   
                   
                   
                   
               
                     When a message is received from a queue, it becomes temporarily invisible to
                    other consumers for the duration of the visibility timeout. This prevents
                    multiple consumers from processing the same message simultaneously. If the
                    message is not deleted or its visibility timeout is not extended before the
                    timeout expires, it becomes visible again and can be retrieved by other
                    consumers.
                  
                     Setting an appropriate visibility timeout is crucial. If it's too short, the
                    message might become visible again before processing is complete, leading to
                    duplicate processing. If it's too long, it delays the reprocessing of messages
                    if the initial processing fails.
                  
                     You can adjust the visibility timeout using the
                        --visibility-timeout parameter in the
                        receive-message command to match the processing time required
                    by your application.
                  
                     A message that isn't deleted or a message whose visibility isn't extended
                    before the visibility timeout expires counts as a failed receive. Depending on
                    the configuration of the queue, the message might be sent to the dead-letter
                    queue.
                  
               For more information, see Visibility Timeout in the Amazon SQS Developer
            Guide.
               Type: Integer
               Required: No
            
          
            
               
                  WaitTimeSeconds
               
            
            
               The duration (in seconds) for which the call waits for a message to arrive in the
            queue before returning. If a message is available, the call returns sooner than
                WaitTimeSeconds. If no messages are available and the wait time
            expires, the call does not return a message list. If you are using the Java SDK, it
            returns a ReceiveMessageResponse object, which has a empty list instead of
            a Null object.
               ImportantTo avoid HTTP errors, ensure that the HTTP response timeout for
                    ReceiveMessage requests is longer than the
                    WaitTimeSeconds parameter. For example, with the Java SDK, you can
                set HTTP transport settings using the  NettyNioAsyncHttpClient for asynchronous clients, or the  ApacheHttpClient for synchronous clients. 
               Type: Integer
               Required: No
            
         
    
      Response Syntax
      {
   "Messages": [ 
      { 
         "Attributes": { 
            "string" : "string" 
         },
         "Body": "string",
         "MD5OfBody": "string",
         "MD5OfMessageAttributes": "string",
         "MessageAttributes": { 
            "string" : { 
               "BinaryListValues": [ blob ],
               "BinaryValue": blob,
               "DataType": "string",
               "StringListValues": [ "string" ],
               "StringValue": "string"
            }
         },
         "MessageId": "string",
         "ReceiptHandle": "string"
      }
   ]
}
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response.
      The following data is returned in JSON format by the service.
      
          
      
            
               
                  Messages
               
            
            
               A list of messages.
               Type: Array of Message objects
            
         
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  KmsAccessDenied
               
            
            
               The caller doesn't have the required KMS access.
               HTTP Status Code: 400
            
          
            
               
                  KmsDisabled
               
            
            
               The request was denied due to request throttling.
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidKeyUsage
               
            
            
               The request was rejected for one of the following reasons:
               
                   
                   
               
                     The KeyUsage value of the KMS key is incompatible with the API
                    operation.
                  
                     The encryption algorithm or signing algorithm specified for the operation is
                    incompatible with the type of key material in the KMS key (KeySpec).
                  
               HTTP Status Code: 400
            
          
            
               
                  KmsInvalidState
               
            
            
               The request was rejected because the state of the specified resource is not valid for
            this request.
               HTTP Status Code: 400
            
          
            
               
                  KmsNotFound
               
            
            
               The request was rejected because the specified entity or resource could not be found.
        
               HTTP Status Code: 400
            
          
            
               
                  KmsOptInRequired
               
            
            
               The request was rejected because the specified key policy isn't syntactically or
            semantically correct.
               HTTP Status Code: 400
            
          
            
               
                  KmsThrottled
               
            
            
               
                  AWS KMS throttles requests for the following conditions.
               HTTP Status Code: 400
            
          
            
               
                  OverLimit
               
            
            
               The specified action violates a limit. For example, ReceiveMessage
            returns this error if the maximum number of in flight messages is reached and
                AddPermission returns this error if the maximum number of permissions
            for the queue is reached.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example query request receives messages from the specified queue.
                The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.ReceiveMessage
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "MaxNumberOfMessages": 5,
    "VisibilityTimeout": 15,
    "AttributeNames": ["All"]
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: <PayloadSizeBytes>
Date: <Date>
Content-Type: application/x-amz-json-1.0
{
    "Messages": [
        {
            "Attributes": {
                "SenderId": "AIDASSYFHUBOBT7F4XT75",
                "ApproximateFirstReceiveTimestamp": "1677112433437",
                "ApproximateReceiveCount": "1",
                "SentTimestamp": "1677112427387"
            },
            "Body": "This is a test message",
            "MD5OfBody": "fafb00f5732ab283681e124bf8747ed1",
            "MessageId": "219f8380-5770-4cc2-8c3e-5c715e145f5e",
            "ReceiptHandle": "AQEBaZ+j5qUoOAoxlmrCQPkBm9njMWXqemmIG6shMHCO6fV20JrQYg/AiZ8JELwLwOu5U61W+aIX5Qzu7GGofxJuvzymr4Ph53RiR0mudj4InLSgpSspYeTRDteBye5tV/txbZDdNZxsi+qqZA9xPnmMscKQqF6pGhnGIKrnkYGl45Nl6GPIZv62LrIRb6mSqOn1fn0yqrvmWuuY3w2UzQbaYunJWGxpzZze21EOBtywknU3Je/g7G9is+c6K9hGniddzhLkK1tHzZKjejOU4jokaiB4nmi0dF3JqLzDsQuPF0Gi8qffhEvw56nl8QCbluSJScFhJYvoagGnDbwOnd9z50L239qtFIgETdpKyirlWwl/NGjWJ45dqWpiW3d2Ws7q"
        }
    ]
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=ReceiveMessage
&MaxNumberOfMessages=5
&VisibilityTimeout=15
&AttributeName=All
          
          
            Sample Response
            HTTP/1.1 200 OK
<ReceiveMessageResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ReceiveMessageResult>
        <Message>
            <MessageId>60e827c3-c8a5-410a-af0e-fb43746e70b1</MessageId>
            <ReceiptHandle>AQEBwPTK2fT2gy97H1iyU5in9umgT+Y4IOxyKGOzpZa8iemEqoR5/aPn0xAodmiVTzyrW7S4e8XwcWbB04XK92jIQzUpiGwRFA4Dl7r3GOw84Qzq/0OBQe/JaKxJw6iilafYA5fo1SJQo5Wg8xXbJHTVlJqgvTXd/UtlByLMhWMi0JMra1UUjYiPsGtYUpLVnOaRkYSPvzRnFFYUbcqCW9lm2Bi/jQKK6KNOZyCCfIh8TooE5i4P2L9N3o9yUHwMdv6p0nb5lKaGurQ2sJwwsyhXf38ZHnVN6pWwsqQnWKYuEXpxPofxd2lcLdgUurMpydS22DzCrkAaf6gmrdxbmCAoeQxE0sFf8alwX9yQmcOjny9aLGe7ro4Vl5o5KMr5hHM4vHEyhwi4wHeKM6MGX0vATA==</ReceiptHandle>
            <MD5OfBody>0e024d309850c78cba5eabbeff7cae71</MD5OfBody>
            <Body>test message body 1</Body>
            <Attribute>
                <Name>SenderId</Name>
                <Value>AIDASSYFHUBOBT7F4XT75</Value>
            </Attribute>
            <Attribute>
                <Name>ApproximateFirstReceiveTimestamp</Name>
                <Value>1677112300463</Value>
            </Attribute>
            <Attribute>
                <Name>ApproximateReceiveCount</Name>
                <Value>1</Value>
            </Attribute>
            <Attribute>
                <Name>SentTimestamp</Name>
                <Value>1677111805489</Value>
            </Attribute>
        </Message>
    </ReceiveMessageResult>
    <ResponseMetadata>
        <RequestId>5ba605cc-1e4b-58ba-93db-59bca8677ec9</RequestId>
    </ResponseMetadata>
</ReceiveMessageResponse>
          
       
       
         Example
         The following example enables long polling by calling the
                        ReceiveMessage action with the WaitTimeSeconds
                    parameter set to 10 seconds.
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.ReceiveMessage
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "WaitTimeSeconds": 10,
    "MaxNumberOfMessages": 5,
    "VisibilityTimeout": 15,
    "AttributeNames": ["All"]
}
            
          
       
       
         Example
         The following example shows the request and response when using the parameter
                        MessageSystemAttributeNames.
          
            Sample Request
            aws sqs receive-message \
  --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/MyQueue \
  --message-system-attribute-names SentTimestamp SenderId
          
          
            Sample Response
            {
  "Messages": [
    {
      "MessageId": "abc1234d-5678-90ab-cdef-EXAMPLE11111",
      "ReceiptHandle": "AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...",
      "MD5OfBody": "e99a18c428cb38d5f260853678922e03",
      "Body": "Example message",
      "Attributes": {
        "SenderId": "AIDAEXAMPLE123ABC",
        "SentTimestamp": "1638368280000"
      }
    }
  ]
}
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=ReceiveMessage
&WaitTimeSeconds=10
&MaxNumberOfMessages=5
&VisibilityTimeout=15
&AttributeName=All
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsPurgeQueueRemovePermissionDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUse casesPartitions and data distributionHigh throughput for FIFO queues in Amazon SQSHigh throughput FIFO queues in Amazon SQS efficiently manage high message throughput while
    maintaining strict message order, ensuring reliability and scalability for applications
    processing numerous messages. This solution is ideal for scenarios demanding both high
    throughput and ordered message delivery.Amazon SQS high throughput FIFO queues are not necessary in scenarios where strict message
    ordering is not crucial and where the volume of incoming messages is relatively low or sporadic.
    For instance, if you have a small-scale application that processes infrequent or non-sequential
    messages, the added complexity and cost associated with high throughput FIFO queues may not be
    justified. Additionally, if your application does not require the enhanced throughput
    capabilities provided by high throughput FIFO queues, opting for a standard Amazon SQS queue might be
    more cost-effective and simpler to manage.To enhance request capacity in high throughput FIFO queues, increasing the number of message
    groups is recommended. For more information on high throughput message quotas, see Amazon SQS service
      quotas in the Amazon Web Services General Reference.For information per-queue quotas and data distribution strategies, see Amazon SQS message quotas and Partitions and data distribution for high
      throughput for SQS FIFO queues.
  Use cases for high throughput for Amazon SQS FIFO
      queues
  The following use cases highlight the diverse applications of high throughput FIFO queues,
    showcasing their effectiveness across industries and scenarios:
  
     
     
     
     
  
      Real-time data processing: Applications dealing with
        real-time data streams, such as event processing or telemetry data ingestion, can benefit
        from high throughput FIFO queues to handle the continuous influx of messages while
        preserving their order for accurate analysis.
    
      E-commerce order processing: In e-commerce platforms
        where maintaining the order of customer transactions is critical, high throughput FIFO
        queues ensure that orders are processed sequentially and without delays, even during peak
        shopping seasons.
    
      Financial services: Financial institutions handling
        high-frequency trading or transactional data rely on high throughput FIFO Queues to process
        market data and transactions with minimal latency while adhering to strict regulatory
        requirements for message ordering.
    
      Media streaming: Streaming platforms and media
        distribution services utilize high throughput FIFO queues to manage the delivery of media
        files and streaming content, ensuring smooth playback experiences for users while
        maintaining the correct order of content delivery.
    
 
  Partitions and data distribution for high
      throughput for SQS FIFO queues
  Amazon SQS stores FIFO queue data in partitions. A partition is an
    allocation of storage for a queue that is automatically replicated across multiple Availability
    Zones within an AWS Region. You don't manage partitions. Instead, Amazon SQS handles partition
    management.
  For FIFO queues, Amazon SQS modifies the number of partitions in a queue in the following
    situations:
  
     
     
  
      If the current request rate approaches or exceeds what the existing partitions can
        support, additional partitions are allocated until the queue reaches the regional quota. For
        information on quotas, see Amazon SQS message quotas.
    
      If the current partitions have low utilization, the number of partitions may be
        reduced.
    
  Partition management occurs automatically in the background and is transparent to your
    applications. Your queue and messages are available at all times.
   
    Distributing data by message group IDs
    To add a message to a FIFO queue, Amazon SQS uses the value of each message’s message group ID
      as input to an internal hash function. The output value from the hash function determines
      which partition stores the message.
    The following diagram shows a queue that spans multiple partitions. The queue’s message
      group ID is based on item number. Amazon SQS uses its hash function to determine where to store a
      new item; in this case, it's based on the hash value of the string item0. Note
      that the items are stored in the same order in which they are added to the queue. Each item's
      location is determined by the hash value of its message group ID.
    
       
        
       
       
    
    NoteAmazon SQS is optimized for uniform distribution of items across a FIFO queue's partitions,
        regardless of the number of partitions. AWS recommends that you use message group IDs that
        can have a large number of distinct values. 
   
   
    Optimizing partition
        utilization
    Each partition supports up to 3,000 messages per second with batching, or up to 300
      messages per second for send, receive, and delete operations in supported regions. For more
      information on high throughput message quotas, 
      see Amazon SQS service quotas
      in the Amazon Web Services General Reference.
    When using batch APIs, each message is routed based on the process described in
      Distributing data by message group IDs.
      Messages that are routed to the same partition are grouped and processed in a single transaction.
    To optimize partition utilization for the SendMessageBatch API, AWS recommends batching
      messages with the same message group IDs when possible.
    To optimize partition utilization for the DeleteMessageBatch and
        ChangeMessageVisibilityBatch APIs, AWS recommends using
        ReceiveMessage requests with the MaxNumberOfMessages parameter set
      to 10, and batching the receipt-handles returned by a single ReceiveMessage
      request.
    In the following example, a batch of messages with various message group IDs is sent. The
      batch is split into three groups, each of which counts against the quota for the
      partition.
    
       
        
       
       
    
    NoteAmazon SQS only guarantees that messages with the same message group ID's internal hash
        function are grouped within a batch request. Depending on the output of the internal hash
        function and the number of partitions, messages with different message group IDs might be
        grouped. Since the hash function or number of partitions can change at any time, messages
        that are grouped at one point may not be grouped later.
   
Document ConventionsFIFO queue and Lambda concurrency behaviorEnabling high throughput for FIFO
        queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUse casesPartitions and data distributionHigh throughput for FIFO queues in Amazon SQSHigh throughput FIFO queues in Amazon SQS efficiently manage high message throughput while
    maintaining strict message order, ensuring reliability and scalability for applications
    processing numerous messages. This solution is ideal for scenarios demanding both high
    throughput and ordered message delivery.Amazon SQS high throughput FIFO queues are not necessary in scenarios where strict message
    ordering is not crucial and where the volume of incoming messages is relatively low or sporadic.
    For instance, if you have a small-scale application that processes infrequent or non-sequential
    messages, the added complexity and cost associated with high throughput FIFO queues may not be
    justified. Additionally, if your application does not require the enhanced throughput
    capabilities provided by high throughput FIFO queues, opting for a standard Amazon SQS queue might be
    more cost-effective and simpler to manage.To enhance request capacity in high throughput FIFO queues, increasing the number of message
    groups is recommended. For more information on high throughput message quotas, see Amazon SQS service
      quotas in the Amazon Web Services General Reference.For information per-queue quotas and data distribution strategies, see Amazon SQS message quotas and Partitions and data distribution for high
      throughput for SQS FIFO queues.
  Use cases for high throughput for Amazon SQS FIFO
      queues
  The following use cases highlight the diverse applications of high throughput FIFO queues,
    showcasing their effectiveness across industries and scenarios:
  
     
     
     
     
  
      Real-time data processing: Applications dealing with
        real-time data streams, such as event processing or telemetry data ingestion, can benefit
        from high throughput FIFO queues to handle the continuous influx of messages while
        preserving their order for accurate analysis.
    
      E-commerce order processing: In e-commerce platforms
        where maintaining the order of customer transactions is critical, high throughput FIFO
        queues ensure that orders are processed sequentially and without delays, even during peak
        shopping seasons.
    
      Financial services: Financial institutions handling
        high-frequency trading or transactional data rely on high throughput FIFO Queues to process
        market data and transactions with minimal latency while adhering to strict regulatory
        requirements for message ordering.
    
      Media streaming: Streaming platforms and media
        distribution services utilize high throughput FIFO queues to manage the delivery of media
        files and streaming content, ensuring smooth playback experiences for users while
        maintaining the correct order of content delivery.
    
 
  Partitions and data distribution for high
      throughput for SQS FIFO queues
  Amazon SQS stores FIFO queue data in partitions. A partition is an
    allocation of storage for a queue that is automatically replicated across multiple Availability
    Zones within an AWS Region. You don't manage partitions. Instead, Amazon SQS handles partition
    management.
  For FIFO queues, Amazon SQS modifies the number of partitions in a queue in the following
    situations:
  
     
     
  
      If the current request rate approaches or exceeds what the existing partitions can
        support, additional partitions are allocated until the queue reaches the regional quota. For
        information on quotas, see Amazon SQS message quotas.
    
      If the current partitions have low utilization, the number of partitions may be
        reduced.
    
  Partition management occurs automatically in the background and is transparent to your
    applications. Your queue and messages are available at all times.
   
    Distributing data by message group IDs
    To add a message to a FIFO queue, Amazon SQS uses the value of each message’s message group ID
      as input to an internal hash function. The output value from the hash function determines
      which partition stores the message.
    The following diagram shows a queue that spans multiple partitions. The queue’s message
      group ID is based on item number. Amazon SQS uses its hash function to determine where to store a
      new item; in this case, it's based on the hash value of the string item0. Note
      that the items are stored in the same order in which they are added to the queue. Each item's
      location is determined by the hash value of its message group ID.
    
       
        
       
       
    
    NoteAmazon SQS is optimized for uniform distribution of items across a FIFO queue's partitions,
        regardless of the number of partitions. AWS recommends that you use message group IDs that
        can have a large number of distinct values. 
   
   
    Optimizing partition
        utilization
    Each partition supports up to 3,000 messages per second with batching, or up to 300
      messages per second for send, receive, and delete operations in supported regions. For more
      information on high throughput message quotas, 
      see Amazon SQS service quotas
      in the Amazon Web Services General Reference.
    When using batch APIs, each message is routed based on the process described in
      Distributing data by message group IDs.
      Messages that are routed to the same partition are grouped and processed in a single transaction.
    To optimize partition utilization for the SendMessageBatch API, AWS recommends batching
      messages with the same message group IDs when possible.
    To optimize partition utilization for the DeleteMessageBatch and
        ChangeMessageVisibilityBatch APIs, AWS recommends using
        ReceiveMessage requests with the MaxNumberOfMessages parameter set
      to 10, and batching the receipt-handles returned by a single ReceiveMessage
      request.
    In the following example, a batch of messages with various message group IDs is sent. The
      batch is split into three groups, each of which counts against the quota for the
      partition.
    
       
        
       
       
    
    NoteAmazon SQS only guarantees that messages with the same message group ID's internal hash
        function are grouped within a batch request. Depending on the output of the internal hash
        function and the number of partitions, messages with different message group IDs might be
        grouped. Since the hash function or number of partitions can change at any time, messages
        that are grouped at one point may not be grouped later.
   
Document ConventionsFIFO queue and Lambda concurrency behaviorEnabling high throughput for FIFO
        queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationReference guideService endpointsService quotasAmazon Simple Queue Service endpoints and quotasTo connect programmatically to an AWS service, you use an endpoint. AWS services offer the following endpoint types 
                in some or all of the AWS Regions that the service supports: IPv4 endpoints, IPv6 endpoints, dual-stack endpoints, and FIPS endpoints.
                Some services provide global endpoints. For more information, see AWS service endpoints.Service quotas, also referred to as limits, are the maximum number of service resources or operations for your AWS account.
				For more information, see AWS service quotas.The following are the service endpoints and service quotas for this service.
        Service endpoints

         
            Amazon SQS
            


         
            Region Name
            Region
            Endpoint
            Protocol
            
         
      
         
            US East (Ohio)
            us-east-2
            
               
                  sqs.us-east-2.amazonaws.com
               
               
                  sqs-fips.us-east-2.amazonaws.com
               
               
                  sqs.us-east-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
            US East (N. Virginia)
            us-east-1
            
               
                  sqs.us-east-1.amazonaws.com
               
               
                  sqs-fips.us-east-1.amazonaws.com
               
               
                  sqs.us-east-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
         
         
         
         
         
         
         
            US West (N. California)
            us-west-1
            
               
                  sqs.us-west-1.amazonaws.com
               
               
                  sqs-fips.us-west-1.amazonaws.com
               
               
                  sqs.us-west-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
            US West (Oregon)
            us-west-2
            
               
                  sqs.us-west-2.amazonaws.com
               
               
                  sqs-fips.us-west-2.amazonaws.com
               
               
                  sqs.us-west-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
            Africa (Cape Town)
            af-south-1
            
               
                  sqs.af-south-1.amazonaws.com
               
               
                  sqs.af-south-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Hong Kong)
            ap-east-1
            
               
                  sqs.ap-east-1.amazonaws.com
               
               
                  sqs.ap-east-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Hyderabad)
            ap-south-2
            
               
                  sqs.ap-south-2.amazonaws.com
               
               
                  sqs.ap-south-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Jakarta)
            ap-southeast-3
            
               
                  sqs.ap-southeast-3.amazonaws.com
               
               
                  sqs.ap-southeast-3.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Malaysia)
            ap-southeast-5
            
               
                  sqs.ap-southeast-5.amazonaws.com
               
               
                  sqs.ap-southeast-5.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Melbourne)
            ap-southeast-4
            
               
                  sqs.ap-southeast-4.amazonaws.com
               
               
                  sqs.ap-southeast-4.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Mumbai)
            ap-south-1
            
               
                  sqs.ap-south-1.amazonaws.com
               
               
                  sqs.ap-south-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Osaka)
            ap-northeast-3
            
               
                  sqs.ap-northeast-3.amazonaws.com
               
               
                  sqs.ap-northeast-3.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Seoul)
            ap-northeast-2
            
               
                  sqs.ap-northeast-2.amazonaws.com
               
               
                  sqs.ap-northeast-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Singapore)
            ap-southeast-1
            
               
                  sqs.ap-southeast-1.amazonaws.com
               
               
                  sqs.ap-southeast-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Sydney)
            ap-southeast-2
            
               
                  sqs.ap-southeast-2.amazonaws.com
               
               
                  sqs.ap-southeast-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
         
            Asia Pacific (Thailand)
            ap-southeast-7
            
               
                  sqs.ap-southeast-7.amazonaws.com
               
               
                  sqs.ap-southeast-7.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Asia Pacific (Tokyo)
            ap-northeast-1
            
               
                  sqs.ap-northeast-1.amazonaws.com
               
               
                  sqs.ap-northeast-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Canada (Central)
            ca-central-1
            
               
                  sqs.ca-central-1.amazonaws.com
               
               
                  sqs-fips.ca-central-1.amazonaws.com
               
               
                  sqs.ca-central-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
            Canada West (Calgary)
            ca-west-1
            
               
                  sqs.ca-west-1.amazonaws.com
               
               
                  sqs-fips.ca-west-1.amazonaws.com
               
               
                  sqs.ca-west-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTPS
               HTTP and HTTPS
            
            
         
         
         
         
         
         
            Europe (Frankfurt)
            eu-central-1
            
               
                  sqs.eu-central-1.amazonaws.com
               
               
                  sqs.eu-central-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Ireland)
            eu-west-1
            
               
                  sqs.eu-west-1.amazonaws.com
               
               
                  sqs.eu-west-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (London)
            eu-west-2
            
               
                  sqs.eu-west-2.amazonaws.com
               
               
                  sqs.eu-west-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Milan)
            eu-south-1
            
               
                  sqs.eu-south-1.amazonaws.com
               
               
                  sqs.eu-south-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Paris)
            eu-west-3
            
               
                  sqs.eu-west-3.amazonaws.com
               
               
                  sqs.eu-west-3.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Spain)
            eu-south-2
            
               
                  sqs.eu-south-2.amazonaws.com
               
               
                  sqs.eu-south-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Stockholm)
            eu-north-1
            
               
                  sqs.eu-north-1.amazonaws.com
               
               
                  sqs.eu-north-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Europe (Zurich)
            eu-central-2
            
               
                  sqs.eu-central-2.amazonaws.com
               
               
                  sqs.eu-central-2.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Israel (Tel Aviv)
            il-central-1
            
               
                  sqs.il-central-1.amazonaws.com
               
               
                  sqs.il-central-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Mexico (Central)
            mx-central-1
            
               
                  sqs.mx-central-1.amazonaws.com
               
               
                  sqs.mx-central-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Middle East (Bahrain)
            me-south-1
            
               
                  sqs.me-south-1.amazonaws.com
               
               
                  sqs.me-south-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            Middle East (UAE)
            me-central-1
            
               
                  sqs.me-central-1.amazonaws.com
               
               
                  sqs.me-central-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            South America (São Paulo)
            sa-east-1
            
               
                  sqs.sa-east-1.amazonaws.com
               
               
                  sqs.sa-east-1.api.aws
               
            
            
               HTTP and HTTPS
               HTTP and HTTPS
            
            
         
         
            
               AWS GovCloud (US-East)
            us-gov-east-1
            
               sqs.us-gov-east-1.amazonaws.com
            
            HTTP and HTTPS
            
         
         
            
               AWS GovCloud (US-West)
            us-gov-west-1
            
               sqs.us-gov-west-1.amazonaws.com
            
            HTTP and HTTPS
            
         
      

         

         
            Legacy endpoints
            If you use the AWS CLI or SDK for Python, you can use the following legacy endpoints. 
            
                        
                            Region Name
                            Region
                            Endpoint
                            Protocol
                        
                    
                        
                            US East (Ohio)
                            us-east-2
                            us-east-2.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            US East (N. Virginia)
                            us-east-1
                            queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            US West (N. California)
                            us-west-1
                            us-west-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            US West (Oregon)
                            us-west-2
                            us-west-2.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Africa (Cape Town)
                            af-south-1
                            af-south-1.queue.amazonaws.com
                            HTTP
                        
                        
                            Asia Pacific (Mumbai)
                            ap-south-1
                            ap-south-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Asia Pacific (Osaka)
                            ap-northeast-3
                            ap-northeast-3.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Asia Pacific (Seoul)
                            ap-northeast-2
                            ap-northeast-2.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Asia Pacific (Singapore)
                            ap-southeast-1
                            ap-southeast-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Asia Pacific (Sydney)
                            ap-southeast-2
                            ap-southeast-2.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Asia Pacific (Tokyo)
                            ap-northeast-1
                            ap-northeast-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Canada (Central)
                            ca-central-1
                            ca-central-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            China (Beijing)
                            cn-north-1
                            cn-north-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            China (Ningxia)
                            cn-northwest-1
                            cn-northwest-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Europe (Frankfurt)
                            eu-central-1
                            eu-central-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Europe (Ireland)
                            eu-west-1
                            eu-west-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Europe (London)
                            eu-west-2
                            eu-west-2.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                        
                            Europe (Paris)
                            eu-west-3
                            eu-west-3.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            Europe (Stockholm)
                            eu-north-1
                            eu-north-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                        
                            South America (São Paulo)
                            sa-east-1
                            sa-east-1.queue.amazonaws.com
                            HTTP and HTTPS
                        
                    
         
     
        Service quotas

        
                    
                        Name
                        Default
                        Adjustable
                        Description
                    
                
                    
                        Actions per Queue Policy
                        Each supported Region: 7
                        No
                        The number of actions in a queue policy.
                    
                    
                        Attributes per Message
                        Each supported Region: 10
                        No
                        The number of attributes added to a message.
                    
                    
                        Batched Message ID Length
                        Each supported Region: 80
                        No
                        The length of a batched message ID.
                    
                    
                        Batched Message Throughput for FIFO Queues
                        Each supported Region: 3,000
                        No
                        The number of batched transactions per second (TPS)
                            for FIFO queues.
                    
                    
                        Batched Message High Throughput for FIFO
                            Queues
                        Supported Regions (US East (N. Virginia),
                                US West (Oregon), and Europe (Ireland)): 700,000
                             Europe (Frankfurt) and US East (Ohio): 180,000
                            Asia Pacific (Mumbai), Asia Pacific (Singapore),
                                Asia Pacific (Sydney) and Asia Pacific (Tokyo): 90,000
                            Europe (London) and South America (São Paulo):45,000
                            All other supported Regions: 24,000
                        No
                        The number of batched transactions per second (TPS)
                            for FIFO queues.
                    
                    
                        Conditions per Queue Policy
                        Each supported Region: 10
                        No
                        The number of conditions in a queue policy.
                    
                    
                        In-Flight Messages per FIFO Queue
                        Each supported Region: 120,000
                        Contact AWS Support
                        The number of in-flight messages in a FIFO
                            queue.
                    
                    
                        In-Flight Messages per Standard Queue
                        Each supported Region: 120,000
                        Yes
                        The number of in-flight messages in a standard
                            queue.
                    
                    
                        Message Invisibility Period
                        Each supported Region: 0 Seconds
                        No
                        The length of time, in seconds, for which Amazon SQS
                            retains a message if it isn't deleted. The maximum is 14 days (1,209,600
                            seconds).
                    
                    
                        Message Size
                        Each supported Region: 256 Kilobytes
                        No
                        The size of a message, in kilobytes.
                    
                    
                        Message Size in Amazon S3 Bucket
                        Each supported Region: 2 Gigabytes
                        No
                        The size of a message, in gigabytes, in an Amazon S3
                            bucket.
                    
                    
                        Messages per Batch
                        Each supported Region: 10
                        No
                        The number of messages in a message batch.
                    
                    
                        Principals per Queue Policy
                        Each supported Region: 50
                        No
                        The length of time, in minutes, by which to delay the
                            initial delivery of messages to a queue.
                    
                    
                        Queue Name Length
                        Each supported Region: 80
                        No
                        The queue name length.
                    
                    
                        Queue Policy Size
                        Each supported Region: 8,192 Bytes
                        No
                        The size, in bytes, of a queue policy.
                    
                    
                        Statements per Queue Policy
                        Each supported Region: 20
                        No
                        The number of tags added to a queue.
                    
                    
                        UTF-8 Queue Tag Key Length
                        Each supported Region: 128
                        No
                        The length of a UTF-8 queue tag key.
                    
                    
                        UTF-8 Queue Tag Value Length
                        Each supported Region: 256
                        No
                        The length of a UTF-8 queue tag value.
                    
                    
                        Unbatched Message Throughput for FIFO Queues
                        Each supported Region: 300
                        No
                        The number of unbatched transactions per second (TPS)
                            for FIFO queues.
                    
                    
                        Unbatched Message High Throughput for FIFO
                            Queues
                        
                            Supported Regions (US East (N. Virginia), US West (Oregon), and
                                Europe (Ireland)): 70,000
                            US East (Ohio) and Europe (Frankfurt): 18,000
                            Supported Regions (Asia Pacific (Mumbai), Asia Pacific (Singapore),
                                Asia Pacific (Sydney), Asia Pacific (Tokyo)): 9,000
                            Europe (London) and South America (São Paulo): 4,500
                            All other supported Regions: 2,400
                        
                        No
                        The number of unbatched transactions per second (TPS)
                            for FIFO queues.
                    
                
        For more information, see Amazon SQS
                quotas in the Amazon Simple Queue Service Developer Guide and the Limits and restrictions section of the
                Amazon SQS FAQs.
    Document ConventionsAmazon SNSAWS STSDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS message quotasThe following table lists quotas related to messages.
        
          Quota
          Description
        
      
        
          Batched message ID
          A batched message ID can have up to 80 characters. The following characters are accepted: alphanumeric characters, hyphens (-), and underscores (_).
        
        
          Message attributes
          A message can contain up to 10 metadata attributes.
        
        
          Message batch
          
            A single message batch request can include a maximum of 10 messages. For more
              information, see Configuring
						AmazonSQSBufferedAsyncClient in the Amazon SQS batch actions
              section.
          
        
        
          Message content
          
            A message can include only XML, JSON, and unformatted text. The following Unicode
              characters are allowed: #x9 | #xA | #xD |
                #x20 to #xD7FF | #xE000 to
                #xFFFD | #x10000 to #x10FFFF
            Any characters not included in this list are rejected. For more information, see
              the W3C specification for
                characters.
          
        
        
          Message group ID
          Consume messages from the backlog to avoid building up a large backlog of
              messages with the same message group ID.MessageGroupId is
              required for FIFO queues. You can't use it for Standard queues.You must
              associate a non-empty MessageGroupId with a message. If you don't provide
              a MessageGroupId, the action fails. The length of
                MessageGroupId is 128 characters. Valid values: alphanumeric characters
              and punctuation (!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~).
          
        
        
          Message retention
          By default, a message is retained for 4 days. The minimum is 60 seconds (1 minute).
            The maximum is 1,209,600 seconds (14 days).
        
        
          Message throughput
          
            Standard
                queuesStandard queues support a very high, nearly unlimited number of API calls per second, per action 
    (SendMessage, ReceiveMessage, or DeleteMessage). This high throughput makes them ideal for use cases that require processing large volumes of messages quickly, such as real-time data streaming or large-scale applications. While standard queues scale automatically with demand, it is essential to monitor usage patterns to ensure optimal performance, especially in regions with higher workloads.
        
        
          
            FIFO queues
                
            
               
               
            
                Each partition in a FIFO queue is limited to 300 transactions per second, per
                  API action (SendMessage, ReceiveMessage, and
                    DeleteMessage). This limit applies specifically to non-high
                  throughput mode. By switching to high throughput mode, you can surpass this
                  default limit. To
                  enable high-throughput mode, see Enabling high throughput for FIFO queues in
        Amazon SQS.
              
                If you use batching, non-high throughput FIFO queues support up to 3,000
                  messages per second, per API action (SendMessage,
                    ReceiveMessage, and DeleteMessage). The 3,000 messages
                  per second represent 300 API calls, each with a batch of 10 messages.
              
            High throughput for
                  FIFO queues 
            Amazon SQS FIFO limits are based on the number of API requests, not message limits. For
              high throughput mode, these API request limits are as follows:
            Transaction throughput limits (Non-batching API
                calls)
            These limits define how frequently each API operation (such as SendMessage, ReceiveMessage, or DeleteMessage) can be performed independently, ensuring efficient system
              performance within the allowed transactions per second (TPS).
             The following limits are based on non-batched API calls:
            
               
               
               
               
               
            
                US East (N. Virginia), US West (Oregon), and Europe (Ireland): Up to 70,000
                  transactions per second (TPS).
              
                US East (Ohio) and Europe (Frankfurt): Up to 19,000 TPS.
              
                Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), and
                  Asia Pacific (Tokyo): Up to 9,000 TPS.
              
                Europe (London) and South America (São Paulo): Up to 4,500 TPS.
              
                All other AWS Regions: Default throughput of 2,400 TPS.
              
            Maximizing throughput with batching
            Processes multiple messages in a single API call, which significantly increasing
              efficiency. Instead of handling each message individually, batching allows you to
              send, receive, or delete up to 10 messages in a single API request. This reduces the
              total number of API calls, allowing you to process more messages per second while
              staying within the transaction limits (TPS) for the region, maximizing throughput and
              system performance. For more information, see Increasing throughput
				using horizontal scaling and action batching with Amazon SQS.
            The following limits are based on batched API calls:
            
               
               
               
               
               
            
                US East (N. Virginia), US West (Oregon), and Europe (Ireland): Up to 700,000
                  messages per second (10x the non-batch limit of 70,000 TPS).
              
                US East (Ohio) and Europe (Frankfurt): Up to 190,000 messages per
                  second.
              
                Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), and
                  Asia Pacific (Tokyo): Up to 90,000 messages per second.
              
                Europe (London) and South America (São Paulo): Up to 45,000 messages per
                  second.
              
                All other AWS Regions: Up to 24,000 messages per second.
              
            Optimizing throughput beyond batching
            While batching can greatly increase throughput, it’s important to consider other
              strategies for optimizing FIFO performance:
            
               
               
               
               
            
                Distribute messages across multiple message group
                    IDs – Since messages within a single group are processed
                  sequentially, distributing your workload across multiple message groups allows for
                  better parallelism and higher overall throughput. For more information, see Partitions and data distribution for high
      throughput for SQS FIFO queues. 
              
                Efficient use of API calls – Minimize
                  unnecessary API calls, such as frequent visibility changes or repeated message
                  deletions, to optimize the use of your available TPS and improve
                  efficiency.
              
                Use long poll receives – Utilize long polling
                  by setting WaitTimeSeconds in your receive requests to reduce empty
                  responses when no messages are available, lowering unnecessary API calls and
                  making better use of your TPS quota.
              
                Requesting throughput increases – If
                  your application requires throughput higher than the default limits, request an increase
                  using the Service Quotas console. This can be necessary for high-demand workloads
                  or in regions with lower default limits. To
                  enable high-throughput mode, see Enabling high throughput for FIFO queues in
        Amazon SQS.
              
          
        
        
          Message timer
          The default (minimum) delay for a message is 0 seconds. The maximum is 15 minutes.
        
        
          Message size
          
            The minimum message size is 1 byte (1 character). The maximum is 262,144 bytes
              (256 KiB).
            To send messages larger than 256 KiB, you can use the Amazon SQS Extended Client Library for Java and the Amazon SQS
                Extended Client Library for Python. This library allows you to send an Amazon SQS
              message that contains a reference to a message payload in Amazon S3. The maximum payload
              size is 2 GB.
            NoteThis extended library works only for synchronous clients.
          
        
        
          Message visibility timeout
          The default visibility timeout for a message is 30 seconds. The minimum is 0 seconds. The maximum is 12 hours.
        
        
          Policy information
          The maximum quota is 8,192 bytes, 20 statements, 50 principals, or 10 conditions.
            For more information, see Amazon SQS policy quotas.
        
      Document ConventionsStandard queue quotasPolicy quotasDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUse casesPartitions and data distributionHigh throughput for FIFO queues in Amazon SQSHigh throughput FIFO queues in Amazon SQS efficiently manage high message throughput while
    maintaining strict message order, ensuring reliability and scalability for applications
    processing numerous messages. This solution is ideal for scenarios demanding both high
    throughput and ordered message delivery.Amazon SQS high throughput FIFO queues are not necessary in scenarios where strict message
    ordering is not crucial and where the volume of incoming messages is relatively low or sporadic.
    For instance, if you have a small-scale application that processes infrequent or non-sequential
    messages, the added complexity and cost associated with high throughput FIFO queues may not be
    justified. Additionally, if your application does not require the enhanced throughput
    capabilities provided by high throughput FIFO queues, opting for a standard Amazon SQS queue might be
    more cost-effective and simpler to manage.To enhance request capacity in high throughput FIFO queues, increasing the number of message
    groups is recommended. For more information on high throughput message quotas, see Amazon SQS service
      quotas in the Amazon Web Services General Reference.For information per-queue quotas and data distribution strategies, see Amazon SQS message quotas and Partitions and data distribution for high
      throughput for SQS FIFO queues.
  Use cases for high throughput for Amazon SQS FIFO
      queues
  The following use cases highlight the diverse applications of high throughput FIFO queues,
    showcasing their effectiveness across industries and scenarios:
  
     
     
     
     
  
      Real-time data processing: Applications dealing with
        real-time data streams, such as event processing or telemetry data ingestion, can benefit
        from high throughput FIFO queues to handle the continuous influx of messages while
        preserving their order for accurate analysis.
    
      E-commerce order processing: In e-commerce platforms
        where maintaining the order of customer transactions is critical, high throughput FIFO
        queues ensure that orders are processed sequentially and without delays, even during peak
        shopping seasons.
    
      Financial services: Financial institutions handling
        high-frequency trading or transactional data rely on high throughput FIFO Queues to process
        market data and transactions with minimal latency while adhering to strict regulatory
        requirements for message ordering.
    
      Media streaming: Streaming platforms and media
        distribution services utilize high throughput FIFO queues to manage the delivery of media
        files and streaming content, ensuring smooth playback experiences for users while
        maintaining the correct order of content delivery.
    
 
  Partitions and data distribution for high
      throughput for SQS FIFO queues
  Amazon SQS stores FIFO queue data in partitions. A partition is an
    allocation of storage for a queue that is automatically replicated across multiple Availability
    Zones within an AWS Region. You don't manage partitions. Instead, Amazon SQS handles partition
    management.
  For FIFO queues, Amazon SQS modifies the number of partitions in a queue in the following
    situations:
  
     
     
  
      If the current request rate approaches or exceeds what the existing partitions can
        support, additional partitions are allocated until the queue reaches the regional quota. For
        information on quotas, see Amazon SQS message quotas.
    
      If the current partitions have low utilization, the number of partitions may be
        reduced.
    
  Partition management occurs automatically in the background and is transparent to your
    applications. Your queue and messages are available at all times.
   
    Distributing data by message group IDs
    To add a message to a FIFO queue, Amazon SQS uses the value of each message’s message group ID
      as input to an internal hash function. The output value from the hash function determines
      which partition stores the message.
    The following diagram shows a queue that spans multiple partitions. The queue’s message
      group ID is based on item number. Amazon SQS uses its hash function to determine where to store a
      new item; in this case, it's based on the hash value of the string item0. Note
      that the items are stored in the same order in which they are added to the queue. Each item's
      location is determined by the hash value of its message group ID.
    
       
        
       
       
    
    NoteAmazon SQS is optimized for uniform distribution of items across a FIFO queue's partitions,
        regardless of the number of partitions. AWS recommends that you use message group IDs that
        can have a large number of distinct values. 
   
   
    Optimizing partition
        utilization
    Each partition supports up to 3,000 messages per second with batching, or up to 300
      messages per second for send, receive, and delete operations in supported regions. For more
      information on high throughput message quotas, 
      see Amazon SQS service quotas
      in the Amazon Web Services General Reference.
    When using batch APIs, each message is routed based on the process described in
      Distributing data by message group IDs.
      Messages that are routed to the same partition are grouped and processed in a single transaction.
    To optimize partition utilization for the SendMessageBatch API, AWS recommends batching
      messages with the same message group IDs when possible.
    To optimize partition utilization for the DeleteMessageBatch and
        ChangeMessageVisibilityBatch APIs, AWS recommends using
        ReceiveMessage requests with the MaxNumberOfMessages parameter set
      to 10, and batching the receipt-handles returned by a single ReceiveMessage
      request.
    In the following example, a batch of messages with various message group IDs is sent. The
      batch is split into three groups, each of which counts against the quota for the
      partition.
    
       
        
       
       
    
    NoteAmazon SQS only guarantees that messages with the same message group ID's internal hash
        function are grouped within a batch request. Depending on the output of the internal hash
        function and the number of partitions, messages with different message group IDs might be
        grouped. Since the hash function or number of partitions can change at any time, messages
        that are grouped at one point may not be grouped later.
   
Document ConventionsFIFO queue and Lambda concurrency behaviorEnabling high throughput for FIFO
        queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideUsing
					AmazonSQSBufferedAsyncClientEnabling client-side
				buffering and request batching with Amazon SQSThe AWS SDK for Java includes
				AmazonSQSBufferedAsyncClient which accesses Amazon SQS. This client allows
			for simple request batching using client-side buffering. Calls made from the client are
			first buffered and then sent as a batch request to Amazon SQS.Client-side buffering allows up to 10 requests to be buffered and sent as a batch
			request, decreasing your cost of using Amazon SQS and reducing the number of sent requests.
				AmazonSQSBufferedAsyncClient buffers both synchronous and asynchronous
			calls. Batched requests and support for long
				polling can also help increase throughput. For more information, see Increasing throughput
				using horizontal scaling and action batching with Amazon SQS.Because AmazonSQSBufferedAsyncClient implements the same interface as
				AmazonSQSAsyncClient, migrating from AmazonSQSAsyncClient
			to AmazonSQSBufferedAsyncClient typically requires only minimal changes to
			your existing code.NoteThe Amazon SQS Buffered Asynchronous Client doesn't currently support FIFO queues.
			Using
					AmazonSQSBufferedAsyncClient
			Before you begin, complete the steps in Setting up Amazon SQS. 
			 
				AWS SDK for Java
						1.x
				For AWS SDK for Java 1.x, you can create a new
						AmazonSQSBufferedAsyncClient based on the following
					example:
				// Create the basic Amazon SQS async client
final AmazonSQSAsync sqsAsync = new AmazonSQSAsyncClient();
 
// Create the buffered client
final AmazonSQSAsync bufferedSqs = new AmazonSQSBufferedAsyncClient(sqsAsync);
				After you create the new AmazonSQSBufferedAsyncClient, you can
					use it to send multiple requests to Amazon SQS (just as you can with
						AmazonSQSAsyncClient), for example:
				final CreateQueueRequest createRequest = new CreateQueueRequest().withQueueName("MyQueue");
 
final CreateQueueResult res = bufferedSqs.createQueue(createRequest);
 
final SendMessageRequest request = new SendMessageRequest();
final String body = "Your message text" + System.currentTimeMillis();
request.setMessageBody( body );
request.setQueueUrl(res.getQueueUrl());
 
final Future<SendMessageResult> sendResult = bufferedSqs.sendMessageAsync(request);
 
final ReceiveMessageRequest receiveRq = new ReceiveMessageRequest()
    .withMaxNumberOfMessages(1)
    .withQueueUrl(queueUrl);
final ReceiveMessageResult rx = bufferedSqs.receiveMessage(receiveRq);
			 
			 
				Configuring
						AmazonSQSBufferedAsyncClient
				AmazonSQSBufferedAsyncClient is preconfigured with settings that
					work for most use cases. You can further configure
						AmazonSQSBufferedAsyncClient, for example:
				
						Create an instance of the QueueBufferConfig class with
							the required configuration parameters.
					
						Provide the instance to the AmazonSQSBufferedAsyncClient
							constructor.
					
				// Create the basic Amazon SQS async client
final AmazonSQSAsync sqsAsync = new AmazonSQSAsyncClient();
 
final QueueBufferConfig config = new QueueBufferConfig()
    .withMaxInflightReceiveBatches(5)
    .withMaxDoneReceiveBatches(15);
 
// Create the buffered client
final AmazonSQSAsync bufferedSqs = new AmazonSQSBufferedAsyncClient(sqsAsync, config);
				QueueBufferConfig configuration parameters
							
								Parameter
								Default value
								Description
							
						
							
								longPoll
								true
								
									When longPoll is set to true,
											AmazonSQSBufferedAsyncClient attempts to
										use long polling when it consumes messages.
								
							
							
								longPollWaitTimeoutSeconds
								20 s
								
									The maximum amount of time (in seconds) which a
											ReceiveMessage call blocks off on the
										server, waiting for messages to appear in the queue before
										returning with an empty receive result.
									NoteWhen long polling is disabled, this setting has no
											effect.
								
							
							
								maxBatchOpenMs
								200 ms
								
									The maximum amount of time (in milliseconds) that an
										outgoing call waits for other calls with which it batches
										messages of the same type.
									The higher the setting, the fewer batches are required to
										perform the same amount of work (however, the first call in
										a batch has to spend a longer time waiting).
									When you set this parameter to 0, submitted
										requests don't wait for other requests, effectively
										disabling batching.
								
							
							
								maxBatchSize
								10 requests per batch
								
									The maximum number of messages that are batched together
										in a single request. The higher the setting, the fewer
										batches are required to carry out the same number of
										requests.
									Note10 requests per batch is the maximum allowed value for
											Amazon SQS.
								
							
							
								maxBatchSizeBytes
								256 KiB
								
									The maximum size of a message batch, in bytes, that the
										client attempts to send to Amazon SQS.
									Note256 KiB is the maximum allowed value for Amazon SQS.
								
							
							
								maxDoneReceiveBatches
								10 batches
								
									The maximum number of receive batches that
											AmazonSQSBufferedAsyncClient prefetches and
										stores client-side.
									The higher the setting, the more receive requests can be
										satisfied without having to make a call to Amazon SQS (however,
										the more messages are prefetched, the longer they remain in
										the buffer, causing their own visibility timeout to
										expire).
									Note0 indicates that all message pre-fetching
											is disabled and messages are consumed only on
											demand.
								
							
							
								maxInflightOutboundBatches
								5 batches
								
									The maximum number of active outbound batches that can be
										processed at the same time.
									The higher the setting, the faster outbound batches can be
										sent (subject to quotas such as CPU or bandwidth) and the
										more threads are consumed by
											AmazonSQSBufferedAsyncClient.
								
							
							
								maxInflightReceiveBatches
								10 batches
								
									The maximum number of active receive batches that can be
										processed at the same time.
									The higher the setting, the more messages can be received
										(subject to quotas such as CPU or bandwidth), and the more
										threads are consumed by
											AmazonSQSBufferedAsyncClient.
									Note0 indicates that all message pre-fetching
											is disabled and messages are consumed only on
											demand.
								
							
							
								visibilityTimeoutSeconds
								-1
								
									When this parameter is set to a positive, non-zero value,
										the visibility timeout set here overrides the visibility
										timeout set on the queue from which messages are
										consumed.
									Note-1 indicates that the default setting is
											selected for the queue.You can't set visibility timeout to
											0.
								
							
						
			 
			 
				AWS SDK for Java
						2.x
				For AWS SDK for Java 2.x, you can create a new
						SqsAsyncBatchManager based on the following example:
				// Create the basic Sqs Async Client
SqsAsyncClient sqs = SqsAsyncClient.builder() 
    .region(Region.US_EAST_1) 
    .build();

// Create the batch manager
SqsAsyncBatchManager sqsAsyncBatchManager = sqs.batchManager();
				After you create the new SqsAsyncBatchManager, you can use it to
					send multiple requests to Amazon SQS (just as you can with
						SqsAsyncClient), for example:
				final String queueName = "MyAsyncBufferedQueue" + UUID.randomUUID();
final CreateQueueRequest request = CreateQueueRequest.builder().queueName(queueName).build();
final String queueUrl = sqs.createQueue(request).join().queueUrl();
System.out.println("Queue created: " + queueUrl);


// Send messages
CompletableFuture<SendMessageResponse> sendMessageFuture;
for (int i = 0; i < 10; i++) {
    final int index = i;
    sendMessageFuture = sqsAsyncBatchManager.sendMessage(
            r -> r.messageBody("Message " + index).queueUrl(queueUrl));
    SendMessageResponse response= sendMessageFuture.join();
    System.out.println("Message " + response.messageId() + " sent!");
}

// Receive messages with customized configurations
CompletableFuture<ReceiveMessageResponse> receiveResponseFuture = customizedBatchManager.receiveMessage(
        r -> r.queueUrl(queueUrl)
                .waitTimeSeconds(10)
                .visibilityTimeout(20)
                .maxNumberOfMessages(10)
);
System.out.println("You have received " + receiveResponseFuture.join().messages().size() + " messages in total.");

// Delete messages
DeleteQueueRequest deleteQueueRequest =  DeleteQueueRequest.builder().queueUrl(queueUrl).build();
int code = sqs.deleteQueue(deleteQueueRequest).join().sdkHttpResponse().statusCode();
System.out.println("Queue is deleted, with statusCode " + code);
			 
			 
				Configuring
						SqsAsyncBatchManager
				SqsAsyncBatchManager is preconfigured with settings that work for
					most use cases. You can further configure SqsAsyncBatchManager, for
					example:
				Creating custom configuration via
					SqsAsyncBatchManager.Builder:
				SqsAsyncBatchManager customizedBatchManager = SqsAsyncBatchManager.builder() 
    .client(sqs)
    .scheduledExecutor(Executors.newScheduledThreadPool(5))
    .overrideConfiguration(b -> b 
        .maxBatchSize(10)
        .sendRequestFrequency(Duration.ofMillis(200))
        .receiveMessageMinWaitDuration(Duration.ofSeconds(10))
        .receiveMessageVisibilityTimeout(Duration.ofSeconds(20)) 
        .receiveMessageAttributeNames(Collections.singletonList("*"))
        .receiveMessageSystemAttributeNames(Collections.singletonList(MessageSystemAttributeName.ALL)))
    .build();
				BatchOverrideConfiguration parameters
							
								Parameter
								Default value
								Description
							
						
							
								maxBatchSize
								
									10 requests per batch
								
								The maximum number of messages that are batched
										together in a single request. The higher the setting, the
										fewer batches are required to carry out the same number of
										requests.
									NoteThe maximum allowed value for Amazon SQS is 10 requests per
											batch.
							
							
								sendRequestFrequency
								
									200 ms
								
								The maximum amount of time (in milliseconds) that an
										outgoing call waits for other calls with which it batches
										messages of the same type.
									The higher the setting, the fewer batches are required to
										perform the same amount of work (however, the first call in
										a batch has to spend a longer time waiting).
									When you set this parameter to 0, submitted
										requests don't wait for other requests, effectively
										disabling batching.
							
							
								receiveMessageVisibilityTimeout
								
									-1
								
								When this parameter is set to a positive, non-zero
										value, the visibility timeout set here overrides the
										visibility timeout set on the queue from which messages are
										consumed.
									Note
											1 indicates that the default setting is
											selected for the queue. You can't set visibility timeout
											to 0.
								
							
							
								receiveMessageMinWaitDuration
								
									50 ms
								
								The minimal amount of time (in milliseconds) that a
											receiveMessage call waits for available
										messages to be fetched. The higher the setting, the fewer
										batches are required to carry out the same number of
										request.
								
							
						
			 
		Document ConventionsBatch actionsIncreasing throughput
				using horizontal scaling and action batching with Amazon SQSDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConsuming messages using short pollingConsuming messages using long pollingDifferences between long and short
                pollingAmazon SQS short and long pollingAmazon SQS offers short and long polling options for receiving messages from a queue. Consider
        your application's requirements for responsiveness and cost efficiency when choosing between
        these two polling options:
         
         
    
            Short polling (default) – The ReceiveMessage
                request queries a subset of servers (based on a weighted random distribution) to
                find available messages and sends an immediate response, even if no messages are
                found. 
        
            Long polling – ReceiveMessage
                queries all servers for messages, sending a response once at least one message is
                available, up to the specified maximum. An empty response is sent only if the
                polling wait time expires. This option can reduce the number of empty responses and
                potentially lower costs.
        The following sections explain the details of short polling and long polling.
        Consuming messages using short polling
        When you consume messages from a queue (FIFO or standard) using short polling, Amazon SQS
            samples a subset of its servers (based on a weighted random distribution) and returns
            messages from only those servers. Thus, a particular ReceiveMessage
            request might not return all of your messages. However, if you have fewer than 1,000
            messages in your queue, a subsequent request will return your messages. If you keep
            consuming from your queues, Amazon SQS samples all of its servers, and you receive all of
            your messages.
        The following diagram shows the short-polling behavior of messages returned from a
            standard queue after one of your system components makes a receive request. Amazon SQS
            samples several of its servers (in gray) and returns messages A, C, D, and B from these
            servers. Message E isn't returned for this request, but is returned for a subsequent
            request.
        
             
                
             
             
        
     
        Consuming messages using long polling
        When the wait time for the ReceiveMessage API action is greater than 0, long polling
    is in effect. The maximum long polling wait time is 20 seconds. Long polling helps reduce the cost of using Amazon SQS by eliminating the number of empty responses
    (when there are no messages available for a ReceiveMessage request) and false
    empty responses (when messages are available but aren't included in a response). For information about enabling long polling for a new or
            existing queue using the Amazon SQS console, see the Configuring queue parameters using the Amazon SQS
      console. For best practices, see Setting-up long polling in
				Amazon SQS.
        Long polling offers the following benefits:
        
             
             
             
        
                Reduce empty responses by allowing Amazon SQS to wait until a message is available
                    in a queue before sending a response. Unless the connection times out, the
                    response to the ReceiveMessage request contains at least one of the
                    available messages, up to the maximum number of messages specified in the
                        ReceiveMessage action. In rare cases, you might receive empty
                    responses even when a queue still contains messages, especially if you specify a
                    low value for the ReceiveMessageWaitTimeSeconds parameter.
            
                Reduce false empty responses by querying all—rather than a subset
                    of—Amazon SQS servers.
            
                Return messages as soon as they become available.
            
        For information about how to confirm that a queue is empty, see Confirming that an Amazon SQS queue is empty.
     
        Differences between long and short
                polling
        Short polling occurs when the WaitTimeSeconds parameter of a ReceiveMessage request
            is set to 0 in one of two ways:
        
             
             
        
                The ReceiveMessage call sets WaitTimeSeconds to
                        0.
            
                The ReceiveMessage call doesn’t set WaitTimeSeconds,
                    but the queue attribute ReceiveMessageWaitTimeSeconds is set to
                        0.
            
    Document ConventionsCost allocation tagsVisibility timeoutDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideHorizontal scalingAction batchingWorking Java example for
					single-operation and batch requestsIncreasing throughput
				using horizontal scaling and action batching with Amazon SQSAmazon SQS supports high-throughput messaging. For details on throughput limits, refer to
				Amazon SQS message quotas.To maximize throughput:
			 
			 
		
				Scale producers and consumers
					horizontally by adding more instances of each.
			
				Use action batching to send or receive
					multiple messages in a single request, reducing API call overhead.
			
			Horizontal scaling
			Because you access Amazon SQS through an HTTP request-response protocol, the
					request latency (the interval between initiating a request
				and receiving a response) limits the throughput that you can achieve from a single
				thread using a single connection. For example, if the latency from an Amazon EC2-based
				client to Amazon SQS in the same region averages 20 ms, the maximum throughput from a
				single thread over a single connection averages 50 TPS. 
			Horizontal scaling involves increasing the number of message
				producers (which make SendMessage requests) and consumers (which make ReceiveMessage and
						DeleteMessage requests) in order to increase your overall queue
				throughput. You can scale horizontally in three ways:
			
				 
				 
				 
			
					Increase the number of threads per client
				
					Add more clients
				
					Increase the number of threads per client and add more clients
				
			When you add more clients, you achieve essentially linear gains in queue
				throughput. For example, if you double the number of clients, you also double the
				throughput. 
		 
			Action batching
			Batching performs more work during each round trip to the
				service (for example, when you send multiple messages with a single
					SendMessageBatch request). The Amazon SQS batch actions are SendMessageBatch, DeleteMessageBatch, and ChangeMessageVisibilityBatch. To take advantage of batching
				without changing your producers or consumers, you can use the Amazon SQS Buffered Asynchronous Client.
			NoteBecause ReceiveMessage can process 10 messages at a time, there
					is no ReceiveMessageBatch action.
			Batching distributes the latency of the batch action over the multiple messages in
				a batch request, rather than accept the entire latency for a single message (for
				example, a SendMessage request). Because each round trip carries more work,
				batch requests make more efficient use of threads and connections, improving
				throughput.
			You can combine batching with horizontal scaling to provide throughput with fewer
				threads, connections, and requests than individual message requests. You can use
				batched Amazon SQS actions to send, receive, or delete up to 10 messages at a time.
				Because Amazon SQS charges by the request, batching can substantially reduce your costs. 
			Batching can introduce some complexity for your application (for example, you
				application must accumulate messages before sending them, or it sometimes must wait
				longer for a response). However, batching can be still effective in the following
				cases: 
			
				 
				 
			
					Your application generates many messages in a short time, so the delay is
						never very long. 
				
					A message consumer fetches messages from a queue at its discretion, unlike
						typical message producers that need to send messages in response to events
						they don't control. 
				
			ImportantA batch request might succeed even though individual messages in the batch
					failed. After a batch request, always check for individual message failures and
					retry the action if necessary.
		 
			Working Java example for
					single-operation and batch requests
			 
				Prerequisites
				Add the aws-java-sdk-sqs.jar, aws-java-sdk-ec2.jar,
					and commons-logging.jar packages to your Java build class path. The
					following example shows these dependencies in a Maven project
						pom.xml file.
				<dependencies>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-sqs</artifactId>
        <version>LATEST</version>
    </dependency>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-ec2</artifactId>
        <version>LATEST</version>
    </dependency>
    <dependency>
        <groupId>commons-logging</groupId>
        <artifactId>commons-logging</artifactId>
        <version>LATEST</version>
    </dependency>
</dependencies>
			 
			 
				SimpleProducerConsumer.java
				The following Java code example implements a simple producer-consumer pattern.
					The main thread spawns a number of producer and consumer threads that process 1
					KB messages for a specified time. This example includes producers and consumers
					that make single-operation requests and those that make batch requests.
				/*
 * Copyright 2010-2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *  https://aws.amazon.com/apache2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 *
 */

import com.amazonaws.AmazonClientException;
import com.amazonaws.ClientConfiguration;
import com.amazonaws.services.sqs.AmazonSQS;
import com.amazonaws.services.sqs.AmazonSQSClientBuilder;
import com.amazonaws.services.sqs.model.*;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import java.math.BigInteger;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.Scanner;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Start a specified number of producer and consumer threads, and produce-consume
 * for the least of the specified duration and 1 hour. Some messages can be left
 * in the queue because producers and consumers might not be in exact balance.
 */
public class SimpleProducerConsumer {

    // The maximum runtime of the program.
    private final static int MAX_RUNTIME_MINUTES = 60;
    private final static Log log = LogFactory.getLog(SimpleProducerConsumer.class);

    public static void main(String[] args) throws InterruptedException {

        final Scanner input = new Scanner(System.in);

        System.out.print("Enter the queue name: ");
        final String queueName = input.nextLine();

        System.out.print("Enter the number of producers: ");
        final int producerCount = input.nextInt();

        System.out.print("Enter the number of consumers: ");
        final int consumerCount = input.nextInt();

        System.out.print("Enter the number of messages per batch: ");
        final int batchSize = input.nextInt();

        System.out.print("Enter the message size in bytes: ");
        final int messageSizeByte = input.nextInt();

        System.out.print("Enter the run time in minutes: ");
        final int runTimeMinutes = input.nextInt();

        /*
         * Create a new instance of the builder with all defaults (credentials
         * and region) set automatically. For more information, see Creating
         * Service Clients in the AWS SDK for Java Developer Guide.
         */
        final ClientConfiguration clientConfiguration = new ClientConfiguration()
                .withMaxConnections(producerCount + consumerCount);

        final AmazonSQS sqsClient = AmazonSQSClientBuilder.standard()
                .withClientConfiguration(clientConfiguration)
                .build();

        final String queueUrl = sqsClient
                .getQueueUrl(new GetQueueUrlRequest(queueName)).getQueueUrl();

        // The flag used to stop producer, consumer, and monitor threads.
        final AtomicBoolean stop = new AtomicBoolean(false);

        // Start the producers.
        final AtomicInteger producedCount = new AtomicInteger();
        final Thread[] producers = new Thread[producerCount];
        for (int i = 0; i < producerCount; i++) {
            if (batchSize == 1) {
                producers[i] = new Producer(sqsClient, queueUrl, messageSizeByte,
                        producedCount, stop);
            } else {
                producers[i] = new BatchProducer(sqsClient, queueUrl, batchSize,
                        messageSizeByte, producedCount,
                        stop);
            }
            producers[i].start();
        }

        // Start the consumers.
        final AtomicInteger consumedCount = new AtomicInteger();
        final Thread[] consumers = new Thread[consumerCount];
        for (int i = 0; i < consumerCount; i++) {
            if (batchSize == 1) {
                consumers[i] = new Consumer(sqsClient, queueUrl, consumedCount,
                        stop);
            } else {
                consumers[i] = new BatchConsumer(sqsClient, queueUrl, batchSize,
                        consumedCount, stop);
            }
            consumers[i].start();
        }

        // Start the monitor thread.
        final Thread monitor = new Monitor(producedCount, consumedCount, stop);
        monitor.start();

        // Wait for the specified amount of time then stop.
        Thread.sleep(TimeUnit.MINUTES.toMillis(Math.min(runTimeMinutes,
                MAX_RUNTIME_MINUTES)));
        stop.set(true);

        // Join all threads.
        for (int i = 0; i < producerCount; i++) {
            producers[i].join();
        }

        for (int i = 0; i < consumerCount; i++) {
            consumers[i].join();
        }

        monitor.interrupt();
        monitor.join();
    }

    private static String makeRandomString(int sizeByte) {
        final byte[] bs = new byte[(int) Math.ceil(sizeByte * 5 / 8)];
        new Random().nextBytes(bs);
        bs[0] = (byte) ((bs[0] | 64) & 127);
        return new BigInteger(bs).toString(32);
    }

    /**
     * The producer thread uses {@code SendMessage}
     * to send messages until it is stopped.
     */
    private static class Producer extends Thread {
        final AmazonSQS sqsClient;
        final String queueUrl;
        final AtomicInteger producedCount;
        final AtomicBoolean stop;
        final String theMessage;

        Producer(AmazonSQS sqsQueueBuffer, String queueUrl, int messageSizeByte,
                 AtomicInteger producedCount, AtomicBoolean stop) {
            this.sqsClient = sqsQueueBuffer;
            this.queueUrl = queueUrl;
            this.producedCount = producedCount;
            this.stop = stop;
            this.theMessage = makeRandomString(messageSizeByte);
        }

        /*
         * The producedCount object tracks the number of messages produced by
         * all producer threads. If there is an error, the program exits the
         * run() method.
         */
        public void run() {
            try {
                while (!stop.get()) {
                    sqsClient.sendMessage(new SendMessageRequest(queueUrl,
                            theMessage));
                    producedCount.incrementAndGet();
                }
            } catch (AmazonClientException e) {
                /*
                 * By default, AmazonSQSClient retries calls 3 times before
                 * failing. If this unlikely condition occurs, stop.
                 */
                log.error("Producer: " + e.getMessage());
                System.exit(1);
            }
        }
    }

    /**
     * The producer thread uses {@code SendMessageBatch}
     * to send messages until it is stopped.
     */
    private static class BatchProducer extends Thread {
        final AmazonSQS sqsClient;
        final String queueUrl;
        final int batchSize;
        final AtomicInteger producedCount;
        final AtomicBoolean stop;
        final String theMessage;

        BatchProducer(AmazonSQS sqsQueueBuffer, String queueUrl, int batchSize,
                      int messageSizeByte, AtomicInteger producedCount,
                      AtomicBoolean stop) {
            this.sqsClient = sqsQueueBuffer;
            this.queueUrl = queueUrl;
            this.batchSize = batchSize;
            this.producedCount = producedCount;
            this.stop = stop;
            this.theMessage = makeRandomString(messageSizeByte);
        }

        public void run() {
            try {
                while (!stop.get()) {
                    final SendMessageBatchRequest batchRequest =
                            new SendMessageBatchRequest().withQueueUrl(queueUrl);

                    final List<SendMessageBatchRequestEntry> entries =
                            new ArrayList<SendMessageBatchRequestEntry>();
                    for (int i = 0; i < batchSize; i++)
                        entries.add(new SendMessageBatchRequestEntry()
                                .withId(Integer.toString(i))
                                .withMessageBody(theMessage));
                    batchRequest.setEntries(entries);

                    final SendMessageBatchResult batchResult =
                            sqsClient.sendMessageBatch(batchRequest);
                    producedCount.addAndGet(batchResult.getSuccessful().size());

                    /*
                     * Because SendMessageBatch can return successfully, but
                     * individual batch items fail, retry the failed batch items.
                     */
                    if (!batchResult.getFailed().isEmpty()) {
                        log.warn("Producer: retrying sending "
                                + batchResult.getFailed().size() + " messages");
                        for (int i = 0, n = batchResult.getFailed().size();
                             i < n; i++) {
                            sqsClient.sendMessage(new
                                    SendMessageRequest(queueUrl, theMessage));
                            producedCount.incrementAndGet();
                        }
                    }
                }
            } catch (AmazonClientException e) {
                /*
                 * By default, AmazonSQSClient retries calls 3 times before
                 * failing. If this unlikely condition occurs, stop.
                 */
                log.error("BatchProducer: " + e.getMessage());
                System.exit(1);
            }
        }
    }

    /**
     * The consumer thread uses {@code ReceiveMessage} and {@code DeleteMessage}
     * to consume messages until it is stopped.
     */
    private static class Consumer extends Thread {
        final AmazonSQS sqsClient;
        final String queueUrl;
        final AtomicInteger consumedCount;
        final AtomicBoolean stop;

        Consumer(AmazonSQS sqsClient, String queueUrl, AtomicInteger consumedCount,
                 AtomicBoolean stop) {
            this.sqsClient = sqsClient;
            this.queueUrl = queueUrl;
            this.consumedCount = consumedCount;
            this.stop = stop;
        }

        /*
         * Each consumer thread receives and deletes messages until the main
         * thread stops the consumer thread. The consumedCount object tracks the
         * number of messages that are consumed by all consumer threads, and the
         * count is logged periodically.
         */
        public void run() {
            try {
                while (!stop.get()) {
                    try {
                        final ReceiveMessageResult result = sqsClient
                                .receiveMessage(new
                                        ReceiveMessageRequest(queueUrl));

                        if (!result.getMessages().isEmpty()) {
                            final Message m = result.getMessages().get(0);
                            sqsClient.deleteMessage(new
                                    DeleteMessageRequest(queueUrl,
                                    m.getReceiptHandle()));
                            consumedCount.incrementAndGet();
                        }
                    } catch (AmazonClientException e) {
                        log.error(e.getMessage());
                    }
                }
            } catch (AmazonClientException e) {
                /*
                 * By default, AmazonSQSClient retries calls 3 times before
                 * failing. If this unlikely condition occurs, stop.
                 */
                log.error("Consumer: " + e.getMessage());
                System.exit(1);
            }
        }
    }

    /**
     * The consumer thread uses {@code ReceiveMessage} and {@code
     * DeleteMessageBatch} to consume messages until it is stopped.
     */
    private static class BatchConsumer extends Thread {
        final AmazonSQS sqsClient;
        final String queueUrl;
        final int batchSize;
        final AtomicInteger consumedCount;
        final AtomicBoolean stop;

        BatchConsumer(AmazonSQS sqsClient, String queueUrl, int batchSize,
                      AtomicInteger consumedCount, AtomicBoolean stop) {
            this.sqsClient = sqsClient;
            this.queueUrl = queueUrl;
            this.batchSize = batchSize;
            this.consumedCount = consumedCount;
            this.stop = stop;
        }

        public void run() {
            try {
                while (!stop.get()) {
                    final ReceiveMessageResult result = sqsClient
                            .receiveMessage(new ReceiveMessageRequest(queueUrl)
                                    .withMaxNumberOfMessages(batchSize));

                    if (!result.getMessages().isEmpty()) {
                        final List<Message> messages = result.getMessages();
                        final DeleteMessageBatchRequest batchRequest =
                                new DeleteMessageBatchRequest()
                                        .withQueueUrl(queueUrl);

                        final List<DeleteMessageBatchRequestEntry> entries =
                                new ArrayList<DeleteMessageBatchRequestEntry>();
                        for (int i = 0, n = messages.size(); i < n; i++)
                            entries.add(new DeleteMessageBatchRequestEntry()
                                    .withId(Integer.toString(i))
                                    .withReceiptHandle(messages.get(i)
                                            .getReceiptHandle()));
                        batchRequest.setEntries(entries);

                        final DeleteMessageBatchResult batchResult = sqsClient
                                .deleteMessageBatch(batchRequest);
                        consumedCount.addAndGet(batchResult.getSuccessful().size());

                        /*
                         * Because DeleteMessageBatch can return successfully,
                         * but individual batch items fail, retry the failed
                         * batch items.
                         */
                        if (!batchResult.getFailed().isEmpty()) {
                            final int n = batchResult.getFailed().size();
                            log.warn("Producer: retrying deleting " + n
                                    + " messages");
                            for (BatchResultErrorEntry e : batchResult
                                    .getFailed()) {

                                sqsClient.deleteMessage(
                                        new DeleteMessageRequest(queueUrl,
                                                messages.get(Integer
                                                        .parseInt(e.getId()))
                                                        .getReceiptHandle()));

                                consumedCount.incrementAndGet();
                            }
                        }
                    }
                }
            } catch (AmazonClientException e) {
                /*
                 * By default, AmazonSQSClient retries calls 3 times before
                 * failing. If this unlikely condition occurs, stop.
                 */
                log.error("BatchConsumer: " + e.getMessage());
                System.exit(1);
            }
        }
    }

    /**
     * This thread prints every second the number of messages produced and
     * consumed so far.
     */
    private static class Monitor extends Thread {
        private final AtomicInteger producedCount;
        private final AtomicInteger consumedCount;
        private final AtomicBoolean stop;

        Monitor(AtomicInteger producedCount, AtomicInteger consumedCount,
                AtomicBoolean stop) {
            this.producedCount = producedCount;
            this.consumedCount = consumedCount;
            this.stop = stop;
        }

        public void run() {
            try {
                while (!stop.get()) {
                    Thread.sleep(1000);
                    log.info("produced messages = " + producedCount.get()
                            + ", consumed messages = " + consumedCount.get());
                }
            } catch (InterruptedException e) {
                // Allow the thread to exit.
            }
        }
    }
}
			 
			 
				Monitoring
						volume metrics from the example run
				Amazon SQS automatically generates volume metrics for sent, received, and deleted
					messages. You can access those metrics and others through the
						Monitoring tab for your queue or on the CloudWatch console.
				NoteThe metrics can take up to 15 minutes after the queue starts to become
						available.
			 
		Document ConventionsEnabling client-side
				buffering and request batching with Amazon SQSWorking with AWS SDKsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideStep 1: Create an AWS account and IAM
				userStep 2: Grant programmatic
				accessStep 3: Get ready to use the example
				codeNext stepsSetting up Amazon SQSBefore you can use Amazon SQS for the first time, you must complete the following steps:
		Step 1: Create an AWS account and IAM
				user
		To access any AWS service, you first need to create an AWS account, an Amazon.com account that can use AWS products. You can
			use your AWS account to view your activity and usage reports and to manage
			authentication and access.
		To avoid using your AWS account root user for Amazon SQS actions, it is a best practice
			to create an IAM user for each person who needs administrative access to Amazon SQS.
		


   
    Sign up for an AWS account 

If you do not have an AWS account, complete the following steps to create one.
To sign up for an AWS accountOpen https://portal.aws.amazon.com/billing/signup.
  Follow the online instructions.
  Part of the sign-up procedure involves receiving a phone call and entering 
  a verification code on the phone keypad.
  When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services
  and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that require root user access.
  
 AWS sends you a confirmation email after the sign-up process is
complete. At any time, you can view your current account activity and manage your account by
going to https://aws.amazon.com/ and choosing My
  Account.
   


 
Create a user with administrative access 
After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity Center, and create an administrative user so that you 
don't use the root user for everyday tasks.
Secure your AWS account root user


 Sign in to the AWS Management Console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password.
 
 For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User Guide.

 Turn on multi-factor authentication (MFA) for your root user.
 For instructions, see Enable a virtual MFA device for your AWS account root user (console) in the IAM User Guide. 

Create a user with administrative access
 Enable IAM Identity Center.
 For instructions, see Enabling
 AWS IAM Identity Center in the
 AWS IAM Identity Center User Guide.

 In IAM Identity Center, grant administrative access to a user.
 For a tutorial about using the IAM Identity Center directory as your identity source, see 
 Configure user access with the default IAM Identity Center directory in the
 AWS IAM Identity Center User Guide.

Sign in as the user with administrative access

To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email address when you created the IAM Identity Center user.

For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in the AWS Sign-In User Guide.

Assign access to additional users
 In IAM Identity Center, create a permission set that follows the best practice of applying least-privilege permissions.
 For instructions, see 
 Create a permission set in the AWS IAM Identity Center User Guide.
 
 Assign users to a group, and then assign single sign-on access to the group.
 For instructions, see 
 Add groups in the AWS IAM Identity Center User Guide.
 
 



   
	 
		Step 2: Grant programmatic
				access
		To use Amazon SQS actions (for example, using Java or through the AWS Command Line Interface), you need an
			access key ID and a secret access key.
		NoteThe access key ID and secret access key are specific to AWS Identity and Access Management. Don't confuse
				them with credentials for other AWS services, such as Amazon EC2 key pairs.
		


Users need programmatic access if they want to interact with AWS outside of the AWS Management Console. The way to grant programmatic access depends on the type of user that's accessing AWS.
    To grant users programmatic access, choose one of the following options.
    
                
                    Which user needs programmatic access?
                    To
                    By
                
            
                
                    
                        Workforce identity
                        (Users managed in IAM Identity Center)
                    
                    Use temporary credentials to sign programmatic requests to the AWS CLI, AWS SDKs, or
                        AWS APIs.
                    
                        Following the instructions for the interface that you want to use.
                        
                             


                             
                        
                                For the AWS CLI, see Configuring the AWS CLI to use AWS IAM Identity Center in the
                                        AWS Command Line Interface User Guide.
                            
                                For AWS SDKs, tools, and AWS APIs, see IAM Identity Center
                                        authentication in the AWS SDKs and Tools Reference Guide.

                            
                    
                
                
                    IAM
                    Use temporary credentials to sign programmatic requests to the AWS CLI, AWS SDKs, or
                        AWS APIs.
                    Following the instructions in Using temporary
                        credentials with AWS resources in the IAM User Guide.
                
                
                    IAM
                    (Not recommended)Use long-term credentials to sign programmatic requests
                        to the AWS CLI, AWS SDKs, or AWS APIs.
                    
                        Following the instructions for the interface that you want to use.
                        
                             
                             
                             
                        
                                For the AWS CLI, see Authenticating using IAM user credentials in
                                    the AWS Command Line Interface User Guide.
                            
                                For AWS SDKs and tools, see Authenticate using long-term credentials in the
                                        AWS SDKs and Tools Reference Guide.
                            
                                For AWS APIs, see Managing access keys for
                                    IAM users in the IAM User Guide.
                            
                    
                
            





 
	 
		Step 3: Get ready to use the example
				code
		This guide includes examples that use the AWS SDK for Java. To run the example code,
			follow the set-up instructions in Getting Started with
				AWS SDK for Java 2.0. 
		You can develop AWS applications in other programming languages, such as Go,
			JavaScript, Python and Ruby. For more information, see Tools to Build on AWS.
		NoteYou can explore Amazon SQS without writing code with tools such as the AWS Command Line Interface
				(AWS CLI) or Windows PowerShell. You can find AWS CLI examples in the Amazon SQS section of the
					AWS CLI Command Reference. You can find Windows PowerShell examples
				in the Amazon Simple Queue Service section of the AWS Tools for PowerShell Cmdlet Reference.
	 
		Next steps
		You are now ready for Getting started with
			managing Amazon SQS queues and messages using the AWS Management Console. 
	Document ConventionsGetting startedUnderstanding the Amazon SQS console Did this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideConfiguring queue parameters using the Amazon SQS
      consoleWhen creating or editing a queue, you can configure the following
    parameters:
     
     
     
     
     
     
     
     
  
      Visibility timeout – The length of time that a message
        received from a queue (by one consumer) won't be visible to the other message consumers. For
        more information, see Visibility timeout. 
      NoteUsing the console to configure the visibility timeout configures the timeout value for
          all of the messages in the queue. To configure the timeout for single or multiple
          messages, you must use one of the AWS SDKs. 
    
      Message retention period – The amount of time that Amazon SQS
        retains messages that remain in the queue. By default, the queue retains messages for four
        days. You can configure a queue to retain messages for up to 14 days. For more information,
        see Message retention period.
    
      Delivery delay – The amount of time that Amazon SQS will delay
        before delivering a message that is added to the queue. For more information, see Delivery delay.
    
      Maximum message size – The maximum message size for this
        queue. For more information, see Maximum message
        size.
    
      Receive message wait time – The maximum amount of time that
        Amazon SQS waits for messages to become available after the queue gets a receive request. For
        more information, see Amazon SQS short and long polling.
    
      Enable content-based deduplication – Amazon SQS can automatically
        create deduplication IDs based on the body of the message. For more information, see Amazon SQS FIFO queues.
    
      Enable high throughput FIFO – Use to enable high throughput
        for messages in the queue. Choosing this option changes the related options (Deduplication scope and FIFO throughput limit) to the required
        settings for enabling high throughput for FIFO queues. For more information, see High throughput for FIFO queues in Amazon SQS and Amazon SQS message quotas.
    
      
        Redrive allow policy: defines which source queues can use this queue as
        the dead-letter queue. For more information, see Using dead-letter queues in Amazon SQS . 
    To configure queue parameters for an existing queue (console)Open the Amazon SQS console at
         https://console.aws.amazon.com/sqs/.
      In the navigation pane, choose Queues. Choose a queue and choose
          Edit. 
    
      Scroll to the Configuration section.
    
      For Visibility timeout , enter the duration and units. The range is
        0 seconds to 12 hours. The default value is 30 seconds.
    
      For Message retention period, enter the duration and units. The
        range is 1 minute to 14 days. The default value is 4 days.
    
      For a standard queue, enter a value for Receive message wait time.
        The range is 0 to 20 seconds. The default value is 0 seconds, which sets short polling. Any non-zero value sets long
        polling.
    
      For Delivery delay, enter the duration and units. The range is 0
        seconds to 15 minutes. The default value is 0 seconds.
    
      For Maximum message size, enter a value. The range is 1 KB to 256
        KB. The default value is 256 KB. 
    
      For a FIFO queue, choose Enable content-based deduplication to
        enable content-based deduplication. The default setting is disabled. 
     (Optional) For a FIFO queue to enable higher throughput for sending and receiving messages in the queue, 
choose Enable high throughput FIFO.
Choosing this option changes the related options (Deduplication scope and FIFO throughput limit) 
to the required settings for enabling high throughput for FIFO queues. If you change any of the settings required for using high throughput FIFO, normal
throughput is in effect for the queue, and deduplication occurs as specified. For more information, see 
High throughput for FIFO queues in Amazon SQS and 
Amazon SQS message quotas. 
      For Redrive allow policy, choose Enabled.
        Select from the following: Allow all (default), By
          queue or Deny all. When choosing By
          queue, specify a list of up to 10 source queues by the Amazon Resource Name
        (ARN). 
    
      When you finish configuring the queue parameters, choose
        Save.
    Document ConventionsTesting attribute-based access controlConfiguring an access policyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon EventBridge SchedulerUser GuideKey features of EventBridge SchedulerAccessing EventBridge SchedulerWhat is Amazon EventBridge Scheduler?
  Amazon EventBridge Scheduler is a serverless scheduler that allows you to create, run, and manage tasks from one central, managed service.
  Highly scalable, EventBridge Scheduler allows you to schedule millions of tasks that can invoke more than 270 AWS services and over 6,000 API operations.
  Without the need to provision and manage infrastructure, or integrate with multiple services, EventBridge Scheduler provides you with the ability to deliver schedules at
  scale and reduce maintenance costs.
 
  EventBridge Scheduler delivers your tasks reliably, with built-in mechanisms that adjust your schedules based on the availability of downstream targets.
  With EventBridge Scheduler, you can create schedules using cron and rate expressions for recurring patterns, or configure one-time invocations.
  You can set up flexible time windows for delivery, define retry limits, and set the maximum retention time for failed triggers.
 TopicsKey features of EventBridge SchedulerAccessing EventBridge Scheduler
  Key features of EventBridge Scheduler
  
   EventBridge Scheduler offers the following key features that you can use to configure targets and scale your schedules.
  
  
    
    
    
    
  
    
     Templated targets – EventBridge Scheduler supports templated targets to perform common API operations using Amazon SQS, Amazon SNS, Lambda, and EventBridge.
     With predefined targets, you can configure your schedules quickly using the EventBridge Scheduler console, the EventBridge Scheduler SDK, or the AWS CLI.
    
   
    
     Universal targets – EventBridge Scheduler provides a universal target parameter (UTP) that you can use to create customized triggers that target more than 270 AWS services and over 6,000 API operations on a schedule.
     With UTP, you can configure your customized triggers using the EventBridge Scheduler console, the EventBridge Scheduler SDK, or the AWS CLI.
    
   
    
     Flexible time windows – EventBridge Scheduler supports flexible time windows, allowing you to disperse your schedules and improve the reliability of your triggers for use cases that do not require precise scheduled invocation of targets.
    
   
    
     Retries – EventBridge Scheduler provides at-least-once event delivery to targets, meaning that at least one delivery succeeds with a response from the target. EventBridge Scheduler allows you to set the number of retries for your schedule for a failed task.
     EventBridge Scheduler retries failed tasks with delayed attempts to improve the reliability of your schedule and ensure targets are available.
    
   
  
  Accessing EventBridge Scheduler
  You can use EventBridge Scheduler via the EventBridge console, the EventBridge Scheduler SDK, the AWS CLI, or by directly using the EventBridge Scheduler API.
 Document ConventionsSetting upDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideAmazon SQS message timersMessage timers allow you to set an initial invisibility period for a message when it's
        added to a queue. For example, if you send a message with a 45-second timer, it remains
        hidden from consumers for the first 45 seconds. The default (minimum) delay for a message is 0 seconds. The maximum is 15 minutes. For
        information about sending messages with timers using the console, see Sending a message using a standard queue.NoteFIFO queues don't support timers on individual messages.To set a delay period on an entire queue, rather than on individual messages, use delay queues. A message timer setting for an
        individual message overrides any DelaySeconds value on an Amazon SQS delay queue. Extended scheduling optionsWhile Amazon SQS delay queues and message timers allow scheduling of message delivery up to 15
        minutes in the future, you may require more flexible scheduling capabilities. In such cases,
        consider using EventBridge Scheduler, which enables you
        to schedule billions of one-time or recurring API actions without time limitations. EventBridge Scheduler is the recommended solution for advanced message scheduling use cases.Document ConventionsTemporary queuesAccessing EventBridge pipesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuidePrerequisitesAWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messagesManaging large Amazon SQS messages using Java and Amazon S3Use the Amazon SQS Extended Client Library for Java with Amazon S3 to manage large Amazon SQS
        messages, particularly for payloads ranging from 256 KB to 2 GB. The library stores the
        message payload in an Amazon S3 bucket and sends a message containing a reference to the
        stored object in the Amazon SQS queue.With the Amazon SQS Extended Client Library for Java, you can:
         
         
         
         
    
            Specify whether messages are always stored in Amazon S3 or only when the size of a
                message exceeds 256 KB
        
            Send a message that references a single message object stored in an S3 bucket
            
        
            Retrieve the message object from an Amazon S3 bucket
        
            Delete the message object from an Amazon S3 bucket
        
        Prerequisites
        
        The following example uses the AWS Java SDK. To install and set up the SDK,
		see Set up the AWS SDK for Java
		in the AWS SDK for Java Developer Guide.
        Before you run the example code, configure your AWS credentials. For
		more information, see Set up AWS Credentials and Region for Development
		in the AWS SDK for Java Developer Guide.
		
        The SDK for Java and Amazon SQS Extended Client Library for Java require the J2SE Development Kit 8.0 or later.
        NoteYou can use the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages using
                Amazon S3 only with the AWS SDK for Java. You can't do this
                with the AWS CLI, the Amazon SQS console, the Amazon SQS HTTP API, or any of the other AWS
                SDKs.
     
        AWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messages
        The following SDK for Java 2.x example creates an Amazon S3 bucket with a random name and adds a
            lifecycle rule to permanently delete objects after 14 days. It also creates a queue
            named MyQueue and sends a random message that is stored in an Amazon S3 bucket
            and is more than 256 KB to the queue. Finally, the code retrieves the message, returns
            information about it, and then deletes the message, the queue, and the bucket.
        /*
 * Copyright 2010-2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *  https://aws.amazon.com/apache2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 *
 */
	            
	            import com.amazon.sqs.javamessaging.AmazonSQSExtendedClient;
import com.amazon.sqs.javamessaging.ExtendedClientConfiguration;
import org.joda.time.DateTime;
import org.joda.time.format.DateTimeFormat;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.BucketLifecycleConfiguration;
import software.amazon.awssdk.services.s3.model.CreateBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;
import software.amazon.awssdk.services.s3.model.ExpirationStatus;
import software.amazon.awssdk.services.s3.model.LifecycleExpiration;
import software.amazon.awssdk.services.s3.model.LifecycleRule;
import software.amazon.awssdk.services.s3.model.LifecycleRuleFilter;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsRequest;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsResponse;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;
import software.amazon.awssdk.services.s3.model.PutBucketLifecycleConfigurationRequest;
import software.amazon.awssdk.services.sqs.SqsClient;
import software.amazon.awssdk.services.sqs.model.CreateQueueRequest;
import software.amazon.awssdk.services.sqs.model.CreateQueueResponse;
import software.amazon.awssdk.services.sqs.model.DeleteMessageRequest;
import software.amazon.awssdk.services.sqs.model.DeleteQueueRequest;
import software.amazon.awssdk.services.sqs.model.Message;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageRequest;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageResponse;
import software.amazon.awssdk.services.sqs.model.SendMessageRequest;

import java.util.Arrays;
import java.util.List;
import java.util.UUID;


/**
 * Examples of using Amazon SQS Extended Client Library for Java 2.x
 *
 */
public class SqsExtendedClientExamples {
    // Create an Amazon S3 bucket with a random name.
    private final static String amzn-s3-demo-bucket = UUID.randomUUID() + "-"
            + DateTimeFormat.forPattern("yyMMdd-hhmmss").print(new DateTime());

    public static void main(String[] args) {

        /*
         * Create a new instance of the builder with all defaults (credentials
         * and region) set automatically. For more information, see
         * Creating Service Clients in the AWS SDK for Java Developer Guide.
         */
        final S3Client s3 = S3Client.create();

        /*
         * Set the Amazon S3 bucket name, and then set a lifecycle rule on the
         * bucket to permanently delete objects 14 days after each object's
         * creation date.
         */
        final LifecycleRule lifeCycleRule = LifecycleRule.builder()
                .expiration(LifecycleExpiration.builder().days(14).build())
                .filter(LifecycleRuleFilter.builder().prefix("").build())
                .status(ExpirationStatus.ENABLED)
                .build();
        final BucketLifecycleConfiguration lifecycleConfig = BucketLifecycleConfiguration.builder()
                .rules(lifeCycleRule)
                .build();

        // Create the bucket and configure it
        s3.createBucket(CreateBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
        s3.putBucketLifecycleConfiguration(PutBucketLifecycleConfigurationRequest.builder()
                .bucket(amzn-s3-demo-bucket)
                .lifecycleConfiguration(lifecycleConfig)
                .build());
        System.out.println("Bucket created and configured.");

        // Set the Amazon SQS extended client configuration with large payload support enabled
        final ExtendedClientConfiguration extendedClientConfig = new ExtendedClientConfiguration().withPayloadSupportEnabled(s3, amzn-s3-demo-bucket);

        final SqsClient sqsExtended = new AmazonSQSExtendedClient(SqsClient.builder().build(), extendedClientConfig);

        // Create a long string of characters for the message object
        int stringLength = 300000;
        char[] chars = new char[stringLength];
        Arrays.fill(chars, 'x');
        final String myLongString = new String(chars);

        // Create a message queue for this example
        final String queueName = "MyQueue-" + UUID.randomUUID();
        final CreateQueueResponse createQueueResponse = sqsExtended.createQueue(CreateQueueRequest.builder().queueName(queueName).build());
        final String myQueueUrl = createQueueResponse.queueUrl();
        System.out.println("Queue created.");

        // Send the message
        final SendMessageRequest sendMessageRequest = SendMessageRequest.builder()
                .queueUrl(myQueueUrl)
                .messageBody(myLongString)
                .build();
        sqsExtended.sendMessage(sendMessageRequest);
        System.out.println("Sent the message.");

        // Receive the message
        final ReceiveMessageResponse receiveMessageResponse = sqsExtended.receiveMessage(ReceiveMessageRequest.builder().queueUrl(myQueueUrl).build());
        List<Message> messages = receiveMessageResponse.messages();

        // Print information about the message
        for (Message message : messages) {
            System.out.println("\nMessage received.");
            System.out.println("  ID: " + message.messageId());
            System.out.println("  Receipt handle: " + message.receiptHandle());
            System.out.println("  Message body (first 5 characters): " + message.body().substring(0, 5));
        }

        // Delete the message, the queue, and the bucket
        final String messageReceiptHandle = messages.get(0).receiptHandle();
        sqsExtended.deleteMessage(DeleteMessageRequest.builder().queueUrl(myQueueUrl).receiptHandle(messageReceiptHandle).build());
        System.out.println("Deleted the message.");

        sqsExtended.deleteQueue(DeleteQueueRequest.builder().queueUrl(myQueueUrl).build());
        System.out.println("Deleted the queue.");

        deleteBucketAndAllContents(s3);
        System.out.println("Deleted the bucket.");

    }

    private static void deleteBucketAndAllContents(S3Client client) {
        ListObjectsV2Response listObjectsResponse = client.listObjectsV2(ListObjectsV2Request.builder().bucket(amzn-s3-demo-bucket).build());

        listObjectsResponse.contents().forEach(object -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(object.key()).build());
        });

        ListObjectVersionsResponse listVersionsResponse = client.listObjectVersions(ListObjectVersionsRequest.builder().bucket(amzn-s3-demo-bucket).build());

        listVersionsResponse.versions().forEach(version -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(version.key()).versionId(version.versionId()).build());
        });

        client.deleteBucket(DeleteBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
    }
}
        

         You can use Apache Maven to configure and build Amazon SQS Extended Client for your Java
            project, or to build the SDK itself. Specify individual modules from the SDK that you
            use in your application. 
        
<properties>
    <aws-java-sdk.version>2.20.153</aws-java-sdk.version>
</properties>

<dependencies>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>sqs</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>s3</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>amazon-sqs-java-extended-client-lib</artifactId>
      <version>2.0.4</version>
    </dependency>

    <dependency>
      <groupId>joda-time</groupId>
      <artifactId>joda-time</artifactId>
      <version>2.12.6</version>
    </dependency>
</dependencies>
	        

    Document ConventionsManaging large
            messagesUsing the Extended Client Library for PythonDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuidePrerequisitesAWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messagesManaging large Amazon SQS messages using Java and Amazon S3Use the Amazon SQS Extended Client Library for Java with Amazon S3 to manage large Amazon SQS
        messages, particularly for payloads ranging from 256 KB to 2 GB. The library stores the
        message payload in an Amazon S3 bucket and sends a message containing a reference to the
        stored object in the Amazon SQS queue.With the Amazon SQS Extended Client Library for Java, you can:
         
         
         
         
    
            Specify whether messages are always stored in Amazon S3 or only when the size of a
                message exceeds 256 KB
        
            Send a message that references a single message object stored in an S3 bucket
            
        
            Retrieve the message object from an Amazon S3 bucket
        
            Delete the message object from an Amazon S3 bucket
        
        Prerequisites
        
        The following example uses the AWS Java SDK. To install and set up the SDK,
		see Set up the AWS SDK for Java
		in the AWS SDK for Java Developer Guide.
        Before you run the example code, configure your AWS credentials. For
		more information, see Set up AWS Credentials and Region for Development
		in the AWS SDK for Java Developer Guide.
		
        The SDK for Java and Amazon SQS Extended Client Library for Java require the J2SE Development Kit 8.0 or later.
        NoteYou can use the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages using
                Amazon S3 only with the AWS SDK for Java. You can't do this
                with the AWS CLI, the Amazon SQS console, the Amazon SQS HTTP API, or any of the other AWS
                SDKs.
     
        AWS SDK for Java 2.x Example: Using Amazon S3 to manage large Amazon SQS messages
        The following SDK for Java 2.x example creates an Amazon S3 bucket with a random name and adds a
            lifecycle rule to permanently delete objects after 14 days. It also creates a queue
            named MyQueue and sends a random message that is stored in an Amazon S3 bucket
            and is more than 256 KB to the queue. Finally, the code retrieves the message, returns
            information about it, and then deletes the message, the queue, and the bucket.
        /*
 * Copyright 2010-2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License").
 * You may not use this file except in compliance with the License.
 * A copy of the License is located at
 *
 *  https://aws.amazon.com/apache2.0
 *
 * or in the "license" file accompanying this file. This file is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 *
 */
	            
	            import com.amazon.sqs.javamessaging.AmazonSQSExtendedClient;
import com.amazon.sqs.javamessaging.ExtendedClientConfiguration;
import org.joda.time.DateTime;
import org.joda.time.format.DateTimeFormat;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.BucketLifecycleConfiguration;
import software.amazon.awssdk.services.s3.model.CreateBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteBucketRequest;
import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;
import software.amazon.awssdk.services.s3.model.ExpirationStatus;
import software.amazon.awssdk.services.s3.model.LifecycleExpiration;
import software.amazon.awssdk.services.s3.model.LifecycleRule;
import software.amazon.awssdk.services.s3.model.LifecycleRuleFilter;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsRequest;
import software.amazon.awssdk.services.s3.model.ListObjectVersionsResponse;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;
import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;
import software.amazon.awssdk.services.s3.model.PutBucketLifecycleConfigurationRequest;
import software.amazon.awssdk.services.sqs.SqsClient;
import software.amazon.awssdk.services.sqs.model.CreateQueueRequest;
import software.amazon.awssdk.services.sqs.model.CreateQueueResponse;
import software.amazon.awssdk.services.sqs.model.DeleteMessageRequest;
import software.amazon.awssdk.services.sqs.model.DeleteQueueRequest;
import software.amazon.awssdk.services.sqs.model.Message;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageRequest;
import software.amazon.awssdk.services.sqs.model.ReceiveMessageResponse;
import software.amazon.awssdk.services.sqs.model.SendMessageRequest;

import java.util.Arrays;
import java.util.List;
import java.util.UUID;


/**
 * Examples of using Amazon SQS Extended Client Library for Java 2.x
 *
 */
public class SqsExtendedClientExamples {
    // Create an Amazon S3 bucket with a random name.
    private final static String amzn-s3-demo-bucket = UUID.randomUUID() + "-"
            + DateTimeFormat.forPattern("yyMMdd-hhmmss").print(new DateTime());

    public static void main(String[] args) {

        /*
         * Create a new instance of the builder with all defaults (credentials
         * and region) set automatically. For more information, see
         * Creating Service Clients in the AWS SDK for Java Developer Guide.
         */
        final S3Client s3 = S3Client.create();

        /*
         * Set the Amazon S3 bucket name, and then set a lifecycle rule on the
         * bucket to permanently delete objects 14 days after each object's
         * creation date.
         */
        final LifecycleRule lifeCycleRule = LifecycleRule.builder()
                .expiration(LifecycleExpiration.builder().days(14).build())
                .filter(LifecycleRuleFilter.builder().prefix("").build())
                .status(ExpirationStatus.ENABLED)
                .build();
        final BucketLifecycleConfiguration lifecycleConfig = BucketLifecycleConfiguration.builder()
                .rules(lifeCycleRule)
                .build();

        // Create the bucket and configure it
        s3.createBucket(CreateBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
        s3.putBucketLifecycleConfiguration(PutBucketLifecycleConfigurationRequest.builder()
                .bucket(amzn-s3-demo-bucket)
                .lifecycleConfiguration(lifecycleConfig)
                .build());
        System.out.println("Bucket created and configured.");

        // Set the Amazon SQS extended client configuration with large payload support enabled
        final ExtendedClientConfiguration extendedClientConfig = new ExtendedClientConfiguration().withPayloadSupportEnabled(s3, amzn-s3-demo-bucket);

        final SqsClient sqsExtended = new AmazonSQSExtendedClient(SqsClient.builder().build(), extendedClientConfig);

        // Create a long string of characters for the message object
        int stringLength = 300000;
        char[] chars = new char[stringLength];
        Arrays.fill(chars, 'x');
        final String myLongString = new String(chars);

        // Create a message queue for this example
        final String queueName = "MyQueue-" + UUID.randomUUID();
        final CreateQueueResponse createQueueResponse = sqsExtended.createQueue(CreateQueueRequest.builder().queueName(queueName).build());
        final String myQueueUrl = createQueueResponse.queueUrl();
        System.out.println("Queue created.");

        // Send the message
        final SendMessageRequest sendMessageRequest = SendMessageRequest.builder()
                .queueUrl(myQueueUrl)
                .messageBody(myLongString)
                .build();
        sqsExtended.sendMessage(sendMessageRequest);
        System.out.println("Sent the message.");

        // Receive the message
        final ReceiveMessageResponse receiveMessageResponse = sqsExtended.receiveMessage(ReceiveMessageRequest.builder().queueUrl(myQueueUrl).build());
        List<Message> messages = receiveMessageResponse.messages();

        // Print information about the message
        for (Message message : messages) {
            System.out.println("\nMessage received.");
            System.out.println("  ID: " + message.messageId());
            System.out.println("  Receipt handle: " + message.receiptHandle());
            System.out.println("  Message body (first 5 characters): " + message.body().substring(0, 5));
        }

        // Delete the message, the queue, and the bucket
        final String messageReceiptHandle = messages.get(0).receiptHandle();
        sqsExtended.deleteMessage(DeleteMessageRequest.builder().queueUrl(myQueueUrl).receiptHandle(messageReceiptHandle).build());
        System.out.println("Deleted the message.");

        sqsExtended.deleteQueue(DeleteQueueRequest.builder().queueUrl(myQueueUrl).build());
        System.out.println("Deleted the queue.");

        deleteBucketAndAllContents(s3);
        System.out.println("Deleted the bucket.");

    }

    private static void deleteBucketAndAllContents(S3Client client) {
        ListObjectsV2Response listObjectsResponse = client.listObjectsV2(ListObjectsV2Request.builder().bucket(amzn-s3-demo-bucket).build());

        listObjectsResponse.contents().forEach(object -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(object.key()).build());
        });

        ListObjectVersionsResponse listVersionsResponse = client.listObjectVersions(ListObjectVersionsRequest.builder().bucket(amzn-s3-demo-bucket).build());

        listVersionsResponse.versions().forEach(version -> {
            client.deleteObject(DeleteObjectRequest.builder().bucket(amzn-s3-demo-bucket).key(version.key()).versionId(version.versionId()).build());
        });

        client.deleteBucket(DeleteBucketRequest.builder().bucket(amzn-s3-demo-bucket).build());
    }
}
        

         You can use Apache Maven to configure and build Amazon SQS Extended Client for your Java
            project, or to build the SDK itself. Specify individual modules from the SDK that you
            use in your application. 
        
<properties>
    <aws-java-sdk.version>2.20.153</aws-java-sdk.version>
</properties>

<dependencies>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>sqs</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>software.amazon.awssdk</groupId>
      <artifactId>s3</artifactId>
      <version>${aws-java-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>amazon-sqs-java-extended-client-lib</artifactId>
      <version>2.0.4</version>
    </dependency>

    <dependency>
      <groupId>joda-time</groupId>
      <artifactId>joda-time</artifactId>
      <version>2.12.6</version>
    </dependency>
</dependencies>
	        

    Document ConventionsManaging large
            messagesUsing the Extended Client Library for PythonDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS SDK for JavaDeveloper Guide for version 2.x Setup overviewSetting up the AWS SDK for Java 2.xThis section provides information about how to set up your development environment and
      projects to use the AWS SDK for Java 2.x.
      Setup overview
      To successfully develop applications that access AWS services using the AWS SDK for Java, the following conditions are required:
      
          
          
          
      
            The Java SDK must have access to credentials to authenticate requests on your behalf.
         
            The permissions of the IAM role configured for the SDK
               must allow access to the AWS services that your application requires. The
               permissions associated with the PowerUserAccess
               AWS managed policy are sufficient for most development needs.
         
            A development environment with the following elements:
            
                
                
                
                
                
            
                  Shared configuration files that are set up in at least one of the
                     following ways:
                  
                      
                      
                  
                        The config file contains IAM Identity Center single sign-on settings so that the SDK
                           can get AWS credentials.
                     
                        The credentials file contains temporary
                           credentials.
                     
               
                  An installation of Java 8 or
                     later.
               
                  A build automation tool such as Maven or Gradle.
               
                  A text editor to work with code.
               
                  (Optional, but recommended) An IDE (integrated development environment) such
                     as IntelliJ IDEA, Eclipse, or NetBeans.
                  If you use IntelliJ IDEA, you can also add the AWS Toolkit for IntelliJ IDEA to integrate
                     AWS services directly into the IDE to help you streamline development.
               
         
      
          
      
            An active AWS access portal session when you are ready to run your application. You use the
               AWS Command Line Interface to initiate the sign-in process to
               IAM Identity Center's AWS access portal.
         
      ImportantThe instructions in this setup section assume that you or organization uses IAM Identity Center. If
            your organization uses an external identity provider that works independently of IAM Identity Center,
            find out how you can get temporary credentials for the SDK for Java to use. Follow these instructions to add
            temporary credentials to the ~/.aws/credentials file.If your identity provider adds temporary credentials automatically to the
               ~/.aws/credentials file, make sure that the profile name is
               [default] so that you do not need to provide a profile name to the SDK
            or AWS CLI.
   Document ConventionsGetting startedInstall Java development
         prerequisitesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS SDK for JavaDeveloper Guide for version 2.x Setup overviewSetting up the AWS SDK for Java 2.xThis section provides information about how to set up your development environment and
      projects to use the AWS SDK for Java 2.x.
      Setup overview
      To successfully develop applications that access AWS services using the AWS SDK for Java, the following conditions are required:
      
          
          
          
      
            The Java SDK must have access to credentials to authenticate requests on your behalf.
         
            The permissions of the IAM role configured for the SDK
               must allow access to the AWS services that your application requires. The
               permissions associated with the PowerUserAccess
               AWS managed policy are sufficient for most development needs.
         
            A development environment with the following elements:
            
                
                
                
                
                
            
                  Shared configuration files that are set up in at least one of the
                     following ways:
                  
                      
                      
                  
                        The config file contains IAM Identity Center single sign-on settings so that the SDK
                           can get AWS credentials.
                     
                        The credentials file contains temporary
                           credentials.
                     
               
                  An installation of Java 8 or
                     later.
               
                  A build automation tool such as Maven or Gradle.
               
                  A text editor to work with code.
               
                  (Optional, but recommended) An IDE (integrated development environment) such
                     as IntelliJ IDEA, Eclipse, or NetBeans.
                  If you use IntelliJ IDEA, you can also add the AWS Toolkit for IntelliJ IDEA to integrate
                     AWS services directly into the IDE to help you streamline development.
               
         
      
          
      
            An active AWS access portal session when you are ready to run your application. You use the
               AWS Command Line Interface to initiate the sign-in process to
               IAM Identity Center's AWS access portal.
         
      ImportantThe instructions in this setup section assume that you or organization uses IAM Identity Center. If
            your organization uses an external identity provider that works independently of IAM Identity Center,
            find out how you can get temporary credentials for the SDK for Java to use. Follow these instructions to add
            temporary credentials to the ~/.aws/credentials file.If your identity provider adds temporary credentials automatically to the
               ~/.aws/credentials file, make sure that the profile name is
               [default] so that you do not need to provide a profile name to the SDK
            or AWS CLI.
   Document ConventionsGetting startedInstall Java development
         prerequisitesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS SDK for JavaDeveloper Guide for version 1.xCreate a new Maven packageConfigure the SDK as a Maven dependencyBuild your projectBuild the SDK with MavenThe AWS SDK for Java 1.x has entered maintenance mode as of July 31, 2024,
      and will reach end-of-support on December 31, 2025. We recommend that you migrate to
      the AWS SDK for Java 2.x to continue receiving new features, availability improvements, and
      security updates.Use the SDK with Apache MavenYou can use  Apache Maven to configure and build AWS SDK for Java projects, or to build the SDK itself.NoteYou must have Maven installed to use the guidance in this topic. If it isn’t already installed, visit http://maven.apache.org/ to download and install it.
      Create a new Maven package
      To create a basic Maven package, open a terminal (command-line) window and run:
      mvn -B archetype:generate \
  -DarchetypeGroupId=org.apache.maven.archetypes \
  -DgroupId=org.example.basicapp \
  -DartifactId=myapp
      Replace  org.example.basicapp with the full package namespace of your application, and myapp with the name of your project (this will become the name of the directory for your project).
      By default,  creates a project template for you using the quickstart archetype, which is a good starting place for many projects. There are more archetypes available; visit the Maven archetypes page for a list of archetypes packaged with . You can choose a particular archetype to use by adding the -DarchetypeArtifactId argument to the archetype:generate command. For example:
      mvn archetype:generate \
  -DarchetypeGroupId=org.apache.maven.archetypes \
  -DarchetypeArtifactId=maven-archetype-webapp \
  -DgroupId=org.example.webapp \
  -DartifactId=mywebapp
      NoteMuch more information about creating and configuring  projects is provided in the  Maven Getting Started Guide.
    
      Configure the SDK as a Maven dependency
      To use the AWS SDK for Java in your project, you’ll need to declare it as a dependency in your project’s  pom.xml file. Beginning with version 1.9.0, you can import  individual components or the entire SDK.
       
         Specifying individual SDK modules
         To select individual SDK modules, use the AWS SDK for Java bill of materials (BOM) for Maven, which will ensure that the modules you specify use the same version of the SDK and that they’re compatible with each other.
         To use the BOM, add a <dependencyManagement> section to your application’s pom.xml file, adding  aws-java-sdk-bom as a dependency and specifying the version of the SDK you want to use:
         <dependencyManagement>
  <dependencies>
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-bom</artifactId>
      <version>1.11.1000</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>
  </dependencies>
</dependencyManagement>
         To view the latest version of the AWS SDK for Java BOM that is available on Maven Central, visit:  https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-bom. You can also use this page to see which modules (dependencies) are managed by the BOM that you can include within the <dependencies> section of your project’s pom.xml file.
         You can now select individual modules from the SDK that you use in your application. Because you already declared the SDK version in the BOM, you don’t need to specify the version number for each component.
         <dependencies>
  <dependency>
    <groupId>com.amazonaws</groupId>
    <artifactId>aws-java-sdk-s3</artifactId>
  </dependency>
  <dependency>
    <groupId>com.amazonaws</groupId>
    <artifactId>aws-java-sdk-dynamodb</artifactId>
  </dependency>
</dependencies>
         You can also refer to the  
            AWS Code Sample Catalog
          to learn what dependencies to use for a given AWS service. Refer to the POM file under a specific service example. For example, if you are interested in the dependencies for the AWS S3 service, see the complete example on GitHub. (Look at the pom under /java/example_code/s3).
       
       
         Importing all SDK modules
         If you would like to pull in the  entire SDK as a dependency, don’t use the BOM method, but simply declare it in your pom.xml like this:
         <dependencies>
  <dependency>
    <groupId>com.amazonaws</groupId>
    <artifactId>aws-java-sdk</artifactId>
    <version>1.11.1000</version>
  </dependency>
</dependencies>
       
    
      Build your project
      Once you have your project set up, you can build it using Maven’s  package command:
      mvn package
      This will create your  –0—jar file in the target directory.
    
      Build the SDK with Maven
      You can use Apache Maven to build the SDK from source. To do so,  download the SDK code from GitHub, unpack it locally, and then execute the following Maven command:
      mvn clean install
   Document ConventionsUse build toolsUse the SDK with GradleDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceDeveloper GuideVisibility timeout use casesSetting and adjusting the visibility
                timeoutIn flight messages and quotasUnderstanding visibility
                timeout in standard and FIFO queuesHandling failuresChanging and terminating
                visibility timeoutBest practicesAmazon SQS visibility timeoutWhen you receive a message from an Amazon SQS queue, it remains in the queue but becomes
        temporarily invisible to other consumers. This invisibility is controlled by the visibility
        timeout, which ensures that other consumers cannot process the same message while you are
        working on it. Amazon SQS offers two options for deleting messages after processing:
         
         
    
            Manual deletion – You explicitly delete
                messages using the DeleteMessage action.
        
            Automatic deletion – Supported in certain
                AWS SDKs, messages are automatically deleted upon successful processing,
                simplifying workflows.
        
         
            
         
         
    
        Visibility timeout use cases
        Manage long-running tasks – Use the visibility
            timeout to handle tasks that require extended processing times. Set an appropriate
            visibility timeout for messages that require extended processing time. This ensures that
            other consumers don't pick up the same message while it's being processed, preventing
            duplicate work and maintaining system efficiency.
        Implement retry mechanisms – Extend the
            visibility timeout programmatically for tasks that fail to complete within the initial
            timeout. If a task fails to complete within the initial visibility timeout, you can
            extend the timeout programmatically. This allows your system to retry processing the
            message without it becoming visible to other consumers, improving fault tolerance and
            reliability. Combine with Dead-Letter Queues (DLQs) to
            manage persistent failures.
        Coordinate distributed systems – Use SQS
            visibility timeout to coordinate tasks across distributed systems. Set visibility
            timeouts that align with your expected processing times for different components. This
            helps maintain consistency and prevents race conditions in complex, distributed
            architectures.
        Optimize resource utilization – Adjust SQS
            visibility timeouts to optimize resource utilization in your application. By setting
            appropriate timeouts, you can ensure that messages are processed efficiently without
            tying up resources unnecessarily. This leads to better overall system performance and
            cost-effectiveness.
     
        Setting and adjusting the visibility
                timeout
        The visibility timeout starts as soon as a message is delivered to you. During this
            period, you're expected to process and delete the message. If you don't delete it before
            the timeout expires, the message becomes visible again in the queue and can be retrieved
            by another consumer. The default visibility timeout for a queue is 30 seconds, but you
            can adjust this to match the time your application needs to process and delete a
            message. You can also set a specific visibility timeout for individual messages without
            changing the queue's overall setting. Use the ChangeMessageVisibility action to programmatically extend
            or shorten the timeout as needed.
     
        In flight messages and quotas
        In Amazon SQS, in-flight messages are messages that have been received by a consumer but
            not yet deleted. For standard queues, there's a limit of approximately 120,000 in-flight
            messages, depending on queue traffic and message backlog. If you reach this limit, Amazon SQS
            returns an OverLimit error, indicating that no additional messages can be
            received until some in-flight messages are deleted. For FIFO queues, limits depend on
            active message groups.
        
             
             
        
                When using short polling – If this
                    limit is reached while using short polling, Amazon SQS will return an
                        OverLimit error, indicating that no additional messages can be
                    received until some in-flight messages are deleted.
            
                When using long polling – If you are
                    using long polling, Amazon SQS does not return an error when the in-flight message
                    limit is reached. Instead, it will not return any new messages until the number
                    of in-flight messages drops below the limit.
            
        To manage in-flight messages effectively:
        
             
             
             
             
        
                Prompt deletion – Delete messages
                    (manually or automatically) after processing to reduce the in-flight
                    count.
            
                Monitor with CloudWatch – Set alarms for
                    high in-flight counts to prevent reaching the limit.
            
                Distribute load – If you're processing
                    a high volume of messages, use additional queues or consumers to balance load
                    and avoid bottlenecks.
            
                Request a quota increase – Submit a
                    request to AWS
                        Support if higher limits are required.
            
     
        Understanding visibility
                timeout in standard and FIFO queues
        In both standard and FIFO (First-In-First-Out) queues, the visibility timeout helps
            prevent multiple consumers from processing the same message simultaneously. However, due
            to the at-least-once delivery model of Amazon SQS, there's no absolute guarantee that a
            message won't be delivered more than once during the visibility timeout period.
        
             
             
        
                Standard queues – The visibility
                    timeout in standard queues prevents multiple consumers from processing the same
                    message at the same time. However, because of the at-least-once delivery model,
                    Amazon SQS doesn't guarantee that a message won’t be delivered more than once within
                    the visibility timeout period.
            
                FIFO queues – For FIFO queues,
                    messages with the same message group ID are processed in a strict sequence. When
                    a message with a message group ID is in-flight, subsequent messages in that
                    group are not made available until the in-flight message is either deleted or
                    the visibility timeout expires. However, this doesn’t "lock" the group
                    indefinitely– each message is processed in sequence, and only when each
                    message is deleted or becomes visible again will the next message in that group
                    be available to consumers. This approach ensures ordered processing within the
                    group without unnecessarily locking the group from delivering messages.
            
     
        Handling failures
        If you don't process and delete a message before the visibility timeout expires—due to
            application errors, crashes, or connectivity problems—the message becomes visible again
            in the queue. It can then be retrieved by the same or a different consumer for another
            processing attempt. This ensures that messages aren't lost even if the initial
            processing fails. However, setting the visibility timeout too high can delay the
            reappearance of unprocessed messages, potentially slowing down retries. It's crucial to
            set an appropriate visibility timeout based on the expected processing time for timely
            message handling.
     
        Changing and terminating
                visibility timeout
        You can change or terminate the visibility timeout using the
                ChangeMessageVisibility action:
        
             
             
        
                Changing the timeout – Adjust the
                    visibility timeout dynamically using ChangeMessageVisibility. This allows you to extend
                    or reduce timeout durations to match processing needs.
            
                Terminating the timeout – If you
                    decide not to process a received message, terminate its visibility timeout by
                    setting the VisibilityTimeout to 0 seconds through the
                        ChangeMessageVisibility action. This immediately makes the
                    message available for other consumers to process.
            
     
        Best practices
        Use the following best practices for managing visibility timeouts in Amazon SQS, including
            setting, adjusting, and extending timeouts, as well as handling unprocessed messages
            using Dead-Letter Queues (DLQs).
        
             
             
             
        
                Setting and adjusting the timeout. Start by
                    setting the visibility timeout to match the maximum time your application
                    typically needs to process and delete a message. If you're unsure about the
                    exact processing time, begin with a shorter timeout (for example, 2 minutes) and
                    extend it as necessary. Implement a heartbeat mechanism to periodically extend
                    the visibility timeout, ensuring the message remains invisible until processing
                    is complete. This minimizes delays in reprocessing unhandled messages and
                    prevents premature visibility.
            
                Extending the timeout and handling the 12-Hour
                        limit. If your processing time varies or may exceed the initially
                    set timeout, use the ChangeMessageVisibility action to extend the
                    visibility timeout while processing the message. Keep in mind that the
                    visibility timeout has a maximum limit of 12 hours from when the message is
                    first received. Extending the timeout doesn't reset this 12-hour limit. If your
                    processing requires more time than this limit, consider using AWS Step Functions or
                    breaking the task into smaller steps.
            
                Handling unprocessed messages. To manage
                    messages that fail multiple processing attempts, configure a Dead-Letter Queue
                    (DLQ). This ensures that messages that can't be processed after several retries
                    are captured separately for further analysis or handling, preventing them from
                    repeatedly circulating in the main queue. 
            
    Document ConventionsShort and long pollingDelay queuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse ElementsErrorsExamplesSee AlsoDeleteMessageDeletes the specified message from the specified queue. To select the message to
            delete, use the ReceiptHandle of the message (not the
                MessageId which you receive when you send the message). Amazon SQS can
            delete a message from a queue even if a visibility timeout setting causes the message to
            be locked by another consumer. Amazon SQS automatically deletes messages left in a queue
            longer than the retention period configured for the queue. NoteEach time you receive a message, meaning when a consumer retrieves a message from
                the queue, it comes with a unique ReceiptHandle. If you receive the
                same message more than once, you will get a different ReceiptHandle
                each time. When you want to delete a message using the DeleteMessage
                action, you must use the ReceiptHandle from the most recent time you
                received the message. If you use an old ReceiptHandle, the request will
                succeed, but the message might not be deleted. For standard queues, it is possible to receive a message even after you
                delete it. This might happen on rare occasions if one of the servers which stores a
                copy of the message is unavailable when you send the request to delete the message.
                The copy remains on the server and might be returned to you during a subsequent
                receive request. You should ensure that your application is idempotent, so that
                receiving a message more than once does not cause issues.
      Request Syntax
      {
   "QueueUrl": "string",
   "ReceiptHandle": "string"
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
      
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue from which messages are deleted.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
          
            
               
                  ReceiptHandle
               
            
            
               The receipt handle associated with the message to delete.
               Type: String
               Required: Yes
            
         
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidIdFormat
               
            
            
               
                  This error has been deprecated.
               
               The specified receipt handle isn't valid for the current version.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  ReceiptHandleIsInvalid
               
            
            
               The specified receipt handle isn't valid.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example query request deletes a message from the queue named
                    MyQueue. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.DeleteMessage
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "ReceiptHandle": "AQEB3LQoW7GQWgodQCEJXHjMvO/QkeCHiRldRfLC/E6RUggm+BjpthqxfoUOUn6Vs271qmrBaufFqEmnMKgk2n1EuUBne1pe+hZcrDE8IveUUPmqkUT54FGhAAjPX3oEIryz/XeQ/muKAuLclcZvt2Q+ZDPW8DvZqMa1RoHxOqSq+6kQ4PwgQxB+VqDYvIc/LpHOoL4PTROBXgLPjWrzz/knK6HTzKpqC4ESvFdJ/dkk2nvS0iqYOly5VQknK/lv/rTUOgEYevjJSrNLIPDgZGyvgcLwbm6+yo1cW/c9cPDiVm96gIhVkuiCZ1gtskoOtyroZVPcY71clDG2EPZJeY8akMd3u+sXEMWhiOPFs1cgWQs2ugsL+vdwMCbsZRkXbJv7"
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: 0
Date: <Date>
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue/ HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
Content-Type: application/x-www-form-urlencoded
X-Amz-Date: <Date>
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=DeleteMessage
&ReceiptHandle=AQEBMeG2RcZZrIcgBkDFb6lHqL9B9tbbEHNh+4uxMIG+CPupPjqJtRswDlOr6hOTzgcq105i0iZNci5GS5RTnHTkD2zipM9gHfSP2tWPhY7HHsU5GCTZ+egzS5HiEvmGZ71g71Lucdk7mes1/WGXnmU27K26Koo9GGrB0AKTv16dync1ezCMNyrBHEMUyIWS2lUTbrSj7fw93dgZSg2eWTk+thSVUB/ibOwpmj+wBN99nKQQklsZHtZd4exT1V3JHwP4kqz+D3C2RGn7js3nNdFpH41lBH8rCTZDU8DQp9eQNHLIL6RUf1WrI8gv8L7NErGlIH4Y3wZbFEOMKilVHenfpP2G6ElMuxyM3y+qdlZq4m00VGIIZeMg9PPmVsLtB7u9mruLyNFraN5ihKMjzQoKgA==
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<DeleteMessageResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>b5293cb5-d306-4a17-9048-b263635abe42</RequestId>
    </ResponseMetadata>
</DeleteMessageResponse>
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsCreateQueueDeleteMessageBatchDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceRequest SyntaxRequest ParametersResponse ElementsErrorsExamplesSee AlsoChangeMessageVisibilityChanges the visibility timeout of a specified message in a queue to a new value. The
            default visibility timeout for a message is 30 seconds. The minimum is 0 seconds. The
            maximum is 12 hours. For more information, see Visibility Timeout in the Amazon SQS Developer
            Guide.For example, if the default timeout for a queue is 60 seconds, 15 seconds have elapsed
            since you received the message, and you send a ChangeMessageVisibility call with
                VisibilityTimeout set to 10 seconds, the 10 seconds begin to count from
            the time that you make the ChangeMessageVisibility call. Thus, any attempt
            to change the visibility timeout or to delete that message 10 seconds after you
            initially change the visibility timeout (a total of 25 seconds) might result in an
            error.An Amazon SQS message has three basic states:
       
       
       
   
         Sent to a queue by a producer.
      
         Received from the queue by a consumer.
      
         Deleted from the queue.
      A message is considered to be stored after it is sent to a queue by a producer, but not yet received from the queue by a consumer (that is, between states 1 and 2). There is no limit to the number of stored messages.
    A message is considered to be in flight after it is received from a queue by a consumer, but not yet deleted from the queue (that is, between states 2 and 3). There is a limit to the number of in flight messages.Limits that apply to in flight messages are unrelated to the unlimited number of stored messages.For most standard queues (depending on queue traffic and message backlog), there can be a maximum of approximately 120,000 in flight messages (received from a queue by a consumer, but not yet deleted from the queue). 
    If you reach this limit, Amazon SQS returns the OverLimit error message.
    To avoid reaching the limit, you should delete messages from the queue after they're processed. You can also increase the number of queues you use to process your messages.
    To request a limit increase, file a support request.For FIFO queues, there can be a maximum of 120,000 in flight messages (received from a queue by a consumer, but not yet deleted from the queue). If you reach this limit, Amazon SQS returns no error messages.ImportantIf you attempt to set the VisibilityTimeout to a value greater than
                the maximum time left, Amazon SQS returns an error. Amazon SQS doesn't automatically
                recalculate and increase the timeout to the maximum remaining time.Unlike with a queue, when you change the visibility timeout for a specific message
                the timeout value is applied immediately but isn't saved in memory for that message.
                If you don't delete a message after it is received, the visibility timeout for the
                message reverts to the original timeout value (not to the value you set using the
                    ChangeMessageVisibility action) the next time the message is
                received.
      Request Syntax
      {
   "QueueUrl": "string",
   "ReceiptHandle": "string",
   "VisibilityTimeout": number
}
    
      Request Parameters
      For information about the parameters that are common to all actions, see Common Parameters.
      The request accepts the following data in JSON format.
      
          
          
          
      
            
               
                  QueueUrl
               
            
            
               The URL of the Amazon SQS queue whose message's visibility is changed.
               Queue URLs and names are case-sensitive.
               Type: String
               Required: Yes
            
          
            
               
                  ReceiptHandle
               
            
            
               The receipt handle associated with the message, whose visibility timeout is changed.
            This parameter is returned by the 
                     ReceiveMessage
                  
            action.
               Type: String
               Required: Yes
            
          
            
               
                  VisibilityTimeout
               
            
            
               The new value for the message's visibility timeout (in seconds). Values range:
                0 to 43200. Maximum: 12 hours.
               Type: Integer
               Required: Yes
            
         
    
      Response Elements
      If the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.
    
      Errors
      For information about the errors that are common to all actions, see Common Errors.
      
          
          
          
          
          
          
          
      
            
               
                  InvalidAddress
               
            
            
               The specified ID is invalid.
               HTTP Status Code: 400
            
          
            
               
                  InvalidSecurity
               
            
            
               The request was not made over HTTPS or did not use SigV4 for signing.
               HTTP Status Code: 400
            
          
            
               
                  MessageNotInflight
               
            
            
               The specified message isn't in flight.
               HTTP Status Code: 400
            
          
            
               
                  QueueDoesNotExist
               
            
            
               Ensure that the QueueUrl is correct and that the queue has not been
            deleted.
               HTTP Status Code: 400
            
          
            
               
                  ReceiptHandleIsInvalid
               
            
            
               The specified receipt handle isn't valid.
               HTTP Status Code: 400
            
          
            
               
                  RequestThrottled
               
            
            
               The request was denied due to request throttling.
               
                   
                   
               
                     Exceeds the permitted request rate for the queue or for the recipient of the
                    request.
                  
                     Ensure that the request rate is within the Amazon SQS limits for
                    sending messages. For more information, see Amazon SQS quotas in the Amazon SQS
                        Developer Guide.
                  
               HTTP Status Code: 400
            
          
            
               
                  UnsupportedOperation
               
            
            
               Error code 400. Unsupported operation.
               HTTP Status Code: 400
            
         
    
      Examples
      The following example queries request changes the visibility timeout for a message
                to 60 seconds. The structure of AUTHPARAMS depends on the signature of the API request. 
                For more information, see 
                Examples of Signed Signature Version 4 Requests in the 
            AWS General Reference.
       
         Example
         
            Using AWS JSON protocol
                        (Default)
         
          
            Sample Request
            POST / HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Target: AmazonSQS.ChangeMessageVisibility
X-Amz-Date: <Date>
Content-Type: application/x-amz-json-1.0
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive 
{
    "QueueUrl": "https://sqs.us-east-1.amazonaws.com/177715257436/MyQueue/",
    "ReceiptHandle": "AQEBaZ+j5qUoOAoxlmrCQPkBm9njMWXqemmIG6shMHCO6fV20JrQYg/AiZ8JELwLwOu5U61W+aIX5Qzu7GGofxJuvzymr4Ph53RiR0mudj4InLSgpSspYeTRDteBye5tV/txbZDdNZxsi+qqZA9xPnmMscKQqF6pGhnGIKrnkYGl45Nl6GPIZv62LrIRb6mSqOn1fn0yqrvmWuuY3w2UzQbaYunJWGxpzZze21EOBtywknU3Je/g7G9is+c6K9hGniddzhLkK1tHzZKjejOU4jokaiB4nmi0dF3JqLzDsQuPF0Gi8qffhEvw56nl8QCbluSJScFhJYvoagGnDbwOnd9z50L239qtFIgETdpKyirlWwl/NGjWJ45dqWpiW3d2Ws7q",
    "VisibilityTimeout": 60
}
          
          
            Sample Response
            HTTP/1.1 200 OK
x-amzn-RequestId: <requestId>
Content-Length: 0
Date: <Date>
Content-Type: application/x-amz-json-1.0
          
       
       
         Example
         
            Using AWS query
                    protocol
         
          
            Sample Request
            POST /177715257436/MyQueue HTTP/1.1
Host: sqs.us-east-1.amazonaws.com
X-Amz-Date: <Date>
Content-Type: application/x-www-form-urlencoded
Authorization: <AuthParams>
Content-Length: <PayloadSizeBytes>
Connection: Keep-Alive
Action=ChangeMessageVisibility
&VisibilityTimeout=60
&ReceiptHandle=AQEBwPTK2fT2gy97H1iyU5in9umgT+Y4IOxyKGOzpZa8iemEqoR5/aPn0xAodmiVTzyrW7S4e8XwcWbB04XK92jIQzUpiGwRFA4Dl7r3GOw84Qzq/0OBQe/JaKxJw6iilafYA5fo1SJQo5Wg8xXbJHTVlJqgvTXd/UtlByLMhWMi0JMra1UUjYiPsGtYUpLVnOaRkYSPvzRnFFYUbcqCW9lm2BijQKK6KNOZyCCfIh8TooE5i4P2L9N3o9yUHwMdv6p0nb5lKaGurQ2sJwwsyhXf38ZHnVN6pWwsqQnWKYuEXpxPofxd2lcLdgUurMpydS22DzCrkAaf6gmrdxbmCAoeQxE0sFf8alwX9yQmcOjny9aLGe7ro4Vl5o5KMr5hHM4vHEyhwi4wHeKM6MGX0vATA==
          
          
            Sample Response
            HTTP/1.1 200 OK
<?xml version="1.0"?>
<ChangeMessageVisibilityResponse xmlns="http://queue.amazonaws.com/doc/2012-11-05/">
    <ResponseMetadata>
        <RequestId>6a7a282a-d013-4a59-aba9-335b0fa48bed</RequestId>
    </ResponseMetadata>
</ChangeMessageVisibilityResponse>
          
       
    
      See Also
      For more information about using this API in one of the language-specific AWS SDKs, see the following:
      
          
          
          
          
          
          
          
          
          
          
      
            
               AWS Command Line Interface
            
         
            
               AWS SDK for .NET
            
         
            
               AWS SDK for C++
            
         
            
               AWS SDK for Go v2
            
         
            
               AWS SDK for Java V2
            
         
            
               AWS SDK for JavaScript V3
            
         
            
               AWS SDK for Kotlin
            
         
            
               AWS SDK for PHP V3
            
         
            
               AWS SDK for Python
            
         
            
               AWS SDK for Ruby V3
            
         
   Document ConventionsCancelMessageMoveTaskChangeMessageVisibilityBatchDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS SupportUser GuideCreating a service quota increaseTo improve the performance of your service, request increases to your service quotas
        (formerly referred to as limits).NoteYou can also use the Service Quotas service to request increases directly for your services.
            Currently, Service Quotas doesn't support service quotas for all services. For more information,
            see What is
                Service Quotas? in the Service Quotas User Guide.To create a support case for service quota increases
            Sign in to the AWS Support Center Console.
            TipIn the AWS Management Console, you can also choose the question mark icon (
                             
                                
                             
                        ) and then choose Support Center.
        
            Choose Create case.
        
            Choose Looking for service limit increases?
        
            To request an increase, follow the prompts. Possible options include the
                following:
            
                 
                 
            
                    Limit
                            type
                
                    Severity
                    NoteBased on your category choice, the prompts might request more
                            information.
                
        
            For Requests, choose the Region.
        
            For Limit, choose the service limit type.
        
            For New limit value, enter the value that you want. 
        
            (Optional) To request another increase, choose Add another
                    request.
        
            For Case description, describe your support case.
        
            For Contact options page, choose your preferred language and
                how you want to be contacted. You can choose one of the following options:
            
                 
                 
                 
            
                    Web – Receive a reply in Support Center.
                
                    Chat – Start a live chat with a support
                        agent.
                        If you can't connect to a chat, see Troubleshooting.
                
                    Phone – Receive a phone call from a support
                        agent. If you choose this option, enter the following information:
                    
                         
                         
                         
                    
                            Country/Region
                        
                            Phone number
                        
                            (Optional) Extension
                        
                
        
            Choose Submit. Your case ID number and summary appear.
        Document ConventionsTroubleshootingUpdate, resolve, and reopen your casesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAmazon Simple Queue ServiceAPI ReferenceWelcomeWelcome to the Amazon SQS API Reference.Amazon SQS is a reliable, highly-scalable hosted queue for storing messages as they travel
            between applications or microservices. Amazon SQS moves data between distributed application
            components and helps you decouple these components.For information on the permissions you need to use this API, see Identity and access management in the Amazon SQS Developer
                Guide.
   You can use AWS SDKs to access
            Amazon SQS using your favorite programming language. The SDKs perform tasks such as the
            following automatically:
       
       
       
   
         Cryptographically sign your service requests
      
         Retry requests
      
         Handle error responses
      
      Additional information
   
       
       
       
       
   
         
            Amazon SQS Product Page
         
      
         
            Amazon SQS Developer Guide
         
         
             
             
             
         
               
                  Making API Requests
               
            
               
                  Amazon SQS Message Attributes
               
            
               
                  Amazon SQS Dead-Letter Queues
               
            
      
         
            Amazon SQS in the AWS Command Line Interface
         
      
         
            Amazon Web Services General Reference
         
         
             
         
               
                  Regions and
                                Endpoints
               
            
      This document was last published on May 1, 2025. Document ConventionsActionsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n