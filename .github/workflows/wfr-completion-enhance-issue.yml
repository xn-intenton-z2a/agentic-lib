# .github/workflows/wfr-completion-enhance-issue.yml
#
# agentic-lib
# Copyright (C) 2025 Polycode Limited
#
# This file is part of agentic-lib.
#
# agentic-lib is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License v3.0 (GPL‑3).
# along with this program. If not, see <https://www.gnu.org/licenses/>.
#
# IMPORTANT: Any derived work must include the following attribution:
# "This work is derived from https://github.com/xn-intenton-z2a/agentic-lib"
#

name: ∞ enhance-issue

on:
  workflow_call:
    inputs:
      issueNumber:
        description: 'The issue number to enhance or close. e.g. "123"'
        type: string
        required: true
      featuresPath:
        description: 'The directory to create/update the features in. e.g. "features/"'
        type: string
        required: false
        default: 'features/'
      libraryDocumentsPath:
        description: 'The directory containing library documents. e.g. "library/"'
        type: string
        required: false
        default: 'library/'
      allSourcePaths:
        description: 'The source file(s) to review. e.g. "src/lib/" or multiple files separated by semicolons "src/lib/;src/utils/utils.js"'
        type: string
        required: false
        default: 'src/lib/'
      allTestsPaths:
        description: 'The test file(s) to review. e.g. "tests/unit/" or multiple files separated by semicolons "tests/unit/;tests/utils/utils.test.js"'
        type: string
        required: false
        default: 'tests/unit/'
      documentationPath:
        description: 'The documentation file(s) to write to. e.g. "docs/" or multiple files separated by semicolons "docs/api;docs/API.md"'
        type: string
        required: false
        default: 'docs/'
      readmeFilepath:
        description: 'The README file to review. e.g. "README.md"'
        type: string
        required: false
        default: 'README.md'
      missionFilepath:
        description: 'The MISSION statement file. e.g. "MISSION.md"'
        type: string
        required: false
        default: 'MISSION.md'
      contributingFilepath:
        description: 'The CONTRIBUTING file to review. e.g. "CONTRIBUTING.md"'
        type: string
        required: false
        default: 'CONTRIBUTING.md'
      dependenciesFilepath:
        description: 'The dependencies file to review. e.g. "package.json"'
        type: string
        required: false
        default: 'package.json'
      buildScript:
        description: 'The script must be runnable as: `npm ci ; <script>` and succeed with a zero exit code. e.g. `npm run build`'
        type: string
        required: false
        default: 'echo "No build script specified."'
      testScript:
        description: 'The script must be runnable as: `npm ci ; <script>` and succeed with a zero exit code. e.g. `npm test`'
        type: string
        required: false
        default: 'npm test'
      mainScript:
        description: 'The script must be runnable as: `npm ci ; <script>` and succeed with a zero exit code. e.g. `npm run start`'
        type: string
        required: false
        default: 'npm run start'
      model:
        description: 'The OpenAI model to use. e.g. "o3-mini"'
        type: string
        required: false
        default: ${{ vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation:
        description: 'The GitHub organisation to authenticate with for npm. e.g. "xn-intenton-z2a"'
        type: string
        required: false
        default: ''
      gitUserEmail:
        description: 'The email to use for git commits. e.g. "action@github.com"'
        type: string
        required: false
        default: 'action@github.com'
      gitUserName:
        description: 'The name to use for git commits. e.g. "GitHub Actions[bot]"'
        type: string
        required: false
        default: 'GitHub Actions[bot]'
      cache:
        description: 'The cache to use for npm. e.g. "npm"'
        type: string
        required: false
        default: 'npm'
      promptFilepath:
        description: 'The file containing the prompt text. e.g. ".github/agents/agent-ready-issue.md"'
        type: string
        required: true
      s3BucketUrl:
        description: 'The S3 bucket URL with prefix to use. e.g. "s3://my-bucket/prefix"'
        type: string
        required: false
        default: ''
      iamRoleArn:
        description: 'The ARN of the IAM role to assume. e.g. "arn:aws:iam::123456789012:role/my-role"'
        type: string
        required: false
        default: ''
      agentConfigContent:
        description: 'The content of the agent config file. e.g. Yaml read from "./github/agents/agent-config.yaml"'
        type: string
        required: false
        default: ''
      writeableFilepaths:
        description: 'Semicolon-separated list of file paths that can be written by the workflow. e.g. "elaborator-sandbox/SOURCES.md;elaborator-sandbox/library/;engineer-sandbox/features/;engineer-sandbox/source/;engineer-sandbox/tests/;engineer-sandbox/docs/"'
        type: string
        required: false
        default: ''
    secrets:
      PERSONAL_ACCESS_TOKEN:
        required: false
      CHATGPT_API_SECRET_KEY:
        required: true
    outputs:
      action:
        value: ${{ jobs.enhance-issue.outputs.action }}
      enhancedDescription:
        value: ${{ jobs.enhance-issue.outputs.enhancedDescription }}
      relevantLibraryDocuments:
        value: ${{ jobs.enhance-issue.outputs.relevantLibraryDocuments }}
      closeReason:
        value: ${{ jobs.enhance-issue.outputs.closeReason }}
      usage:
        description: 'The LLM API usage of the action'
        value: ${{ jobs.enhance-issue.outputs.usage }}

jobs:
  enhance-issue:
    runs-on: ubuntu-latest

    env:
      issueNumber: ${{ inputs.issueNumber }}
      featuresPath: ${{ inputs.featuresPath || 'features/' }}
      libraryDocumentsPath: ${{ inputs.libraryDocumentsPath || 'library/' }}
      allSourcePaths: ${{ inputs.allSourcePaths || '' }}
      allTestsPaths: ${{ inputs.allTestsPaths || '' }}
      documentationPath: ${{ inputs.documentationPath || '' }}
      readmeFilepath: ${{ inputs.readmeFilepath || 'README.md' }}
      missionFilepath: ${{ inputs.missionFilepath || 'MISSION.md' }}
      contributingFilepath: ${{ inputs.contributingFilepath || 'CONTRIBUTING.md' }}
      dependenciesFilepath: ${{ inputs.dependenciesFilepath || 'package.json' }}
      buildScript: ${{ inputs.buildScript || 'npm run build' }}
      testScript: ${{ inputs.testScript || 'npm test' }}
      testScriptTimeout: '5m'
      mainScript: ${{ inputs.mainScript || 'npm run start' }}
      mainScriptTimeout: '5m'
      model: ${{ inputs.model || vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation: ${{ inputs.npmAuthOrganisation || '' }}
      gitUserEmail: ${{ inputs.gitUserEmail || 'action@github.com' }}
      gitUserName: ${{ inputs.gitUserName || 'GitHub Actions[bot]' }}
      chatgptApiSecretKey: ${{ secrets.CHATGPT_API_SECRET_KEY }}
      cache: ${{ inputs.cache || 'npm' }}
      promptFilepath: ${{ inputs.promptFilepath || '.github/agents/agent-ready-issue.md' }}
      s3BucketUrl: ${{ inputs.s3BucketUrl || '' }}
      iamRoleArn: ${{ inputs.iamRoleArn || '' }}
      agentConfigContent: ${{ inputs.agentConfigContent || '' }}
      writeableFilepaths: ${{ inputs.writeableFilepaths || '' }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.ref }}

      - name: Get latest from remote
        run: |
          git config --local user.email '${{ env.gitUserEmail }}'
          git config --local user.name '${{ env.gitUserName }}'
          git config --local pull.ff     false       # never fast-forward
          git config --local pull.rebase false       # never rebase on pull
          git fetch origin ${{ github.ref_name }}
          git merge origin/${{ github.ref_name }} --no-ff --no-edit --strategy=recursive --strategy-option=ours

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: ${{ env.cache }}

      - name: Check GitHub authentication
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          curl --include --header "Authorization: token ${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" https://api.github.com/user

      - name: Set up .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          echo "${{ env.npmAuthOrganisation }}:registry=https://npm.pkg.github.com" >> .npmrc
          echo "//npm.pkg.github.com/:_authToken=${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" >> .npmrc
          echo "always-auth=true" >> .npmrc

      - run: npm ci || npm install

      - name: List current features
        id: features
        shell: bash
        run: |
          output=$(find "${{ env.featuresPath }}" -maxdepth 1 -type f -name '*.md' -print -exec echo "# {}" \; -exec cat {} \; 2>&1 || echo 'none')
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List dependencies
        id: list
        shell: bash
        run: |
          output=$(npm list 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Build project
        id: build
        shell: bash
        run: |
          output=$(${{ env.buildScript }} 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Tear down .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: rm -f .npmrc

      - name: Run tests
        id: test
        shell: bash
        run: |
          output=$(timeout ${{ env.testScriptTimeout }} ${{ env.testScript }} 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Run main
        id: main
        shell: bash
        run: |
          output=$(timeout ${{ env.mainScriptTimeout }} ${{ env.mainScript }} 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: enhance-issue
        id: enhance-issue
        uses: actions/github-script@v7
        env:
          dependenciesListOutput: ${{ steps.list.outputs.output }}
          buildOutput: ${{ steps.build.outputs.output }}
          testOutput: ${{ steps.test.outputs.output }}
          mainOutput: ${{ steps.main.outputs.output }}
          currentFeatures: ${{ steps.features.outputs.output }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const currentFeatures = process.env.currentFeatures;
            const allSourcePaths = process.env.allSourcePaths;
            const allTestsPaths = process.env.allTestsPaths;
            const documentationPath = process.env.documentationPath.replace(/\/+$/, '');
            const readmeFilepath = process.env.readmeFilepath;
            const missionFilepath = process.env.missionFilepath;
            const contributingFilepath = process.env.contributingFilepath;
            const dependenciesFilepath = process.env.dependenciesFilepath;
            const libraryDocumentsPath = process.env.libraryDocumentsPath.replace(/\/+$/, '');
            const model = process.env.model;
            const apiKey = process.env.chatgptApiSecretKey;
            const issueNumberStr = process.env.issueNumber
            const issueNumber = (parseInt(issueNumberStr) ? parseInt(issueNumberStr) : "");
            const promptFilepath = process.env.promptFilepath;
            const dependenciesListOutput = process.env.dependenciesListOutput;
            const buildScript = process.env.buildScript;
            const buildOutput = process.env.buildOutput;
            const testScript = process.env.testScript;
            const testOutput = process.env.testOutput;
            const mainScript = process.env.mainScript;
            const mainOutput = process.env.mainOutput;
            const agentConfigContent = process.env.agentConfigContent;
            const writeableFilepaths = process.env.writeableFilepaths;

            const fs = require('fs');
            const path = require('path');
            const OpenAI = require('openai').default;
            const { z } = require('zod');
            require('dotenv').config();

            if (!apiKey) { 
              core.setFailed("Missing CHATGPT_API_SECRET_KEY");
              return;
            }
            const openai = new OpenAI({ apiKey });

            core.info(`currentFeatures: "${currentFeatures}"`);
            core.info(`allSourcePaths: "${allSourcePaths}"`);
            core.info(`allTestsPaths: "${allTestsPaths}"`);
            core.info(`readmeFilepath: "${readmeFilepath}"`);
            core.info(`missionFilepath: "${missionFilepath}"`);
            core.info(`contributingFilepath: "${contributingFilepath}"`);
            core.info(`dependenciesFilepath: "${dependenciesFilepath}"`);
            core.info(`libraryDocumentsPath: "${libraryDocumentsPath}"`);
            core.info(`promptFilepath: "${promptFilepath}"`);
            core.info(`agentConfigContent: "${agentConfigContent}"`);
            core.info(`writeableFilepaths: "${writeableFilepaths}"`);

            // Handle multiple source files
            const srcFiles = allSourcePaths.split(';');
            let sourceFileContents = {};
            for (const file of srcFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        sourceFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Source file '${fullPath}' from directory has been loaded (length ${sourceFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    sourceFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Source file '${trimmedFile}' has been loaded (length ${sourceFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Source file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading source file '${file}': ${e.message}`);
              }
            }

            // Handle multiple test files
            const testFiles = allTestsPaths.split(';');
            let testsFileContents = {};
            for (const file of testFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        testsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Test file '${fullPath}' from directory has been loaded (length ${testsFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    testsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Test file '${trimmedFile}' has been loaded (length ${testsFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Test file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading test file '${file}': ${e.message}`);
              }
            }

            // Handle documents path to file or directory
            let docsFileContents = {};
            try {
              const trimmedFile = documentationPath.trim();
              if (fs.existsSync(trimmedFile)) {
                const stats = fs.statSync(trimmedFile);
                if (stats.isDirectory()) {
                  // If it's a directory, read all files in the directory
                  const files = fs.readdirSync(trimmedFile);
                  for (const subFile of files) {
                    const fullPath = path.join(trimmedFile, subFile);
                    if (fs.statSync(fullPath).isFile()) {
                      docsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                      core.info(`Docs file '${fullPath}' from directory has been loaded (length ${docsFileContents[fullPath].length}).`);
                    }
                  }
                } else {
                  // It's a file, read it directly
                  docsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                  core.info(`Docs file '${trimmedFile}' has been loaded (length ${docsFileContents[trimmedFile].length}).`);
                }
              } else {
                // Create directory if it doesn't exist
                const docsDir = path.dirname(trimmedFile);
                if (!fs.existsSync(docsDir)) {
                  fs.mkdirSync(docsDir, { recursive: true });
                }
                docsFileContents[trimmedFile] = '';
                core.info(`Docs file '${trimmedFile}' does not exist and will be created.`);
              }
            } catch (e) {
              core.warning(`Error reading docs file '${documentationPath}': ${e.message}`);
            }

            let readmeFilepathContent;
            try {
              readmeFilepathContent = fs.readFileSync(readmeFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading README file '${readmeFilepath}': ${e.message}`);
              readmeFilepathContent = '';
            }
            let missionFilepathContent;
            try {
              missionFilepathContent = fs.readFileSync(missionFilepath, 'utf8');
            } catch (e) {
                core.warning(`Error reading MISSION file '${missionFilepath}': ${e.message}`);
                missionFilepathContent = '';
            }
            let contributingFilepathContent;
            try {
              contributingFilepathContent = fs.readFileSync(contributingFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading CONTRIBUTING file '${contributingFilepath}': ${e.message}`);
              contributingFilepathContent = '';
            }
            let dependenciesFilepathContent;
            try {
              dependenciesFilepathContent = fs.readFileSync(dependenciesFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading dependencies file '${dependenciesFilepath}': ${e.message}`);
              dependenciesFilepathContent = '';
            }
            let promptContent;
            try {
              promptContent = fs.readFileSync(promptFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading prompt file '${promptFilepath}': ${e.message}`);
              promptContent = '';
            }

            core.info(`Readme file '${readmeFilepath}' has been loaded (length ${readmeFilepathContent.length}).`);
            core.info(`Mission file '${missionFilepath}' has been loaded (length ${missionFilepathContent.length}).`);
            core.info(`Contributing file '${contributingFilepath}' has been loaded (length ${contributingFilepathContent.length}).`);
            core.info(`Dependencies file '${dependenciesFilepath}' has been loaded (length ${dependenciesFilepathContent.length}).`);
            core.info(`Prompt file '${promptFilepath}' has been loaded (length ${promptContent.length}).`);

            // Load library documents
            let libraryFiles = [];
            let libraryContent = '';
            try {
              if (fs.existsSync(libraryDocumentsPath)) {
                // First, load all library files and extract their content
                const allLibraryFiles = fs.readdirSync(libraryDocumentsPath)
                  .filter(file => file.endsWith('.md'))
                  .map(file => {
                    const filePath = path.join(libraryDocumentsPath, file);
                    const content = fs.readFileSync(filePath, 'utf8');

                    // Extract the Information Dense Extract section if it exists
                    let informationDenseExtract = '';
                    const match = content.match(/## Information Dense Extract\n([\s\S]*?)(?=\n##|$)/);
                    if (match && match[1] && match[1].trim()) {
                      informationDenseExtract = match[1].trim();
                    }

                    // Extract the Sanitised Extract section if it exists
                    let sanitisedExtract = '';
                    const sanitisedMatch = content.match(/## Sanitised Extract\n([\s\S]*?)(?=\n##|$)/);
                    if (sanitisedMatch && sanitisedMatch[1] && sanitisedMatch[1].trim()) {
                      sanitisedExtract = sanitisedMatch[1].trim();
                    } else {
                      // If Sanitised Extract is not found, try to find Escaped Extract (for older documents)
                      const escapedMatch = content.match(/## Escaped Extract\n([\s\S]*?)(?=\n##|$)/);
                      if (escapedMatch && escapedMatch[1] && escapedMatch[1].trim()) {
                        sanitisedExtract = escapedMatch[1].trim();
                        core.info(`Using Escaped Extract for ${file} as fallback`);
                      }
                    }

                    if (informationDenseExtract) {
                      return { name: file, content, informationDenseExtract, sanitisedExtract, extractSize: informationDenseExtract.length };
                    } else {
                      // Fallback to the full content if Information Dense Extract is not found or empty
                      return { name: file, content, sanitisedExtract, extractSize: content.length };
                    }
                  });

                // Sort files by the size of their extract (smallest first) to maximize the number of files we can include
                allLibraryFiles.sort((a, b) => a.extractSize - b.extractSize);

                // Limit the total size to 500,000 characters to avoid token limits in OpenAI models
                const maxTotalSize = 500000;
                let currentSize = 0;
                let includedCount = 0;

                // Process each file and add it to libraryContent if it fits within the size limit
                libraryFiles = allLibraryFiles.filter(file => {
                  const contentToUse = file.informationDenseExtract || file.content;
                  const docSize = contentToUse.length + file.name.length + 5; // +5 for "# " and "\n\n"

                  if (currentSize + docSize <= maxTotalSize) {
                    libraryContent += `# ${file.name}\n${contentToUse}\n\n`;
                    currentSize += docSize;
                    includedCount++;
                    return true;
                  } else {
                    // If we can't include the full document, log a note
                    core.info(`Skipping document ${file.name} (size: ${docSize}) to avoid exceeding token limits.`);
                    return false;
                  }
                });

                core.info(`Included ${includedCount} of ${allLibraryFiles.length} library documents in prompt (total size: ${currentSize} characters).`);
              } else {
                core.warning(`Library directory '${libraryDocumentsPath}' does not exist.`);
              }
            } catch (e) {
              core.warning(`Error reading library directory: ${e.message}`);
            }

            core.info(`Found ${libraryFiles.length} library documents in ${libraryDocumentsPath}`);
            core.info(`Retrieving issue ${issueNumber} details...`);

            const issue = await github.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber
            });
            core.info(`Issue title: ${issue.data.title}`);
            const issueTitle = issue.data.title;
            const issueDescription = issue.data.body;
            const issueComments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber
            });
            const issueCommentsText = issueComments.data
              .map(comment => `Author:${comment.user.login}, Created:${comment.created_at}, Comment: ${comment.body}`)
              .join('\n');

            const chatGptPrompt = `
            ${promptContent}

            Only include the library documents in relevantLibraryDocuments not the others and in particular not CONTRIBUTING.md.
            Documents not from the library directory won't be found later when attaching documents to the issue so don't include them.
            If enough documents are already summarised as comments on the issues don't add more.

            Consider the following when making your decision:
            * Issue details (title, description, comments)
            * Mission statement
            * Contributing file content
            * Current features and specifications
            * Source code content
            * Test content
            * Documentation file content
            * README file content
            * Library documents
            * Repository structure and dependencies
            * Agent configuration file content

            Current feature names and specifications:
            CURRENT_FEATURES_START
            ${currentFeatures}
            CURRENT_FEATURES_END

            The relevantLibrary documents to be taken from the documents between LIBRARY_DOCUMENTS_START and LIBRARY_DOCUMENTS_END.
            Library documents:
            LIBRARY_DOCUMENTS_START
            ${libraryContent}
            LIBRARY_DOCUMENTS_END

            Source files:
            SOURCE_FILES_START
            ${Object.entries(sourceFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            SOURCE_FILES_END

            Test files:
            TEST_FILES_START
            ${Object.entries(testsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            TEST_FILES_END

            Documentation files (to be updated if necessary):
            DOCS_FILES_START
            ${Object.entries(docsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            DOCS_FILES_END

            README file: ${readmeFilepath}
            README_FILE_START
            ${readmeFilepathContent}
            README_FILE_END

            MISSION file: ${missionFilepath}
            MISSION_FILE_START
            ${missionFilepathContent}
            MISSION_FILE_END

            Contributing file: ${contributingFilepath}
            CONTRIBUTING_FILE_START
            ${contributingFilepathContent}
            CONTRIBUTING_FILE_END

            Dependencies file: ${dependenciesFilepath}
            DEPENDENCIES_FILE_START
            ${dependenciesFilepathContent}
            DEPENDENCIES_FILE_END

            Agent configuration file:
            AGENT_CONFIG_FILE_START
            ${agentConfigContent}
            AGENT_CONFIG_FILE_END

            Issue:
            ISSUE_START
            title: ${issueTitle}
            description:
            ${issueDescription}
            comments:
            ${issueCommentsText}
            ISSUE_END            

            Dependencies list from command: npm list
            DEPENDENCIES_LIST_START
            ${dependenciesListOutput}
            DEPENDENCIES_LIST_END    

            Build output from command: ${buildScript}
            BUILD_OUTPUT_START
            ${buildOutput}
            BUILD_OUTPUT_END

            Test output from command: ${testScript}
            TEST_OUTPUT_START
            ${testOutput}
            TEST_OUTPUT_END            

            Main output from command: ${mainScript}
            MAIN_OUTPUT_START
            ${mainOutput}
            MAIN_OUTPUT_END    

            Answer strictly with a JSON object following this schema:
            {
              "action": "enhance", // Whether to enhance the issue, close it pr do nothing.
              "enhancedDescription": "Updated issue description with testable acceptance criteria", // Updated issue description with testable acceptance criteria if action is 'enhance', otherwise match the supplied issue description.
              "relevantLibraryDocuments": ["document1.md", "document2.md"], // Array of relevant library document names from the documents between LIBRARY_DOCUMENTS_START and LIBRARY_DOCUMENTS_END if action is 'enhance', otherwise a an empty array.
              "closeReason": "Explanation of why the issue was closed" // Explanation of why the issue was closed if action is 'close', otherwise 'n/a'.
            }
            Ensure valid JSON.
            `;

            const promptFilePath = 'prompt.txt';
            fs.writeFileSync(promptFilePath, chatGptPrompt);
            core.setOutput("promptFilePath", promptFilePath);
            core.info("promptFilePath: " + promptFilePath);

            const ResponseSchema = z.object({ 
              action: z.enum(["enhance", "close", "nop"]), 
              enhancedDescription: z.string(), 
              relevantLibraryDocuments: z.array(z.string()),
              closeReason: z.string()
            });

            // Define the function schema for function calling
            const tools = [{
              type: "function",
              function: {
                name: "enhance_issue",
                description: "Evaluate whether a GitHub issue should be enhanced or closed. If enhanced, provide updated description and relevant library documents. If closed, provide a reason.",
                parameters: {
                  type: "object",
                  properties: {
                    action: { 
                      type: "string", 
                      enum: ["enhance", "close", "nop"],
                      description: "Whether to enhance the issue, close it pr do nothing." 
                    },
                    enhancedDescription: { 
                      type: "string", 
                      description: "Updated issue description with testable acceptance criteria if action is 'enhance', otherwise match the supplied issue description." 
                    },
                    relevantLibraryDocuments: { 
                      type: "array", 
                      items: { type: "string" },
                      description: "Array of relevant library document names from the documents between LIBRARY_DOCUMENTS_START and LIBRARY_DOCUMENTS_END if action is 'enhance', otherwise a an empty array." 
                    },
                    closeReason: { 
                      type: "string", 
                      description: "Explanation of why the issue was closed if action is 'close', otherwise 'n/a'." 
                    }
                  },
                  required: ["action", "enhancedDescription", "relevantLibraryDocuments", "closeReason"],
                  additionalProperties: false
                },
                strict: true
              }
            }];

            // Call OpenAI using function calling format
            const request = {
              model,
              messages: [
                { role: "system", content: "You are evaluating whether a GitHub issue should be enhanced or closed based on its relevance and value. Answer strictly with a JSON object following the provided function schema." },
                { role: "user", content: chatGptPrompt }
              ],
              tools: tools
            };
            
            const requestFilePath = 'request.json';
            fs.writeFileSync(requestFilePath, JSON.stringify(request, null, 2));
            core.setOutput("requestFilePath", requestFilePath);
            core.info("requestFilePath: " + requestFilePath);
            const response = await openai.chat.completions.create(request);
            
            const responseFilePath = 'response.json';
            fs.writeFileSync(responseFilePath, JSON.stringify(response, null, 2));
            core.setOutput("responseFilePath", responseFilePath);
            core.info("responseFilePath: " + responseFilePath);

            let result;
            if (response.choices[0].message.tool_calls && response.choices[0].message.tool_calls.length > 0) {
              try {
                result = JSON.parse(response.choices[0].message.tool_calls[0].function.arguments);
              } catch (e) {
                core.setFailed(`Failed to parse function call arguments: ${e.message}`);
                return;
              }
            } else if (response.choices[0].message.content) {
              try {
                result = JSON.parse(response.choices[0].message.content);
              } catch (e) {
                core.setFailed(`Failed to parse response content: ${e.message}`);
                return;
              }
            } else {
              core.setFailed("No valid response received from OpenAI.");
              return;
            }

            let parsed;
            try {
              parsed = ResponseSchema.parse(result);
              const resultFilePath = 'result.json';
              fs.writeFileSync(resultFilePath, JSON.stringify(parsed, null, 2));
              core.setOutput("resultFilePath", resultFilePath);
              core.info("resultFilePath: " + resultFilePath);
              core.setOutput("action", parsed.action);
            } catch (e) {
              core.setFailed(`Failed to parse ChatGPT response: ${e.message}`);
              return;
            }
            
            core.info(`enhancedDescription: "${parsed.enhancedDescription}"`);
            core.info(`relevantLibraryDocuments: ${JSON.stringify(parsed.relevantLibraryDocuments)}`);
            core.setOutput("enhancedDescription", parsed.enhancedDescription || "");
            core.setOutput("relevantLibraryDocuments", JSON.stringify(parsed.relevantLibraryDocuments || []));

            // Get current issue labels
            const hasInProgressLabel = issue.data.labels.some(label => label.name === 'in-progress');

            // Remove 'in progress' label if it exists
            if (hasInProgressLabel) {
              try{ 
                await github.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  name: 'in-progress'
                });
              } catch (e) {
                core.warning(`Failed to remove 'in progress' label: ${e.message}`);
              }
            }

            if (parsed.action === "enhance") {
              try {
                // Update issue description
                await github.rest.issues.update({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: parsed.enhancedDescription
                });

                // Add 'ready' label
                await github.rest.issues.addLabels({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  labels: ['ready']
                });

                // Add relevant library documents as comments
                if (parsed.relevantLibraryDocuments && parsed.relevantLibraryDocuments.length > 0) {
                  for (const docName of parsed.relevantLibraryDocuments) {
                    const doc = libraryFiles.find(file => file.name === docName);
                    if (doc) {
                      // Prepare the comment content, using Sanitised Extract if available
                      let commentContent = doc.sanitisedExtract || doc.informationDenseExtract || doc.content;

                      // GitHub comments have a maximum length of 65,536 characters
                      // Truncate if necessary, leaving room for the header and a truncation message
                      const maxCommentLength = 65000;
                      if (commentContent.length > maxCommentLength) {
                        commentContent = commentContent.substring(0, maxCommentLength) + 
                          '\n\n... (content truncated due to GitHub comment length limits)';
                      }

                      await github.rest.issues.createComment({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        issue_number: issueNumber,
                        body: `
            ## Relevant Library Document: ${docName}\n\n${commentContent}`
                      });
                    } else {
                      core.warning(`Document ${docName} not found in library files.`);
                    }
                  }
                }

                // Add a comment indicating the issue has been enhanced
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `This issue has been reviewed and marked as 'ready'. The description has been updated with testable acceptance criteria, and relevant library documents ([${parsed.relevantLibraryDocuments}], ${parsed.relevantLibraryDocuments.length} in total) have been added as comments.`
                });
              } catch (e) {
                core.setFailed(`Failed to update issue and add comments: ${e.message}`);
                return;
              }
            } else if (parsed.action === "close") {
              try {
                core.setOutput("closeReason", parsed.closeReason || "");
                core.info(`action: "close"`);
                core.info(`closeReason: "${parsed.closeReason}"`);

                // Add a comment explaining why the issue was closed
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: parsed.closeReason
                });

                // Close the issue
                await github.rest.issues.update({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  state: "closed"
                });
              } catch (e) {
                core.setFailed(`Failed to close issue or update issue description: ${e.message}`);
                return;
              }
            } else if (parsed.action === "nop") {
              core.info(`action: "nop"`);
            } else {
              core.info(`action: "${parsed.action}" unmapped. nop`);
            }

            core.setOutput("usage", JSON.stringify(response.usage));
            core.info(`usage: "${JSON.stringify(response.usage)}"`);

      - id: uuid
        name: uuid
        shell: bash
        run: |
          uuid=$(uuidgen)
          echo "uuid: ${uuid}"
          echo "uuid=${uuid}" >> $GITHUB_OUTPUT

      - name: Upload prompt file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "enhance-issue-prompt-${{ steps.uuid.outputs.uuid }}.txt"
          path: ${{ steps.enhance-issue.outputs.promptFilePath }}
          retention-days: 7

      - name: Upload request file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "enhance-issue-request-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.enhance-issue.outputs.requestFilePath }}
          retention-days: 7

      - name: Upload response file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "enhance-issue-response-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.enhance-issue.outputs.responseFilePath }}
          retention-days: 7

      - name: Upload result file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "enhance-issue-result-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.enhance-issue.outputs.resultFilePath }}

    outputs:
      action: ${{ steps.enhance-issue.outputs.action }}
      enhancedDescription: ${{ steps.enhance-issue.outputs.enhancedDescription }}
      relevantLibraryDocuments: ${{ steps.enhance-issue.outputs.relevantLibraryDocuments }}
      closeReason: ${{ steps.enhance-issue.outputs.closeReason }}
      usage: ${{ steps.enhance-issue.outputs.usage }}
