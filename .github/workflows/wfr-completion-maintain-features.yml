# .github/workflows/wfr-completion-maintain-features.yml

#
# agentic-lib
# Copyright (C) 2025 Polycode Limited
#
# This file is part of agentic-lib.
#
# agentic-lib is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License v3.0 (GPL‑3).
# along with this program. If not, see <https://www.gnu.org/licenses/>.
#
# IMPORTANT: Any derived work must include the following attribution:
# "This work is derived from https://github.com/xn-intenton-z2a/agentic-lib"
#

name: ∞ maintain-features

on:
  workflow_call:
    inputs:
      feature:
        description: 'Text to drive the feature creation (if "", the repository will be assessed an action chosen). e.g. "Support output to PDF."'
        type: string
        required: false
        default: ''
      featuresPath:
        description: 'The directory to create/update the features in. e.g. "features/"'
        type: string
        required: false
        default: 'features/'
      featuresLimit:
        description: 'The maximum number of features to create. e.g. "3"'
        type: string
        required: false
        default: '3'
      allSourcePaths:
        description: 'The source file(s) to create the issue to change. e.g. "src/lib/main.js" or multiple files separated by semicolons "src/lib/main.js;src/lib/utils.js"'
        type: string
        required: false
        default: 'src/lib/'
      allTestsPaths:
        description: 'The test file(s). e.g. "tests/unit/main.test.js" or multiple files separated by semicolons "tests/unit/main.test.js;tests/unit/utils.test.js"'
        type: string
        required: false
        default: 'tests/unit/'
      documentationPath:
        description: 'The documentation file(s) to write to. e.g. "docs/" or multiple files separated by semicolons "docs/api;docs/API.md"'
        type: string
        required: false
        default: 'docs/'
      readmeFilepath:
        description: 'The README file. e.g. "README.md"'
        type: string
        required: false
        default: 'README.md'
      missionFilepath:
        description: 'The MISSION statement file. e.g. "MISSION.md"'
        type: string
        required: false
        default: 'MISSION.md'
      contributingFilepath:
        description: 'The CONTRIBUTING file. e.g. "CONTRIBUTING.md"'
        type: string
        required: false
        default: 'CONTRIBUTING.md'
      dependenciesFilepath:
        description: 'The dependencies file. e.g. "package.json"'
        type: string
        required: false
        default: 'package.json'
      intentionFilepath:
        description: 'The intention file to review. e.g. "intentïon.md"'
        type: string
        required: false
        default: 'intentïon.md'
      model:
        description: 'The OpenAI model to use. e.g. "o3-mini"'
        type: string
        required: false
        default: ${{ vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation:
        description: 'The GitHub organisation to authenticate with for npm. e.g. "xn-intenton-z2a"'
        type: string
        required: false
        default: ''
      gitUserEmail:
        description: 'The email to use for git commits. e.g. "action@github.com"'
        type: string
        required: false
        default: 'action@github.com'
      gitUserName:
        description: 'The name to use for git commits. e.g. "GitHub Actions[bot]"'
        type: string
        required: false
        default: 'GitHub Actions[bot]'
      s3BucketUrl:
        description: 'The S3 bucket URL with prefix to use. e.g. "s3://my-bucket/prefix"'
        type: string
        required: false
        default: ''
      promptFilepath:
        description: 'The file containing the prompt text. e.g. ".github/agents/agent-ready-issue.md"'
        type: string
        required: true
      iamRoleArn:
        description: 'The ARN of the IAM role to assume. e.g. "arn:aws:iam::123456789012:role/my-role"'
        type: string
        required: false
        default: ''
      agentConfigContent:
        description: 'The content of the agent config file. e.g. Yaml read from "./github/agents/agent-config.yaml"'
        type: string
        required: false
        default: ''
      writeableFilepaths:
        description: 'Semicolon-separated list of file paths that can be written by the workflow. e.g. "elaborator-sandbox/SOURCES.md;elaborator-sandbox/library/;engineer-sandbox/features/;engineer-sandbox/source/;engineer-sandbox/tests/;engineer-sandbox/docs/"'
        type: string
        required: false
        default: ''
    secrets:
      PERSONAL_ACCESS_TOKEN:
        required: false
      CHATGPT_API_SECRET_KEY:
        required: true
    outputs:
      featureName:
        value: ${{ jobs.maintain-features.outputs.featureName }}
      featureSpec:
        value: ${{ jobs.maintain-features.outputs.featureSpec }}
      gitDiff:
        description: 'The changes applied as seen by a git diff of the workspace after the changes were applied'
        value: ${{ jobs.maintain-features.outputs.gitDiff }}
      usage:
        description: 'The LLM API usage of the action'
        value: ${{ jobs.maintain-features.outputs.usage }}

jobs:
  maintain-features:
    runs-on: ubuntu-latest

    env:
      feature: ${{ inputs.feature || '' }}
      featuresPath: ${{ inputs.featuresPath || 'features/' }}
      featuresLimit: ${{ inputs.featuresLimit || '3' }}
      allSourcePaths: ${{ inputs.allSourcePaths || '' }}
      allTestsPaths: ${{ inputs.allTestsPaths || '' }}
      documentationPath: ${{ inputs.documentationPath || '' }}
      readmeFilepath: ${{ inputs.readmeFilepath || 'README.md' }}
      missionFilepath: ${{ inputs.missionFilepath || 'MISSION.md' }}
      contributingFilepath: ${{ inputs.contributingFilepath || 'CONTRIBUTING.md' }}
      dependenciesFilepath: ${{ inputs.dependenciesFilepath || 'package.json' }}
      intentionFilepath: ${{ inputs.intentionFilepath || 'intentïon.md' }}
      model: ${{ inputs.model || vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation: ${{ inputs.npmAuthOrganisation || '' }}
      gitUserEmail: ${{ inputs.gitUserEmail || 'action@github.com' }}
      gitUserName: ${{ inputs.gitUserName || 'GitHub Actions[bot]' }}
      chatgptApiSecretKey: ${{ secrets.CHATGPT_API_SECRET_KEY }}
      promptFilepath: ${{ inputs.promptFilepath || '.github/agents/agent-maintain-features.md' }}
      s3BucketUrl: ${{ inputs.s3BucketUrl || '' }}
      iamRoleArn: ${{ inputs.iamRoleArn || '' }}
      agentConfigContent: ${{ inputs.agentConfigContent || '' }}
      writeableFilepaths: ${{ inputs.writeableFilepaths || '' }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.ref }}

      - name: Get latest from remote
        run: |
          git config --local user.email "${{ env.gitUserEmail }}"
          git config --local user.name "${{ env.gitUserName }}"
          git pull --ff-only origin ${{ github.ref }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Check GitHub authentication
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          curl --include --header "Authorization: token ${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" https://api.github.com/user

      - name: Set up .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          echo "${{ env.npmAuthOrganisation }}:registry=https://npm.pkg.github.com" >> .npmrc
          echo "//npm.pkg.github.com/:_authToken=${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" >> .npmrc
          echo "always-auth=true" >> .npmrc

      - run: npm ci || npm install

      - name: List current features
        id: features
        shell: bash
        run: |
          output=$(find "${{ env.featuresPath }}" -maxdepth 1 -type f -name '*.md' -print -exec echo "# {}" \; -exec cat {} \; 2>&1 || echo 'none')
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List rejected feature named
        id: rejectedFeatures
        shell: bash
        run: |
          mkdir -p "${{ env.featuresPath }}/rejects"
          output=$(ls -1 "${{ env.featuresPath }}/rejects" | sed 's/\.md//' | xargs echo )
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List dependencies
        id: list
        shell: bash
        run: |
          output=$(npm list 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Tear down .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: rm -f .npmrc

      - name: maintain-features
        id: maintain-features
        uses: actions/github-script@v7
        env:
          currentFeatures: ${{ steps.features.outputs.output }}
          rejectedFeatures: ${{ steps.rejectedFeatures.outputs.output }}
          dependenciesListOutput: ${{ steps.list.outputs.output }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const feature = process.env.feature;
            const featuresPath = process.env.featuresPath.replace(/\/+$/, '');
            const featuresLimit = process.env.featuresLimit;
            const currentFeatures = process.env.currentFeatures;
            const rejectedFeatures = process.env.rejectedFeatures;
            const allSourcePaths = process.env.allSourcePaths;
            const allTestsPaths = process.env.allTestsPaths;
            const documentationPath = process.env.documentationPath.replace(/\/+$/, '');
            const readmeFilepath = process.env.readmeFilepath;
            const missionFilepath = process.env.missionFilepath;
            const contributingFilepath = process.env.contributingFilepath;
            const dependenciesFilepath = process.env.dependenciesFilepath;
            const intentionFilepath = process.env.intentionFilepath || '';
            const model = process.env.model;
            const apiKey = process.env.chatgptApiSecretKey;
            const promptFilepath = process.env.promptFilepath;
            const dependenciesListOutput = process.env.dependenciesListOutput;
            const agentConfigContent = process.env.agentConfigContent;
            const writeableFilepaths = process.env.writeableFilepaths;

            const fs = require('fs');
            const path = require('path');
            const OpenAI = require('openai').default;
            const { z } = require('zod');
            require('dotenv').config();

            if (!apiKey) { 
              core.setFailed("Missing CHATGPT_API_SECRET_KEY");
              return;
            }
            const openai = new OpenAI({ apiKey });

            core.info(`feature: "${feature}"`);
            core.info(`featuresPath: "${featuresPath}"`);
            core.info(`currentFeatures: "${currentFeatures}"`);
            core.info(`allSourcePaths: "${allSourcePaths}"`);
            core.info(`allTestsPaths: "${allTestsPaths}"`);
            core.info(`documentationPath: "${documentationPath}"`);
            core.info(`readmeFilepath: "${readmeFilepath}"`);
            core.info(`missionFilepath: "${missionFilepath}"`);
            core.info(`contributingFilepath: "${contributingFilepath}"`);
            core.info(`dependenciesFilepath: "${dependenciesFilepath}"`);
            core.info(`agentConfigContent: "${agentConfigContent}"`);
            core.info(`writeableFilepaths: "${writeableFilepaths}"`);

            // Handle multiple source files
            const srcFiles = allSourcePaths.split(';');
            let sourceFileContents = {};
            for (const file of srcFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        sourceFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Source file '${fullPath}' from directory has been loaded (length ${sourceFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    sourceFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Source file '${trimmedFile}' has been loaded (length ${sourceFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Source file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading source file '${file}': ${e.message}`);
              }
            }

            // Handle multiple test files
            const testFiles = allTestsPaths.split(';');
            let testsFileContents = {};
            for (const file of testFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        testsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Test file '${fullPath}' from directory has been loaded (length ${testsFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    testsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Test file '${trimmedFile}' has been loaded (length ${testsFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Test file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading test file '${file}': ${e.message}`);
              }
            }

            // Handle documents path to file or directory
            let docsFileContents = {};
            try {
              const trimmedFile = documentationPath.trim();
              if (fs.existsSync(trimmedFile)) {
                const stats = fs.statSync(trimmedFile);
                if (stats.isDirectory()) {
                  // If it's a directory, read all files in the directory
                  const files = fs.readdirSync(trimmedFile);
                  for (const subFile of files) {
                    const fullPath = path.join(trimmedFile, subFile);
                    if (fs.statSync(fullPath).isFile()) {
                      docsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                      core.info(`Docs file '${fullPath}' from directory has been loaded (length ${docsFileContents[fullPath].length}).`);
                    }
                  }
                } else {
                  // It's a file, read it directly
                  docsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                  core.info(`Docs file '${trimmedFile}' has been loaded (length ${docsFileContents[trimmedFile].length}).`);
                }
              } else {
                // Create directory if it doesn't exist
                const docsDir = path.dirname(trimmedFile);
                if (!fs.existsSync(docsDir)) {
                  fs.mkdirSync(docsDir, { recursive: true });
                }
                docsFileContents[trimmedFile] = '';
                core.info(`Docs file '${trimmedFile}' does not exist and will be created.`);
              }
            } catch (e) {
              core.warning(`Error reading docs file '${file}': ${e.message}`);
            }

            let readmeFilepathContent;
            try {
              readmeFilepathContent = fs.readFileSync(readmeFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading README file '${readmeFilepath}': ${e.message}`);
              readmeFilepathContent = '';
            }
            let missionFilepathContent;
            try {
              missionFilepathContent = fs.readFileSync(missionFilepath, 'utf8');
            } catch (e) {
                core.warning(`Error reading MISSION file '${missionFilepath}': ${e.message}`);
                missionFilepathContent = '';
            }
            let contributingFilepathContent;
            try {
              contributingFilepathContent = fs.readFileSync(contributingFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading CONTRIBUTING file '${contributingFilepath}': ${e.message}`);
              contributingFilepathContent = '';
            }
            let dependenciesFilepathContent;
            try {
              dependenciesFilepathContent = fs.readFileSync(dependenciesFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading dependencies file '${dependenciesFilepath}': ${e.message}`);
              dependenciesFilepathContent = '';
            }
            let promptContent;
            try {
              promptContent = fs.readFileSync(promptFilepath, 'utf8');
            } catch (e) {
              core.warning(`Error reading prompt file '${promptFilepath}': ${e.message}`);
              promptContent = '';
            }

            core.info(`Readme file '${readmeFilepath}' has been loaded (length ${readmeFilepathContent.length}).`);
            core.info(`Mission file '${missionFilepath}' has been loaded (length ${missionFilepathContent.length}).`);
            core.info(`Contributing file '${contributingFilepath}' has been loaded (length ${contributingFilepathContent.length}).`);
            core.info(`Dependencies file '${dependenciesFilepath}' has been loaded (length ${dependenciesFilepathContent.length}).`);
            core.info(`Prompt file '${promptFilepath}' has been loaded (length ${promptContent.length}).`);

            // Load library documents
            let libraryDocuments = '';
            try {
              const libraryDocumentsPath = 'library';
              if (fs.existsSync(libraryDocumentsPath)) {
                const libraryFiles = fs.readdirSync(libraryDocumentsPath)
                  .filter(file => file.endsWith('.md'))
                  .map(file => path.join(libraryDocumentsPath, file));

                // Prepare an array to hold all document contents
                const documentContents = [];

                for (const file of libraryFiles) {
                  const fileName = path.basename(file);
                  const content = fs.readFileSync(file, 'utf8');

                  // Extract the Information Dense Extract section if it exists
                  let informationDenseExtract = '';
                  const match = content.match(/## Information Dense Extract\n([\s\S]*?)(?=\n##|$)/);
                  if (match && match[1] && match[1].trim()) {
                    informationDenseExtract = match[1].trim();
                    documentContents.push({ name: fileName, content: informationDenseExtract });
                  } else {
                    // Fallback to the full content if Information Dense Extract is not found or empty
                    documentContents.push({ name: fileName, content });
                  }
                }

                // Sort documents by size (smallest first) to maximize the number of documents we can include
                documentContents.sort((a, b) => a.content.length - b.content.length);

                // Limit the total size to 500,000 characters to avoid token limits in OpenAI models
                const maxTotalSize = 500000;
                let currentSize = 0;
                let includedCount = 0;

                for (const doc of documentContents) {
                  const docSize = doc.content.length + doc.name.length + 5; // +5 for "# " and "\n\n"
                  if (currentSize + docSize <= maxTotalSize) {
                    libraryDocuments += `# ${doc.name}\n${doc.content}\n\n`;
                    currentSize += docSize;
                    includedCount++;
                  } else {
                    // If we can't include the full document, add a note
                    core.info(`Skipping document ${doc.name} (size: ${docSize}) to avoid exceeding token limits.`);
                  }
                }

                core.info(`Loaded ${includedCount} of ${libraryFiles.length} library documents (total size: ${currentSize} characters).`);
              } else {
                core.info('Library directory not found.');
              }
            } catch (e) {
              core.warning(`Error reading library documents: ${e.message}`);
            }

            // generate the feature prompt either by using the supplied feature or by reviewing the current features and full context
            let prompt = feature;
            if (feature === '') {
              prompt = `Please review the current features in the repository and either;
                * add a new feature to the repository, or
                * extend an existing feature to add a new aspect to it, or
                * update an existing feature to bring it to a high standard matching other features in the repository.
                The feature name should either be a current feature name or be supplied with a feature specification which is distinct from any other feature in the repository.
              `;
            }

            // intention Filepath contents 
            let intentionContent = '';
            try {
              const intentionFilepath = process.env.intentionFilepath;
              if (fs.existsSync(intentionFilepath)) {
                intentionContent = fs.readFileSync(intentionFilepath, 'utf8');
                core.info(`Intention file content: ${intentionContent}`);
              } else {
                core.warning(`Intention file '${intentionFilepath}' does not exist.`);
              }
            } catch (error) {
              core.warning(`Error reading intention file: ${error.message}`);
            }

            const chatGptPrompt = `
            ${promptContent}

            If there are more than the maximum number of ${featuresLimit} features in the repository, you must merge 
            similar features into a single feature and name the features to be deleted.
            All significant features of the repository should be present in the feature set before new features are 
            added and features can be consolidated to make room below the maximum of ${featuresLimit} features.

            The intentïon file contents is a log of both taken in the repository since the last repository seed and you
            should see an alignment between the intentïon file entries and commits in the repository (where a commit is required).
            Use this log to determine the current direction of the repository towards its mission. The combination of the
            repository code, tests, dependencies and supporting documentation show the current state of the repository.

            Consider the following when refining your response:
            * Feature prompt details
            * Current feature names and specifications in the repository
            * intentïon file contents
            * Rejected feature names
            * Source file content
            * Test file content
            * Documentation file content
            * README file content
            * MISSION file content
            * Contributing file content
            * Dependencies file content
            * Library documents
            * Dependency list

            Feature prompt:
            FEATURE_PROMPT_START
            ${prompt}
            FEATURE_PROMPT_END

            intentïon file contents:
            INTENTION_FILE_START
            ${intentionContent}
            INTENTION_FILE_END

            Current feature names and specifications:
            CURRENT_FEATURES_START
            ${currentFeatures}
            CURRENT_FEATURES_END

            Library documents:
            LIBRARY_DOCUMENTS_START
            ${libraryDocuments}
            LIBRARY_DOCUMENTS_END

            Rejected feature names:
            REJECTED_FEATURES_START
            ${rejectedFeatures}
            REJECTED_FEATURES_END

            Source files:
            SOURCE_FILES_START
            ${Object.entries(sourceFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            SOURCE_FILES_END

            Test files:
            TEST_FILES_START
            ${Object.entries(testsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            TEST_FILES_END

            Documentation files:
            DOCS_FILES_START
            ${Object.entries(docsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            DOCS_FILES_END

            README file: ${readmeFilepath}
            README_FILE_START
            ${readmeFilepathContent}
            README_FILE_END

            MISSION file: ${missionFilepath}
            MISSION_FILE_START
            ${missionFilepathContent}
            MISSION_FILE_END

            Contributing file: ${contributingFilepath}
            CONTRIBUTING_FILE_START
            ${contributingFilepathContent}
            CONTRIBUTING_FILE_END

            Dependencies file: ${dependenciesFilepath}
            DEPENDENCIES_FILE_START
            ${dependenciesFilepathContent}
            DEPENDENCIES_FILE_END

            Dependencies list from command: npm list
            DEPENDENCIES_LIST_START
            ${dependenciesListOutput}
            DEPENDENCIES_LIST_END    

            Agent configuration file:
            AGENT_CONFIG_FILE_START
            ${agentConfigContent}
            AGENT_CONFIG_FILE_END

            Answer strictly with a JSON object following this schema:
            {
              "featureName": "The feature name as one or two words in SCREAMING_SNAKECASE.",
              "featureSpec": "The feature specification as multiline markdown with a few level 1 headings.",
              "featureNamesToBeDeleted": "The comma separated list of feature names to be deleted or 'none' if no feature is to be deleted."
            }
            Ensure valid JSON.
            `;

            const promptFilePath = 'prompt.txt';
            fs.writeFileSync(promptFilePath, chatGptPrompt);
            core.setOutput("promptFilePath", promptFilePath);
            core.info("promptFilePath: " + promptFilePath);

            const ResponseSchema = z.object({ featureName: z.string(), featureSpec: z.string(), featureNamesToBeDeleted: z.string() });

            // Define the function schema for function calling
            const tools = [{
              type: "function",
              function: {
                name: "generate_feature",
                description: "Elaborate on the supplied prompt and project files to create the featureName and featureSpec of a repository feature, and the feature names to be deleted. Return an object with featureName (string), featureSpec (string), and featureNamesToBeDeleted (string).",
                parameters: {
                  type: "object",
                  properties: {
                    featureName: { type: "string", description: "The feature name as one or two words in SCREAMING_SNAKECASE." },
                    featureSpec: { type: "string", description: "The feature specification as multiline markdown with a few level 1 headings." },
                    featureNamesToBeDeleted: { type: "string", description: "The comma separated list of feature names to be deleted or 'none' if no feature is to be deleted." }
                  },
                  required: ["featureName", "featureSpec", "featureNamesToBeDeleted"],
                  additionalProperties: false
                },
                strict: true
              }
            }];

            // Call OpenAI using function calling format
            const request = {
              model,
              messages: [
                { role: "system", content: "You are maintaining a feature set by providing expert contemporary insight into both the product market and you will perform a detailed analysis of the current state of the repository and current feature set in search of value opportunities and unique selling points. Answer strictly with a JSON object following the provided function schema." },
                { role: "user", content: chatGptPrompt }
              ],
              tools: tools
            };

            const requestFilePath = 'request.json';
            fs.writeFileSync(requestFilePath, JSON.stringify(request, null, 2));
            core.setOutput("requestFilePath", requestFilePath);
            core.info("requestFilePath: " + requestFilePath);
            const response = await openai.chat.completions.create(request);

            const responseFilePath = 'response.json';
            fs.writeFileSync(responseFilePath, JSON.stringify(response, null, 2));
            core.setOutput("responseFilePath", responseFilePath);
            core.info("responseFilePath: " + responseFilePath);

            let result;
            if (response.choices[0].message.tool_calls && response.choices[0].message.tool_calls.length > 0) {
              try {
                result = JSON.parse(response.choices[0].message.tool_calls[0].function.arguments);
              } catch (e) {
                core.setFailed(`Failed to parse function call arguments: ${e.message}`);
                return;
              }
            } else if (response.choices[0].message.content) {
              try {
                result = JSON.parse(response.choices[0].message.content);
              } catch (e) {
                core.setFailed(`Failed to parse response content: ${e.message}`);
                return;
              }
            } else {
              core.setFailed("No valid response received from OpenAI.");
              return;
            }

            try {
              let parsed;
              try {
                parsed = ResponseSchema.parse(result);
                const resultFilePath = 'result.json';
                fs.writeFileSync(resultFilePath, JSON.stringify(parsed, null, 2));
                core.setOutput("resultFilePath", resultFilePath);
                core.info("resultFilePath: " + resultFilePath);
              } catch (e) {
                core.setFailed(`Failed to parse ChatGPT response: ${e.message}`);
                return;
              }

              core.setOutput("featureName", parsed.featureName);
              core.setOutput("featureSpec", parsed.featureSpec);
              core.setOutput("featureNamesToBeDeleted", parsed.featureNamesToBeDeleted);
              core.info(`featureName: "${parsed.featureName}"`);
              core.info(`featureSpec: "${parsed.featureSpec}"`);
              core.info(`featureNamesToBeDeleted: "${parsed.featureNamesToBeDeleted}"`);

              // Save the feature spec to a file using the convention of <featuresPath> plus path SCREAMING_SNAKE_CASE(<feature name>).md
              const featureName = parsed.featureName.replace(/ /g, "_").toUpperCase();
              const featureSpec = parsed.featureSpec;
              const featuresPath = process.env.featuresPath || 'features/';

              const featureFilePath = path.join(featuresPath, `${featureName}.md`);
              try {
                fs.mkdirSync(featuresPath, { recursive: true });
                fs.writeFileSync(featureFilePath, featureSpec);
                core.info(`Feature spec saved to ${featureFilePath}`);
              } catch (e) {
                core.setFailed(`Failed to save feature spec: ${e.message}`);
                return;
              }

              const featureFilepathsToBeDeleted = parsed.featureNamesToBeDeleted
                .split(',')
                .map(name => path.join(featuresPath, `${name.trim().replace(/.md$/, "").toUpperCase()}.md`));
              for (const filepath of featureFilepathsToBeDeleted) {
                try {
                  if( fs.existsSync(filepath) ) {
                    core.info(`Deleting feature file: ${filepath}`);
                    fs.unlinkSync(filepath);
                  }
                } catch (e) {
                  core.info(`Could not delete ${filepath}: ${e.message}`);
                }
              }

            } catch (e) {
              core.setFailed(`Failed to parse ChatGPT response: ${e.message}`);
              return;
            }

            core.setOutput("usage", JSON.stringify(response.usage));
            core.info(`usage: "${JSON.stringify(response.usage)}"`);

      - name: Collect git diff as a text output
        id: git-diff
        shell: bash
        run: |
          git config --local user.email '${{ env.gitUserEmail }}'
          git config --local user.name '${{ env.gitUserName }}'
          #output=$(git add --intent-to-add $(git ls-files -o --exclude-standard) ; git diff 2>&1)
          output=$(git diff 2>&1)
          # Get a list of the new files not added to the index and concatenate them to the output with a lable showing
          # the file name proceeding with "new-file: "
          newFiles=$(git ls-files -o --exclude-standard)
          for file in ${newFiles?}; do
            output+="\n\n// New [${file?}]:\n"
            output+=$(cat "${file?}")
          done
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Commit changes
        id: commit
        continue-on-error: true
        run: |
          git config --local user.email '${{ env.gitUserEmail }}'
          git config --local user.name '${{ env.gitUserName }}'
          git config --local pull.ff     false       # never fast-forward
          git config --local pull.rebase false       # never rebase on pull
          git status -v
          git add -v --all '${{ env.featuresPath }}'
          git commit -m 'Maintain features ${{ steps.maintain-features.outputs.featureName }}'
          git status -v
          #git pull --ff-only origin ${{ github.ref }}
          # 4) Fetch & merge remote (always creates a merge commit, no editor prompt)
          git fetch origin ${{ github.ref_name }}
          git merge origin/${{ github.ref_name }} --no-ff --no-edit
          git push -v origin ${{ github.ref_name }}
          git status -v

      - id: uuid
        name: uuid
        shell: bash
        run: |
          uuid=$(uuidgen)
          echo "uuid: ${uuid}"
          echo "uuid=${uuid}" >> $GITHUB_OUTPUT

      - name: Upload prompt file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "maintain-features-prompt-${{ steps.uuid.outputs.uuid }}.txt"
          path: ${{ steps.maintain-features.outputs.promptFilePath }}
          retention-days: 7

      - name: Upload request file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "maintain-features-request-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.maintain-features.outputs.requestFilePath }}
          retention-days: 7

      - name: Upload response file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "maintain-features-response-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.maintain-features.outputs.responseFilePath }}
          retention-days: 7

      - name: Upload result file as an artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: "maintain-features-result-${{ steps.uuid.outputs.uuid }}.json"
          path: ${{ steps.maintain-features.outputs.resultFilePath }}


    outputs:
      featureName: ${{ steps.maintain-features.outputs.featureName }}
      featureSpec: ${{ steps.maintain-features.outputs.featureSpec }}
      gitDiff: ${{ steps.git-diff.outputs.output }}
      usage: ${{ steps.maintain-features.outputs.usage }}
