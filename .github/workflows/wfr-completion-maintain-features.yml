# .github/workflows/wfr-completion-maintain-features.yml

#
# agentic-lib
# Copyright (C) 2025 Polycode Limited
#
# This file is part of agentic-lib.
#
# agentic-lib is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License v3.0 (GPL‑3).
# along with this program. If not, see <https://www.gnu.org/licenses/>.
#
# IMPORTANT: Any derived work must include the following attribution:
# "This work is derived from https://github.com/xn-intenton-z2a/agentic-lib"
#

name: ∞ maintain-features

on:
  workflow_call:
    inputs:
      feature:
        description: 'Text to drive the feature creation (if "house choice", the repository will be assessed an action chosen). e.g. "Support output to PDF."'
        type: string
        required: false
        default: 'house choice'
      featuresPath:
        description: 'The directory to create/update the features in. e.g. "features/"'
        type: string
        required: false
        default: 'features/'
      featuresLimit:
        description: 'The maximum number of features to create. e.g. "3"'
        type: string
        required: false
        default: '3'
      allSourcePaths:
        description: 'The source file(s) to create the issue to change. e.g. "src/lib/main.js" or multiple files separated by semicolons "src/lib/main.js;src/lib/utils.js"'
        type: string
        required: false
        default: 'src/lib/'
      allTestsPaths:
        description: 'The test file(s). e.g. "tests/unit/main.test.js" or multiple files separated by semicolons "tests/unit/main.test.js;tests/unit/utils.test.js"'
        type: string
        required: false
        default: 'tests/unit/'
      documentationPath:
        description: 'The documentation file(s) to write to. e.g. "docs/" or multiple files separated by semicolons "docs/api;docs/API.md"'
        type: string
        required: false
        default: 'docs/'
      readmeFilepath:
        description: 'The README file. e.g. "README.md"'
        type: string
        required: false
        default: 'README.md'
      missionFilepath:
        description: 'The MISSION statement file. e.g. "MISSION.md"'
        type: string
        required: false
        default: 'MISSION.md'
      contributingFilepath:
        description: 'The CONTRIBUTING file. e.g. "CONTRIBUTING.md"'
        type: string
        required: false
        default: 'CONTRIBUTING.md'
      dependenciesFilepath:
        description: 'The dependencies file. e.g. "package.json"'
        type: string
        required: false
        default: 'package.json'
      model:
        description: 'The OpenAI model to use. e.g. "o3-mini"'
        type: string
        required: false
        default: ${{ vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation:
        description: 'The GitHub organisation to authenticate with for npm. e.g. "xn-intenton-z2a"'
        type: string
        required: false
        default: ''
      gitUserEmail:
        description: 'The email to use for git commits. e.g. "action@github.com"'
        type: string
        required: false
        default: 'action@github.com'
      gitUserName:
        description: 'The name to use for git commits. e.g. "GitHub Actions[bot]"'
        type: string
        required: false
        default: 'GitHub Actions[bot]'
      s3BucketUrl:
        description: 'The S3 bucket URL with prefix to use. e.g. "s3://my-bucket/prefix"'
        type: string
        required: false
        default: ''
      promptFilepath:
        description: 'The file containing the prompt text. e.g. ".github/agents/agent-ready-issue.md"'
        type: string
        required: true
      iamRoleArn:
        description: 'The ARN of the IAM role to assume. e.g. "arn:aws:iam::123456789012:role/my-role"'
        type: string
        required: false
        default: ''
      agentConfigContent:
        description: 'The content of the agent config file. e.g. Yaml read from "./github/agents/agent-config.yaml"'
        type: string
        required: false
        default: ''
      writeableFilepaths:
        description: 'Semicolon-separated list of file paths that can be written by the workflow. e.g. "elaborator-sandbox/SOURCES.md;elaborator-sandbox/library/;engineer-sandbox/features/;engineer-sandbox/source/;engineer-sandbox/tests/;engineer-sandbox/docs/"'
        type: string
        required: false
        default: ''
    secrets:
      PERSONAL_ACCESS_TOKEN:
        required: false
      CHATGPT_API_SECRET_KEY:
        required: true
    outputs:
      featureName:
        value: ${{ jobs.maintain-features.outputs.featureName }}
      featureSpec:
        value: ${{ jobs.maintain-features.outputs.featureSpec }}

jobs:
  maintain-features:
    runs-on: ubuntu-latest

    env:
      feature: ${{ inputs.feature || '' }}
      featuresPath: ${{ inputs.featuresPath || 'features/' }}
      featuresLimit: ${{ inputs.featuresLimit || '3' }}
      allSourcePaths: ${{ inputs.allSourcePaths || '' }}
      allTestsPaths: ${{ inputs.allTestsPaths || '' }}
      documentationPath: ${{ inputs.documentationPath || '' }}
      readmeFilepath: ${{ inputs.readmeFilepath || 'README.md' }}
      missionFilepath: ${{ inputs.missionFilepath || 'MISSION.md' }}
      contributingFilepath: ${{ inputs.contributingFilepath || 'CONTRIBUTING.md' }}
      dependenciesFilepath: ${{ inputs.dependenciesFilepath || 'package.json' }}
      model: ${{ inputs.model || vars.CHATGPT_API_MODEL || 'o4-mini' }}
      npmAuthOrganisation: ${{ inputs.npmAuthOrganisation || '' }}
      gitUserEmail: ${{ inputs.gitUserEmail || 'action@github.com' }}
      gitUserName: ${{ inputs.gitUserName || 'GitHub Actions[bot]' }}
      chatgptApiSecretKey: ${{ secrets.CHATGPT_API_SECRET_KEY }}
      promptFilepath: ${{ inputs.promptFilepath || '.github/agents/agent-maintain-features.md' }}
      s3BucketUrl: ${{ inputs.s3BucketUrl || '' }}
      iamRoleArn: ${{ inputs.iamRoleArn || '' }}
      agentConfigContent: ${{ inputs.agentConfigContent || '' }}
      writeableFilepaths: ${{ inputs.writeableFilepaths || '' }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Check GitHub authentication
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          curl --include --header "Authorization: token ${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" https://api.github.com/user

      - name: Set up .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          echo "${{ env.npmAuthOrganisation }}:registry=https://npm.pkg.github.com" >> .npmrc
          echo "//npm.pkg.github.com/:_authToken=${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" >> .npmrc
          echo "always-auth=true" >> .npmrc

      - run: npm ci

      - name: List current features
        id: features
        shell: bash
        run: |
          output=$(find "${{ env.featuresPath }}" -maxdepth 1 -type f -name '*.md' -print -exec echo "# {}" \; -exec cat {} \; 2>&1 || echo 'none')
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List rejected feature named
        id: rejectedFeatures
        shell: bash
        run: |
          mkdir -p "${{ env.featuresPath }}/rejects"
          output=$(ls -1 "${{ env.featuresPath }}/rejects" | sed 's/\.md//' | xargs echo )
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List dependencies
        id: list
        shell: bash
        run: |
          output=$(npm list 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Tear down .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: rm -f .npmrc

      - name: maintain-features
        id: maintain-features
        uses: actions/github-script@v7
        env:
          currentFeatures: ${{ steps.features.outputs.output }}
          rejectedFeatures: ${{ steps.rejectedFeatures.outputs.output }}
          dependenciesListOutput: ${{ steps.list.outputs.output }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const feature = process.env.feature;
            const featuresPath = process.env.featuresPath;
            const featuresLimit = process.env.featuresLimit;
            const currentFeatures = process.env.currentFeatures;
            const rejectedFeatures = process.env.rejectedFeatures;
            const allSourcePaths = process.env.allSourcePaths;
            const allTestsPaths = process.env.allTestsPaths;
            const documentationPath = process.env.documentationPath;
            const readmeFilepath = process.env.readmeFilepath;
            const missionFilepath = process.env.missionFilepath;
            const contributingFilepath = process.env.contributingFilepath;
            const dependenciesFilepath = process.env.dependenciesFilepath;
            const model = process.env.model;
            const apiKey = process.env.chatgptApiSecretKey;
            const promptFilepath = process.env.promptFilepath;
            const dependenciesListOutput = process.env.dependenciesListOutput;
            const agentConfigContent = process.env.agentConfigContent;
            const writeableFilepaths = process.env.writeableFilepaths;

            const fs = require('fs');
            const path = require('path');
            const OpenAI = require('openai').default;
            const { z } = require('zod');
            require('dotenv').config();

            if (!apiKey) { 
              core.setFailed("Missing CHATGPT_API_SECRET_KEY"); 
            }
            const openai = new OpenAI({ apiKey });

            core.info(`feature: "${feature}"`);
            core.info(`featuresPath: "${featuresPath}"`);
            core.info(`currentFeatures: "${currentFeatures}"`);
            core.info(`allSourcePaths: "${allSourcePaths}"`);
            core.info(`allTestsPaths: "${allTestsPaths}"`);
            core.info(`documentationPath: "${documentationPath}"`);
            core.info(`readmeFilepath: "${readmeFilepath}"`);
            core.info(`missionFilepath: "${missionFilepath}"`);
            core.info(`contributingFilepath: "${contributingFilepath}"`);
            core.info(`dependenciesFilepath: "${dependenciesFilepath}"`);
            core.info(`agentConfigContent: "${agentConfigContent}"`);
            core.info(`writeableFilepaths: "${writeableFilepaths}"`);
            
            function isWriteable(filepath) {
              core.info(`Checking if writing to filepath '${filepath}' is allowed in writeableFilepaths: ${patterns}`);
              const writeableFilepaths = writeableFilepaths.split(';').map(file => file.trim());
              return writeableFilepaths.some(pattern => (
                minimatch(filepath, pattern) || 
                minimatch(filepath, `${pattern}*`) || 
                minimatch(filepath, `${pattern}**`) || 
                minimatch(filepath, `${pattern}/**`)
              ));
            }
            
            // Handle multiple source files
            const srcFiles = allSourcePaths.split(';');
            let sourceFileContents = {};
            for (const file of srcFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        sourceFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Source file '${fullPath}' from directory has been loaded (length ${sourceFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    sourceFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Source file '${trimmedFile}' has been loaded (length ${sourceFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Source file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading source file '${file}': ${e.message}`);
              }
            }

            // Handle multiple test files
            const testFiles = allTestsPaths.split(';');
            let testFileContents = {};
            for (const file of testFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        testFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Test file '${fullPath}' from directory has been loaded (length ${testFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    testFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Test file '${trimmedFile}' has been loaded (length ${testFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Test file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading test file '${file}': ${e.message}`);
              }
            }

            // Handle documents path to file or directory
            let docsFileContents = {};
            try {
              const trimmedFile = documentationPath.trim();
              if (fs.existsSync(trimmedFile)) {
                const stats = fs.statSync(trimmedFile);
                if (stats.isDirectory()) {
                  // If it's a directory, read all files in the directory
                  const files = fs.readdirSync(trimmedFile);
                  for (const subFile of files) {
                    const fullPath = path.join(trimmedFile, subFile);
                    if (fs.statSync(fullPath).isFile()) {
                      docsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                      core.info(`Docs file '${fullPath}' from directory has been loaded (length ${docsFileContents[fullPath].length}).`);
                    }
                  }
                } else {
                  // It's a file, read it directly
                  docsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                  core.info(`Docs file '${trimmedFile}' has been loaded (length ${docsFileContents[trimmedFile].length}).`);
                }
              } else {
                // Create directory if it doesn't exist
                const docsDir = path.dirname(trimmedFile);
                if (!fs.existsSync(docsDir)) {
                  fs.mkdirSync(docsDir, { recursive: true });
                }
                docsFileContents[trimmedFile] = '';
                core.info(`Docs file '${trimmedFile}' does not exist and will be created.`);
              }
            } catch (e) {
              core.warning(`Error reading docs file '${file}': ${e.message}`);
            }

            const readmeFilepathContent = fs.readFileSync(readmeFilepath, 'utf8');
            const missionFilepathContent = fs.readFileSync(missionFilepath, 'utf8');
            const contributingFilepathContent = fs.readFileSync(contributingFilepath, 'utf8');
            const dependenciesFilepathContent = fs.readFileSync(dependenciesFilepath, 'utf8');
            const promptContent = fs.readFileSync(promptFilepath, 'utf8');

            core.info(`Readme file '${readmeFilepath}' has been loaded (length ${readmeFilepathContent.length}).`);
            core.info(`Mission file '${missionFilepath}' has been loaded (length ${missionFilepathContent.length}).`);
            core.info(`Contributing file '${contributingFilepath}' has been loaded (length ${contributingFilepathContent.length}).`);
            core.info(`Dependencies file '${dependenciesFilepath}' has been loaded (length ${dependenciesFilepathContent.length}).`);
            core.info(`Prompt file '${promptFilepath}' has been loaded (length ${promptContent.length}).`);

            // Load library documents
            let libraryDocuments = '';
            try {
              const libraryDocumentsPath = 'library';
              if (fs.existsSync(libraryDocumentsPath)) {
                const libraryFiles = fs.readdirSync(libraryDocumentsPath)
                  .filter(file => file.endsWith('.md'))
                  .map(file => path.join(libraryDocumentsPath, file));

                // Prepare an array to hold all document contents
                const documentContents = [];

                for (const file of libraryFiles) {
                  const fileName = path.basename(file);
                  const content = fs.readFileSync(file, 'utf8');

                  // Extract the Information Dense Extract section if it exists
                  let informationDenseExtract = '';
                  const match = content.match(/## Information Dense Extract\n([\s\S]*?)(?=\n##|$)/);
                  if (match && match[1] && match[1].trim()) {
                    informationDenseExtract = match[1].trim();
                    documentContents.push({ name: fileName, content: informationDenseExtract });
                  } else {
                    // Fallback to the full content if Information Dense Extract is not found or empty
                    documentContents.push({ name: fileName, content });
                  }
                }

                // Sort documents by size (smallest first) to maximize the number of documents we can include
                documentContents.sort((a, b) => a.content.length - b.content.length);

                // Limit the total size to 500,000 characters to avoid token limits in OpenAI models
                const maxTotalSize = 500000;
                let currentSize = 0;
                let includedCount = 0;

                for (const doc of documentContents) {
                  const docSize = doc.content.length + doc.name.length + 5; // +5 for "# " and "\n\n"
                  if (currentSize + docSize <= maxTotalSize) {
                    libraryDocuments += `# ${doc.name}\n${doc.content}\n\n`;
                    currentSize += docSize;
                    includedCount++;
                  } else {
                    // If we can't include the full document, add a note
                    core.info(`Skipping document ${doc.name} (size: ${docSize}) to avoid exceeding token limits.`);
                  }
                }

                core.info(`Loaded ${includedCount} of ${libraryFiles.length} library documents (total size: ${currentSize} characters).`);
              } else {
                core.info('Library directory not found.');
              }
            } catch (e) {
              core.warning(`Error reading library documents: ${e.message}`);
            }

            // generate the feature prompt either by using the supplied feature or by reviewing the current features and full context
            let prompt = feature;
            if (feature === 'house choice') {
              prompt = `Please review the current features in the repository and either;
                * add a new feature to the repository, or
                * extend an existing feature to add a new aspect to it, or
                * update an existing feature to bring it to a high standard matching other features in the repository.
                The feature name should either be a current feature name or be supplied with a feature specification which is distinct from any other feature in the repository.
              `;
            }

            const chatGptPrompt = `
            ${promptContent}
            If there are more than the maximum number of ${featuresLimit} features in the repository, you must merge similar features into a single feature and name the features to be deleted.
            All significant features of the repository should be present in the feature set before new features are added and features can be consolidated to make room below the maximum of ${featuresLimit} features.

            Consider the following when refining your response:
            * Feature prompt details
            * Current feature names and specifications in the repository
            * Rejected feature names
            * Source file content
            * Test file content
            * Documentation file content
            * README file content
            * MISSION file content
            * Contributing file content
            * Dependencies file content
            * Library documents
            * Dependency list

            Feature prompt:
            FEATURE_PROMPT_START
            ${prompt}
            FEATURE_PROMPT_END            

            Current feature names and specifications:
            CURRENT_FEATURES_START
            ${currentFeatures}
            CURRENT_FEATURES_END

            Library documents:
            LIBRARY_DOCUMENTS_START
            ${libraryDocuments}
            LIBRARY_DOCUMENTS_END

            Rejected feature names:
            REJECTED_FEATURES_START
            ${rejectedFeatures}
            REJECTED_FEATURES_END

            Source files:
            SOURCE_FILES_START
            ${Object.entries(sourceFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            SOURCE_FILES_END

            Test files:
            TEST_FILES_START
            ${Object.entries(testFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            TEST_FILES_END

            Documentation files:
            DOCS_FILES_START
            ${Object.entries(docsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            DOCS_FILES_END

            README file: ${readmeFilepath}
            README_FILE_START
            ${readmeFilepathContent}
            README_FILE_END

            MISSION file: ${missionFilepath}
            MISSION_FILE_START
            ${missionFilepathContent}
            MISSION_FILE_END

            Contributing file: ${contributingFilepath}
            CONTRIBUTING_FILE_START
            ${contributingFilepathContent}
            CONTRIBUTING_FILE_END

            Dependencies file: ${dependenciesFilepath}
            DEPENDENCIES_FILE_START
            ${dependenciesFilepathContent}
            DEPENDENCIES_FILE_END

            Dependencies list from command: npm list
            DEPENDENCIES_LIST_START
            ${dependenciesListOutput}
            DEPENDENCIES_LIST_END    

            Agent configuration file: ${agentConfigPath}
            AGENT_CONFIG_FILE_START
            ${agentConfigContent}
            AGENT_CONFIG_FILE_END

            Answer strictly with a JSON object following this schema:
            {
              "featureName": "The feature name as one or two words in SCREAMING_SNAKECASE.",
              "featureSpec": "The feature specification as multiline markdown with a few level 1 headings.",
              "featureNamesToBeDeleted": "The comma separated list of feature names to be deleted or 'none' if no feature is to be deleted."
            }
            Ensure valid JSON.
            `;

            const ResponseSchema = z.object({ featureName: z.string(), featureSpec: z.string(), featureNamesToBeDeleted: z.string() });

            // Define the function schema for function calling
            const tools = [{
              type: "function",
              function: {
                name: "generate_feature",
                description: "Elaborate on the supplied prompt and project files to create the featureName and featureSpec of a repository feature, and the feature names to be deleted. Return an object with featureName (string), featureSpec (string), and featureNamesToBeDeleted (string).",
                parameters: {
                  type: "object",
                  properties: {
                    featureName: { type: "string", description: "The feature name as one or two words in SCREAMING_SNAKECASE." },
                    featureSpec: { type: "string", description: "The feature specification as multiline markdown with a few level 1 headings." },
                    featureNamesToBeDeleted: { type: "string", description: "The comma separated list of feature names to be deleted or 'none' if no feature is to be deleted." }
                  },
                  required: ["featureName", "featureSpec", "featureNamesToBeDeleted"],
                  additionalProperties: false
                },
                strict: true
              }
            }];

            // Call OpenAI using function calling format
            const response = await openai.chat.completions.create({
              model,
              messages: [
                { role: "system", content: "You are maintaining a feature set by providing expert contemporary insight into both the product market and you will perform a detailed analysis of the current state of the repository and current feature set in search of value opportunities and unique selling points. Answer strictly with a JSON object following the provided function schema." },
                { role: "user", content: chatGptPrompt }
              ],
              tools: tools
            });

            let result;
            if (response.choices[0].message.tool_calls && response.choices[0].message.tool_calls.length > 0) {
              try {
                result = JSON.parse(response.choices[0].message.tool_calls[0].function.arguments);
              } catch (e) {
                core.setFailed(`Failed to parse function call arguments: ${e.message}`);
              }
            } else if (response.choices[0].message.content) {
              try {
                result = JSON.parse(response.choices[0].message.content);
              } catch (e) {
                core.setFailed(`Failed to parse response content: ${e.message}`);
              }
            } else {
              core.setFailed("No valid response received from OpenAI.");
            }

            try {
              core.info("raw response start: **********************************************");
              core.info(`raw response (${(result ? result.length : "undefined")} characters): "${result}"`);
              core.info("raw response mid: ================================================");
              core.info(`raw response as JSON: "${JSON.stringify(result)}"`);
              core.info("raw response end: ************************************************");
              const parsed = ResponseSchema.parse(result);
              core.info(`parsed response: "${JSON.stringify(parsed)}"`);
              core.setOutput("featureName", parsed.featureName);
              core.setOutput("featureSpec", parsed.featureSpec);
              core.setOutput("featureNamesToBeDeleted", parsed.featureNamesToBeDeleted);
              core.info(`featureName: "${parsed.featureName}"`);
              core.info(`featureSpec: "${parsed.featureSpec}"`);
              core.info(`featureNamesToBeDeleted: "${parsed.featureNamesToBeDeleted}"`);

              // Save the feature spec to a file using the convention of <featuresPath> plus path SCREAMING_SNAKE_CASE(<feature name>).md
              const featureName = parsed.featureName.replace(/ /g, "_").toUpperCase();
              const featureSpec = parsed.featureSpec;
              const featuresPath = process.env.featuresPath || 'features/';

              const featureFilePath = path.join(featuresPath, `${featureName}.md`);
              try {
                fs.mkdirSync(featuresPath, { recursive: true });
                fs.writeFileSync(featureFilePath, featureSpec);
                core.info(`Feature spec saved to ${featureFilePath}`);
              } catch (e) {
                core.setFailed(`Failed to save feature spec: ${e.message}`);
              }

              const featureFilepathsToBeDeleted = parsed.featureNamesToBeDeleted
                .split(',')
                .map(name => path.join(featuresPath, `${name.trim().replace(/.md^/, "").toUpperCase()}.md`));
              for (const filepath of featureFilepathsToBeDeleted) {
                try {
                  if( fs.existsSync(filepath) ) {
                    core.info(`Deleting feature file: ${filepath}`);
                    fs.unlinkSync(filepath);
                  }
                } catch (e) {
                  core.info(`Could not delete ${filepath}: ${e.message}`);
                }
              }

            } catch (e) {
              core.setFailed(`Failed to parse ChatGPT response: ${e.message}`);
            }

            core.setOutput("response", JSON.stringify(response));
            core.setOutput("usage", JSON.stringify(response.usage));
            core.info(`response: "${JSON.stringify(response)}"`);
            core.info(`usage: "${JSON.stringify(response.usage)}"`);

      - name: Commit changes
        id: commit
        continue-on-error: true
        run: |
          git config --local user.email '${{ env.gitUserEmail }}'
          git config --local user.name '${{ env.gitUserName }}'
          git status -v
          git add -v --all '${{ env.featuresPath }}'
          git commit -m 'Maintain ${{ steps.maintain-features.outputs.featureName }}'
          git status -v
          git pull --ff-only origin ${{ github.ref }}
          git push -v origin ${{ github.ref }}
          git status -v

    outputs:
      featureName: ${{ steps.maintain-features.outputs.featureName }}
      featureSpec: ${{ steps.maintain-features.outputs.featureSpec }}
