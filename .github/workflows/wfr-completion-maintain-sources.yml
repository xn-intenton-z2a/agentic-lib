# .github/workflows/wfr-completion-maintain-sources.yml

#
# agentic-lib
# Copyright (C) 2025 Polycode Limited
#
# This file is part of agentic-lib.
#
# agentic-lib is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License v3.0 (GPL‑3).
# along with this program. If not, see <https://www.gnu.org/licenses/>.
#
# IMPORTANT: Any derived work must include the following attribution:
# "This work is derived from https://github.com/xn-intenton-z2a/agentic-lib"
#

name: ∞ maintain-sources

on:
  workflow_call:
    inputs:
      source:
        description: 'Text to drive the source creation (if "house choice", the repository will be assessed and an action chosen). e.g. "Add a source about agents."'
        type: string
        required: false
        default: 'house choice'
      sourcesFile:
        description: 'The file to create/update the sources in. Can include wildcards for multiple files. e.g. "SOURCES.md" or "SOURCES*.md"'
        type: string
        required: false
        default: 'SOURCES.md'
      sourcesLimit:
        description: 'The maximum number of sources to create. e.g. "3"'
        type: string
        required: false
        default: '32'
      featuresDir:
        description: 'The directory to read the features from. e.g. "features/"'
        type: string
        required: false
        default: 'features/'
      srcPath:
        description: 'The source file(s) to create the issue to change. e.g. "src/lib/main.js" or multiple files separated by semicolons "src/lib/main.js;src/lib/utils.js"'
        type: string
        required: false
        default: 'src/lib/main.js'
      testsPath:
        description: 'The test file(s). e.g. "tests/unit/main.test.js" or multiple files separated by semicolons "tests/unit/main.test.js;tests/unit/utils.test.js"'
        type: string
        required: false
        default: 'tests/unit/main.test.js'
      docsPath:
        description: 'The documentation file(s) to write to. e.g. "docs/USAGE.md" or multiple files separated by semicolons "docs/USAGE.md;docs/API.md"'
        type: string
        required: false
        default: 'docs/USAGE.md'
      readmeFile:
        description: 'The README file. e.g. "README.md"'
        type: string
        required: false
        default: 'README.md'
      missionFile:
        description: 'The MISSION statement file. e.g. "MISSION.md"'
        type: string
        required: false
        default: 'MISSION.md'
      contributingFile:
        description: 'The CONTRIBUTING file. e.g. "CONTRIBUTING.md"'
        type: string
        required: false
        default: 'CONTRIBUTING.md'
      dependenciesFile:
        description: 'The dependencies file. e.g. "package.json"'
        type: string
        required: false
        default: 'package.json'
      model:
        description: 'The OpenAI model to use. e.g. "o3-mini"'
        type: string
        required: false
        default: ${{ vars.CHATGPT_API_MODEL || 'o3-mini' }}
      npmAuthOrganisation:
        description: 'The GitHub organisation to authenticate with for npm. e.g. "xn-intenton-z2a"'
        type: string
        required: false
        default: ''
      gitUserEmail:
        description: 'The email to use for git commits. e.g. "action@github.com"'
        type: string
        required: false
        default: 'action@github.com'
      gitUserName:
        description: 'The name to use for git commits. e.g. "GitHub Actions[bot]"'
        type: string
        required: false
        default: 'GitHub Actions[bot]'
      s3BucketUrl:
        description: 'The S3 bucket URL with prefix to use. e.g. "s3://my-bucket/prefix"'
        type: string
        required: false
        default: ''
      iamRoleArn:
        description: 'The ARN of the IAM role to assume. e.g. "arn:aws:iam::123456789012:role/my-role"'
        type: string
        required: false
        default: ''
      promptFile:
        description: 'The file containing the prompt text. e.g. "AGENT-MAINTAIN-SOURCES.md"'
        type: string
        required: false
        default: 'AGENT-MAINTAIN-SOURCES.md'
    secrets:
      PERSONAL_ACCESS_TOKEN:
        required: false
      CHATGPT_API_SECRET_KEY:
        required: true
    outputs:
      sourcesDirectoryFileContent:
        value: ${{ jobs.maintain-sources.outputs.sourcesDirectoryFileContent }}

jobs:
  maintain-sources:
    runs-on: ubuntu-latest

    env:
      source: ${{ inputs.source || '' }}
      sourcesFile: ${{ inputs.sourcesFile || 'SOURCES.md' }}
      sourcesLimit: ${{ inputs.sourcesLimit || '32' }}
      featuresDir: ${{ inputs.featuresDir || 'features/' }}
      srcPath: ${{ inputs.srcPath || 'src/lib/main.js' }}
      testsPath: ${{ inputs.testsPath || 'tests/unit/main.test.js' }}
      docsPath: ${{ inputs.docsPath || 'docs/USAGE.md' }}
      readmeFile: ${{ inputs.readmeFile || 'README.md' }}
      missionFile: ${{ inputs.missionFile || 'MISSION.md' }}
      contributingFile: ${{ inputs.contributingFile || 'CONTRIBUTING.md' }}
      dependenciesFile: ${{ inputs.dependenciesFile || 'package.json' }}
      model: ${{ inputs.model || vars.CHATGPT_API_MODEL || 'o3-mini' }}
      npmAuthOrganisation: ${{ inputs.npmAuthOrganisation || '' }}
      gitUserEmail: ${{ inputs.gitUserEmail || 'action@github.com' }}
      gitUserName: ${{ inputs.gitUserName || 'GitHub Actions[bot]' }}
      chatgptApiSecretKey: ${{ secrets.CHATGPT_API_SECRET_KEY }}
      promptFile: ${{ inputs.promptFile || 'AGENT-MAINTAIN-SOURCES.md' }}
      s3BucketUrl: ${{ inputs.s3BucketUrl || '' }}
      iamRoleArn: ${{ inputs.iamRoleArn || '' }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Check GitHub authentication
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          curl --include --header "Authorization: token ${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" https://api.github.com/user

      - name: Set up .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: |
          echo "${{ env.npmAuthOrganisation }}:registry=https://npm.pkg.github.com" >> .npmrc
          echo "//npm.pkg.github.com/:_authToken=${{ secrets.PERSONAL_ACCESS_TOKEN || secrets.GITHUB_TOKEN }}" >> .npmrc
          echo "always-auth=true" >> .npmrc

      - run: npm ci

      - name: List current features
        id: features
        shell: bash
        run: |
          output=$(find "${{ env.featuresDir }}" -maxdepth 1 -type f -name '*.md' -print -exec echo "# {}" \; -exec cat {} \; 2>&1 || echo 'none')
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: List dependencies
        id: list
        shell: bash
        run: |
          output=$(npm list 2>&1)
          echo "output<<EOF" >> "$GITHUB_OUTPUT"
          echo "$output" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"
          echo "output=${output}"

      - name: Tear down .npmrc
        if: ${{ env.npmAuthOrganisation != '' }}
        shell: bash
        run: rm -f .npmrc

      - name: Touch or create sources file
        id: touch
        shell: bash
        run: |
          # Check if sourcesFile contains a wildcard
          if [[ "${{ env.sourcesFile }}" == *"*"* ]]; then
            # Get the pattern and create the main file if it doesn't exist
            # For example, if pattern is SOURCES*.md, create SOURCES.md if it doesn't exist
            mainFile=$(echo "${{ env.sourcesFile }}" | sed 's/\*//g')
            if [ ! -f "$mainFile" ]; then
              echo "Creating main sources file ${GITHUB_WORKSPACE}/$mainFile"
              touch "$mainFile"
              ls -lrt "$mainFile"
              cat "$mainFile"
            else
              echo "Touching main sources file ${GITHUB_WORKSPACE}/$mainFile"
              touch "$mainFile"
              ls -lrt "$mainFile"
              cat "$mainFile"
            fi

            # List all files matching the pattern
            echo "Files matching pattern ${{ env.sourcesFile }}:"
            ls -la ${{ env.sourcesFile }} 2>/dev/null || echo "No files found matching ${{ env.sourcesFile }}"
          else
            # Handle single file case
            if [ ! -f "${{ env.sourcesFile }}" ]; then
              echo "Creating sources file ${GITHUB_WORKSPACE}/${{ env.sourcesFile }}"
              touch "${{ env.sourcesFile }}"
              ls -lrt "${{ env.sourcesFile }}"
              cat "${{ env.sourcesFile }}"
            else
              echo "Touching sources file ${GITHUB_WORKSPACE}/${{ env.sourcesFile }}"
              touch "${{ env.sourcesFile }}"
              ls -lrt "${{ env.sourcesFile }}"
              cat "${{ env.sourcesFile }}"
            fi
          fi

      - name: maintain-sources
        id: maintain-sources
        uses: actions/github-script@v7
        env:
          currentFeatures: ${{ steps.features.outputs.output }}
          dependenciesListOutput: ${{ steps.list.outputs.output }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const source = process.env.source;
            const sourcesFile = process.env.sourcesFile;
            const sourcesLimit = process.env.sourcesLimit;
            const currentFeatures = process.env.currentFeatures;
            const srcPath = process.env.srcPath;
            const testsPath = process.env.testsPath;
            const docsPath = process.env.docsPath;
            const readmeFile = process.env.readmeFile;
            const missionFile = process.env.missionFile;
            const contributingFile = process.env.contributingFile;
            const dependenciesFile = process.env.dependenciesFile;
            const model = process.env.model;
            const apiKey = process.env.chatgptApiSecretKey;
            const promptFile = process.env.promptFile;
            const dependenciesListOutput = process.env.dependenciesListOutput;

            const fs = require('fs');
            const path = require('path');
            const OpenAI = require('openai').default;
            const { z } = require('zod');
            require('dotenv').config();

            if (!apiKey) { 
              core.setFailed("Missing CHATGPT_API_SECRET_KEY"); 
            }
            const openai = new OpenAI({ apiKey });

            core.info(`source: "${source}"`);
            core.info(`sourcesFile: "${sourcesFile}"`);
            core.info(`currentFeatures: "${currentFeatures}"`);
            core.info(`srcPath: "${srcPath}"`);
            core.info(`testsPath: "${testsPath}"`);
            core.info(`readmeFile: "${readmeFile}"`);
            core.info(`missionFile: "${missionFile}"`);
            core.info(`contributingFile: "${contributingFile}"`);
            core.info(`dependenciesFile: "${dependenciesFile}"`);

            core.info(`Loading sources directory file(s) '${sourcesFile}'...`);

            let sourcesFileContent = '';

            // If sourcesFile contains a wildcard, find all matching files
            if (sourcesFile.includes('*')) {
              const sourcesPattern = sourcesFile;
              const sourcesDir = path.dirname(sourcesPattern);
              const sourcesBasename = path.basename(sourcesPattern);
              const sourcesRegex = new RegExp('^' + sourcesBasename.replace(/\*/g, '.*') + '$');

              // Get all files in the directory
              const files = fs.readdirSync(sourcesDir || '.');

              // Filter files that match the pattern
              const matchingFiles = files.filter(file => sourcesRegex.test(file))
                .map(file => path.join(sourcesDir || '.', file));

              core.info(`Found ${matchingFiles.length} sources files matching pattern '${sourcesPattern}': ${matchingFiles.join(', ')}`);

              // Read content from all matching files
              for (const file of matchingFiles) {
                try {
                  const content = fs.readFileSync(file, 'utf8');
                  core.info(`Sources file '${file}' has been loaded (length ${content.length}).`);
                  sourcesFileContent += content + '\n\n';
                } catch (e) {
                  core.warning(`Error reading sources file '${file}': ${e.message}`);
                }
              }
            } else {
              // Load a single sources file
              sourcesFileContent = fs.readFileSync(sourcesFile, 'utf8');
              core.info(`Sources directory file '${sourcesFile}' has been loaded (length ${sourcesFileContent.length}).`);
            }

            // Handle multiple source files
            const srcFiles = srcPath.split(';');
            let sourceFileContents = {};
            for (const file of srcFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        sourceFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Source file '${fullPath}' from directory has been loaded (length ${sourceFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    sourceFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Source file '${trimmedFile}' has been loaded (length ${sourceFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Source file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading source file '${file}': ${e.message}`);
              }
            }

            // Handle multiple test files
            const testFiles = testsPath.split(';');
            let testFileContents = {};
            for (const file of testFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        testFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Test file '${fullPath}' from directory has been loaded (length ${testFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    testFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Test file '${trimmedFile}' has been loaded (length ${testFileContents[trimmedFile].length}).`);
                  }
                } else {
                  core.warning(`Test file '${trimmedFile}' does not exist.`);
                }
              } catch (e) {
                core.warning(`Error reading test file '${file}': ${e.message}`);
              }
            }

            // Handle multiple docs files
            const docsFiles = docsPath.split(';');
            let docsFileContents = {};
            for (const file of docsFiles) {
              try {
                const trimmedFile = file.trim();
                if (fs.existsSync(trimmedFile)) {
                  const stats = fs.statSync(trimmedFile);
                  if (stats.isDirectory()) {
                    // If it's a directory, read all files in the directory
                    const files = fs.readdirSync(trimmedFile);
                    for (const subFile of files) {
                      const fullPath = path.join(trimmedFile, subFile);
                      if (fs.statSync(fullPath).isFile()) {
                        docsFileContents[fullPath] = fs.readFileSync(fullPath, 'utf8');
                        core.info(`Docs file '${fullPath}' from directory has been loaded (length ${docsFileContents[fullPath].length}).`);
                      }
                    }
                  } else {
                    // It's a file, read it directly
                    docsFileContents[trimmedFile] = fs.readFileSync(trimmedFile, 'utf8');
                    core.info(`Docs file '${trimmedFile}' has been loaded (length ${docsFileContents[trimmedFile].length}).`);
                  }
                } else {
                  // Create directory if it doesn't exist
                  const docsDir = path.dirname(trimmedFile);
                  if (!fs.existsSync(docsDir)) {
                    fs.mkdirSync(docsDir, { recursive: true });
                  }
                  docsFileContents[trimmedFile] = '';
                  core.info(`Docs file '${trimmedFile}' does not exist and will be created.`);
                }
              } catch (e) {
                core.warning(`Error reading docs file '${file}': ${e.message}`);
              }
            }

            const readmeFileContent = fs.readFileSync(readmeFile, 'utf8');
            const missionFileContent = fs.readFileSync(missionFile, 'utf8');
            const contributingFileContent = fs.readFileSync(contributingFile, 'utf8');
            const dependenciesFileContent = fs.readFileSync(dependenciesFile, 'utf8');
            const promptContent = fs.readFileSync(promptFile, 'utf8');
            core.info(`Readme file '${readmeFile}' has been loaded (length ${readmeFileContent.length}).`);
            core.info(`Dependencies file '${dependenciesFile}' has been loaded (length ${dependenciesFileContent.length}).`);
            core.info(`Prompt file '${promptFile}' has been loaded (length ${promptContent.length}).`);

            // generate the source prompt either by using the supplied source prompt or by reviewing the current sources and full context
            let prompt = source;
            if (source === 'house choice') {
              prompt = `Please review the current sources in the directory and either;
                * add a new source to the repository, or
                * extend an existing source to add a new aspect to it, or
                * update an existing source to bring it to a high standard matching other sources in the repository.
                The source name should either be a current source name or be supplied with a source specification which is distinct from any other feature in the repository.
              `;
            }

            const chatGptPrompt = `
            ${promptContent}
            If there are more than the maximum number of ${sourcesLimit} sources in the repository, you must merge similar sources into a single source.

            Consider the following when refining your response:
            * Source prompt details
            * Current sources file content
            * Current feature names and specifications in the repository
            * Target file content
            * Test file content
            * README file content
            * MISSION file content
            * Contributing file content
            * Dependencies file content
            * Dependency list

            Source prompt:
            SOURCE_PROMPT_START
            ${prompt}
            SOURCE_PROMPT_END            

            Current sources file content:
            SOURCES_FILE_START
            ${sourcesFileContent}
            SOURCES_FILE_END

            Current feature names and specifications:
            CURRENT_FEATURES_START
            ${currentFeatures}
            CURRENT_FEATURES_END

            Source files:
            SOURCE_FILES_START
            ${Object.entries(sourceFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            SOURCE_FILES_END

            Test files:
            TEST_FILES_START
            ${Object.entries(testFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            TEST_FILES_END

            Documentation files:
            DOCS_FILES_START
            ${Object.entries(docsFileContents).map(([file, content]) => `File: ${file}\n${content}\n`).join('\n')}
            DOCS_FILES_END

            README file: ${readmeFile}
            README_FILE_START
            ${readmeFileContent}
            README_FILE_END

            MISSION file: ${missionFile}
            MISSION_FILE_START
            ${missionFileContent}
            MISSION_FILE_END

            Contributing file: ${contributingFile}
            CONTRIBUTING_FILE_START
            ${contributingFileContent}
            CONTRIBUTING_FILE_END

            Dependencies file: ${dependenciesFile}
            DEPENDENCIES_FILE_START
            ${dependenciesFileContent}
            DEPENDENCIES_FILE_END

            Dependencies list from command: npm list
            DEPENDENCIES_LIST_START
            ${dependenciesListOutput}
            DEPENDENCIES_LIST_END    

            Answer strictly with a JSON object following this schema:
            {
              "sourcesDirectoryFileContent": "The source directory should be a multiline markdown with a few level 1 (#) headings a source name preceding level 2 (##) with the url of a document source."
            }
            Ensure valid JSON.
            `;

            const ResponseSchema = z.object({ sourcesDirectoryFileContent: z.string() });

            // Define the function schema for function calling
            const tools = [{
              type: "function",
              function: {
                name: "generate_sources",
                description: "Elaborate on the supplied prompt and project files to create the sourcesDirectoryFileContent of a repository source. Return an object with sourcesDirectoryFileContent (string).",
                parameters: {
                  type: "object",
                  properties: {
                    sourcesDirectoryFileContent: { type: "string", description: "The source directory should be a multiline markdown with a few level 1 (#) headings a source name preceding level 2 (##) with the url of a document source." }
                  },
                  required: ["sourcesDirectoryFileContent"],
                  additionalProperties: false
                },
                strict: true
              }
            }];

            // Call OpenAI using function calling format
            const response = await openai.chat.completions.create({
              model,
              messages: [
                { role: "system", content: "You are maintaining a library of repository context providing expert contemporary insight into both the product market and you will perform a detailed analysis of the current state of the repository and current feature set in search of ideas for find useful information sources. Answer strictly with a JSON object following the provided function schema." },
                { role: "user", content: chatGptPrompt }
              ],
              tools: tools
            });

            let result;
            if (response.choices[0].message.tool_calls && response.choices[0].message.tool_calls.length > 0) {
              try {
                result = JSON.parse(response.choices[0].message.tool_calls[0].function.arguments);
              } catch (e) {
                core.setFailed(`Failed to parse function call arguments: ${e.message}`);
              }
            } else if (response.choices[0].message.content) {
              try {
                result = JSON.parse(response.choices[0].message.content);
              } catch (e) {
                core.setFailed(`Failed to parse response content: ${e.message}`);
              }
            } else {
              core.setFailed("No valid response received from OpenAI.");
            }

            try {
              const parsed = ResponseSchema.parse(result);
              core.info(`parsed response: "${JSON.stringify(parsed)}"`);
              core.setOutput("sourcesDirectoryFileContent", parsed.sourcesDirectoryFileContent);
              core.info(`sourcesDirectoryFileContent: "${parsed.sourcesDirectoryFileContent}"`);

              const sourcesDirectoryFileContent = parsed.sourcesDirectoryFileContent;
              let sourcesDirectoryFilePath = process.env.sourcesFile || 'SOURCES.md';

              // If sourcesFile contains a wildcard, write to the main file (with the wildcard removed)
              if (sourcesDirectoryFilePath.includes('*')) {
                sourcesDirectoryFilePath = sourcesDirectoryFilePath.replace(/\*/g, '');
                core.info(`Writing to main sources file: ${sourcesDirectoryFilePath}`);
              }

              try {
                fs.writeFileSync(sourcesDirectoryFilePath, sourcesDirectoryFileContent);
                core.info(`source directory saved to ${sourcesDirectoryFilePath}`);
              } catch (e) {
                core.setFailed(`Failed to save source directory: ${e.message}`);
              }

            } catch (e) {
              core.setFailed(`Failed to parse ChatGPT response: ${e.message}`);
            }

            core.setOutput("response", JSON.stringify(response));
            core.setOutput("usage", JSON.stringify(response.usage));
            core.info(`response: "${JSON.stringify(response)}"`);
            core.info(`usage: "${JSON.stringify(response.usage)}"`);

      - name: Commit changes
        id: commit
        continue-on-error: true
        run: |
          git config --local user.email '${{ env.gitUserEmail }}'
          git config --local user.name '${{ env.gitUserName }}'
          git status -v

          # If sourcesFile contains a wildcard, add all matching files
          if [[ "${{ env.sourcesFile }}" == *"*"* ]]; then
            echo "Adding all files matching pattern ${{ env.sourcesFile }}"
            git add -v --all ${{ env.sourcesFile }}
            # Also add the main file (with the wildcard removed)
            mainFile=$(echo "${{ env.sourcesFile }}" | sed 's/\*//g')
            git add -v --all "$mainFile"
            git commit -m "Maintain sources files matching ${{ env.sourcesFile }}"
          else
            # Add the specific file
            git add -v --all '${{ env.sourcesFile }}'
            git commit -m "Maintain ${{ env.sourcesFile }}"
          fi

          git status -v
          git pull --ff-only origin ${{ github.ref }}
          git push -v origin ${{ github.ref }}
          git status -v
